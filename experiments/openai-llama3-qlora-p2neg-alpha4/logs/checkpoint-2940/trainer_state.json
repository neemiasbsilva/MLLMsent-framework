{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 2940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12755102040816327,
      "grad_norm": 0.36498671770095825,
      "learning_rate": 5.6179775280898885e-05,
      "loss": 2.3836,
      "step": 25
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 0.2671872675418854,
      "learning_rate": 0.00011235955056179777,
      "loss": 2.0585,
      "step": 50
    },
    {
      "epoch": 0.3826530612244898,
      "grad_norm": 0.3193589150905609,
      "learning_rate": 0.00016853932584269662,
      "loss": 1.6525,
      "step": 75
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.6635311245918274,
      "learning_rate": 0.00019999265392482905,
      "loss": 1.4768,
      "step": 100
    },
    {
      "epoch": 0.6377551020408163,
      "grad_norm": 0.29466143250465393,
      "learning_rate": 0.0001999213274253263,
      "loss": 1.457,
      "step": 125
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 0.3543296754360199,
      "learning_rate": 0.00019977417529060088,
      "loss": 1.4073,
      "step": 150
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.31976887583732605,
      "learning_rate": 0.0001995513091875449,
      "loss": 1.4124,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4161206483840942,
      "eval_runtime": 170.7977,
      "eval_samples_per_second": 4.584,
      "eval_steps_per_second": 4.584,
      "step": 196
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.29756489396095276,
      "learning_rate": 0.00019925289823884994,
      "loss": 1.3799,
      "step": 200
    },
    {
      "epoch": 1.1479591836734695,
      "grad_norm": 0.37399864196777344,
      "learning_rate": 0.00019887916889466752,
      "loss": 1.3921,
      "step": 225
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 0.35711920261383057,
      "learning_rate": 0.00019843040476076685,
      "loss": 1.3563,
      "step": 250
    },
    {
      "epoch": 1.403061224489796,
      "grad_norm": 0.284077912569046,
      "learning_rate": 0.00019790694638331956,
      "loss": 1.3681,
      "step": 275
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 0.2888699769973755,
      "learning_rate": 0.0001973091909904751,
      "loss": 1.3657,
      "step": 300
    },
    {
      "epoch": 1.6581632653061225,
      "grad_norm": 0.32466110587120056,
      "learning_rate": 0.00019663759219092279,
      "loss": 1.3594,
      "step": 325
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.2985018789768219,
      "learning_rate": 0.00019589265962966938,
      "loss": 1.3543,
      "step": 350
    },
    {
      "epoch": 1.913265306122449,
      "grad_norm": 0.27381208539009094,
      "learning_rate": 0.00019507495860129326,
      "loss": 1.338,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3790345191955566,
      "eval_runtime": 170.9584,
      "eval_samples_per_second": 4.58,
      "eval_steps_per_second": 4.58,
      "step": 392
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.2895233631134033,
      "learning_rate": 0.00019418510962096862,
      "loss": 1.3375,
      "step": 400
    },
    {
      "epoch": 2.1683673469387754,
      "grad_norm": 0.3089270293712616,
      "learning_rate": 0.00019322378795358564,
      "loss": 1.3204,
      "step": 425
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 0.35057491064071655,
      "learning_rate": 0.00019219172310132326,
      "loss": 1.3306,
      "step": 450
    },
    {
      "epoch": 2.423469387755102,
      "grad_norm": 0.3091978132724762,
      "learning_rate": 0.00019108969825006419,
      "loss": 1.3045,
      "step": 475
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.31460660696029663,
      "learning_rate": 0.00018991854967507138,
      "loss": 1.3373,
      "step": 500
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.28022363781929016,
      "learning_rate": 0.00018867916610637808,
      "loss": 1.2911,
      "step": 525
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 0.3173779845237732,
      "learning_rate": 0.0001873724880543718,
      "loss": 1.3239,
      "step": 550
    },
    {
      "epoch": 2.933673469387755,
      "grad_norm": 0.32326531410217285,
      "learning_rate": 0.00018599950709608505,
      "loss": 1.3024,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.359616994857788,
      "eval_runtime": 170.6864,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 588
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 0.284433513879776,
      "learning_rate": 0.0001845612651227335,
      "loss": 1.3115,
      "step": 600
    },
    {
      "epoch": 3.188775510204082,
      "grad_norm": 0.318491667509079,
      "learning_rate": 0.0001830588535490736,
      "loss": 1.2674,
      "step": 625
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 0.3426763713359833,
      "learning_rate": 0.00018149341248517868,
      "loss": 1.3021,
      "step": 650
    },
    {
      "epoch": 3.443877551020408,
      "grad_norm": 0.3193589746952057,
      "learning_rate": 0.00017986612987126263,
      "loss": 1.2613,
      "step": 675
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.33063679933547974,
      "learning_rate": 0.00017817824057620745,
      "loss": 1.2969,
      "step": 700
    },
    {
      "epoch": 3.6989795918367347,
      "grad_norm": 0.32294297218322754,
      "learning_rate": 0.0001764310254604789,
      "loss": 1.2499,
      "step": 725
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 0.3036240339279175,
      "learning_rate": 0.00017462581040414118,
      "loss": 1.3065,
      "step": 750
    },
    {
      "epoch": 3.954081632653061,
      "grad_norm": 0.3765612244606018,
      "learning_rate": 0.00017276396530070836,
      "loss": 1.2523,
      "step": 775
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3557498455047607,
      "eval_runtime": 170.5253,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 784
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.3353302776813507,
      "learning_rate": 0.00017084690301759613,
      "loss": 1.2763,
      "step": 800
    },
    {
      "epoch": 4.209183673469388,
      "grad_norm": 0.34941425919532776,
      "learning_rate": 0.00016887607832396273,
      "loss": 1.214,
      "step": 825
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 0.34200042486190796,
      "learning_rate": 0.00016685298678675213,
      "loss": 1.2732,
      "step": 850
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.35260090231895447,
      "learning_rate": 0.00016477916363577845,
      "loss": 1.2276,
      "step": 875
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 0.33618080615997314,
      "learning_rate": 0.0001626561825987114,
      "loss": 1.275,
      "step": 900
    },
    {
      "epoch": 4.719387755102041,
      "grad_norm": 0.3591514229774475,
      "learning_rate": 0.00016048565470684772,
      "loss": 1.2074,
      "step": 925
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 0.3384716808795929,
      "learning_rate": 0.00015826922707257488,
      "loss": 1.2807,
      "step": 950
    },
    {
      "epoch": 4.974489795918368,
      "grad_norm": 0.39626920223236084,
      "learning_rate": 0.0001560085816394541,
      "loss": 1.2061,
      "step": 975
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3476126194000244,
      "eval_runtime": 170.5351,
      "eval_samples_per_second": 4.591,
      "eval_steps_per_second": 4.591,
      "step": 980
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 0.3627210855484009,
      "learning_rate": 0.00015370543390587192,
      "loss": 1.2616,
      "step": 1000
    },
    {
      "epoch": 5.229591836734694,
      "grad_norm": 0.3969779312610626,
      "learning_rate": 0.00015136153162322852,
      "loss": 1.1615,
      "step": 1025
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.39151668548583984,
      "learning_rate": 0.00014897865346965054,
      "loss": 1.2483,
      "step": 1050
    },
    {
      "epoch": 5.48469387755102,
      "grad_norm": 0.43242645263671875,
      "learning_rate": 0.00014655860770023535,
      "loss": 1.1672,
      "step": 1075
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 0.35275575518608093,
      "learning_rate": 0.00014410323077485056,
      "loss": 1.2624,
      "step": 1100
    },
    {
      "epoch": 5.739795918367347,
      "grad_norm": 0.3332563042640686,
      "learning_rate": 0.0001416143859645303,
      "loss": 1.1726,
      "step": 1125
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 0.346998006105423,
      "learning_rate": 0.00013909396193752556,
      "loss": 1.2684,
      "step": 1150
    },
    {
      "epoch": 5.994897959183674,
      "grad_norm": 0.4060249924659729,
      "learning_rate": 0.0001365438713260822,
      "loss": 1.1722,
      "step": 1175
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3485087156295776,
      "eval_runtime": 170.6094,
      "eval_samples_per_second": 4.589,
      "eval_steps_per_second": 4.589,
      "step": 1176
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 0.38493940234184265,
      "learning_rate": 0.00013396604927503337,
      "loss": 1.2281,
      "step": 1200
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.32128095626831055,
      "learning_rate": 0.00013136245197330836,
      "loss": 1.1198,
      "step": 1225
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 0.3982372581958771,
      "learning_rate": 0.0001287350551694721,
      "loss": 1.2496,
      "step": 1250
    },
    {
      "epoch": 6.505102040816326,
      "grad_norm": 0.40993720293045044,
      "learning_rate": 0.00012608585267242175,
      "loss": 1.1401,
      "step": 1275
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 0.39181017875671387,
      "learning_rate": 0.00012341685483837798,
      "loss": 1.2203,
      "step": 1300
    },
    {
      "epoch": 6.760204081632653,
      "grad_norm": 0.45590391755104065,
      "learning_rate": 0.0001207300870453196,
      "loss": 1.1657,
      "step": 1325
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 0.3715928792953491,
      "learning_rate": 0.00011802758815601844,
      "loss": 1.1972,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3585968017578125,
      "eval_runtime": 171.1921,
      "eval_samples_per_second": 4.574,
      "eval_steps_per_second": 4.574,
      "step": 1372
    },
    {
      "epoch": 7.01530612244898,
      "grad_norm": 0.3597106337547302,
      "learning_rate": 0.00011531140897084166,
      "loss": 1.1553,
      "step": 1375
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.39704200625419617,
      "learning_rate": 0.00011258361067149494,
      "loss": 1.1859,
      "step": 1400
    },
    {
      "epoch": 7.270408163265306,
      "grad_norm": 0.4553108215332031,
      "learning_rate": 0.00010984626325688778,
      "loss": 1.1361,
      "step": 1425
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 0.402067095041275,
      "learning_rate": 0.0001071014439723079,
      "loss": 1.1883,
      "step": 1450
    },
    {
      "epoch": 7.525510204081632,
      "grad_norm": 0.4136655926704407,
      "learning_rate": 0.00010435123573309669,
      "loss": 1.1354,
      "step": 1475
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 0.4047906994819641,
      "learning_rate": 0.00010159772554402183,
      "loss": 1.177,
      "step": 1500
    },
    {
      "epoch": 7.780612244897959,
      "grad_norm": 0.3915495276451111,
      "learning_rate": 9.884300291554685e-05,
      "loss": 1.1534,
      "step": 1525
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 0.4219297468662262,
      "learning_rate": 9.608915827819884e-05,
      "loss": 1.1551,
      "step": 1550
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3633811473846436,
      "eval_runtime": 170.5399,
      "eval_samples_per_second": 4.591,
      "eval_steps_per_second": 4.591,
      "step": 1568
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.3711285889148712,
      "learning_rate": 9.333828139623851e-05,
      "loss": 1.1391,
      "step": 1575
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.4232412576675415,
      "learning_rate": 9.059245978183544e-05,
      "loss": 1.1358,
      "step": 1600
    },
    {
      "epoch": 8.290816326530612,
      "grad_norm": 0.43001145124435425,
      "learning_rate": 8.785377711095224e-05,
      "loss": 1.1233,
      "step": 1625
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 0.4321264326572418,
      "learning_rate": 8.51243116421404e-05,
      "loss": 1.1336,
      "step": 1650
    },
    {
      "epoch": 8.545918367346939,
      "grad_norm": 0.4089178144931793,
      "learning_rate": 8.240613463944659e-05,
      "loss": 1.1335,
      "step": 1675
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 0.42496058344841003,
      "learning_rate": 7.9701308800627e-05,
      "loss": 1.1298,
      "step": 1700
    },
    {
      "epoch": 8.801020408163264,
      "grad_norm": 0.405394583940506,
      "learning_rate": 7.701188669186231e-05,
      "loss": 1.1503,
      "step": 1725
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.4559169411659241,
      "learning_rate": 7.433990919016067e-05,
      "loss": 1.1164,
      "step": 1750
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3674930334091187,
      "eval_runtime": 170.5809,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 1764
    },
    {
      "epoch": 9.056122448979592,
      "grad_norm": 0.3974441885948181,
      "learning_rate": 7.168740393463173e-05,
      "loss": 1.1347,
      "step": 1775
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 0.46557995676994324,
      "learning_rate": 6.905638378780558e-05,
      "loss": 1.1101,
      "step": 1800
    },
    {
      "epoch": 9.311224489795919,
      "grad_norm": 0.41402217745780945,
      "learning_rate": 6.644884530816531e-05,
      "loss": 1.1229,
      "step": 1825
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 0.45335009694099426,
      "learning_rate": 6.386676723505208e-05,
      "loss": 1.0927,
      "step": 1850
    },
    {
      "epoch": 9.566326530612244,
      "grad_norm": 0.4355914890766144,
      "learning_rate": 6.13121089870917e-05,
      "loss": 1.125,
      "step": 1875
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 0.4774288535118103,
      "learning_rate": 5.878680917528374e-05,
      "loss": 1.0953,
      "step": 1900
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.41066497564315796,
      "learning_rate": 5.629278413187965e-05,
      "loss": 1.1289,
      "step": 1925
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 0.4816204309463501,
      "learning_rate": 5.3831926456167825e-05,
      "loss": 1.0824,
      "step": 1950
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3742494583129883,
      "eval_runtime": 170.5297,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 1960
    },
    {
      "epoch": 10.076530612244898,
      "grad_norm": 0.44019952416419983,
      "learning_rate": 5.1406103578268184e-05,
      "loss": 1.1196,
      "step": 1975
    },
    {
      "epoch": 10.204081632653061,
      "grad_norm": 0.4912806749343872,
      "learning_rate": 4.901715634202644e-05,
      "loss": 1.0604,
      "step": 2000
    },
    {
      "epoch": 10.331632653061224,
      "grad_norm": 0.4101540446281433,
      "learning_rate": 4.666689760808384e-05,
      "loss": 1.1247,
      "step": 2025
    },
    {
      "epoch": 10.459183673469388,
      "grad_norm": 0.50461345911026,
      "learning_rate": 4.4357110878181415e-05,
      "loss": 1.0637,
      "step": 2050
    },
    {
      "epoch": 10.58673469387755,
      "grad_norm": 0.44034072756767273,
      "learning_rate": 4.2089548941744026e-05,
      "loss": 1.1163,
      "step": 2075
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.5322896838188171,
      "learning_rate": 3.986593254577e-05,
      "loss": 1.0718,
      "step": 2100
    },
    {
      "epoch": 10.841836734693878,
      "grad_norm": 0.46443259716033936,
      "learning_rate": 3.7687949089036576e-05,
      "loss": 1.1377,
      "step": 2125
    },
    {
      "epoch": 10.96938775510204,
      "grad_norm": 0.5525733232498169,
      "learning_rate": 3.555725134161165e-05,
      "loss": 1.0405,
      "step": 2150
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3819340467453003,
      "eval_runtime": 170.588,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 2156
    },
    {
      "epoch": 11.096938775510203,
      "grad_norm": 0.43625879287719727,
      "learning_rate": 3.347545619064357e-05,
      "loss": 1.1287,
      "step": 2175
    },
    {
      "epoch": 11.224489795918368,
      "grad_norm": 0.5377660393714905,
      "learning_rate": 3.144414341338108e-05,
      "loss": 1.0446,
      "step": 2200
    },
    {
      "epoch": 11.35204081632653,
      "grad_norm": 0.48543643951416016,
      "learning_rate": 2.9464854478353875e-05,
      "loss": 1.1178,
      "step": 2225
    },
    {
      "epoch": 11.479591836734693,
      "grad_norm": 0.5528655648231506,
      "learning_rate": 2.753909137562405e-05,
      "loss": 1.0295,
      "step": 2250
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.46596887707710266,
      "learning_rate": 2.5668315476995997e-05,
      "loss": 1.1295,
      "step": 2275
    },
    {
      "epoch": 11.73469387755102,
      "grad_norm": 0.658424437046051,
      "learning_rate": 2.3853946427049344e-05,
      "loss": 1.0176,
      "step": 2300
    },
    {
      "epoch": 11.862244897959183,
      "grad_norm": 0.4694329500198364,
      "learning_rate": 2.209736106583703e-05,
      "loss": 1.1336,
      "step": 2325
    },
    {
      "epoch": 11.989795918367347,
      "grad_norm": 0.5186434388160706,
      "learning_rate": 2.0399892384065578e-05,
      "loss": 1.0334,
      "step": 2350
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3846627473831177,
      "eval_runtime": 170.6163,
      "eval_samples_per_second": 4.589,
      "eval_steps_per_second": 4.589,
      "step": 2352
    },
    {
      "epoch": 12.11734693877551,
      "grad_norm": 0.4786224961280823,
      "learning_rate": 1.8762828511550457e-05,
      "loss": 1.1118,
      "step": 2375
    },
    {
      "epoch": 12.244897959183673,
      "grad_norm": 0.5971624255180359,
      "learning_rate": 1.718741173971471e-05,
      "loss": 1.0101,
      "step": 2400
    },
    {
      "epoch": 12.372448979591837,
      "grad_norm": 0.4772433638572693,
      "learning_rate": 1.5674837578871693e-05,
      "loss": 1.1256,
      "step": 2425
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.4401542544364929,
      "learning_rate": 1.422625385100822e-05,
      "loss": 1.0295,
      "step": 2450
    },
    {
      "epoch": 12.627551020408163,
      "grad_norm": 0.4953364133834839,
      "learning_rate": 1.28427598187559e-05,
      "loss": 1.118,
      "step": 2475
    },
    {
      "epoch": 12.755102040816327,
      "grad_norm": 0.44908347725868225,
      "learning_rate": 1.152540535121196e-05,
      "loss": 1.0325,
      "step": 2500
    },
    {
      "epoch": 12.88265306122449,
      "grad_norm": 0.48004332184791565,
      "learning_rate": 1.0275190127242696e-05,
      "loss": 1.0992,
      "step": 2525
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.386728048324585,
      "eval_runtime": 170.6003,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 2548
    },
    {
      "epoch": 13.010204081632653,
      "grad_norm": 0.41148611903190613,
      "learning_rate": 9.093062876873625e-06,
      "loss": 1.0233,
      "step": 2550
    },
    {
      "epoch": 13.137755102040817,
      "grad_norm": 0.510703980922699,
      "learning_rate": 7.979920661342677e-06,
      "loss": 1.1057,
      "step": 2575
    },
    {
      "epoch": 13.26530612244898,
      "grad_norm": 0.46419647336006165,
      "learning_rate": 6.936608192362182e-06,
      "loss": 1.0189,
      "step": 2600
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.5074481964111328,
      "learning_rate": 5.963917191106494e-06,
      "loss": 1.0926,
      "step": 2625
    },
    {
      "epoch": 13.520408163265307,
      "grad_norm": 0.4800851345062256,
      "learning_rate": 5.062585787411833e-06,
      "loss": 1.0533,
      "step": 2650
    },
    {
      "epoch": 13.64795918367347,
      "grad_norm": 0.48605942726135254,
      "learning_rate": 4.233297959643912e-06,
      "loss": 1.0735,
      "step": 2675
    },
    {
      "epoch": 13.775510204081632,
      "grad_norm": 0.48007652163505554,
      "learning_rate": 3.476683015658644e-06,
      "loss": 1.0462,
      "step": 2700
    },
    {
      "epoch": 13.903061224489797,
      "grad_norm": 0.5130314826965332,
      "learning_rate": 2.793315115249806e-06,
      "loss": 1.0813,
      "step": 2725
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3854063749313354,
      "eval_runtime": 170.6103,
      "eval_samples_per_second": 4.589,
      "eval_steps_per_second": 4.589,
      "step": 2744
    },
    {
      "epoch": 14.03061224489796,
      "grad_norm": 0.4651342034339905,
      "learning_rate": 2.1837128344458723e-06,
      "loss": 1.0472,
      "step": 2750
    },
    {
      "epoch": 14.158163265306122,
      "grad_norm": 0.5134216547012329,
      "learning_rate": 1.648338771986957e-06,
      "loss": 1.079,
      "step": 2775
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.4879717528820038,
      "learning_rate": 1.1875991982801093e-06,
      "loss": 1.0476,
      "step": 2800
    },
    {
      "epoch": 14.41326530612245,
      "grad_norm": 0.5104451179504395,
      "learning_rate": 8.018437470997176e-07,
      "loss": 1.0686,
      "step": 2825
    },
    {
      "epoch": 14.540816326530612,
      "grad_norm": 0.4740457832813263,
      "learning_rate": 4.913651502667094e-07,
      "loss": 1.0586,
      "step": 2850
    },
    {
      "epoch": 14.668367346938776,
      "grad_norm": 0.5112971663475037,
      "learning_rate": 2.5639901550801317e-07,
      "loss": 1.0455,
      "step": 2875
    },
    {
      "epoch": 14.795918367346939,
      "grad_norm": 0.48110127449035645,
      "learning_rate": 9.712364766489845e-08,
      "loss": 1.0689,
      "step": 2900
    },
    {
      "epoch": 14.923469387755102,
      "grad_norm": 0.5438941717147827,
      "learning_rate": 1.36599133856663e-08,
      "loss": 1.0533,
      "step": 2925
    }
  ],
  "logging_steps": 25,
  "max_steps": 2940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.3071158701449216e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
