{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.534531831741333,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.389,
      "step": 25
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2573893070220947,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.6295,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.49455156922340393,
      "learning_rate": 0.0001,
      "loss": 0.7747,
      "step": 75
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7489708065986633,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.2175,
      "step": 100
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.620337963104248,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.5951,
      "step": 125
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.718513011932373,
      "learning_rate": 0.0002,
      "loss": 0.987,
      "step": 150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42332327365875244,
      "learning_rate": 0.00019998688836656323,
      "loss": 0.6515,
      "step": 175
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.670487105846405,
      "learning_rate": 0.00019994755690455152,
      "loss": 0.9569,
      "step": 200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3465300500392914,
      "learning_rate": 0.0001998820159279591,
      "loss": 0.5371,
      "step": 225
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5791872143745422,
      "learning_rate": 0.00019979028262377118,
      "loss": 0.9304,
      "step": 250
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3529348373413086,
      "learning_rate": 0.00019967238104745696,
      "loss": 0.6046,
      "step": 275
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5512814521789551,
      "learning_rate": 0.0001995283421166614,
      "loss": 0.9133,
      "step": 300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3690049350261688,
      "learning_rate": 0.00019935820360309777,
      "loss": 0.5866,
      "step": 325
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6199203729629517,
      "learning_rate": 0.00019916201012264254,
      "loss": 0.9177,
      "step": 350
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3577328026294708,
      "learning_rate": 0.00019893981312363562,
      "loss": 0.5816,
      "step": 375
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.727541983127594,
      "learning_rate": 0.00019869167087338907,
      "loss": 0.8913,
      "step": 400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.32127055525779724,
      "learning_rate": 0.00019841764844290744,
      "loss": 0.4815,
      "step": 425
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.521787703037262,
      "learning_rate": 0.0001981178176898239,
      "loss": 0.9111,
      "step": 450
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3414452075958252,
      "learning_rate": 0.00019779225723955707,
      "loss": 0.552,
      "step": 475
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4119994342327118,
      "learning_rate": 0.00019744105246469263,
      "loss": 0.8741,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8157805800437927,
      "eval_runtime": 218.5605,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 500
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.3009911775588989,
      "learning_rate": 0.00019706429546259593,
      "loss": 0.5125,
      "step": 525
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5835811495780945,
      "learning_rate": 0.00019666208503126112,
      "loss": 0.8802,
      "step": 550
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.3277309834957123,
      "learning_rate": 0.00019623452664340306,
      "loss": 0.5808,
      "step": 575
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5222446918487549,
      "learning_rate": 0.00019578173241879872,
      "loss": 0.8487,
      "step": 600
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.31526461243629456,
      "learning_rate": 0.0001953038210948861,
      "loss": 0.5513,
      "step": 625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.3913657069206238,
      "learning_rate": 0.00019480091799562704,
      "loss": 0.8798,
      "step": 650
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.31253665685653687,
      "learning_rate": 0.00019427315499864344,
      "loss": 0.5465,
      "step": 675
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5578293204307556,
      "learning_rate": 0.00019372067050063438,
      "loss": 0.8464,
      "step": 700
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.3264358937740326,
      "learning_rate": 0.00019314360938108425,
      "loss": 0.5126,
      "step": 725
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5105932354927063,
      "learning_rate": 0.00019254212296427044,
      "loss": 0.859,
      "step": 750
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.33064329624176025,
      "learning_rate": 0.00019191636897958122,
      "loss": 0.5745,
      "step": 775
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.43514013290405273,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8502,
      "step": 800
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.31569844484329224,
      "learning_rate": 0.0001905927209998447,
      "loss": 0.5388,
      "step": 825
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.486056387424469,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.8476,
      "step": 850
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.3110043704509735,
      "learning_rate": 0.00018917405376582145,
      "loss": 0.5311,
      "step": 875
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.44915711879730225,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.8201,
      "step": 900
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.309505432844162,
      "learning_rate": 0.0001876618552635348,
      "loss": 0.467,
      "step": 925
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.416510671377182,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.8749,
      "step": 950
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.3507195711135864,
      "learning_rate": 0.00018605771158039253,
      "loss": 0.5258,
      "step": 975
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4092550277709961,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.8546,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7219033241271973,
      "eval_runtime": 218.5757,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 1000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.3202497065067291,
      "learning_rate": 0.00018436330524160047,
      "loss": 0.5024,
      "step": 1025
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.49557021260261536,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.7953,
      "step": 1050
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.3488471806049347,
      "learning_rate": 0.00018258041344542566,
      "loss": 0.4758,
      "step": 1075
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.44271352887153625,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.8096,
      "step": 1100
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3591049313545227,
      "learning_rate": 0.00018071090619916093,
      "loss": 0.5022,
      "step": 1125
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.5113486051559448,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.7788,
      "step": 1150
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.32645827531814575,
      "learning_rate": 0.00017875674435774547,
      "loss": 0.5583,
      "step": 1175
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.43638190627098083,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.8089,
      "step": 1200
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3514382243156433,
      "learning_rate": 0.00017671997756709863,
      "loss": 0.4452,
      "step": 1225
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.43813279271125793,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.8241,
      "step": 1250
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3397935628890991,
      "learning_rate": 0.0001746027421143246,
      "loss": 0.5424,
      "step": 1275
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5010918974876404,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.7947,
      "step": 1300
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.33676138520240784,
      "learning_rate": 0.00017240725868704218,
      "loss": 0.4913,
      "step": 1325
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.46916505694389343,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.7863,
      "step": 1350
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.3408016860485077,
      "learning_rate": 0.00017013583004418993,
      "loss": 0.5281,
      "step": 1375
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.4770265519618988,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.7791,
      "step": 1400
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.3591264486312866,
      "learning_rate": 0.00016779083860075033,
      "loss": 0.5009,
      "step": 1425
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5424772500991821,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.8073,
      "step": 1450
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.35865670442581177,
      "learning_rate": 0.00016537474392892528,
      "loss": 0.4487,
      "step": 1475
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.4063018560409546,
      "learning_rate": 0.000164140821963114,
      "loss": 0.7844,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7107596397399902,
      "eval_runtime": 218.4259,
      "eval_samples_per_second": 4.578,
      "eval_steps_per_second": 4.578,
      "step": 1500
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.361031711101532,
      "learning_rate": 0.00016289008017838445,
      "loss": 0.4508,
      "step": 1525
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.4766595661640167,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.7509,
      "step": 1550
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.3877277970314026,
      "learning_rate": 0.00016033945341829248,
      "loss": 0.4541,
      "step": 1575
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.5085638165473938,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.752,
      "step": 1600
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.35937848687171936,
      "learning_rate": 0.00015772553890390197,
      "loss": 0.4667,
      "step": 1625
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.5448082089424133,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.7178,
      "step": 1650
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.40372538566589355,
      "learning_rate": 0.00015505107827058036,
      "loss": 0.4742,
      "step": 1675
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.5316929817199707,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.7578,
      "step": 1700
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.43462085723876953,
      "learning_rate": 0.000152318876658213,
      "loss": 0.4712,
      "step": 1725
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.47578322887420654,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.7336,
      "step": 1750
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.4265582263469696,
      "learning_rate": 0.00014953179976899878,
      "loss": 0.5071,
      "step": 1775
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.4349457323551178,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.7226,
      "step": 1800
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.4124011695384979,
      "learning_rate": 0.00014669277086172406,
      "loss": 0.4723,
      "step": 1825
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.4409661591053009,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.7409,
      "step": 1850
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.3919650912284851,
      "learning_rate": 0.00014380476768566824,
      "loss": 0.5038,
      "step": 1875
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.5469326972961426,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.7399,
      "step": 1900
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.42893916368484497,
      "learning_rate": 0.00014087081935735564,
      "loss": 0.4814,
      "step": 1925
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.443624347448349,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.738,
      "step": 1950
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.4138941168785095,
      "learning_rate": 0.00013789400318343068,
      "loss": 0.4251,
      "step": 1975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.49295568466186523,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.7415,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6961408853530884,
      "eval_runtime": 218.459,
      "eval_samples_per_second": 4.578,
      "eval_steps_per_second": 4.578,
      "step": 2000
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.3856264054775238,
      "learning_rate": 0.00013487744143298822,
      "loss": 0.4858,
      "step": 2025
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.48630011081695557,
      "learning_rate": 0.00013335524316508208,
      "loss": 0.6875,
      "step": 2050
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.44423046708106995,
      "learning_rate": 0.0001318242980627444,
      "loss": 0.3798,
      "step": 2075
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.5066887736320496,
      "learning_rate": 0.00013028500758979506,
      "loss": 0.6879,
      "step": 2100
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.4280601143836975,
      "learning_rate": 0.00012873777539848283,
      "loss": 0.4787,
      "step": 2125
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.5239988565444946,
      "learning_rate": 0.0001271830072236343,
      "loss": 0.6777,
      "step": 2150
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.4489426910877228,
      "learning_rate": 0.00012562111077625722,
      "loss": 0.4412,
      "step": 2175
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.5505057573318481,
      "learning_rate": 0.00012405249563662537,
      "loss": 0.6951,
      "step": 2200
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.4722651541233063,
      "learning_rate": 0.00012247757314687297,
      "loss": 0.4446,
      "step": 2225
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.4606814980506897,
      "learning_rate": 0.00012089675630312754,
      "loss": 0.6757,
      "step": 2250
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.4529043436050415,
      "learning_rate": 0.00011931045964720881,
      "loss": 0.447,
      "step": 2275
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.584716260433197,
      "learning_rate": 0.0001177190991579223,
      "loss": 0.7038,
      "step": 2300
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.4658590257167816,
      "learning_rate": 0.00011612309214197599,
      "loss": 0.4476,
      "step": 2325
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.5467966794967651,
      "learning_rate": 0.00011452285712454904,
      "loss": 0.6941,
      "step": 2350
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.43342024087905884,
      "learning_rate": 0.00011291881373954065,
      "loss": 0.4642,
      "step": 2375
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.5007681250572205,
      "learning_rate": 0.00011131138261952845,
      "loss": 0.6727,
      "step": 2400
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.4646036922931671,
      "learning_rate": 0.00010970098528546481,
      "loss": 0.3964,
      "step": 2425
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.634101390838623,
      "learning_rate": 0.00010808804403614043,
      "loss": 0.6667,
      "step": 2450
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.5218493938446045,
      "learning_rate": 0.00010647298183744359,
      "loss": 0.4372,
      "step": 2475
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.6135673522949219,
      "learning_rate": 0.00010485622221144484,
      "loss": 0.6696,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7027298808097839,
      "eval_runtime": 218.5855,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 2500
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.4762839376926422,
      "learning_rate": 0.00010323818912533561,
      "loss": 0.4197,
      "step": 2525
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.5894041657447815,
      "learning_rate": 0.00010161930688025017,
      "loss": 0.6321,
      "step": 2550
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.5225691199302673,
      "learning_rate": 0.0001,
      "loss": 0.3672,
      "step": 2575
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.5665719509124756,
      "learning_rate": 9.838069311974986e-05,
      "loss": 0.6272,
      "step": 2600
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.5143303871154785,
      "learning_rate": 9.676181087466444e-05,
      "loss": 0.4445,
      "step": 2625
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.5859829783439636,
      "learning_rate": 9.514377778855521e-05,
      "loss": 0.6104,
      "step": 2650
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.5341120958328247,
      "learning_rate": 9.352701816255643e-05,
      "loss": 0.4406,
      "step": 2675
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.6735013723373413,
      "learning_rate": 9.19119559638596e-05,
      "loss": 0.6187,
      "step": 2700
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.5356220602989197,
      "learning_rate": 9.02990147145352e-05,
      "loss": 0.419,
      "step": 2725
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.7068591117858887,
      "learning_rate": 8.868861738047158e-05,
      "loss": 0.6363,
      "step": 2750
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.5292702317237854,
      "learning_rate": 8.70811862604594e-05,
      "loss": 0.4507,
      "step": 2775
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.5923959612846375,
      "learning_rate": 8.5477142875451e-05,
      "loss": 0.613,
      "step": 2800
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.518565833568573,
      "learning_rate": 8.387690785802402e-05,
      "loss": 0.4367,
      "step": 2825
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.5476701259613037,
      "learning_rate": 8.228090084207774e-05,
      "loss": 0.624,
      "step": 2850
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.5420591831207275,
      "learning_rate": 8.068954035279121e-05,
      "loss": 0.414,
      "step": 2875
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.6018252372741699,
      "learning_rate": 7.91032436968725e-05,
      "loss": 0.6346,
      "step": 2900
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.5629088878631592,
      "learning_rate": 7.75224268531271e-05,
      "loss": 0.403,
      "step": 2925
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.6062105894088745,
      "learning_rate": 7.594750436337467e-05,
      "loss": 0.631,
      "step": 2950
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.5645389556884766,
      "learning_rate": 7.437888922374276e-05,
      "loss": 0.3919,
      "step": 2975
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.5521354079246521,
      "learning_rate": 7.281699277636572e-05,
      "loss": 0.6532,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7122446894645691,
      "eval_runtime": 218.4996,
      "eval_samples_per_second": 4.577,
      "eval_steps_per_second": 4.577,
      "step": 3000
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.5143793821334839,
      "learning_rate": 7.126222460151719e-05,
      "loss": 0.443,
      "step": 3025
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.6146826148033142,
      "learning_rate": 6.971499241020495e-05,
      "loss": 0.5661,
      "step": 3050
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.6297295093536377,
      "learning_rate": 6.817570193725564e-05,
      "loss": 0.3739,
      "step": 3075
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.5821261405944824,
      "learning_rate": 6.664475683491796e-05,
      "loss": 0.5539,
      "step": 3100
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.6387301087379456,
      "learning_rate": 6.512255856701177e-05,
      "loss": 0.4218,
      "step": 3125
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.5534520149230957,
      "learning_rate": 6.360950630365126e-05,
      "loss": 0.5802,
      "step": 3150
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.6097425222396851,
      "learning_rate": 6.210599681656933e-05,
      "loss": 0.4014,
      "step": 3175
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.6303243041038513,
      "learning_rate": 6.061242437507131e-05,
      "loss": 0.5757,
      "step": 3200
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.6164438128471375,
      "learning_rate": 5.9129180642644414e-05,
      "loss": 0.4352,
      "step": 3225
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.7558322548866272,
      "learning_rate": 5.765665457425102e-05,
      "loss": 0.5925,
      "step": 3250
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.5827900171279907,
      "learning_rate": 5.6195232314331766e-05,
      "loss": 0.4011,
      "step": 3275
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.6696884632110596,
      "learning_rate": 5.474529709554612e-05,
      "loss": 0.5965,
      "step": 3300
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.5853701233863831,
      "learning_rate": 5.3307229138275936e-05,
      "loss": 0.3638,
      "step": 3325
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.49161645770072937,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 0.5934,
      "step": 3350
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.6008785367012024,
      "learning_rate": 5.0468200231001286e-05,
      "loss": 0.3658,
      "step": 3375
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.6211680173873901,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 0.598,
      "step": 3400
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.5583895444869995,
      "learning_rate": 4.768112334178699e-05,
      "loss": 0.4112,
      "step": 3425
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.6878373026847839,
      "learning_rate": 4.630798263510162e-05,
      "loss": 0.6002,
      "step": 3450
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.6009690761566162,
      "learning_rate": 4.494892172941965e-05,
      "loss": 0.3548,
      "step": 3475
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.6431997418403625,
      "learning_rate": 4.360429701490934e-05,
      "loss": 0.5672,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7299730181694031,
      "eval_runtime": 218.4586,
      "eval_samples_per_second": 4.578,
      "eval_steps_per_second": 4.578,
      "step": 3500
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.6518498063087463,
      "learning_rate": 4.227446109609809e-05,
      "loss": 0.4025,
      "step": 3525
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.6475735902786255,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 0.5305,
      "step": 3550
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.6310995221138,
      "learning_rate": 3.966054658170754e-05,
      "loss": 0.4049,
      "step": 3575
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.6542565822601318,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 0.5434,
      "step": 3600
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.682070791721344,
      "learning_rate": 3.710991982161555e-05,
      "loss": 0.3527,
      "step": 3625
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.7091543078422546,
      "learning_rate": 3.585917803688603e-05,
      "loss": 0.5511,
      "step": 3650
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.6858533024787903,
      "learning_rate": 3.4625256071074773e-05,
      "loss": 0.3656,
      "step": 3675
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.7227030396461487,
      "learning_rate": 3.340847749883191e-05,
      "loss": 0.5368,
      "step": 3700
    },
    {
      "epoch": 7.45,
      "grad_norm": 0.7048631310462952,
      "learning_rate": 3.2209161399249674e-05,
      "loss": 0.3834,
      "step": 3725
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.569776177406311,
      "learning_rate": 3.102762227218957e-05,
      "loss": 0.523,
      "step": 3750
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.6703068614006042,
      "learning_rate": 2.9864169955810084e-05,
      "loss": 0.3869,
      "step": 3775
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.7398860454559326,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 0.5615,
      "step": 3800
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.6978838443756104,
      "learning_rate": 2.759274131295787e-05,
      "loss": 0.4095,
      "step": 3825
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.7500434517860413,
      "learning_rate": 2.6485360629279987e-05,
      "loss": 0.5235,
      "step": 3850
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.6906771659851074,
      "learning_rate": 2.5397257885675397e-05,
      "loss": 0.3665,
      "step": 3875
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.631628692150116,
      "learning_rate": 2.432871841823047e-05,
      "loss": 0.5406,
      "step": 3900
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.637408971786499,
      "learning_rate": 2.3280022432901383e-05,
      "loss": 0.3583,
      "step": 3925
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.7295311689376831,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 0.5543,
      "step": 3950
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.6882609128952026,
      "learning_rate": 2.1243255642254578e-05,
      "loss": 0.3913,
      "step": 3975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.7140238285064697,
      "learning_rate": 2.025571894372794e-05,
      "loss": 0.5606,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.738375186920166,
      "eval_runtime": 218.4151,
      "eval_samples_per_second": 4.578,
      "eval_steps_per_second": 4.578,
      "step": 4000
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.7074938416481018,
      "learning_rate": 1.9289093800839066e-05,
      "loss": 0.354,
      "step": 4025
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.7646974921226501,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 0.5395,
      "step": 4050
    },
    {
      "epoch": 8.15,
      "grad_norm": 0.6894540190696716,
      "learning_rate": 1.741958655457436e-05,
      "loss": 0.3682,
      "step": 4075
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7313809990882874,
      "learning_rate": 1.65171946970729e-05,
      "loss": 0.5102,
      "step": 4100
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.6845383644104004,
      "learning_rate": 1.563669475839956e-05,
      "loss": 0.3739,
      "step": 4125
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.5811274647712708,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 0.5163,
      "step": 4150
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.7024001479148865,
      "learning_rate": 1.3942288419607475e-05,
      "loss": 0.3898,
      "step": 4175
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.7037094831466675,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 0.5087,
      "step": 4200
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.6334701776504517,
      "learning_rate": 1.233814473646524e-05,
      "loss": 0.3485,
      "step": 4225
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.638171911239624,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 0.5143,
      "step": 4250
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.7569769024848938,
      "learning_rate": 1.0825946234178574e-05,
      "loss": 0.3876,
      "step": 4275
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.6262896060943604,
      "learning_rate": 1.010482589146048e-05,
      "loss": 0.5331,
      "step": 4300
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.7491309642791748,
      "learning_rate": 9.407279000155312e-06,
      "loss": 0.4078,
      "step": 4325
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.6268479824066162,
      "learning_rate": 8.733488479845997e-06,
      "loss": 0.5038,
      "step": 4350
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.7247037887573242,
      "learning_rate": 8.083631020418791e-06,
      "loss": 0.3333,
      "step": 4375
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.687578022480011,
      "learning_rate": 7.457877035729588e-06,
      "loss": 0.5239,
      "step": 4400
    },
    {
      "epoch": 8.85,
      "grad_norm": 0.6888356804847717,
      "learning_rate": 6.856390618915775e-06,
      "loss": 0.3761,
      "step": 4425
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.7492050528526306,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 0.5075,
      "step": 4450
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.7779647707939148,
      "learning_rate": 5.726845001356573e-06,
      "loss": 0.3747,
      "step": 4475
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.7516434192657471,
      "learning_rate": 5.199082004372957e-06,
      "loss": 0.5244,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7492567300796509,
      "eval_runtime": 218.5193,
      "eval_samples_per_second": 4.576,
      "eval_steps_per_second": 4.576,
      "step": 4500
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.7236334085464478,
      "learning_rate": 4.6961789051139124e-06,
      "loss": 0.3691,
      "step": 4525
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.708212673664093,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 0.5094,
      "step": 4550
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.7421522736549377,
      "learning_rate": 3.7654733565969826e-06,
      "loss": 0.3402,
      "step": 4575
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.7019355297088623,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 0.498,
      "step": 4600
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.705398678779602,
      "learning_rate": 2.9357045374040825e-06,
      "loss": 0.381,
      "step": 4625
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.7618646025657654,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 0.5001,
      "step": 4650
    },
    {
      "epoch": 9.35,
      "grad_norm": 0.7450039386749268,
      "learning_rate": 2.2077427604429433e-06,
      "loss": 0.3712,
      "step": 4675
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.6520190834999084,
      "learning_rate": 1.882182310176095e-06,
      "loss": 0.4967,
      "step": 4700
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.7209770679473877,
      "learning_rate": 1.5823515570925763e-06,
      "loss": 0.3638,
      "step": 4725
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.7220669388771057,
      "learning_rate": 1.30832912661093e-06,
      "loss": 0.5312,
      "step": 4750
    },
    {
      "epoch": 9.55,
      "grad_norm": 0.7010599970817566,
      "learning_rate": 1.0601868763643996e-06,
      "loss": 0.3842,
      "step": 4775
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.6439112424850464,
      "learning_rate": 8.379898773574924e-07,
      "loss": 0.4985,
      "step": 4800
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.7173570394515991,
      "learning_rate": 6.41796396902239e-07,
      "loss": 0.3544,
      "step": 4825
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.7196497321128845,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 0.5116,
      "step": 4850
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.7104085087776184,
      "learning_rate": 3.2761895254306287e-07,
      "loss": 0.3422,
      "step": 4875
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.6070632338523865,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 0.4903,
      "step": 4900
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.7091878056526184,
      "learning_rate": 1.179840720409331e-07,
      "loss": 0.3903,
      "step": 4925
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.6738971471786499,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 0.5202,
      "step": 4950
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.7669798731803894,
      "learning_rate": 1.3111633436779791e-08,
      "loss": 0.3592,
      "step": 4975
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.6655763387680054,
      "learning_rate": 0.0,
      "loss": 0.5195,
      "step": 5000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.076336194751693e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
