{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.5306330323219299,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.3429,
      "step": 25
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2904027700424194,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.4712,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5545055270195007,
      "learning_rate": 0.0001,
      "loss": 0.7752,
      "step": 75
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.784598708152771,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.2282,
      "step": 100
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5736451745033264,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.5933,
      "step": 125
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8929664492607117,
      "learning_rate": 0.0002,
      "loss": 0.9855,
      "step": 150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39161160588264465,
      "learning_rate": 0.00019998688836656323,
      "loss": 0.6497,
      "step": 175
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.69020676612854,
      "learning_rate": 0.00019994755690455152,
      "loss": 0.9604,
      "step": 200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3475888967514038,
      "learning_rate": 0.0001998820159279591,
      "loss": 0.5402,
      "step": 225
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5235878825187683,
      "learning_rate": 0.00019979028262377118,
      "loss": 0.9308,
      "step": 250
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.32558685541152954,
      "learning_rate": 0.00019967238104745696,
      "loss": 0.6059,
      "step": 275
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.530147135257721,
      "learning_rate": 0.0001995283421166614,
      "loss": 0.9173,
      "step": 300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.35853299498558044,
      "learning_rate": 0.00019935820360309777,
      "loss": 0.5869,
      "step": 325
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5811585187911987,
      "learning_rate": 0.00019916201012264254,
      "loss": 0.9217,
      "step": 350
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3558991253376007,
      "learning_rate": 0.00019893981312363562,
      "loss": 0.5809,
      "step": 375
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6902410387992859,
      "learning_rate": 0.00019869167087338907,
      "loss": 0.8951,
      "step": 400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3291137218475342,
      "learning_rate": 0.00019841764844290744,
      "loss": 0.4823,
      "step": 425
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4532122313976288,
      "learning_rate": 0.0001981178176898239,
      "loss": 0.9124,
      "step": 450
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3285539746284485,
      "learning_rate": 0.00019779225723955707,
      "loss": 0.5534,
      "step": 475
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.39432287216186523,
      "learning_rate": 0.00019744105246469263,
      "loss": 0.8755,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8166214823722839,
      "eval_runtime": 218.7688,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 500
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.30064740777015686,
      "learning_rate": 0.00019706429546259593,
      "loss": 0.5111,
      "step": 525
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5738099813461304,
      "learning_rate": 0.00019666208503126112,
      "loss": 0.8802,
      "step": 550
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.3321923613548279,
      "learning_rate": 0.00019623452664340306,
      "loss": 0.5814,
      "step": 575
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5043205618858337,
      "learning_rate": 0.00019578173241879872,
      "loss": 0.8506,
      "step": 600
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.31051871180534363,
      "learning_rate": 0.0001953038210948861,
      "loss": 0.5534,
      "step": 625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.3841414749622345,
      "learning_rate": 0.00019480091799562704,
      "loss": 0.8822,
      "step": 650
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.3103470802307129,
      "learning_rate": 0.00019427315499864344,
      "loss": 0.5462,
      "step": 675
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5636414289474487,
      "learning_rate": 0.00019372067050063438,
      "loss": 0.8458,
      "step": 700
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.3200247287750244,
      "learning_rate": 0.00019314360938108425,
      "loss": 0.5138,
      "step": 725
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.485258549451828,
      "learning_rate": 0.00019254212296427044,
      "loss": 0.8619,
      "step": 750
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.3324466645717621,
      "learning_rate": 0.00019191636897958122,
      "loss": 0.5769,
      "step": 775
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4370819926261902,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8528,
      "step": 800
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.32002419233322144,
      "learning_rate": 0.0001905927209998447,
      "loss": 0.5382,
      "step": 825
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.46963584423065186,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.8489,
      "step": 850
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.3187749683856964,
      "learning_rate": 0.00018917405376582145,
      "loss": 0.5325,
      "step": 875
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.4620469808578491,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.8215,
      "step": 900
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.31130242347717285,
      "learning_rate": 0.0001876618552635348,
      "loss": 0.4669,
      "step": 925
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.4205467700958252,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.8742,
      "step": 950
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.35418814420700073,
      "learning_rate": 0.00018605771158039253,
      "loss": 0.5271,
      "step": 975
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.41383180022239685,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.8567,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7298133373260498,
      "eval_runtime": 218.7944,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 1000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.3220958709716797,
      "learning_rate": 0.00018436330524160047,
      "loss": 0.5024,
      "step": 1025
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5048972368240356,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.7961,
      "step": 1050
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.35190653800964355,
      "learning_rate": 0.00018258041344542566,
      "loss": 0.4776,
      "step": 1075
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.4478459358215332,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.8116,
      "step": 1100
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3550534248352051,
      "learning_rate": 0.00018071090619916093,
      "loss": 0.5017,
      "step": 1125
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.4977700412273407,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.7798,
      "step": 1150
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.32303282618522644,
      "learning_rate": 0.00017875674435774547,
      "loss": 0.5576,
      "step": 1175
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.45017513632774353,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.8101,
      "step": 1200
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.34762606024742126,
      "learning_rate": 0.00017671997756709863,
      "loss": 0.4468,
      "step": 1225
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.44805893301963806,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.8221,
      "step": 1250
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3439318537712097,
      "learning_rate": 0.0001746027421143246,
      "loss": 0.5433,
      "step": 1275
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.4967583417892456,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.7951,
      "step": 1300
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.33865615725517273,
      "learning_rate": 0.00017240725868704218,
      "loss": 0.4912,
      "step": 1325
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.44727954268455505,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.7868,
      "step": 1350
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.3450052738189697,
      "learning_rate": 0.00017013583004418993,
      "loss": 0.5284,
      "step": 1375
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.4584529995918274,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.78,
      "step": 1400
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.3551176190376282,
      "learning_rate": 0.00016779083860075033,
      "loss": 0.4995,
      "step": 1425
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.49849870800971985,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.8072,
      "step": 1450
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.35479986667633057,
      "learning_rate": 0.00016537474392892528,
      "loss": 0.4488,
      "step": 1475
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.40280982851982117,
      "learning_rate": 0.000164140821963114,
      "loss": 0.7831,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7175947427749634,
      "eval_runtime": 218.8851,
      "eval_samples_per_second": 4.569,
      "eval_steps_per_second": 4.569,
      "step": 1500
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.3598077893257141,
      "learning_rate": 0.00016289008017838445,
      "loss": 0.4506,
      "step": 1525
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.48595505952835083,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.7499,
      "step": 1550
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.3770977258682251,
      "learning_rate": 0.00016033945341829248,
      "loss": 0.453,
      "step": 1575
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.5240683555603027,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.7536,
      "step": 1600
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.35958319902420044,
      "learning_rate": 0.00015772553890390197,
      "loss": 0.4664,
      "step": 1625
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.5552368760108948,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.7148,
      "step": 1650
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.4001203179359436,
      "learning_rate": 0.00015505107827058036,
      "loss": 0.4734,
      "step": 1675
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.5150401592254639,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.7549,
      "step": 1700
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.43428969383239746,
      "learning_rate": 0.000152318876658213,
      "loss": 0.4721,
      "step": 1725
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.495711088180542,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.732,
      "step": 1750
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.4220883548259735,
      "learning_rate": 0.00014953179976899878,
      "loss": 0.5075,
      "step": 1775
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.4411610960960388,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.7216,
      "step": 1800
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.40463918447494507,
      "learning_rate": 0.00014669277086172406,
      "loss": 0.4716,
      "step": 1825
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.4368310868740082,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.7428,
      "step": 1850
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.39870572090148926,
      "learning_rate": 0.00014380476768566824,
      "loss": 0.5038,
      "step": 1875
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.5448030233383179,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.7401,
      "step": 1900
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.4255486726760864,
      "learning_rate": 0.00014087081935735564,
      "loss": 0.4826,
      "step": 1925
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.4343303442001343,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.7378,
      "step": 1950
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.4126340448856354,
      "learning_rate": 0.00013789400318343068,
      "loss": 0.4248,
      "step": 1975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.502575159072876,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.7423,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.703903317451477,
      "eval_runtime": 218.7601,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 2000
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.3782223165035248,
      "learning_rate": 0.00013487744143298822,
      "loss": 0.4857,
      "step": 2025
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.47556939721107483,
      "learning_rate": 0.00013335524316508208,
      "loss": 0.6874,
      "step": 2050
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.4488801658153534,
      "learning_rate": 0.0001318242980627444,
      "loss": 0.3828,
      "step": 2075
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.5343642234802246,
      "learning_rate": 0.00013028500758979506,
      "loss": 0.6859,
      "step": 2100
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.42280834913253784,
      "learning_rate": 0.00012873777539848283,
      "loss": 0.4801,
      "step": 2125
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.5245603322982788,
      "learning_rate": 0.0001271830072236343,
      "loss": 0.6784,
      "step": 2150
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.45525893568992615,
      "learning_rate": 0.00012562111077625722,
      "loss": 0.4429,
      "step": 2175
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.5439398884773254,
      "learning_rate": 0.00012405249563662537,
      "loss": 0.6933,
      "step": 2200
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.4768342971801758,
      "learning_rate": 0.00012247757314687297,
      "loss": 0.4447,
      "step": 2225
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.47225505113601685,
      "learning_rate": 0.00012089675630312754,
      "loss": 0.6744,
      "step": 2250
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.45450711250305176,
      "learning_rate": 0.00011931045964720881,
      "loss": 0.446,
      "step": 2275
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.5649134516716003,
      "learning_rate": 0.0001177190991579223,
      "loss": 0.7049,
      "step": 2300
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.4645718038082123,
      "learning_rate": 0.00011612309214197599,
      "loss": 0.4461,
      "step": 2325
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.5220506191253662,
      "learning_rate": 0.00011452285712454904,
      "loss": 0.6926,
      "step": 2350
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.43434959650039673,
      "learning_rate": 0.00011291881373954065,
      "loss": 0.4646,
      "step": 2375
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.534214973449707,
      "learning_rate": 0.00011131138261952845,
      "loss": 0.6735,
      "step": 2400
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.46223968267440796,
      "learning_rate": 0.00010970098528546481,
      "loss": 0.398,
      "step": 2425
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.6220152378082275,
      "learning_rate": 0.00010808804403614043,
      "loss": 0.6693,
      "step": 2450
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.5206254720687866,
      "learning_rate": 0.00010647298183744359,
      "loss": 0.4359,
      "step": 2475
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.5784783959388733,
      "learning_rate": 0.00010485622221144484,
      "loss": 0.6704,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7090482115745544,
      "eval_runtime": 218.6602,
      "eval_samples_per_second": 4.573,
      "eval_steps_per_second": 4.573,
      "step": 2500
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.466746985912323,
      "learning_rate": 0.00010323818912533561,
      "loss": 0.4219,
      "step": 2525
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.5924657583236694,
      "learning_rate": 0.00010161930688025017,
      "loss": 0.6321,
      "step": 2550
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.5292902588844299,
      "learning_rate": 0.0001,
      "loss": 0.3674,
      "step": 2575
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.5732548832893372,
      "learning_rate": 9.838069311974986e-05,
      "loss": 0.6244,
      "step": 2600
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.5118852853775024,
      "learning_rate": 9.676181087466444e-05,
      "loss": 0.445,
      "step": 2625
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.5711217522621155,
      "learning_rate": 9.514377778855521e-05,
      "loss": 0.609,
      "step": 2650
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.5322654843330383,
      "learning_rate": 9.352701816255643e-05,
      "loss": 0.4385,
      "step": 2675
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.6277101039886475,
      "learning_rate": 9.19119559638596e-05,
      "loss": 0.6191,
      "step": 2700
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.5429368615150452,
      "learning_rate": 9.02990147145352e-05,
      "loss": 0.4196,
      "step": 2725
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.6444020867347717,
      "learning_rate": 8.868861738047158e-05,
      "loss": 0.638,
      "step": 2750
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.5239187479019165,
      "learning_rate": 8.70811862604594e-05,
      "loss": 0.4497,
      "step": 2775
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.5921968817710876,
      "learning_rate": 8.5477142875451e-05,
      "loss": 0.6092,
      "step": 2800
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.5219113230705261,
      "learning_rate": 8.387690785802402e-05,
      "loss": 0.4378,
      "step": 2825
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.512773871421814,
      "learning_rate": 8.228090084207774e-05,
      "loss": 0.6264,
      "step": 2850
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.5452637672424316,
      "learning_rate": 8.068954035279121e-05,
      "loss": 0.4145,
      "step": 2875
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.6383250951766968,
      "learning_rate": 7.91032436968725e-05,
      "loss": 0.6328,
      "step": 2900
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.5545250773429871,
      "learning_rate": 7.75224268531271e-05,
      "loss": 0.4017,
      "step": 2925
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.6267677545547485,
      "learning_rate": 7.594750436337467e-05,
      "loss": 0.6311,
      "step": 2950
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.5625284910202026,
      "learning_rate": 7.437888922374276e-05,
      "loss": 0.3896,
      "step": 2975
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.5776503086090088,
      "learning_rate": 7.281699277636572e-05,
      "loss": 0.6513,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7207440137863159,
      "eval_runtime": 221.4182,
      "eval_samples_per_second": 4.516,
      "eval_steps_per_second": 4.516,
      "step": 3000
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.5000000596046448,
      "learning_rate": 7.126222460151719e-05,
      "loss": 0.442,
      "step": 3025
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.6327428817749023,
      "learning_rate": 6.971499241020495e-05,
      "loss": 0.5632,
      "step": 3050
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.6102038621902466,
      "learning_rate": 6.817570193725564e-05,
      "loss": 0.3744,
      "step": 3075
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.6315488815307617,
      "learning_rate": 6.664475683491796e-05,
      "loss": 0.5538,
      "step": 3100
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.6192219853401184,
      "learning_rate": 6.512255856701177e-05,
      "loss": 0.4219,
      "step": 3125
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.5221797227859497,
      "learning_rate": 6.360950630365126e-05,
      "loss": 0.5791,
      "step": 3150
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.6049165725708008,
      "learning_rate": 6.210599681656933e-05,
      "loss": 0.404,
      "step": 3175
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.6985620856285095,
      "learning_rate": 6.061242437507131e-05,
      "loss": 0.5762,
      "step": 3200
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.605857253074646,
      "learning_rate": 5.9129180642644414e-05,
      "loss": 0.4354,
      "step": 3225
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.6824442744255066,
      "learning_rate": 5.765665457425102e-05,
      "loss": 0.5932,
      "step": 3250
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.6003903150558472,
      "learning_rate": 5.6195232314331766e-05,
      "loss": 0.4014,
      "step": 3275
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.6516232490539551,
      "learning_rate": 5.474529709554612e-05,
      "loss": 0.5958,
      "step": 3300
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.5837440490722656,
      "learning_rate": 5.3307229138275936e-05,
      "loss": 0.3638,
      "step": 3325
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.5407217741012573,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 0.5925,
      "step": 3350
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.6223374009132385,
      "learning_rate": 5.0468200231001286e-05,
      "loss": 0.3656,
      "step": 3375
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.6529479026794434,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 0.5989,
      "step": 3400
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.5690494179725647,
      "learning_rate": 4.768112334178699e-05,
      "loss": 0.4101,
      "step": 3425
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.7232433557510376,
      "learning_rate": 4.630798263510162e-05,
      "loss": 0.598,
      "step": 3450
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.5959927439689636,
      "learning_rate": 4.494892172941965e-05,
      "loss": 0.3534,
      "step": 3475
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.6512966156005859,
      "learning_rate": 4.360429701490934e-05,
      "loss": 0.567,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7360853552818298,
      "eval_runtime": 218.8082,
      "eval_samples_per_second": 4.57,
      "eval_steps_per_second": 4.57,
      "step": 3500
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.6667513251304626,
      "learning_rate": 4.227446109609809e-05,
      "loss": 0.4033,
      "step": 3525
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.6234861612319946,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 0.5309,
      "step": 3550
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.6314767003059387,
      "learning_rate": 3.966054658170754e-05,
      "loss": 0.4054,
      "step": 3575
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.6513315439224243,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 0.547,
      "step": 3600
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.6805623769760132,
      "learning_rate": 3.710991982161555e-05,
      "loss": 0.3516,
      "step": 3625
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.7023934721946716,
      "learning_rate": 3.585917803688603e-05,
      "loss": 0.5524,
      "step": 3650
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.690974771976471,
      "learning_rate": 3.4625256071074773e-05,
      "loss": 0.3651,
      "step": 3675
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.668155312538147,
      "learning_rate": 3.340847749883191e-05,
      "loss": 0.5394,
      "step": 3700
    },
    {
      "epoch": 7.45,
      "grad_norm": 0.6715559363365173,
      "learning_rate": 3.2209161399249674e-05,
      "loss": 0.3831,
      "step": 3725
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.5981776714324951,
      "learning_rate": 3.102762227218957e-05,
      "loss": 0.5217,
      "step": 3750
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.6669062376022339,
      "learning_rate": 2.9864169955810084e-05,
      "loss": 0.386,
      "step": 3775
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.7168733477592468,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 0.5621,
      "step": 3800
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.7014177441596985,
      "learning_rate": 2.759274131295787e-05,
      "loss": 0.41,
      "step": 3825
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.7749751806259155,
      "learning_rate": 2.6485360629279987e-05,
      "loss": 0.5223,
      "step": 3850
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.6936259865760803,
      "learning_rate": 2.5397257885675397e-05,
      "loss": 0.3679,
      "step": 3875
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.6282033324241638,
      "learning_rate": 2.432871841823047e-05,
      "loss": 0.5383,
      "step": 3900
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.6384917497634888,
      "learning_rate": 2.3280022432901383e-05,
      "loss": 0.3583,
      "step": 3925
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.7011017799377441,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 0.55,
      "step": 3950
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.6920185685157776,
      "learning_rate": 2.1243255642254578e-05,
      "loss": 0.3914,
      "step": 3975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.7066527009010315,
      "learning_rate": 2.025571894372794e-05,
      "loss": 0.5558,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7474460601806641,
      "eval_runtime": 218.8668,
      "eval_samples_per_second": 4.569,
      "eval_steps_per_second": 4.569,
      "step": 4000
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.7060039043426514,
      "learning_rate": 1.9289093800839066e-05,
      "loss": 0.355,
      "step": 4025
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.7357053160667419,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 0.5376,
      "step": 4050
    },
    {
      "epoch": 8.15,
      "grad_norm": 0.6801773905754089,
      "learning_rate": 1.741958655457436e-05,
      "loss": 0.3675,
      "step": 4075
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7138431668281555,
      "learning_rate": 1.65171946970729e-05,
      "loss": 0.5114,
      "step": 4100
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.6912665963172913,
      "learning_rate": 1.563669475839956e-05,
      "loss": 0.373,
      "step": 4125
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.6210004687309265,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 0.515,
      "step": 4150
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.7355136275291443,
      "learning_rate": 1.3942288419607475e-05,
      "loss": 0.3903,
      "step": 4175
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.7037073373794556,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 0.5088,
      "step": 4200
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.6464942097663879,
      "learning_rate": 1.233814473646524e-05,
      "loss": 0.3487,
      "step": 4225
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.631192147731781,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 0.5156,
      "step": 4250
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.7565549612045288,
      "learning_rate": 1.0825946234178574e-05,
      "loss": 0.387,
      "step": 4275
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.6665159463882446,
      "learning_rate": 1.010482589146048e-05,
      "loss": 0.5346,
      "step": 4300
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.7651522159576416,
      "learning_rate": 9.407279000155312e-06,
      "loss": 0.4059,
      "step": 4325
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.5562714338302612,
      "learning_rate": 8.733488479845997e-06,
      "loss": 0.5028,
      "step": 4350
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.7206895351409912,
      "learning_rate": 8.083631020418791e-06,
      "loss": 0.3322,
      "step": 4375
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.6656275987625122,
      "learning_rate": 7.457877035729588e-06,
      "loss": 0.5258,
      "step": 4400
    },
    {
      "epoch": 8.85,
      "grad_norm": 0.689763605594635,
      "learning_rate": 6.856390618915775e-06,
      "loss": 0.3773,
      "step": 4425
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.7826374173164368,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 0.5034,
      "step": 4450
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.7863619923591614,
      "learning_rate": 5.726845001356573e-06,
      "loss": 0.3738,
      "step": 4475
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.6970286965370178,
      "learning_rate": 5.199082004372957e-06,
      "loss": 0.5204,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7568153142929077,
      "eval_runtime": 218.7706,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 4500
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.7424162030220032,
      "learning_rate": 4.6961789051139124e-06,
      "loss": 0.3701,
      "step": 4525
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.6714051365852356,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 0.5096,
      "step": 4550
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.732315719127655,
      "learning_rate": 3.7654733565969826e-06,
      "loss": 0.3406,
      "step": 4575
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.6609334349632263,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 0.5004,
      "step": 4600
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.7000221610069275,
      "learning_rate": 2.9357045374040825e-06,
      "loss": 0.3821,
      "step": 4625
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.7472731471061707,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 0.5011,
      "step": 4650
    },
    {
      "epoch": 9.35,
      "grad_norm": 0.7309903502464294,
      "learning_rate": 2.2077427604429433e-06,
      "loss": 0.3704,
      "step": 4675
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.6392871141433716,
      "learning_rate": 1.882182310176095e-06,
      "loss": 0.4928,
      "step": 4700
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.7064268589019775,
      "learning_rate": 1.5823515570925763e-06,
      "loss": 0.3644,
      "step": 4725
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.7319055199623108,
      "learning_rate": 1.30832912661093e-06,
      "loss": 0.5304,
      "step": 4750
    },
    {
      "epoch": 9.55,
      "grad_norm": 0.6865100860595703,
      "learning_rate": 1.0601868763643996e-06,
      "loss": 0.3844,
      "step": 4775
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.6756576895713806,
      "learning_rate": 8.379898773574924e-07,
      "loss": 0.4967,
      "step": 4800
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.726553738117218,
      "learning_rate": 6.41796396902239e-07,
      "loss": 0.3547,
      "step": 4825
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.7118145227432251,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 0.5109,
      "step": 4850
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.7055439949035645,
      "learning_rate": 3.2761895254306287e-07,
      "loss": 0.34,
      "step": 4875
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.602037250995636,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 0.4872,
      "step": 4900
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.697485089302063,
      "learning_rate": 1.179840720409331e-07,
      "loss": 0.3906,
      "step": 4925
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.6492431163787842,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 0.5195,
      "step": 4950
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.7402990460395813,
      "learning_rate": 1.3111633436779791e-08,
      "loss": 0.3597,
      "step": 4975
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.6707105040550232,
      "learning_rate": 0.0,
      "loss": 0.518,
      "step": 5000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.064011777494221e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
