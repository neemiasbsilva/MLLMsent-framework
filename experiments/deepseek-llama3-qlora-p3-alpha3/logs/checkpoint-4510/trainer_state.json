{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4510,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05543237250554324,
      "grad_norm": 0.5690626502037048,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.2765,
      "step": 25
    },
    {
      "epoch": 0.11086474501108648,
      "grad_norm": 1.5038871765136719,
      "learning_rate": 7.352941176470589e-05,
      "loss": 2.4449,
      "step": 50
    },
    {
      "epoch": 0.1662971175166297,
      "grad_norm": 0.49494487047195435,
      "learning_rate": 0.00011029411764705884,
      "loss": 0.7252,
      "step": 75
    },
    {
      "epoch": 0.22172949002217296,
      "grad_norm": 1.2497105598449707,
      "learning_rate": 0.00014705882352941178,
      "loss": 1.2095,
      "step": 100
    },
    {
      "epoch": 0.2771618625277162,
      "grad_norm": 0.48317718505859375,
      "learning_rate": 0.0001838235294117647,
      "loss": 0.6401,
      "step": 125
    },
    {
      "epoch": 0.3325942350332594,
      "grad_norm": 0.7029271721839905,
      "learning_rate": 0.00019999494449430045,
      "loss": 1.0013,
      "step": 150
    },
    {
      "epoch": 0.38802660753880264,
      "grad_norm": 0.3518317639827728,
      "learning_rate": 0.0001999607704786645,
      "loss": 0.5637,
      "step": 175
    },
    {
      "epoch": 0.4434589800443459,
      "grad_norm": 0.5228105187416077,
      "learning_rate": 0.0001998943679601577,
      "loss": 0.9365,
      "step": 200
    },
    {
      "epoch": 0.49889135254988914,
      "grad_norm": 0.40333908796310425,
      "learning_rate": 0.0001997957583477163,
      "loss": 0.632,
      "step": 225
    },
    {
      "epoch": 0.5543237250554324,
      "grad_norm": 0.7644914984703064,
      "learning_rate": 0.0001996649734342143,
      "loss": 0.9216,
      "step": 250
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 0.32137659192085266,
      "learning_rate": 0.00019950205538621292,
      "loss": 0.5834,
      "step": 275
    },
    {
      "epoch": 0.6651884700665188,
      "grad_norm": 0.45771846175193787,
      "learning_rate": 0.00019930705673036606,
      "loss": 0.9445,
      "step": 300
    },
    {
      "epoch": 0.720620842572062,
      "grad_norm": 0.3660951256752014,
      "learning_rate": 0.00019908004033648453,
      "loss": 0.6466,
      "step": 325
    },
    {
      "epoch": 0.7760532150776053,
      "grad_norm": 0.5186494588851929,
      "learning_rate": 0.00019882107939726655,
      "loss": 0.9069,
      "step": 350
    },
    {
      "epoch": 0.8314855875831486,
      "grad_norm": 0.3484289050102234,
      "learning_rate": 0.0001985302574046993,
      "loss": 0.5876,
      "step": 375
    },
    {
      "epoch": 0.8869179600886918,
      "grad_norm": 0.48084262013435364,
      "learning_rate": 0.00019820766812314036,
      "loss": 0.9077,
      "step": 400
    },
    {
      "epoch": 0.9423503325942351,
      "grad_norm": 0.31294557452201843,
      "learning_rate": 0.00019785341555908685,
      "loss": 0.5462,
      "step": 425
    },
    {
      "epoch": 0.9977827050997783,
      "grad_norm": 0.4243483543395996,
      "learning_rate": 0.00019746761392764253,
      "loss": 0.894,
      "step": 450
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8203914761543274,
      "eval_runtime": 198.5346,
      "eval_samples_per_second": 4.538,
      "eval_steps_per_second": 4.538,
      "step": 451
    },
    {
      "epoch": 1.0532150776053215,
      "grad_norm": 0.3017718195915222,
      "learning_rate": 0.0001970503876156937,
      "loss": 0.4974,
      "step": 475
    },
    {
      "epoch": 1.1086474501108647,
      "grad_norm": 0.34328988194465637,
      "learning_rate": 0.00019660187114180528,
      "loss": 0.8724,
      "step": 500
    },
    {
      "epoch": 1.164079822616408,
      "grad_norm": 0.3273063600063324,
      "learning_rate": 0.00019612220911285048,
      "loss": 0.536,
      "step": 525
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 0.4534965455532074,
      "learning_rate": 0.00019561155617738797,
      "loss": 0.8775,
      "step": 550
    },
    {
      "epoch": 1.2749445676274944,
      "grad_norm": 0.33444130420684814,
      "learning_rate": 0.00019507007697580137,
      "loss": 0.5282,
      "step": 575
    },
    {
      "epoch": 1.3303769401330376,
      "grad_norm": 0.39427822828292847,
      "learning_rate": 0.00019449794608721724,
      "loss": 0.87,
      "step": 600
    },
    {
      "epoch": 1.3858093126385809,
      "grad_norm": 0.3464430570602417,
      "learning_rate": 0.00019389534797321884,
      "loss": 0.6222,
      "step": 625
    },
    {
      "epoch": 1.441241685144124,
      "grad_norm": 0.4673633277416229,
      "learning_rate": 0.00019326247691837356,
      "loss": 0.8812,
      "step": 650
    },
    {
      "epoch": 1.4966740576496673,
      "grad_norm": 0.3502732515335083,
      "learning_rate": 0.00019259953696759328,
      "loss": 0.4908,
      "step": 675
    },
    {
      "epoch": 1.5521064301552108,
      "grad_norm": 0.4052894413471222,
      "learning_rate": 0.00019190674186034807,
      "loss": 0.9083,
      "step": 700
    },
    {
      "epoch": 1.6075388026607538,
      "grad_norm": 0.3241325616836548,
      "learning_rate": 0.00019118431496175403,
      "loss": 0.4945,
      "step": 725
    },
    {
      "epoch": 1.6629711751662972,
      "grad_norm": 0.406539648771286,
      "learning_rate": 0.00019043248919055778,
      "loss": 0.8771,
      "step": 750
    },
    {
      "epoch": 1.7184035476718402,
      "grad_norm": 0.32962948083877563,
      "learning_rate": 0.00018965150694404094,
      "loss": 0.5563,
      "step": 775
    },
    {
      "epoch": 1.7738359201773837,
      "grad_norm": 0.4233372211456299,
      "learning_rate": 0.00018884162001986821,
      "loss": 0.8552,
      "step": 800
    },
    {
      "epoch": 1.8292682926829267,
      "grad_norm": 0.33527496457099915,
      "learning_rate": 0.0001880030895349051,
      "loss": 0.501,
      "step": 825
    },
    {
      "epoch": 1.8847006651884701,
      "grad_norm": 0.4606839716434479,
      "learning_rate": 0.0001871361858410308,
      "loss": 0.879,
      "step": 850
    },
    {
      "epoch": 1.9401330376940134,
      "grad_norm": 0.32349491119384766,
      "learning_rate": 0.00018624118843797355,
      "loss": 0.5538,
      "step": 875
    },
    {
      "epoch": 1.9955654101995566,
      "grad_norm": 0.3497122824192047,
      "learning_rate": 0.00018531838588319683,
      "loss": 0.8706,
      "step": 900
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7367746233940125,
      "eval_runtime": 198.5495,
      "eval_samples_per_second": 4.538,
      "eval_steps_per_second": 4.538,
      "step": 902
    },
    {
      "epoch": 2.0509977827050996,
      "grad_norm": 0.30082809925079346,
      "learning_rate": 0.000184368075698865,
      "loss": 0.4706,
      "step": 925
    },
    {
      "epoch": 2.106430155210643,
      "grad_norm": 0.42361173033714294,
      "learning_rate": 0.00018339056427591884,
      "loss": 0.8167,
      "step": 950
    },
    {
      "epoch": 2.1618625277161865,
      "grad_norm": 0.32500025629997253,
      "learning_rate": 0.0001823861667752914,
      "loss": 0.4556,
      "step": 975
    },
    {
      "epoch": 2.2172949002217295,
      "grad_norm": 0.41853201389312744,
      "learning_rate": 0.00018135520702629675,
      "loss": 0.8636,
      "step": 1000
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.38668203353881836,
      "learning_rate": 0.0001802980174222235,
      "loss": 0.4577,
      "step": 1025
    },
    {
      "epoch": 2.328159645232816,
      "grad_norm": 0.41210946440696716,
      "learning_rate": 0.0001792149388131674,
      "loss": 0.8445,
      "step": 1050
    },
    {
      "epoch": 2.3835920177383594,
      "grad_norm": 0.3554641306400299,
      "learning_rate": 0.00017810632039613736,
      "loss": 0.5566,
      "step": 1075
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 0.412445992231369,
      "learning_rate": 0.00017697251960247036,
      "loss": 0.8378,
      "step": 1100
    },
    {
      "epoch": 2.494456762749446,
      "grad_norm": 0.3337023854255676,
      "learning_rate": 0.00017581390198259138,
      "loss": 0.4984,
      "step": 1125
    },
    {
      "epoch": 2.549889135254989,
      "grad_norm": 0.4243049621582031,
      "learning_rate": 0.00017463084108815586,
      "loss": 0.8237,
      "step": 1150
    },
    {
      "epoch": 2.6053215077605323,
      "grad_norm": 0.34685277938842773,
      "learning_rate": 0.00017342371835161227,
      "loss": 0.4793,
      "step": 1175
    },
    {
      "epoch": 2.6607538802660753,
      "grad_norm": 0.42973968386650085,
      "learning_rate": 0.00017219292296322385,
      "loss": 0.812,
      "step": 1200
    },
    {
      "epoch": 2.7161862527716187,
      "grad_norm": 0.3443552553653717,
      "learning_rate": 0.0001709388517455893,
      "loss": 0.5061,
      "step": 1225
    },
    {
      "epoch": 2.7716186252771617,
      "grad_norm": 0.40084728598594666,
      "learning_rate": 0.00016966190902570257,
      "loss": 0.8516,
      "step": 1250
    },
    {
      "epoch": 2.827050997782705,
      "grad_norm": 0.33838045597076416,
      "learning_rate": 0.0001683625065045931,
      "loss": 0.4545,
      "step": 1275
    },
    {
      "epoch": 2.882483370288248,
      "grad_norm": 0.44412487745285034,
      "learning_rate": 0.00016704106312458877,
      "loss": 0.8192,
      "step": 1300
    },
    {
      "epoch": 2.9379157427937916,
      "grad_norm": 0.35260069370269775,
      "learning_rate": 0.00016569800493424413,
      "loss": 0.5262,
      "step": 1325
    },
    {
      "epoch": 2.9933481152993346,
      "grad_norm": 0.351834237575531,
      "learning_rate": 0.00016433376495097717,
      "loss": 0.822,
      "step": 1350
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7101761102676392,
      "eval_runtime": 198.551,
      "eval_samples_per_second": 4.538,
      "eval_steps_per_second": 4.538,
      "step": 1353
    },
    {
      "epoch": 3.048780487804878,
      "grad_norm": 0.36989742517471313,
      "learning_rate": 0.00016294878302145987,
      "loss": 0.3817,
      "step": 1375
    },
    {
      "epoch": 3.104212860310421,
      "grad_norm": 0.4197900891304016,
      "learning_rate": 0.00016154350567980635,
      "loss": 0.8101,
      "step": 1400
    },
    {
      "epoch": 3.1596452328159645,
      "grad_norm": 0.41990312933921814,
      "learning_rate": 0.00016011838600360508,
      "loss": 0.4858,
      "step": 1425
    },
    {
      "epoch": 3.2150776053215075,
      "grad_norm": 0.45224395394325256,
      "learning_rate": 0.0001586738834678418,
      "loss": 0.7805,
      "step": 1450
    },
    {
      "epoch": 3.270509977827051,
      "grad_norm": 0.39439988136291504,
      "learning_rate": 0.000157210463796759,
      "loss": 0.4381,
      "step": 1475
    },
    {
      "epoch": 3.3259423503325944,
      "grad_norm": 0.47254881262779236,
      "learning_rate": 0.00015572859881370148,
      "loss": 0.7619,
      "step": 1500
    },
    {
      "epoch": 3.3813747228381374,
      "grad_norm": 0.38424351811408997,
      "learning_rate": 0.0001542287662889948,
      "loss": 0.5031,
      "step": 1525
    },
    {
      "epoch": 3.436807095343681,
      "grad_norm": 0.4747062027454376,
      "learning_rate": 0.00015271144978590685,
      "loss": 0.7778,
      "step": 1550
    },
    {
      "epoch": 3.492239467849224,
      "grad_norm": 0.37879833579063416,
      "learning_rate": 0.00015117713850474135,
      "loss": 0.3654,
      "step": 1575
    },
    {
      "epoch": 3.5476718403547673,
      "grad_norm": 0.4577743113040924,
      "learning_rate": 0.00014962632712511395,
      "loss": 0.7602,
      "step": 1600
    },
    {
      "epoch": 3.6031042128603104,
      "grad_norm": 0.37274548411369324,
      "learning_rate": 0.00014805951564646213,
      "loss": 0.4779,
      "step": 1625
    },
    {
      "epoch": 3.658536585365854,
      "grad_norm": 0.4431755542755127,
      "learning_rate": 0.0001464772092268393,
      "loss": 0.7834,
      "step": 1650
    },
    {
      "epoch": 3.713968957871397,
      "grad_norm": 0.42101356387138367,
      "learning_rate": 0.00014487991802004623,
      "loss": 0.3916,
      "step": 1675
    },
    {
      "epoch": 3.7694013303769403,
      "grad_norm": 0.4491010308265686,
      "learning_rate": 0.00014326815701115156,
      "loss": 0.802,
      "step": 1700
    },
    {
      "epoch": 3.8248337028824833,
      "grad_norm": 0.40013518929481506,
      "learning_rate": 0.0001416424458504546,
      "loss": 0.517,
      "step": 1725
    },
    {
      "epoch": 3.8802660753880267,
      "grad_norm": 0.4503875970840454,
      "learning_rate": 0.00014000330868594427,
      "loss": 0.7978,
      "step": 1750
    },
    {
      "epoch": 3.9356984478935697,
      "grad_norm": 0.407469242811203,
      "learning_rate": 0.00013835127399430748,
      "loss": 0.4775,
      "step": 1775
    },
    {
      "epoch": 3.991130820399113,
      "grad_norm": 0.4577785134315491,
      "learning_rate": 0.00013668687441054252,
      "loss": 0.7931,
      "step": 1800
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.704595685005188,
      "eval_runtime": 198.6678,
      "eval_samples_per_second": 4.535,
      "eval_steps_per_second": 4.535,
      "step": 1804
    },
    {
      "epoch": 4.046563192904657,
      "grad_norm": 0.38393840193748474,
      "learning_rate": 0.00013501064655623094,
      "loss": 0.4323,
      "step": 1825
    },
    {
      "epoch": 4.101995565410199,
      "grad_norm": 0.5017234086990356,
      "learning_rate": 0.00013332313086652516,
      "loss": 0.7222,
      "step": 1850
    },
    {
      "epoch": 4.157427937915743,
      "grad_norm": 0.462085098028183,
      "learning_rate": 0.0001316248714159054,
      "loss": 0.4415,
      "step": 1875
    },
    {
      "epoch": 4.212860310421286,
      "grad_norm": 0.5075187683105469,
      "learning_rate": 0.00012991641574276418,
      "loss": 0.7377,
      "step": 1900
    },
    {
      "epoch": 4.2682926829268295,
      "grad_norm": 0.46779921650886536,
      "learning_rate": 0.0001281983146728735,
      "loss": 0.3848,
      "step": 1925
    },
    {
      "epoch": 4.323725055432373,
      "grad_norm": 0.4657268226146698,
      "learning_rate": 0.00012647112214179222,
      "loss": 0.7439,
      "step": 1950
    },
    {
      "epoch": 4.3791574279379155,
      "grad_norm": 0.48673683404922485,
      "learning_rate": 0.000124735395016271,
      "loss": 0.3751,
      "step": 1975
    },
    {
      "epoch": 4.434589800443459,
      "grad_norm": 0.5411598086357117,
      "learning_rate": 0.00012299169291471197,
      "loss": 0.7617,
      "step": 2000
    },
    {
      "epoch": 4.490022172949002,
      "grad_norm": 0.47298464179039,
      "learning_rate": 0.0001212405780267412,
      "loss": 0.4575,
      "step": 2025
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.4577333331108093,
      "learning_rate": 0.00011948261493195256,
      "loss": 0.7166,
      "step": 2050
    },
    {
      "epoch": 4.600886917960088,
      "grad_norm": 0.43795156478881836,
      "learning_rate": 0.00011771837041788059,
      "loss": 0.4622,
      "step": 2075
    },
    {
      "epoch": 4.656319290465632,
      "grad_norm": 0.522642970085144,
      "learning_rate": 0.00011594841329726158,
      "loss": 0.7321,
      "step": 2100
    },
    {
      "epoch": 4.711751662971175,
      "grad_norm": 0.47553151845932007,
      "learning_rate": 0.00011417331422464205,
      "loss": 0.4004,
      "step": 2125
    },
    {
      "epoch": 4.767184035476719,
      "grad_norm": 0.49698400497436523,
      "learning_rate": 0.000112393645512393,
      "loss": 0.733,
      "step": 2150
    },
    {
      "epoch": 4.822616407982261,
      "grad_norm": 0.4536716043949127,
      "learning_rate": 0.00011060998094618982,
      "loss": 0.3756,
      "step": 2175
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 0.45862236618995667,
      "learning_rate": 0.0001088228956000172,
      "loss": 0.7409,
      "step": 2200
    },
    {
      "epoch": 4.933481152993348,
      "grad_norm": 0.4646991193294525,
      "learning_rate": 0.00010703296565075867,
      "loss": 0.3386,
      "step": 2225
    },
    {
      "epoch": 4.988913525498892,
      "grad_norm": 0.48548033833503723,
      "learning_rate": 0.00010524076819243051,
      "loss": 0.7678,
      "step": 2250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6987441778182983,
      "eval_runtime": 198.6625,
      "eval_samples_per_second": 4.535,
      "eval_steps_per_second": 4.535,
      "step": 2255
    },
    {
      "epoch": 5.044345898004434,
      "grad_norm": 0.4755799472332001,
      "learning_rate": 0.00010344688105012005,
      "loss": 0.349,
      "step": 2275
    },
    {
      "epoch": 5.099778270509978,
      "grad_norm": 0.5528295040130615,
      "learning_rate": 0.00010165188259368823,
      "loss": 0.6666,
      "step": 2300
    },
    {
      "epoch": 5.155210643015521,
      "grad_norm": 0.5119068622589111,
      "learning_rate": 9.985635155129632e-05,
      "loss": 0.3882,
      "step": 2325
    },
    {
      "epoch": 5.210643015521065,
      "grad_norm": 0.5369423627853394,
      "learning_rate": 9.806086682281758e-05,
      "loss": 0.7033,
      "step": 2350
    },
    {
      "epoch": 5.266075388026607,
      "grad_norm": 0.5110085606575012,
      "learning_rate": 9.626600729319302e-05,
      "loss": 0.3801,
      "step": 2375
    },
    {
      "epoch": 5.321507760532151,
      "grad_norm": 0.5644497871398926,
      "learning_rate": 9.447235164579237e-05,
      "loss": 0.6913,
      "step": 2400
    },
    {
      "epoch": 5.376940133037694,
      "grad_norm": 0.5618342757225037,
      "learning_rate": 9.268047817583998e-05,
      "loss": 0.4024,
      "step": 2425
    },
    {
      "epoch": 5.4323725055432375,
      "grad_norm": 0.5652624368667603,
      "learning_rate": 9.089096460396552e-05,
      "loss": 0.6899,
      "step": 2450
    },
    {
      "epoch": 5.487804878048781,
      "grad_norm": 0.5133106112480164,
      "learning_rate": 8.910438788994043e-05,
      "loss": 0.3889,
      "step": 2475
    },
    {
      "epoch": 5.5432372505543235,
      "grad_norm": 0.553298830986023,
      "learning_rate": 8.732132404665947e-05,
      "loss": 0.7135,
      "step": 2500
    },
    {
      "epoch": 5.598669623059867,
      "grad_norm": 0.5624638199806213,
      "learning_rate": 8.554234795442724e-05,
      "loss": 0.3456,
      "step": 2525
    },
    {
      "epoch": 5.65410199556541,
      "grad_norm": 0.6052119135856628,
      "learning_rate": 8.376803317561048e-05,
      "loss": 0.7035,
      "step": 2550
    },
    {
      "epoch": 5.709534368070954,
      "grad_norm": 0.5647794604301453,
      "learning_rate": 8.199895176971488e-05,
      "loss": 0.3831,
      "step": 2575
    },
    {
      "epoch": 5.764966740576496,
      "grad_norm": 0.5980101227760315,
      "learning_rate": 8.023567410894639e-05,
      "loss": 0.6858,
      "step": 2600
    },
    {
      "epoch": 5.82039911308204,
      "grad_norm": 0.5166578888893127,
      "learning_rate": 7.847876869431674e-05,
      "loss": 0.3923,
      "step": 2625
    },
    {
      "epoch": 5.875831485587583,
      "grad_norm": 0.5879822969436646,
      "learning_rate": 7.672880197235222e-05,
      "loss": 0.6986,
      "step": 2650
    },
    {
      "epoch": 5.931263858093127,
      "grad_norm": 0.5016456842422485,
      "learning_rate": 7.498633815246465e-05,
      "loss": 0.3226,
      "step": 2675
    },
    {
      "epoch": 5.986696230598669,
      "grad_norm": 0.5738722085952759,
      "learning_rate": 7.3251939025044e-05,
      "loss": 0.6856,
      "step": 2700
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7119171619415283,
      "eval_runtime": 198.5803,
      "eval_samples_per_second": 4.537,
      "eval_steps_per_second": 4.537,
      "step": 2706
    },
    {
      "epoch": 6.042128603104213,
      "grad_norm": 0.49085143208503723,
      "learning_rate": 7.152616378033042e-05,
      "loss": 0.2974,
      "step": 2725
    },
    {
      "epoch": 6.097560975609756,
      "grad_norm": 0.5794496536254883,
      "learning_rate": 6.980956882812515e-05,
      "loss": 0.6625,
      "step": 2750
    },
    {
      "epoch": 6.1529933481153,
      "grad_norm": 0.5855565667152405,
      "learning_rate": 6.810270761839741e-05,
      "loss": 0.3524,
      "step": 2775
    },
    {
      "epoch": 6.208425720620842,
      "grad_norm": 0.6123746633529663,
      "learning_rate": 6.640613046284581e-05,
      "loss": 0.6518,
      "step": 2800
    },
    {
      "epoch": 6.263858093126386,
      "grad_norm": 0.5949437022209167,
      "learning_rate": 6.472038435747151e-05,
      "loss": 0.3667,
      "step": 2825
    },
    {
      "epoch": 6.319290465631929,
      "grad_norm": 0.6053878664970398,
      "learning_rate": 6.304601280622055e-05,
      "loss": 0.6507,
      "step": 2850
    },
    {
      "epoch": 6.3747228381374725,
      "grad_norm": 0.6289336681365967,
      "learning_rate": 6.138355564575169e-05,
      "loss": 0.3688,
      "step": 2875
    },
    {
      "epoch": 6.430155210643015,
      "grad_norm": 0.723175585269928,
      "learning_rate": 5.9733548871387e-05,
      "loss": 0.6627,
      "step": 2900
    },
    {
      "epoch": 6.4855875831485585,
      "grad_norm": 0.5475134253501892,
      "learning_rate": 5.8096524464300826e-05,
      "loss": 0.3421,
      "step": 2925
    },
    {
      "epoch": 6.541019955654102,
      "grad_norm": 0.6495052576065063,
      "learning_rate": 5.647301022000284e-05,
      "loss": 0.6743,
      "step": 2950
    },
    {
      "epoch": 6.596452328159645,
      "grad_norm": 0.5723852515220642,
      "learning_rate": 5.4863529578170744e-05,
      "loss": 0.3161,
      "step": 2975
    },
    {
      "epoch": 6.651884700665189,
      "grad_norm": 0.6714123487472534,
      "learning_rate": 5.326860145388731e-05,
      "loss": 0.6459,
      "step": 3000
    },
    {
      "epoch": 6.7073170731707314,
      "grad_norm": 0.6206068396568298,
      "learning_rate": 5.168874007033615e-05,
      "loss": 0.3236,
      "step": 3025
    },
    {
      "epoch": 6.762749445676275,
      "grad_norm": 0.6652349829673767,
      "learning_rate": 5.012445479301027e-05,
      "loss": 0.6631,
      "step": 3050
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.6270636916160583,
      "learning_rate": 4.8576249965486776e-05,
      "loss": 0.358,
      "step": 3075
    },
    {
      "epoch": 6.873614190687362,
      "grad_norm": 0.6517759561538696,
      "learning_rate": 4.704462474682055e-05,
      "loss": 0.653,
      "step": 3100
    },
    {
      "epoch": 6.929046563192904,
      "grad_norm": 0.6124897003173828,
      "learning_rate": 4.553007295060999e-05,
      "loss": 0.359,
      "step": 3125
    },
    {
      "epoch": 6.984478935698448,
      "grad_norm": 0.6335738897323608,
      "learning_rate": 4.403308288578544e-05,
      "loss": 0.6339,
      "step": 3150
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7254754900932312,
      "eval_runtime": 198.657,
      "eval_samples_per_second": 4.535,
      "eval_steps_per_second": 4.535,
      "step": 3157
    },
    {
      "epoch": 7.039911308203991,
      "grad_norm": 0.5848420858383179,
      "learning_rate": 4.255413719917294e-05,
      "loss": 0.3132,
      "step": 3175
    },
    {
      "epoch": 7.095343680709535,
      "grad_norm": 0.7024881839752197,
      "learning_rate": 4.109371271988335e-05,
      "loss": 0.6271,
      "step": 3200
    },
    {
      "epoch": 7.150776053215077,
      "grad_norm": 0.6544085741043091,
      "learning_rate": 3.9652280305577095e-05,
      "loss": 0.3339,
      "step": 3225
    },
    {
      "epoch": 7.206208425720621,
      "grad_norm": 0.6621837019920349,
      "learning_rate": 3.8230304690654304e-05,
      "loss": 0.6218,
      "step": 3250
    },
    {
      "epoch": 7.261640798226164,
      "grad_norm": 0.6169628500938416,
      "learning_rate": 3.682824433641902e-05,
      "loss": 0.3382,
      "step": 3275
    },
    {
      "epoch": 7.317073170731708,
      "grad_norm": 0.6952550411224365,
      "learning_rate": 3.5446551283266025e-05,
      "loss": 0.6207,
      "step": 3300
    },
    {
      "epoch": 7.37250554323725,
      "grad_norm": 0.7291684150695801,
      "learning_rate": 3.408567100493787e-05,
      "loss": 0.3025,
      "step": 3325
    },
    {
      "epoch": 7.427937915742794,
      "grad_norm": 0.7433757185935974,
      "learning_rate": 3.2746042264898905e-05,
      "loss": 0.6203,
      "step": 3350
    },
    {
      "epoch": 7.483370288248337,
      "grad_norm": 0.6536163687705994,
      "learning_rate": 3.142809697487298e-05,
      "loss": 0.3033,
      "step": 3375
    },
    {
      "epoch": 7.5388026607538805,
      "grad_norm": 0.72004234790802,
      "learning_rate": 3.0132260055590088e-05,
      "loss": 0.6159,
      "step": 3400
    },
    {
      "epoch": 7.594235033259423,
      "grad_norm": 0.6408752202987671,
      "learning_rate": 2.8858949299787074e-05,
      "loss": 0.2885,
      "step": 3425
    },
    {
      "epoch": 7.6496674057649665,
      "grad_norm": 0.727556586265564,
      "learning_rate": 2.760857523750637e-05,
      "loss": 0.6492,
      "step": 3450
    },
    {
      "epoch": 7.70509977827051,
      "grad_norm": 0.6223993897438049,
      "learning_rate": 2.6381541003736486e-05,
      "loss": 0.293,
      "step": 3475
    },
    {
      "epoch": 7.760532150776053,
      "grad_norm": 0.7360326647758484,
      "learning_rate": 2.5178242208436554e-05,
      "loss": 0.6278,
      "step": 3500
    },
    {
      "epoch": 7.815964523281597,
      "grad_norm": 0.6569265127182007,
      "learning_rate": 2.399906680898719e-05,
      "loss": 0.3156,
      "step": 3525
    },
    {
      "epoch": 7.871396895787139,
      "grad_norm": 0.667968213558197,
      "learning_rate": 2.284439498510854e-05,
      "loss": 0.611,
      "step": 3550
    },
    {
      "epoch": 7.926829268292683,
      "grad_norm": 0.6500259637832642,
      "learning_rate": 2.1714599016285975e-05,
      "loss": 0.3573,
      "step": 3575
    },
    {
      "epoch": 7.982261640798226,
      "grad_norm": 0.7285665273666382,
      "learning_rate": 2.0610043161742888e-05,
      "loss": 0.6452,
      "step": 3600
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7363599538803101,
      "eval_runtime": 198.5559,
      "eval_samples_per_second": 4.538,
      "eval_steps_per_second": 4.538,
      "step": 3608
    },
    {
      "epoch": 8.037694013303769,
      "grad_norm": 0.6025878190994263,
      "learning_rate": 1.9531083542999317e-05,
      "loss": 0.3289,
      "step": 3625
    },
    {
      "epoch": 8.093126385809313,
      "grad_norm": 0.7227293252944946,
      "learning_rate": 1.8478068029054386e-05,
      "loss": 0.5932,
      "step": 3650
    },
    {
      "epoch": 8.148558758314856,
      "grad_norm": 0.6343204379081726,
      "learning_rate": 1.7451336124229066e-05,
      "loss": 0.293,
      "step": 3675
    },
    {
      "epoch": 8.203991130820398,
      "grad_norm": 0.6789700388908386,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 0.608,
      "step": 3700
    },
    {
      "epoch": 8.259423503325943,
      "grad_norm": 0.6409421563148499,
      "learning_rate": 1.5478038681803254e-05,
      "loss": 0.311,
      "step": 3725
    },
    {
      "epoch": 8.314855875831485,
      "grad_norm": 0.7581982612609863,
      "learning_rate": 1.4532109358009272e-05,
      "loss": 0.6334,
      "step": 3750
    },
    {
      "epoch": 8.37028824833703,
      "grad_norm": 0.15749813616275787,
      "learning_rate": 1.3613735865825305e-05,
      "loss": 0.2485,
      "step": 3775
    },
    {
      "epoch": 8.425720620842572,
      "grad_norm": 0.7007592916488647,
      "learning_rate": 1.2723214299434982e-05,
      "loss": 0.6196,
      "step": 3800
    },
    {
      "epoch": 8.481152993348115,
      "grad_norm": 0.6015790700912476,
      "learning_rate": 1.1860831773240499e-05,
      "loss": 0.2933,
      "step": 3825
    },
    {
      "epoch": 8.536585365853659,
      "grad_norm": 0.7819767594337463,
      "learning_rate": 1.1026866329293628e-05,
      "loss": 0.6021,
      "step": 3850
    },
    {
      "epoch": 8.592017738359202,
      "grad_norm": 0.6318076848983765,
      "learning_rate": 1.0221586847651777e-05,
      "loss": 0.2775,
      "step": 3875
    },
    {
      "epoch": 8.647450110864746,
      "grad_norm": 0.7898155450820923,
      "learning_rate": 9.445252959687944e-06,
      "loss": 0.6194,
      "step": 3900
    },
    {
      "epoch": 8.702882483370288,
      "grad_norm": 0.16115987300872803,
      "learning_rate": 8.698114964382598e-06,
      "loss": 0.2501,
      "step": 3925
    },
    {
      "epoch": 8.758314855875831,
      "grad_norm": 0.7358778715133667,
      "learning_rate": 7.980413747624383e-06,
      "loss": 0.6195,
      "step": 3950
    },
    {
      "epoch": 8.813747228381375,
      "grad_norm": 0.7147247791290283,
      "learning_rate": 7.292380704545743e-06,
      "loss": 0.3026,
      "step": 3975
    },
    {
      "epoch": 8.869179600886918,
      "grad_norm": 0.8330191969871521,
      "learning_rate": 6.6342376649184855e-06,
      "loss": 0.6391,
      "step": 4000
    },
    {
      "epoch": 8.92461197339246,
      "grad_norm": 0.6847809553146362,
      "learning_rate": 6.006196821633281e-06,
      "loss": 0.3216,
      "step": 4025
    },
    {
      "epoch": 8.980044345898005,
      "grad_norm": 0.7900612950325012,
      "learning_rate": 5.408460662286241e-06,
      "loss": 0.5943,
      "step": 4050
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7446352243423462,
      "eval_runtime": 198.5422,
      "eval_samples_per_second": 4.538,
      "eval_steps_per_second": 4.538,
      "step": 4059
    },
    {
      "epoch": 9.035476718403547,
      "grad_norm": 0.5251699090003967,
      "learning_rate": 4.841221903894633e-06,
      "loss": 0.2946,
      "step": 4075
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.6920002102851868,
      "learning_rate": 4.304663430762601e-06,
      "loss": 0.6116,
      "step": 4100
    },
    {
      "epoch": 9.146341463414634,
      "grad_norm": 0.21528570353984833,
      "learning_rate": 3.7989582355172582e-06,
      "loss": 0.2724,
      "step": 4125
    },
    {
      "epoch": 9.201773835920177,
      "grad_norm": 0.7379891276359558,
      "learning_rate": 3.3242693633337983e-06,
      "loss": 0.6197,
      "step": 4150
    },
    {
      "epoch": 9.257206208425721,
      "grad_norm": 0.6583831906318665,
      "learning_rate": 2.880749859367915e-06,
      "loss": 0.2956,
      "step": 4175
    },
    {
      "epoch": 9.312638580931264,
      "grad_norm": 0.7349483966827393,
      "learning_rate": 2.4685427194122368e-06,
      "loss": 0.5971,
      "step": 4200
    },
    {
      "epoch": 9.368070953436806,
      "grad_norm": 0.39102455973625183,
      "learning_rate": 2.0877808437928637e-06,
      "loss": 0.2725,
      "step": 4225
    },
    {
      "epoch": 9.42350332594235,
      "grad_norm": 0.7386260032653809,
      "learning_rate": 1.7385869945207523e-06,
      "loss": 0.5826,
      "step": 4250
    },
    {
      "epoch": 9.478935698447893,
      "grad_norm": 0.17516127228736877,
      "learning_rate": 1.4210737557118548e-06,
      "loss": 0.261,
      "step": 4275
    },
    {
      "epoch": 9.534368070953438,
      "grad_norm": 0.7968011498451233,
      "learning_rate": 1.1353434972886878e-06,
      "loss": 0.6498,
      "step": 4300
    },
    {
      "epoch": 9.58980044345898,
      "grad_norm": 0.4560546875,
      "learning_rate": 8.814883419750786e-07,
      "loss": 0.2844,
      "step": 4325
    },
    {
      "epoch": 9.645232815964523,
      "grad_norm": 0.8031205534934998,
      "learning_rate": 6.595901355947898e-07,
      "loss": 0.6119,
      "step": 4350
    },
    {
      "epoch": 9.700665188470067,
      "grad_norm": 0.14100861549377441,
      "learning_rate": 4.6972042068341714e-07,
      "loss": 0.2606,
      "step": 4375
    },
    {
      "epoch": 9.75609756097561,
      "grad_norm": 0.7284805774688721,
      "learning_rate": 3.1194041342230695e-07,
      "loss": 0.6097,
      "step": 4400
    },
    {
      "epoch": 9.811529933481154,
      "grad_norm": 0.6758754253387451,
      "learning_rate": 1.8630098390172156e-07,
      "loss": 0.3038,
      "step": 4425
    },
    {
      "epoch": 9.866962305986696,
      "grad_norm": 0.7979736924171448,
      "learning_rate": 9.284263971972573e-08,
      "loss": 0.5997,
      "step": 4450
    },
    {
      "epoch": 9.922394678492239,
      "grad_norm": 0.6607866883277893,
      "learning_rate": 3.159551292214458e-08,
      "loss": 0.3012,
      "step": 4475
    },
    {
      "epoch": 9.977827050997783,
      "grad_norm": 0.765375018119812,
      "learning_rate": 2.5793502875459673e-09,
      "loss": 0.614,
      "step": 4500
    }
  ],
  "logging_steps": 25,
  "max_steps": 4510,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.6115599545266176e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
