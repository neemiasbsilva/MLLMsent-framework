{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4510,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05543237250554324,
      "grad_norm": 0.49698159098625183,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.2608,
      "step": 25
    },
    {
      "epoch": 0.11086474501108648,
      "grad_norm": 1.5679614543914795,
      "learning_rate": 7.352941176470589e-05,
      "loss": 2.3682,
      "step": 50
    },
    {
      "epoch": 0.1662971175166297,
      "grad_norm": 0.49134865403175354,
      "learning_rate": 0.00011029411764705884,
      "loss": 0.7041,
      "step": 75
    },
    {
      "epoch": 0.22172949002217296,
      "grad_norm": 0.974396288394928,
      "learning_rate": 0.00014705882352941178,
      "loss": 1.1278,
      "step": 100
    },
    {
      "epoch": 0.2771618625277162,
      "grad_norm": 0.4615024924278259,
      "learning_rate": 0.0001838235294117647,
      "loss": 0.6276,
      "step": 125
    },
    {
      "epoch": 0.3325942350332594,
      "grad_norm": 0.6875749230384827,
      "learning_rate": 0.00019999494449430045,
      "loss": 0.9268,
      "step": 150
    },
    {
      "epoch": 0.38802660753880264,
      "grad_norm": 0.3317379951477051,
      "learning_rate": 0.0001999607704786645,
      "loss": 0.5425,
      "step": 175
    },
    {
      "epoch": 0.4434589800443459,
      "grad_norm": 0.4278263747692108,
      "learning_rate": 0.0001998943679601577,
      "loss": 0.8672,
      "step": 200
    },
    {
      "epoch": 0.49889135254988914,
      "grad_norm": 0.363280713558197,
      "learning_rate": 0.0001997957583477163,
      "loss": 0.6086,
      "step": 225
    },
    {
      "epoch": 0.5543237250554324,
      "grad_norm": 0.6592221260070801,
      "learning_rate": 0.0001996649734342143,
      "loss": 0.8481,
      "step": 250
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 0.34791576862335205,
      "learning_rate": 0.00019950205538621292,
      "loss": 0.5591,
      "step": 275
    },
    {
      "epoch": 0.6651884700665188,
      "grad_norm": 0.49728819727897644,
      "learning_rate": 0.00019930705673036606,
      "loss": 0.8701,
      "step": 300
    },
    {
      "epoch": 0.720620842572062,
      "grad_norm": 0.3613949418067932,
      "learning_rate": 0.00019908004033648453,
      "loss": 0.6167,
      "step": 325
    },
    {
      "epoch": 0.7760532150776053,
      "grad_norm": 0.48092055320739746,
      "learning_rate": 0.00019882107939726655,
      "loss": 0.8318,
      "step": 350
    },
    {
      "epoch": 0.8314855875831486,
      "grad_norm": 0.3588334321975708,
      "learning_rate": 0.0001985302574046993,
      "loss": 0.562,
      "step": 375
    },
    {
      "epoch": 0.8869179600886918,
      "grad_norm": 0.43734773993492126,
      "learning_rate": 0.00019820766812314036,
      "loss": 0.835,
      "step": 400
    },
    {
      "epoch": 0.9423503325942351,
      "grad_norm": 0.3260622024536133,
      "learning_rate": 0.00019785341555908685,
      "loss": 0.5244,
      "step": 425
    },
    {
      "epoch": 0.9977827050997783,
      "grad_norm": 0.3983796238899231,
      "learning_rate": 0.00019746761392764253,
      "loss": 0.8225,
      "step": 450
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7599106431007385,
      "eval_runtime": 200.8157,
      "eval_samples_per_second": 4.487,
      "eval_steps_per_second": 4.487,
      "step": 451
    },
    {
      "epoch": 1.0532150776053215,
      "grad_norm": 0.30087682604789734,
      "learning_rate": 0.0001970503876156937,
      "loss": 0.4803,
      "step": 475
    },
    {
      "epoch": 1.1086474501108647,
      "grad_norm": 0.337417334318161,
      "learning_rate": 0.00019660187114180528,
      "loss": 0.8069,
      "step": 500
    },
    {
      "epoch": 1.164079822616408,
      "grad_norm": 0.3214204013347626,
      "learning_rate": 0.00019612220911285048,
      "loss": 0.5117,
      "step": 525
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 0.4336690604686737,
      "learning_rate": 0.00019561155617738797,
      "loss": 0.8102,
      "step": 550
    },
    {
      "epoch": 1.2749445676274944,
      "grad_norm": 0.3218989074230194,
      "learning_rate": 0.00019507007697580137,
      "loss": 0.5067,
      "step": 575
    },
    {
      "epoch": 1.3303769401330376,
      "grad_norm": 0.3792390823364258,
      "learning_rate": 0.00019449794608721724,
      "loss": 0.8038,
      "step": 600
    },
    {
      "epoch": 1.3858093126385809,
      "grad_norm": 0.34045884013175964,
      "learning_rate": 0.00019389534797321884,
      "loss": 0.5938,
      "step": 625
    },
    {
      "epoch": 1.441241685144124,
      "grad_norm": 0.43604326248168945,
      "learning_rate": 0.00019326247691837356,
      "loss": 0.8127,
      "step": 650
    },
    {
      "epoch": 1.4966740576496673,
      "grad_norm": 0.3386567533016205,
      "learning_rate": 0.00019259953696759328,
      "loss": 0.4736,
      "step": 675
    },
    {
      "epoch": 1.5521064301552108,
      "grad_norm": 0.37150269746780396,
      "learning_rate": 0.00019190674186034807,
      "loss": 0.8435,
      "step": 700
    },
    {
      "epoch": 1.6075388026607538,
      "grad_norm": 0.3242766857147217,
      "learning_rate": 0.00019118431496175403,
      "loss": 0.4743,
      "step": 725
    },
    {
      "epoch": 1.6629711751662972,
      "grad_norm": 0.390882670879364,
      "learning_rate": 0.00019043248919055778,
      "loss": 0.8122,
      "step": 750
    },
    {
      "epoch": 1.7184035476718402,
      "grad_norm": 0.32262101769447327,
      "learning_rate": 0.00018965150694404094,
      "loss": 0.5306,
      "step": 775
    },
    {
      "epoch": 1.7738359201773837,
      "grad_norm": 0.39443954825401306,
      "learning_rate": 0.00018884162001986821,
      "loss": 0.7912,
      "step": 800
    },
    {
      "epoch": 1.8292682926829267,
      "grad_norm": 0.32989761233329773,
      "learning_rate": 0.0001880030895349051,
      "loss": 0.4786,
      "step": 825
    },
    {
      "epoch": 1.8847006651884701,
      "grad_norm": 0.4205222725868225,
      "learning_rate": 0.0001871361858410308,
      "loss": 0.8105,
      "step": 850
    },
    {
      "epoch": 1.9401330376940134,
      "grad_norm": 0.3202891945838928,
      "learning_rate": 0.00018624118843797355,
      "loss": 0.5283,
      "step": 875
    },
    {
      "epoch": 1.9955654101995566,
      "grad_norm": 0.3285994827747345,
      "learning_rate": 0.00018531838588319683,
      "loss": 0.8046,
      "step": 900
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6950280070304871,
      "eval_runtime": 200.593,
      "eval_samples_per_second": 4.492,
      "eval_steps_per_second": 4.492,
      "step": 902
    },
    {
      "epoch": 2.0509977827050996,
      "grad_norm": 0.2938249111175537,
      "learning_rate": 0.000184368075698865,
      "loss": 0.4538,
      "step": 925
    },
    {
      "epoch": 2.106430155210643,
      "grad_norm": 0.3839150071144104,
      "learning_rate": 0.00018339056427591884,
      "loss": 0.7592,
      "step": 950
    },
    {
      "epoch": 2.1618625277161865,
      "grad_norm": 0.3085746765136719,
      "learning_rate": 0.0001823861667752914,
      "loss": 0.4387,
      "step": 975
    },
    {
      "epoch": 2.2172949002217295,
      "grad_norm": 0.3925231397151947,
      "learning_rate": 0.00018135520702629675,
      "loss": 0.8022,
      "step": 1000
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.36943310499191284,
      "learning_rate": 0.0001802980174222235,
      "loss": 0.4401,
      "step": 1025
    },
    {
      "epoch": 2.328159645232816,
      "grad_norm": 0.38692253828048706,
      "learning_rate": 0.0001792149388131674,
      "loss": 0.7849,
      "step": 1050
    },
    {
      "epoch": 2.3835920177383594,
      "grad_norm": 0.3596789538860321,
      "learning_rate": 0.00017810632039613736,
      "loss": 0.5318,
      "step": 1075
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 0.3793981969356537,
      "learning_rate": 0.00017697251960247036,
      "loss": 0.7771,
      "step": 1100
    },
    {
      "epoch": 2.494456762749446,
      "grad_norm": 0.3159196078777313,
      "learning_rate": 0.00017581390198259138,
      "loss": 0.4791,
      "step": 1125
    },
    {
      "epoch": 2.549889135254989,
      "grad_norm": 0.39575624465942383,
      "learning_rate": 0.00017463084108815586,
      "loss": 0.7644,
      "step": 1150
    },
    {
      "epoch": 2.6053215077605323,
      "grad_norm": 0.3310855031013489,
      "learning_rate": 0.00017342371835161227,
      "loss": 0.4604,
      "step": 1175
    },
    {
      "epoch": 2.6607538802660753,
      "grad_norm": 0.40481001138687134,
      "learning_rate": 0.00017219292296322385,
      "loss": 0.7527,
      "step": 1200
    },
    {
      "epoch": 2.7161862527716187,
      "grad_norm": 0.3291846215724945,
      "learning_rate": 0.0001709388517455893,
      "loss": 0.485,
      "step": 1225
    },
    {
      "epoch": 2.7716186252771617,
      "grad_norm": 0.3822726011276245,
      "learning_rate": 0.00016966190902570257,
      "loss": 0.7927,
      "step": 1250
    },
    {
      "epoch": 2.827050997782705,
      "grad_norm": 0.33140212297439575,
      "learning_rate": 0.0001683625065045931,
      "loss": 0.4359,
      "step": 1275
    },
    {
      "epoch": 2.882483370288248,
      "grad_norm": 0.4086499810218811,
      "learning_rate": 0.00016704106312458877,
      "loss": 0.7604,
      "step": 1300
    },
    {
      "epoch": 2.9379157427937916,
      "grad_norm": 0.3366744816303253,
      "learning_rate": 0.00016569800493424413,
      "loss": 0.5027,
      "step": 1325
    },
    {
      "epoch": 2.9933481152993346,
      "grad_norm": 0.33028584718704224,
      "learning_rate": 0.00016433376495097717,
      "loss": 0.763,
      "step": 1350
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6628913283348083,
      "eval_runtime": 200.6289,
      "eval_samples_per_second": 4.491,
      "eval_steps_per_second": 4.491,
      "step": 1353
    },
    {
      "epoch": 3.048780487804878,
      "grad_norm": 0.36074256896972656,
      "learning_rate": 0.00016294878302145987,
      "loss": 0.3685,
      "step": 1375
    },
    {
      "epoch": 3.104212860310421,
      "grad_norm": 0.3962826430797577,
      "learning_rate": 0.00016154350567980635,
      "loss": 0.757,
      "step": 1400
    },
    {
      "epoch": 3.1596452328159645,
      "grad_norm": 0.4061407446861267,
      "learning_rate": 0.00016011838600360508,
      "loss": 0.4654,
      "step": 1425
    },
    {
      "epoch": 3.2150776053215075,
      "grad_norm": 0.4204391837120056,
      "learning_rate": 0.0001586738834678418,
      "loss": 0.726,
      "step": 1450
    },
    {
      "epoch": 3.270509977827051,
      "grad_norm": 0.3791252076625824,
      "learning_rate": 0.000157210463796759,
      "loss": 0.4188,
      "step": 1475
    },
    {
      "epoch": 3.3259423503325944,
      "grad_norm": 0.4462960362434387,
      "learning_rate": 0.00015572859881370148,
      "loss": 0.7078,
      "step": 1500
    },
    {
      "epoch": 3.3813747228381374,
      "grad_norm": 0.3652803897857666,
      "learning_rate": 0.0001542287662889948,
      "loss": 0.4803,
      "step": 1525
    },
    {
      "epoch": 3.436807095343681,
      "grad_norm": 0.4489710032939911,
      "learning_rate": 0.00015271144978590685,
      "loss": 0.7222,
      "step": 1550
    },
    {
      "epoch": 3.492239467849224,
      "grad_norm": 0.37471839785575867,
      "learning_rate": 0.00015117713850474135,
      "loss": 0.3511,
      "step": 1575
    },
    {
      "epoch": 3.5476718403547673,
      "grad_norm": 0.4323362112045288,
      "learning_rate": 0.00014962632712511395,
      "loss": 0.7081,
      "step": 1600
    },
    {
      "epoch": 3.6031042128603104,
      "grad_norm": 0.368940532207489,
      "learning_rate": 0.00014805951564646213,
      "loss": 0.4557,
      "step": 1625
    },
    {
      "epoch": 3.658536585365854,
      "grad_norm": 0.4093596935272217,
      "learning_rate": 0.0001464772092268393,
      "loss": 0.7284,
      "step": 1650
    },
    {
      "epoch": 3.713968957871397,
      "grad_norm": 0.39943408966064453,
      "learning_rate": 0.00014487991802004623,
      "loss": 0.375,
      "step": 1675
    },
    {
      "epoch": 3.7694013303769403,
      "grad_norm": 0.4232848882675171,
      "learning_rate": 0.00014326815701115156,
      "loss": 0.7466,
      "step": 1700
    },
    {
      "epoch": 3.8248337028824833,
      "grad_norm": 0.39209693670272827,
      "learning_rate": 0.0001416424458504546,
      "loss": 0.4951,
      "step": 1725
    },
    {
      "epoch": 3.8802660753880267,
      "grad_norm": 0.4252246618270874,
      "learning_rate": 0.00014000330868594427,
      "loss": 0.7435,
      "step": 1750
    },
    {
      "epoch": 3.9356984478935697,
      "grad_norm": 0.3890734910964966,
      "learning_rate": 0.00013835127399430748,
      "loss": 0.4576,
      "step": 1775
    },
    {
      "epoch": 3.991130820399113,
      "grad_norm": 0.41637101769447327,
      "learning_rate": 0.00013668687441054252,
      "loss": 0.7381,
      "step": 1800
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6559578776359558,
      "eval_runtime": 200.675,
      "eval_samples_per_second": 4.49,
      "eval_steps_per_second": 4.49,
      "step": 1804
    },
    {
      "epoch": 4.046563192904657,
      "grad_norm": 0.36927759647369385,
      "learning_rate": 0.00013501064655623094,
      "loss": 0.4125,
      "step": 1825
    },
    {
      "epoch": 4.101995565410199,
      "grad_norm": 0.45824503898620605,
      "learning_rate": 0.00013332313086652516,
      "loss": 0.6748,
      "step": 1850
    },
    {
      "epoch": 4.157427937915743,
      "grad_norm": 0.4421044886112213,
      "learning_rate": 0.0001316248714159054,
      "loss": 0.4225,
      "step": 1875
    },
    {
      "epoch": 4.212860310421286,
      "grad_norm": 0.4630393981933594,
      "learning_rate": 0.00012991641574276418,
      "loss": 0.6882,
      "step": 1900
    },
    {
      "epoch": 4.2682926829268295,
      "grad_norm": 0.44904524087905884,
      "learning_rate": 0.0001281983146728735,
      "loss": 0.3676,
      "step": 1925
    },
    {
      "epoch": 4.323725055432373,
      "grad_norm": 0.43677574396133423,
      "learning_rate": 0.00012647112214179222,
      "loss": 0.6954,
      "step": 1950
    },
    {
      "epoch": 4.3791574279379155,
      "grad_norm": 0.46709832549095154,
      "learning_rate": 0.000124735395016271,
      "loss": 0.3598,
      "step": 1975
    },
    {
      "epoch": 4.434589800443459,
      "grad_norm": 0.49642035365104675,
      "learning_rate": 0.00012299169291471197,
      "loss": 0.7125,
      "step": 2000
    },
    {
      "epoch": 4.490022172949002,
      "grad_norm": 0.4390709400177002,
      "learning_rate": 0.0001212405780267412,
      "loss": 0.4353,
      "step": 2025
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.42371249198913574,
      "learning_rate": 0.00011948261493195256,
      "loss": 0.6668,
      "step": 2050
    },
    {
      "epoch": 4.600886917960088,
      "grad_norm": 0.4175018072128296,
      "learning_rate": 0.00011771837041788059,
      "loss": 0.4414,
      "step": 2075
    },
    {
      "epoch": 4.656319290465632,
      "grad_norm": 0.49421370029449463,
      "learning_rate": 0.00011594841329726158,
      "loss": 0.6821,
      "step": 2100
    },
    {
      "epoch": 4.711751662971175,
      "grad_norm": 0.46408891677856445,
      "learning_rate": 0.00011417331422464205,
      "loss": 0.3837,
      "step": 2125
    },
    {
      "epoch": 4.767184035476719,
      "grad_norm": 0.45968931913375854,
      "learning_rate": 0.000112393645512393,
      "loss": 0.683,
      "step": 2150
    },
    {
      "epoch": 4.822616407982261,
      "grad_norm": 0.4529290199279785,
      "learning_rate": 0.00011060998094618982,
      "loss": 0.3612,
      "step": 2175
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 0.44454753398895264,
      "learning_rate": 0.0001088228956000172,
      "loss": 0.6931,
      "step": 2200
    },
    {
      "epoch": 4.933481152993348,
      "grad_norm": 0.4555574953556061,
      "learning_rate": 0.00010703296565075867,
      "loss": 0.3249,
      "step": 2225
    },
    {
      "epoch": 4.988913525498892,
      "grad_norm": 0.44981831312179565,
      "learning_rate": 0.00010524076819243051,
      "loss": 0.7179,
      "step": 2250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6498012542724609,
      "eval_runtime": 200.6288,
      "eval_samples_per_second": 4.491,
      "eval_steps_per_second": 4.491,
      "step": 2255
    },
    {
      "epoch": 5.044345898004434,
      "grad_norm": 0.4645087420940399,
      "learning_rate": 0.00010344688105012005,
      "loss": 0.3324,
      "step": 2275
    },
    {
      "epoch": 5.099778270509978,
      "grad_norm": 0.4958023130893707,
      "learning_rate": 0.00010165188259368823,
      "loss": 0.6208,
      "step": 2300
    },
    {
      "epoch": 5.155210643015521,
      "grad_norm": 0.49632972478866577,
      "learning_rate": 9.985635155129632e-05,
      "loss": 0.3713,
      "step": 2325
    },
    {
      "epoch": 5.210643015521065,
      "grad_norm": 0.49170783162117004,
      "learning_rate": 9.806086682281758e-05,
      "loss": 0.6578,
      "step": 2350
    },
    {
      "epoch": 5.266075388026607,
      "grad_norm": 0.48855116963386536,
      "learning_rate": 9.626600729319302e-05,
      "loss": 0.3646,
      "step": 2375
    },
    {
      "epoch": 5.321507760532151,
      "grad_norm": 0.5031934380531311,
      "learning_rate": 9.447235164579237e-05,
      "loss": 0.6488,
      "step": 2400
    },
    {
      "epoch": 5.376940133037694,
      "grad_norm": 0.5448465347290039,
      "learning_rate": 9.268047817583998e-05,
      "loss": 0.382,
      "step": 2425
    },
    {
      "epoch": 5.4323725055432375,
      "grad_norm": 0.5285276770591736,
      "learning_rate": 9.089096460396552e-05,
      "loss": 0.6418,
      "step": 2450
    },
    {
      "epoch": 5.487804878048781,
      "grad_norm": 0.49184033274650574,
      "learning_rate": 8.910438788994043e-05,
      "loss": 0.3705,
      "step": 2475
    },
    {
      "epoch": 5.5432372505543235,
      "grad_norm": 0.5264220833778381,
      "learning_rate": 8.732132404665947e-05,
      "loss": 0.668,
      "step": 2500
    },
    {
      "epoch": 5.598669623059867,
      "grad_norm": 0.543843686580658,
      "learning_rate": 8.554234795442724e-05,
      "loss": 0.3297,
      "step": 2525
    },
    {
      "epoch": 5.65410199556541,
      "grad_norm": 0.5560997724533081,
      "learning_rate": 8.376803317561048e-05,
      "loss": 0.659,
      "step": 2550
    },
    {
      "epoch": 5.709534368070954,
      "grad_norm": 0.5374506711959839,
      "learning_rate": 8.199895176971488e-05,
      "loss": 0.3658,
      "step": 2575
    },
    {
      "epoch": 5.764966740576496,
      "grad_norm": 0.5300097465515137,
      "learning_rate": 8.023567410894639e-05,
      "loss": 0.6412,
      "step": 2600
    },
    {
      "epoch": 5.82039911308204,
      "grad_norm": 0.5088818073272705,
      "learning_rate": 7.847876869431674e-05,
      "loss": 0.3741,
      "step": 2625
    },
    {
      "epoch": 5.875831485587583,
      "grad_norm": 0.5620299577713013,
      "learning_rate": 7.672880197235222e-05,
      "loss": 0.6537,
      "step": 2650
    },
    {
      "epoch": 5.931263858093127,
      "grad_norm": 0.48437705636024475,
      "learning_rate": 7.498633815246465e-05,
      "loss": 0.3077,
      "step": 2675
    },
    {
      "epoch": 5.986696230598669,
      "grad_norm": 0.5303683876991272,
      "learning_rate": 7.3251939025044e-05,
      "loss": 0.6409,
      "step": 2700
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6625620722770691,
      "eval_runtime": 200.6082,
      "eval_samples_per_second": 4.491,
      "eval_steps_per_second": 4.491,
      "step": 2706
    },
    {
      "epoch": 6.042128603104213,
      "grad_norm": 0.47129830718040466,
      "learning_rate": 7.152616378033042e-05,
      "loss": 0.2843,
      "step": 2725
    },
    {
      "epoch": 6.097560975609756,
      "grad_norm": 0.5455068349838257,
      "learning_rate": 6.980956882812515e-05,
      "loss": 0.6202,
      "step": 2750
    },
    {
      "epoch": 6.1529933481153,
      "grad_norm": 0.5648511648178101,
      "learning_rate": 6.810270761839741e-05,
      "loss": 0.3342,
      "step": 2775
    },
    {
      "epoch": 6.208425720620842,
      "grad_norm": 0.5864396095275879,
      "learning_rate": 6.640613046284581e-05,
      "loss": 0.6096,
      "step": 2800
    },
    {
      "epoch": 6.263858093126386,
      "grad_norm": 0.5673063397407532,
      "learning_rate": 6.472038435747151e-05,
      "loss": 0.3499,
      "step": 2825
    },
    {
      "epoch": 6.319290465631929,
      "grad_norm": 0.5622184872627258,
      "learning_rate": 6.304601280622055e-05,
      "loss": 0.6081,
      "step": 2850
    },
    {
      "epoch": 6.3747228381374725,
      "grad_norm": 0.5640596151351929,
      "learning_rate": 6.138355564575169e-05,
      "loss": 0.3517,
      "step": 2875
    },
    {
      "epoch": 6.430155210643015,
      "grad_norm": 0.651023805141449,
      "learning_rate": 5.9733548871387e-05,
      "loss": 0.6185,
      "step": 2900
    },
    {
      "epoch": 6.4855875831485585,
      "grad_norm": 0.5390425324440002,
      "learning_rate": 5.8096524464300826e-05,
      "loss": 0.3244,
      "step": 2925
    },
    {
      "epoch": 6.541019955654102,
      "grad_norm": 0.612296998500824,
      "learning_rate": 5.647301022000284e-05,
      "loss": 0.6343,
      "step": 2950
    },
    {
      "epoch": 6.596452328159645,
      "grad_norm": 0.5770643353462219,
      "learning_rate": 5.4863529578170744e-05,
      "loss": 0.3006,
      "step": 2975
    },
    {
      "epoch": 6.651884700665189,
      "grad_norm": 0.6319742202758789,
      "learning_rate": 5.326860145388731e-05,
      "loss": 0.6053,
      "step": 3000
    },
    {
      "epoch": 6.7073170731707314,
      "grad_norm": 0.5871139168739319,
      "learning_rate": 5.168874007033615e-05,
      "loss": 0.3079,
      "step": 3025
    },
    {
      "epoch": 6.762749445676275,
      "grad_norm": 0.6017995476722717,
      "learning_rate": 5.012445479301027e-05,
      "loss": 0.6221,
      "step": 3050
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.5926482081413269,
      "learning_rate": 4.8576249965486776e-05,
      "loss": 0.3405,
      "step": 3075
    },
    {
      "epoch": 6.873614190687362,
      "grad_norm": 0.623304009437561,
      "learning_rate": 4.704462474682055e-05,
      "loss": 0.6135,
      "step": 3100
    },
    {
      "epoch": 6.929046563192904,
      "grad_norm": 0.6092343330383301,
      "learning_rate": 4.553007295060999e-05,
      "loss": 0.3415,
      "step": 3125
    },
    {
      "epoch": 6.984478935698448,
      "grad_norm": 0.6045196056365967,
      "learning_rate": 4.403308288578544e-05,
      "loss": 0.5952,
      "step": 3150
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.6739927530288696,
      "eval_runtime": 200.8202,
      "eval_samples_per_second": 4.487,
      "eval_steps_per_second": 4.487,
      "step": 3157
    },
    {
      "epoch": 7.039911308203991,
      "grad_norm": 0.5704502463340759,
      "learning_rate": 4.255413719917294e-05,
      "loss": 0.2981,
      "step": 3175
    },
    {
      "epoch": 7.095343680709535,
      "grad_norm": 0.6322420239448547,
      "learning_rate": 4.109371271988335e-05,
      "loss": 0.591,
      "step": 3200
    },
    {
      "epoch": 7.150776053215077,
      "grad_norm": 0.6395648121833801,
      "learning_rate": 3.9652280305577095e-05,
      "loss": 0.3171,
      "step": 3225
    },
    {
      "epoch": 7.206208425720621,
      "grad_norm": 0.6174746751785278,
      "learning_rate": 3.8230304690654304e-05,
      "loss": 0.5842,
      "step": 3250
    },
    {
      "epoch": 7.261640798226164,
      "grad_norm": 0.595490038394928,
      "learning_rate": 3.682824433641902e-05,
      "loss": 0.3198,
      "step": 3275
    },
    {
      "epoch": 7.317073170731708,
      "grad_norm": 0.6629977822303772,
      "learning_rate": 3.5446551283266025e-05,
      "loss": 0.584,
      "step": 3300
    },
    {
      "epoch": 7.37250554323725,
      "grad_norm": 0.6969617605209351,
      "learning_rate": 3.408567100493787e-05,
      "loss": 0.2895,
      "step": 3325
    },
    {
      "epoch": 7.427937915742794,
      "grad_norm": 0.6847143769264221,
      "learning_rate": 3.2746042264898905e-05,
      "loss": 0.5839,
      "step": 3350
    },
    {
      "epoch": 7.483370288248337,
      "grad_norm": 0.6613551378250122,
      "learning_rate": 3.142809697487298e-05,
      "loss": 0.2899,
      "step": 3375
    },
    {
      "epoch": 7.5388026607538805,
      "grad_norm": 0.6537290215492249,
      "learning_rate": 3.0132260055590088e-05,
      "loss": 0.575,
      "step": 3400
    },
    {
      "epoch": 7.594235033259423,
      "grad_norm": 0.6335256695747375,
      "learning_rate": 2.8858949299787074e-05,
      "loss": 0.2726,
      "step": 3425
    },
    {
      "epoch": 7.6496674057649665,
      "grad_norm": 0.6811407208442688,
      "learning_rate": 2.760857523750637e-05,
      "loss": 0.6117,
      "step": 3450
    },
    {
      "epoch": 7.70509977827051,
      "grad_norm": 0.6009476184844971,
      "learning_rate": 2.6381541003736486e-05,
      "loss": 0.2765,
      "step": 3475
    },
    {
      "epoch": 7.760532150776053,
      "grad_norm": 0.703362226486206,
      "learning_rate": 2.5178242208436554e-05,
      "loss": 0.5893,
      "step": 3500
    },
    {
      "epoch": 7.815964523281597,
      "grad_norm": 0.6411500573158264,
      "learning_rate": 2.399906680898719e-05,
      "loss": 0.3008,
      "step": 3525
    },
    {
      "epoch": 7.871396895787139,
      "grad_norm": 0.6406914591789246,
      "learning_rate": 2.284439498510854e-05,
      "loss": 0.5696,
      "step": 3550
    },
    {
      "epoch": 7.926829268292683,
      "grad_norm": 0.6343733072280884,
      "learning_rate": 2.1714599016285975e-05,
      "loss": 0.3376,
      "step": 3575
    },
    {
      "epoch": 7.982261640798226,
      "grad_norm": 0.674971878528595,
      "learning_rate": 2.0610043161742888e-05,
      "loss": 0.6,
      "step": 3600
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.6884672045707703,
      "eval_runtime": 200.5713,
      "eval_samples_per_second": 4.492,
      "eval_steps_per_second": 4.492,
      "step": 3608
    },
    {
      "epoch": 8.037694013303769,
      "grad_norm": 0.6000550985336304,
      "learning_rate": 1.9531083542999317e-05,
      "loss": 0.3108,
      "step": 3625
    },
    {
      "epoch": 8.093126385809313,
      "grad_norm": 0.6689281463623047,
      "learning_rate": 1.8478068029054386e-05,
      "loss": 0.5583,
      "step": 3650
    },
    {
      "epoch": 8.148558758314856,
      "grad_norm": 0.6416083574295044,
      "learning_rate": 1.7451336124229066e-05,
      "loss": 0.2781,
      "step": 3675
    },
    {
      "epoch": 8.203991130820398,
      "grad_norm": 0.6354079246520996,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 0.5678,
      "step": 3700
    },
    {
      "epoch": 8.259423503325943,
      "grad_norm": 0.621383786201477,
      "learning_rate": 1.5478038681803254e-05,
      "loss": 0.2958,
      "step": 3725
    },
    {
      "epoch": 8.314855875831485,
      "grad_norm": 0.7093526124954224,
      "learning_rate": 1.4532109358009272e-05,
      "loss": 0.5938,
      "step": 3750
    },
    {
      "epoch": 8.37028824833703,
      "grad_norm": 0.1609312891960144,
      "learning_rate": 1.3613735865825305e-05,
      "loss": 0.2317,
      "step": 3775
    },
    {
      "epoch": 8.425720620842572,
      "grad_norm": 0.6496108770370483,
      "learning_rate": 1.2723214299434982e-05,
      "loss": 0.5823,
      "step": 3800
    },
    {
      "epoch": 8.481152993348115,
      "grad_norm": 0.5964774489402771,
      "learning_rate": 1.1860831773240499e-05,
      "loss": 0.2769,
      "step": 3825
    },
    {
      "epoch": 8.536585365853659,
      "grad_norm": 0.734693706035614,
      "learning_rate": 1.1026866329293628e-05,
      "loss": 0.5671,
      "step": 3850
    },
    {
      "epoch": 8.592017738359202,
      "grad_norm": 0.5951042771339417,
      "learning_rate": 1.0221586847651777e-05,
      "loss": 0.2618,
      "step": 3875
    },
    {
      "epoch": 8.647450110864746,
      "grad_norm": 0.733578085899353,
      "learning_rate": 9.445252959687944e-06,
      "loss": 0.5866,
      "step": 3900
    },
    {
      "epoch": 8.702882483370288,
      "grad_norm": 0.14648057520389557,
      "learning_rate": 8.698114964382598e-06,
      "loss": 0.2363,
      "step": 3925
    },
    {
      "epoch": 8.758314855875831,
      "grad_norm": 0.7025089263916016,
      "learning_rate": 7.980413747624383e-06,
      "loss": 0.5839,
      "step": 3950
    },
    {
      "epoch": 8.813747228381375,
      "grad_norm": 0.6882081627845764,
      "learning_rate": 7.292380704545743e-06,
      "loss": 0.2858,
      "step": 3975
    },
    {
      "epoch": 8.869179600886918,
      "grad_norm": 0.814429521560669,
      "learning_rate": 6.6342376649184855e-06,
      "loss": 0.601,
      "step": 4000
    },
    {
      "epoch": 8.92461197339246,
      "grad_norm": 0.6718090772628784,
      "learning_rate": 6.006196821633281e-06,
      "loss": 0.3041,
      "step": 4025
    },
    {
      "epoch": 8.980044345898005,
      "grad_norm": 0.7451397180557251,
      "learning_rate": 5.408460662286241e-06,
      "loss": 0.5554,
      "step": 4050
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.694130539894104,
      "eval_runtime": 200.55,
      "eval_samples_per_second": 4.493,
      "eval_steps_per_second": 4.493,
      "step": 4059
    },
    {
      "epoch": 9.035476718403547,
      "grad_norm": 0.5348451733589172,
      "learning_rate": 4.841221903894633e-06,
      "loss": 0.2759,
      "step": 4075
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.6385295987129211,
      "learning_rate": 4.304663430762601e-06,
      "loss": 0.5757,
      "step": 4100
    },
    {
      "epoch": 9.146341463414634,
      "grad_norm": 0.21785977482795715,
      "learning_rate": 3.7989582355172582e-06,
      "loss": 0.2553,
      "step": 4125
    },
    {
      "epoch": 9.201773835920177,
      "grad_norm": 0.7132108807563782,
      "learning_rate": 3.3242693633337983e-06,
      "loss": 0.5858,
      "step": 4150
    },
    {
      "epoch": 9.257206208425721,
      "grad_norm": 0.6432351469993591,
      "learning_rate": 2.880749859367915e-06,
      "loss": 0.2776,
      "step": 4175
    },
    {
      "epoch": 9.312638580931264,
      "grad_norm": 0.6899137496948242,
      "learning_rate": 2.4685427194122368e-06,
      "loss": 0.5589,
      "step": 4200
    },
    {
      "epoch": 9.368070953436806,
      "grad_norm": 0.38511261343955994,
      "learning_rate": 2.0877808437928637e-06,
      "loss": 0.2555,
      "step": 4225
    },
    {
      "epoch": 9.42350332594235,
      "grad_norm": 0.6817886829376221,
      "learning_rate": 1.7385869945207523e-06,
      "loss": 0.5453,
      "step": 4250
    },
    {
      "epoch": 9.478935698447893,
      "grad_norm": 0.1810850352048874,
      "learning_rate": 1.4210737557118548e-06,
      "loss": 0.2441,
      "step": 4275
    },
    {
      "epoch": 9.534368070953438,
      "grad_norm": 0.7216124534606934,
      "learning_rate": 1.1353434972886878e-06,
      "loss": 0.615,
      "step": 4300
    },
    {
      "epoch": 9.58980044345898,
      "grad_norm": 0.4556375741958618,
      "learning_rate": 8.814883419750786e-07,
      "loss": 0.2672,
      "step": 4325
    },
    {
      "epoch": 9.645232815964523,
      "grad_norm": 0.8136053681373596,
      "learning_rate": 6.595901355947898e-07,
      "loss": 0.5779,
      "step": 4350
    },
    {
      "epoch": 9.700665188470067,
      "grad_norm": 0.14308017492294312,
      "learning_rate": 4.6972042068341714e-07,
      "loss": 0.2482,
      "step": 4375
    },
    {
      "epoch": 9.75609756097561,
      "grad_norm": 0.69682377576828,
      "learning_rate": 3.1194041342230695e-07,
      "loss": 0.5767,
      "step": 4400
    },
    {
      "epoch": 9.811529933481154,
      "grad_norm": 0.6646219491958618,
      "learning_rate": 1.8630098390172156e-07,
      "loss": 0.2849,
      "step": 4425
    },
    {
      "epoch": 9.866962305986696,
      "grad_norm": 0.7640054821968079,
      "learning_rate": 9.284263971972573e-08,
      "loss": 0.5649,
      "step": 4450
    },
    {
      "epoch": 9.922394678492239,
      "grad_norm": 0.6692824363708496,
      "learning_rate": 3.159551292214458e-08,
      "loss": 0.2858,
      "step": 4475
    },
    {
      "epoch": 9.977827050997783,
      "grad_norm": 0.6925637125968933,
      "learning_rate": 2.5793502875459673e-09,
      "loss": 0.5747,
      "step": 4500
    }
  ],
  "logging_steps": 25,
  "max_steps": 4510,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.69024269733888e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
