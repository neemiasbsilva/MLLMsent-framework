{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 0.31970489025115967,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.4288,
      "step": 25
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43749481439590454,
      "learning_rate": 0.00013333333333333334,
      "loss": 2.0259,
      "step": 50
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2913911044597626,
      "learning_rate": 0.0002,
      "loss": 1.6176,
      "step": 75
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3854954242706299,
      "learning_rate": 0.00019994755690455152,
      "loss": 1.4354,
      "step": 100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3246726095676422,
      "learning_rate": 0.00019979028262377118,
      "loss": 1.4797,
      "step": 125
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3569619953632355,
      "learning_rate": 0.0001995283421166614,
      "loss": 1.3796,
      "step": 150
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3038838505744934,
      "learning_rate": 0.00019916201012264254,
      "loss": 1.4585,
      "step": 175
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3894812762737274,
      "learning_rate": 0.00019869167087338907,
      "loss": 1.3463,
      "step": 200
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2833542227745056,
      "learning_rate": 0.0001981178176898239,
      "loss": 1.426,
      "step": 225
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.44552043080329895,
      "learning_rate": 0.00019744105246469263,
      "loss": 1.3438,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3985412120819092,
      "eval_runtime": 219.4367,
      "eval_samples_per_second": 4.557,
      "eval_steps_per_second": 4.557,
      "step": 250
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2676401734352112,
      "learning_rate": 0.00019666208503126112,
      "loss": 1.4091,
      "step": 275
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3711712658405304,
      "learning_rate": 0.00019578173241879872,
      "loss": 1.3094,
      "step": 300
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2992367744445801,
      "learning_rate": 0.00019480091799562704,
      "loss": 1.3995,
      "step": 325
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.38915643095970154,
      "learning_rate": 0.00019372067050063438,
      "loss": 1.3062,
      "step": 350
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.26480409502983093,
      "learning_rate": 0.00019254212296427044,
      "loss": 1.3779,
      "step": 375
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.38709455728530884,
      "learning_rate": 0.00019126651152015403,
      "loss": 1.31,
      "step": 400
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2885105013847351,
      "learning_rate": 0.00018989517410853955,
      "loss": 1.4042,
      "step": 425
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.39237257838249207,
      "learning_rate": 0.00018842954907300236,
      "loss": 1.2924,
      "step": 450
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.31375399231910706,
      "learning_rate": 0.00018687117365181512,
      "loss": 1.3968,
      "step": 475
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.33867204189300537,
      "learning_rate": 0.00018522168236559695,
      "loss": 1.2945,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3661105632781982,
      "eval_runtime": 219.4004,
      "eval_samples_per_second": 4.558,
      "eval_steps_per_second": 4.558,
      "step": 500
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.2726994454860687,
      "learning_rate": 0.00018348280530292713,
      "loss": 1.3642,
      "step": 525
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.4051646292209625,
      "learning_rate": 0.0001816563663057211,
      "loss": 1.2547,
      "step": 550
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.2716018259525299,
      "learning_rate": 0.00017974428105627208,
      "loss": 1.3519,
      "step": 575
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.392325758934021,
      "learning_rate": 0.00017774855506796496,
      "loss": 1.2613,
      "step": 600
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.293295681476593,
      "learning_rate": 0.00017567128158176953,
      "loss": 1.3615,
      "step": 625
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3896680772304535,
      "learning_rate": 0.00017351463937072004,
      "loss": 1.2689,
      "step": 650
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.3001173436641693,
      "learning_rate": 0.00017128089045468294,
      "loss": 1.3529,
      "step": 675
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.4044424593448639,
      "learning_rate": 0.00016897237772781044,
      "loss": 1.2521,
      "step": 700
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.2934234142303467,
      "learning_rate": 0.00016659152250116812,
      "loss": 1.35,
      "step": 725
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.36446183919906616,
      "learning_rate": 0.000164140821963114,
      "loss": 1.2618,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3416223526000977,
      "eval_runtime": 219.4531,
      "eval_samples_per_second": 4.557,
      "eval_steps_per_second": 4.557,
      "step": 750
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.3060452342033386,
      "learning_rate": 0.00016162284656009274,
      "loss": 1.327,
      "step": 775
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.3936370015144348,
      "learning_rate": 0.00015904023730059228,
      "loss": 1.225,
      "step": 800
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.30564025044441223,
      "learning_rate": 0.00015639570298509064,
      "loss": 1.3207,
      "step": 825
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.367661714553833,
      "learning_rate": 0.0001536920173648984,
      "loss": 1.2266,
      "step": 850
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.30151331424713135,
      "learning_rate": 0.00015093201623287631,
      "loss": 1.3231,
      "step": 875
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.423297256231308,
      "learning_rate": 0.00014811859444908052,
      "loss": 1.2154,
      "step": 900
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.2965722978115082,
      "learning_rate": 0.00014525470290445392,
      "loss": 1.3269,
      "step": 925
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.3816577196121216,
      "learning_rate": 0.00014234334542574906,
      "loss": 1.2213,
      "step": 950
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.3260928690433502,
      "learning_rate": 0.00013938757562492873,
      "loss": 1.3198,
      "step": 975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.4326118230819702,
      "learning_rate": 0.00013639049369634876,
      "loss": 1.2215,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3308619260787964,
      "eval_runtime": 219.4856,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 1000
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.3296290636062622,
      "learning_rate": 0.00013335524316508208,
      "loss": 1.2773,
      "step": 1025
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.4289460778236389,
      "learning_rate": 0.00013028500758979506,
      "loss": 1.1865,
      "step": 1050
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.34549480676651,
      "learning_rate": 0.0001271830072236343,
      "loss": 1.2865,
      "step": 1075
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.42007216811180115,
      "learning_rate": 0.00012405249563662537,
      "loss": 1.1911,
      "step": 1100
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.3178543746471405,
      "learning_rate": 0.00012089675630312754,
      "loss": 1.289,
      "step": 1125
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.4180983901023865,
      "learning_rate": 0.0001177190991579223,
      "loss": 1.2002,
      "step": 1150
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.3270418345928192,
      "learning_rate": 0.00011452285712454904,
      "loss": 1.3007,
      "step": 1175
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.4224126935005188,
      "learning_rate": 0.00011131138261952845,
      "loss": 1.1882,
      "step": 1200
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.34122833609580994,
      "learning_rate": 0.00010808804403614043,
      "loss": 1.2976,
      "step": 1225
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.4547172486782074,
      "learning_rate": 0.00010485622221144484,
      "loss": 1.1896,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3271013498306274,
      "eval_runtime": 219.5636,
      "eval_samples_per_second": 4.554,
      "eval_steps_per_second": 4.554,
      "step": 1250
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.35919541120529175,
      "learning_rate": 0.00010161930688025017,
      "loss": 1.259,
      "step": 1275
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.48107680678367615,
      "learning_rate": 9.838069311974986e-05,
      "loss": 1.1678,
      "step": 1300
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.3666117489337921,
      "learning_rate": 9.514377778855521e-05,
      "loss": 1.2638,
      "step": 1325
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.43127185106277466,
      "learning_rate": 9.19119559638596e-05,
      "loss": 1.1606,
      "step": 1350
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.3619598150253296,
      "learning_rate": 8.868861738047158e-05,
      "loss": 1.269,
      "step": 1375
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.46618449687957764,
      "learning_rate": 8.5477142875451e-05,
      "loss": 1.1622,
      "step": 1400
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.3521803915500641,
      "learning_rate": 8.228090084207774e-05,
      "loss": 1.265,
      "step": 1425
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.4792802035808563,
      "learning_rate": 7.91032436968725e-05,
      "loss": 1.1561,
      "step": 1450
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.3419936001300812,
      "learning_rate": 7.594750436337467e-05,
      "loss": 1.2666,
      "step": 1475
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.4636017084121704,
      "learning_rate": 7.281699277636572e-05,
      "loss": 1.1735,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3210117816925049,
      "eval_runtime": 219.5644,
      "eval_samples_per_second": 4.554,
      "eval_steps_per_second": 4.554,
      "step": 1500
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.3728967010974884,
      "learning_rate": 6.971499241020495e-05,
      "loss": 1.24,
      "step": 1525
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.46133559942245483,
      "learning_rate": 6.664475683491796e-05,
      "loss": 1.1443,
      "step": 1550
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.37189382314682007,
      "learning_rate": 6.360950630365126e-05,
      "loss": 1.2437,
      "step": 1575
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.5057682991027832,
      "learning_rate": 6.061242437507131e-05,
      "loss": 1.1438,
      "step": 1600
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.3826856315135956,
      "learning_rate": 5.765665457425102e-05,
      "loss": 1.2502,
      "step": 1625
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.5004826188087463,
      "learning_rate": 5.474529709554612e-05,
      "loss": 1.138,
      "step": 1650
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.3632117509841919,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 1.2476,
      "step": 1675
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.4915038049221039,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 1.14,
      "step": 1700
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.3624187111854553,
      "learning_rate": 4.630798263510162e-05,
      "loss": 1.2395,
      "step": 1725
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.4980897307395935,
      "learning_rate": 4.360429701490934e-05,
      "loss": 1.1411,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3179717063903809,
      "eval_runtime": 219.4598,
      "eval_samples_per_second": 4.557,
      "eval_steps_per_second": 4.557,
      "step": 1750
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.36815929412841797,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 1.2206,
      "step": 1775
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.49816519021987915,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 1.1221,
      "step": 1800
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.37126633524894714,
      "learning_rate": 3.585917803688603e-05,
      "loss": 1.2236,
      "step": 1825
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.4963172376155853,
      "learning_rate": 3.340847749883191e-05,
      "loss": 1.1207,
      "step": 1850
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.3611752986907959,
      "learning_rate": 3.102762227218957e-05,
      "loss": 1.2314,
      "step": 1875
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.5192812085151672,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 1.129,
      "step": 1900
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.3711562752723694,
      "learning_rate": 2.6485360629279987e-05,
      "loss": 1.2274,
      "step": 1925
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.5324005484580994,
      "learning_rate": 2.432871841823047e-05,
      "loss": 1.1356,
      "step": 1950
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.3716760575771332,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 1.2279,
      "step": 1975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.5633091926574707,
      "learning_rate": 2.025571894372794e-05,
      "loss": 1.1275,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3172926902770996,
      "eval_runtime": 219.4727,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 2000
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.38650959730148315,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 1.2152,
      "step": 2025
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.541700005531311,
      "learning_rate": 1.65171946970729e-05,
      "loss": 1.1049,
      "step": 2050
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.37787097692489624,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 1.2198,
      "step": 2075
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.5009140968322754,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 1.116,
      "step": 2100
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.39501646161079407,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 1.2255,
      "step": 2125
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.5264686346054077,
      "learning_rate": 1.010482589146048e-05,
      "loss": 1.1324,
      "step": 2150
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.38018038868904114,
      "learning_rate": 8.733488479845997e-06,
      "loss": 1.2094,
      "step": 2175
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.5606094598770142,
      "learning_rate": 7.457877035729588e-06,
      "loss": 1.1128,
      "step": 2200
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.3955340087413788,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 1.2038,
      "step": 2225
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.6042414903640747,
      "learning_rate": 5.199082004372957e-06,
      "loss": 1.1185,
      "step": 2250
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3160618543624878,
      "eval_runtime": 219.4676,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 2250
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.394546777009964,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 1.2306,
      "step": 2275
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.5601796507835388,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 1.123,
      "step": 2300
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.37841686606407166,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 1.2073,
      "step": 2325
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.581221342086792,
      "learning_rate": 1.882182310176095e-06,
      "loss": 1.1162,
      "step": 2350
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.3844238817691803,
      "learning_rate": 1.30832912661093e-06,
      "loss": 1.2059,
      "step": 2375
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.5335769653320312,
      "learning_rate": 8.379898773574924e-07,
      "loss": 1.1092,
      "step": 2400
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.3891492187976837,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 1.204,
      "step": 2425
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.5537415742874146,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 1.1102,
      "step": 2450
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.37881696224212646,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 1.1972,
      "step": 2475
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.5771649479866028,
      "learning_rate": 0.0,
      "loss": 1.1017,
      "step": 2500
    }
  ],
  "logging_steps": 25,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.690233675071488e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
