{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 2895,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12953367875647667,
      "grad_norm": 0.3515342175960541,
      "learning_rate": 5.747126436781609e-05,
      "loss": 2.3453,
      "step": 25
    },
    {
      "epoch": 0.25906735751295334,
      "grad_norm": 0.2815283536911011,
      "learning_rate": 0.00011494252873563218,
      "loss": 2.0026,
      "step": 50
    },
    {
      "epoch": 0.38860103626943004,
      "grad_norm": 0.28653210401535034,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.5838,
      "step": 75
    },
    {
      "epoch": 0.5181347150259067,
      "grad_norm": 0.6563487648963928,
      "learning_rate": 0.00019998942319271077,
      "loss": 1.4235,
      "step": 100
    },
    {
      "epoch": 0.6476683937823834,
      "grad_norm": 0.29852205514907837,
      "learning_rate": 0.00019990963977153936,
      "loss": 1.4128,
      "step": 125
    },
    {
      "epoch": 0.7772020725388601,
      "grad_norm": 0.401077538728714,
      "learning_rate": 0.00019975169993441627,
      "loss": 1.3604,
      "step": 150
    },
    {
      "epoch": 0.9067357512953368,
      "grad_norm": 0.3241119086742401,
      "learning_rate": 0.0001995157272330992,
      "loss": 1.3631,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.368889331817627,
      "eval_runtime": 104.3056,
      "eval_samples_per_second": 7.363,
      "eval_steps_per_second": 7.363,
      "step": 193
    },
    {
      "epoch": 1.0362694300518134,
      "grad_norm": 0.2623767554759979,
      "learning_rate": 0.00019920190626219423,
      "loss": 1.3259,
      "step": 200
    },
    {
      "epoch": 1.16580310880829,
      "grad_norm": 0.306562215089798,
      "learning_rate": 0.0001988104825147528,
      "loss": 1.3274,
      "step": 225
    },
    {
      "epoch": 1.2953367875647668,
      "grad_norm": 0.3260055482387543,
      "learning_rate": 0.00019834176219022965,
      "loss": 1.3247,
      "step": 250
    },
    {
      "epoch": 1.4248704663212435,
      "grad_norm": 0.30380839109420776,
      "learning_rate": 0.00019779611195495177,
      "loss": 1.3193,
      "step": 275
    },
    {
      "epoch": 1.5544041450777202,
      "grad_norm": 0.33837661147117615,
      "learning_rate": 0.00019717395865528602,
      "loss": 1.3217,
      "step": 300
    },
    {
      "epoch": 1.6839378238341969,
      "grad_norm": 0.2815437912940979,
      "learning_rate": 0.0001964757889837296,
      "loss": 1.294,
      "step": 325
    },
    {
      "epoch": 1.8134715025906736,
      "grad_norm": 0.30259445309638977,
      "learning_rate": 0.00019570214909818466,
      "loss": 1.3274,
      "step": 350
    },
    {
      "epoch": 1.9430051813471503,
      "grad_norm": 0.27645573019981384,
      "learning_rate": 0.00019485364419471454,
      "loss": 1.2977,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3356434106826782,
      "eval_runtime": 104.3818,
      "eval_samples_per_second": 7.358,
      "eval_steps_per_second": 7.358,
      "step": 386
    },
    {
      "epoch": 2.0725388601036268,
      "grad_norm": 0.31541940569877625,
      "learning_rate": 0.00019393093803411686,
      "loss": 1.305,
      "step": 400
    },
    {
      "epoch": 2.2020725388601035,
      "grad_norm": 0.3086971342563629,
      "learning_rate": 0.00019293475242268223,
      "loss": 1.2634,
      "step": 425
    },
    {
      "epoch": 2.33160621761658,
      "grad_norm": 0.31733474135398865,
      "learning_rate": 0.0001918658666475465,
      "loss": 1.2893,
      "step": 450
    },
    {
      "epoch": 2.461139896373057,
      "grad_norm": 0.3019287586212158,
      "learning_rate": 0.00019072511686707663,
      "loss": 1.239,
      "step": 475
    },
    {
      "epoch": 2.5906735751295336,
      "grad_norm": 0.3118222653865814,
      "learning_rate": 0.00018951339545676866,
      "loss": 1.3112,
      "step": 500
    },
    {
      "epoch": 2.7202072538860103,
      "grad_norm": 0.33687931299209595,
      "learning_rate": 0.0001882316503111678,
      "loss": 1.2581,
      "step": 525
    },
    {
      "epoch": 2.849740932642487,
      "grad_norm": 0.2986033856868744,
      "learning_rate": 0.00018688088410235833,
      "loss": 1.3008,
      "step": 550
    },
    {
      "epoch": 2.9792746113989637,
      "grad_norm": 0.28725263476371765,
      "learning_rate": 0.00018546215349560203,
      "loss": 1.2283,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3161505460739136,
      "eval_runtime": 104.5471,
      "eval_samples_per_second": 7.346,
      "eval_steps_per_second": 7.346,
      "step": 579
    },
    {
      "epoch": 3.1088082901554404,
      "grad_norm": 0.2926512062549591,
      "learning_rate": 0.0001839765683227398,
      "loss": 1.2948,
      "step": 600
    },
    {
      "epoch": 3.238341968911917,
      "grad_norm": 0.33352625370025635,
      "learning_rate": 0.00018242529071400214,
      "loss": 1.2038,
      "step": 625
    },
    {
      "epoch": 3.3678756476683938,
      "grad_norm": 0.2863238453865051,
      "learning_rate": 0.00018080953418890853,
      "loss": 1.2887,
      "step": 650
    },
    {
      "epoch": 3.4974093264248705,
      "grad_norm": 0.3548946678638458,
      "learning_rate": 0.0001791305627069662,
      "loss": 1.1839,
      "step": 675
    },
    {
      "epoch": 3.626943005181347,
      "grad_norm": 0.2964249849319458,
      "learning_rate": 0.0001773896896789112,
      "loss": 1.2852,
      "step": 700
    },
    {
      "epoch": 3.756476683937824,
      "grad_norm": 0.33366069197654724,
      "learning_rate": 0.00017558827693926534,
      "loss": 1.1983,
      "step": 725
    },
    {
      "epoch": 3.8860103626943006,
      "grad_norm": 0.289084255695343,
      "learning_rate": 0.0001737277336810124,
      "loss": 1.2701,
      "step": 750
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3042250871658325,
      "eval_runtime": 104.4593,
      "eval_samples_per_second": 7.352,
      "eval_steps_per_second": 7.352,
      "step": 772
    },
    {
      "epoch": 4.015544041450777,
      "grad_norm": 0.3328130841255188,
      "learning_rate": 0.0001718095153532274,
      "loss": 1.1963,
      "step": 775
    },
    {
      "epoch": 4.1450777202072535,
      "grad_norm": 0.30998677015304565,
      "learning_rate": 0.00016983512252252085,
      "loss": 1.2364,
      "step": 800
    },
    {
      "epoch": 4.274611398963731,
      "grad_norm": 0.35499119758605957,
      "learning_rate": 0.0001678060996991891,
      "loss": 1.1855,
      "step": 825
    },
    {
      "epoch": 4.404145077720207,
      "grad_norm": 0.29697081446647644,
      "learning_rate": 0.00016572403412898855,
      "loss": 1.2303,
      "step": 850
    },
    {
      "epoch": 4.533678756476684,
      "grad_norm": 0.3110811710357666,
      "learning_rate": 0.0001635905545514795,
      "loss": 1.2013,
      "step": 875
    },
    {
      "epoch": 4.66321243523316,
      "grad_norm": 0.29841598868370056,
      "learning_rate": 0.0001614073299259101,
      "loss": 1.2211,
      "step": 900
    },
    {
      "epoch": 4.7927461139896375,
      "grad_norm": 0.29309558868408203,
      "learning_rate": 0.0001591760681256382,
      "loss": 1.2105,
      "step": 925
    },
    {
      "epoch": 4.922279792746114,
      "grad_norm": 0.29869726300239563,
      "learning_rate": 0.00015689851460211126,
      "loss": 1.1956,
      "step": 950
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3021897077560425,
      "eval_runtime": 104.5581,
      "eval_samples_per_second": 7.345,
      "eval_steps_per_second": 7.345,
      "step": 965
    },
    {
      "epoch": 5.051813471502591,
      "grad_norm": 0.2897723615169525,
      "learning_rate": 0.00015457645101945046,
      "loss": 1.193,
      "step": 975
    },
    {
      "epoch": 5.181347150259067,
      "grad_norm": 0.35235995054244995,
      "learning_rate": 0.00015221169386070636,
      "loss": 1.1597,
      "step": 1000
    },
    {
      "epoch": 5.310880829015544,
      "grad_norm": 0.3271603286266327,
      "learning_rate": 0.00014980609300687683,
      "loss": 1.1844,
      "step": 1025
    },
    {
      "epoch": 5.4404145077720205,
      "grad_norm": 0.34138065576553345,
      "learning_rate": 0.00014736153028979893,
      "loss": 1.1728,
      "step": 1050
    },
    {
      "epoch": 5.569948186528498,
      "grad_norm": 0.340119332075119,
      "learning_rate": 0.00014487991802004623,
      "loss": 1.1849,
      "step": 1075
    },
    {
      "epoch": 5.699481865284974,
      "grad_norm": 0.3633836805820465,
      "learning_rate": 0.00014236319749098367,
      "loss": 1.1523,
      "step": 1100
    },
    {
      "epoch": 5.829015544041451,
      "grad_norm": 0.31607770919799805,
      "learning_rate": 0.0001398133374601501,
      "loss": 1.2115,
      "step": 1125
    },
    {
      "epoch": 5.958549222797927,
      "grad_norm": 0.34734344482421875,
      "learning_rate": 0.0001372323326091563,
      "loss": 1.1541,
      "step": 1150
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.2991812229156494,
      "eval_runtime": 104.1077,
      "eval_samples_per_second": 7.377,
      "eval_steps_per_second": 7.377,
      "step": 1158
    },
    {
      "epoch": 6.0880829015544045,
      "grad_norm": 0.32465776801109314,
      "learning_rate": 0.00013462220198330328,
      "loss": 1.1816,
      "step": 1175
    },
    {
      "epoch": 6.217616580310881,
      "grad_norm": 0.38854095339775085,
      "learning_rate": 0.00013198498741214166,
      "loss": 1.1131,
      "step": 1200
    },
    {
      "epoch": 6.347150259067358,
      "grad_norm": 0.34451714158058167,
      "learning_rate": 0.00012932275191220776,
      "loss": 1.1762,
      "step": 1225
    },
    {
      "epoch": 6.476683937823834,
      "grad_norm": 0.37862738966941833,
      "learning_rate": 0.00012663757807318521,
      "loss": 1.1061,
      "step": 1250
    },
    {
      "epoch": 6.606217616580311,
      "grad_norm": 0.36281654238700867,
      "learning_rate": 0.0001239315664287558,
      "loss": 1.1921,
      "step": 1275
    },
    {
      "epoch": 6.7357512953367875,
      "grad_norm": 0.38915348052978516,
      "learning_rate": 0.00012120683381341247,
      "loss": 1.1007,
      "step": 1300
    },
    {
      "epoch": 6.865284974093264,
      "grad_norm": 0.3680448830127716,
      "learning_rate": 0.00011846551170652127,
      "loss": 1.2018,
      "step": 1325
    },
    {
      "epoch": 6.994818652849741,
      "grad_norm": 0.447613000869751,
      "learning_rate": 0.00011570974456492678,
      "loss": 1.0904,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.299896240234375,
      "eval_runtime": 104.2091,
      "eval_samples_per_second": 7.37,
      "eval_steps_per_second": 7.37,
      "step": 1351
    },
    {
      "epoch": 7.124352331606218,
      "grad_norm": 0.3534940183162689,
      "learning_rate": 0.00011294168814540553,
      "loss": 1.1843,
      "step": 1375
    },
    {
      "epoch": 7.253886010362694,
      "grad_norm": 0.3594014644622803,
      "learning_rate": 0.00011016350781828019,
      "loss": 1.0609,
      "step": 1400
    },
    {
      "epoch": 7.383419689119171,
      "grad_norm": 0.4003351926803589,
      "learning_rate": 0.00010737737687351284,
      "loss": 1.1764,
      "step": 1425
    },
    {
      "epoch": 7.512953367875648,
      "grad_norm": 0.4295710325241089,
      "learning_rate": 0.00010458547482060341,
      "loss": 1.0764,
      "step": 1450
    },
    {
      "epoch": 7.642487046632124,
      "grad_norm": 0.3935913145542145,
      "learning_rate": 0.00010178998568362243,
      "loss": 1.1529,
      "step": 1475
    },
    {
      "epoch": 7.772020725388601,
      "grad_norm": 0.4163714051246643,
      "learning_rate": 9.899309629271246e-05,
      "loss": 1.0867,
      "step": 1500
    },
    {
      "epoch": 7.901554404145077,
      "grad_norm": 0.41404151916503906,
      "learning_rate": 9.619699457339405e-05,
      "loss": 1.1527,
      "step": 1525
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3046445846557617,
      "eval_runtime": 104.2037,
      "eval_samples_per_second": 7.37,
      "eval_steps_per_second": 7.37,
      "step": 1544
    },
    {
      "epoch": 8.031088082901555,
      "grad_norm": 0.4080829620361328,
      "learning_rate": 9.340386783501507e-05,
      "loss": 1.0995,
      "step": 1550
    },
    {
      "epoch": 8.160621761658032,
      "grad_norm": 0.41163894534111023,
      "learning_rate": 9.061590105968208e-05,
      "loss": 1.1104,
      "step": 1575
    },
    {
      "epoch": 8.290155440414507,
      "grad_norm": 0.43055447936058044,
      "learning_rate": 8.783527519301204e-05,
      "loss": 1.0867,
      "step": 1600
    },
    {
      "epoch": 8.419689119170984,
      "grad_norm": 0.40579506754875183,
      "learning_rate": 8.506416543804182e-05,
      "loss": 1.0968,
      "step": 1625
    },
    {
      "epoch": 8.549222797927461,
      "grad_norm": 0.39888566732406616,
      "learning_rate": 8.23047395536298e-05,
      "loss": 1.0953,
      "step": 1650
    },
    {
      "epoch": 8.678756476683938,
      "grad_norm": 0.40999841690063477,
      "learning_rate": 7.955915615868111e-05,
      "loss": 1.1036,
      "step": 1675
    },
    {
      "epoch": 8.808290155440414,
      "grad_norm": 0.38748788833618164,
      "learning_rate": 7.682956304352243e-05,
      "loss": 1.0983,
      "step": 1700
    },
    {
      "epoch": 8.937823834196891,
      "grad_norm": 0.43272343277931213,
      "learning_rate": 7.411809548974792e-05,
      "loss": 1.084,
      "step": 1725
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3138360977172852,
      "eval_runtime": 104.192,
      "eval_samples_per_second": 7.371,
      "eval_steps_per_second": 7.371,
      "step": 1737
    },
    {
      "epoch": 9.067357512953368,
      "grad_norm": 0.37977713346481323,
      "learning_rate": 7.142687459985042e-05,
      "loss": 1.1055,
      "step": 1750
    },
    {
      "epoch": 9.196891191709845,
      "grad_norm": 0.44750070571899414,
      "learning_rate": 6.875800563794425e-05,
      "loss": 1.049,
      "step": 1775
    },
    {
      "epoch": 9.32642487046632,
      "grad_norm": 0.4173140823841095,
      "learning_rate": 6.611357638287823e-05,
      "loss": 1.0986,
      "step": 1800
    },
    {
      "epoch": 9.455958549222798,
      "grad_norm": 0.4624565541744232,
      "learning_rate": 6.349565549502676e-05,
      "loss": 1.0491,
      "step": 1825
    },
    {
      "epoch": 9.585492227979275,
      "grad_norm": 0.3967703878879547,
      "learning_rate": 6.090629089803668e-05,
      "loss": 1.0929,
      "step": 1850
    },
    {
      "epoch": 9.715025906735752,
      "grad_norm": 0.4445837438106537,
      "learning_rate": 5.834750817679606e-05,
      "loss": 1.0544,
      "step": 1875
    },
    {
      "epoch": 9.844559585492227,
      "grad_norm": 0.42227837443351746,
      "learning_rate": 5.582130899287775e-05,
      "loss": 1.1114,
      "step": 1900
    },
    {
      "epoch": 9.974093264248705,
      "grad_norm": 0.49304959177970886,
      "learning_rate": 5.33296695186977e-05,
      "loss": 1.037,
      "step": 1925
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3195953369140625,
      "eval_runtime": 104.1242,
      "eval_samples_per_second": 7.376,
      "eval_steps_per_second": 7.376,
      "step": 1930
    },
    {
      "epoch": 10.103626943005182,
      "grad_norm": 0.4229256212711334,
      "learning_rate": 5.087453889161229e-05,
      "loss": 1.103,
      "step": 1950
    },
    {
      "epoch": 10.233160621761659,
      "grad_norm": 0.4889131486415863,
      "learning_rate": 4.845783768916482e-05,
      "loss": 1.0133,
      "step": 1975
    },
    {
      "epoch": 10.362694300518134,
      "grad_norm": 0.44410255551338196,
      "learning_rate": 4.608145642667336e-05,
      "loss": 1.0955,
      "step": 2000
    },
    {
      "epoch": 10.492227979274611,
      "grad_norm": 0.5503412485122681,
      "learning_rate": 4.374725407833532e-05,
      "loss": 0.9976,
      "step": 2025
    },
    {
      "epoch": 10.621761658031089,
      "grad_norm": 0.4437737464904785,
      "learning_rate": 4.145705662300595e-05,
      "loss": 1.1133,
      "step": 2050
    },
    {
      "epoch": 10.751295336787564,
      "grad_norm": 0.42190250754356384,
      "learning_rate": 3.9212655615787804e-05,
      "loss": 0.9994,
      "step": 2075
    },
    {
      "epoch": 10.880829015544041,
      "grad_norm": 0.4422589838504791,
      "learning_rate": 3.701580678654925e-05,
      "loss": 1.1204,
      "step": 2100
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3226298093795776,
      "eval_runtime": 104.2064,
      "eval_samples_per_second": 7.37,
      "eval_steps_per_second": 7.37,
      "step": 2123
    },
    {
      "epoch": 11.010362694300518,
      "grad_norm": 0.414018452167511,
      "learning_rate": 3.4868228666467704e-05,
      "loss": 1.0109,
      "step": 2125
    },
    {
      "epoch": 11.139896373056995,
      "grad_norm": 0.43432074785232544,
      "learning_rate": 3.2771601243672825e-05,
      "loss": 1.1031,
      "step": 2150
    },
    {
      "epoch": 11.26943005181347,
      "grad_norm": 0.5003327131271362,
      "learning_rate": 3.072756464904006e-05,
      "loss": 1.02,
      "step": 2175
    },
    {
      "epoch": 11.398963730569948,
      "grad_norm": 0.46700963377952576,
      "learning_rate": 2.8737717873164094e-05,
      "loss": 1.0753,
      "step": 2200
    },
    {
      "epoch": 11.528497409326425,
      "grad_norm": 0.4701023995876312,
      "learning_rate": 2.68036175155147e-05,
      "loss": 1.0219,
      "step": 2225
    },
    {
      "epoch": 11.658031088082902,
      "grad_norm": 0.47217801213264465,
      "learning_rate": 2.492677656675414e-05,
      "loss": 1.0597,
      "step": 2250
    },
    {
      "epoch": 11.787564766839377,
      "grad_norm": 0.4855804145336151,
      "learning_rate": 2.3108663225168435e-05,
      "loss": 1.0178,
      "step": 2275
    },
    {
      "epoch": 11.917098445595855,
      "grad_norm": 0.43043455481529236,
      "learning_rate": 2.1350699748138326e-05,
      "loss": 1.0509,
      "step": 2300
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.322519302368164,
      "eval_runtime": 104.1716,
      "eval_samples_per_second": 7.372,
      "eval_steps_per_second": 7.372,
      "step": 2316
    },
    {
      "epoch": 12.046632124352332,
      "grad_norm": 0.45806577801704407,
      "learning_rate": 1.965426133954854e-05,
      "loss": 1.0406,
      "step": 2325
    },
    {
      "epoch": 12.176165803108809,
      "grad_norm": 0.47595709562301636,
      "learning_rate": 1.8020675074005723e-05,
      "loss": 1.0336,
      "step": 2350
    },
    {
      "epoch": 12.305699481865284,
      "grad_norm": 0.47079360485076904,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 1.0309,
      "step": 2375
    },
    {
      "epoch": 12.435233160621761,
      "grad_norm": 0.4964625835418701,
      "learning_rate": 1.4947120433767047e-05,
      "loss": 1.0407,
      "step": 2400
    },
    {
      "epoch": 12.564766839378239,
      "grad_norm": 0.4587317705154419,
      "learning_rate": 1.350955641179893e-05,
      "loss": 1.0439,
      "step": 2425
    },
    {
      "epoch": 12.694300518134716,
      "grad_norm": 0.5176536440849304,
      "learning_rate": 1.2139651357477788e-05,
      "loss": 1.0107,
      "step": 2450
    },
    {
      "epoch": 12.823834196891191,
      "grad_norm": 0.48340708017349243,
      "learning_rate": 1.083847690782972e-05,
      "loss": 1.0605,
      "step": 2475
    },
    {
      "epoch": 12.953367875647668,
      "grad_norm": 0.5233566761016846,
      "learning_rate": 9.607050933920459e-06,
      "loss": 1.0213,
      "step": 2500
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3244961500167847,
      "eval_runtime": 104.6659,
      "eval_samples_per_second": 7.338,
      "eval_steps_per_second": 7.338,
      "step": 2509
    },
    {
      "epoch": 13.082901554404145,
      "grad_norm": 0.47272905707359314,
      "learning_rate": 8.446336744604378e-06,
      "loss": 1.0573,
      "step": 2525
    },
    {
      "epoch": 13.212435233160623,
      "grad_norm": 0.5212017893791199,
      "learning_rate": 7.357242332955916e-06,
      "loss": 0.9964,
      "step": 2550
    },
    {
      "epoch": 13.341968911917098,
      "grad_norm": 0.46256569027900696,
      "learning_rate": 6.3406196659728465e-06,
      "loss": 1.0501,
      "step": 2575
    },
    {
      "epoch": 13.471502590673575,
      "grad_norm": 0.5217472910881042,
      "learning_rate": 5.397264018107295e-06,
      "loss": 0.9867,
      "step": 2600
    },
    {
      "epoch": 13.601036269430052,
      "grad_norm": 0.46626320481300354,
      "learning_rate": 4.527913349145441e-06,
      "loss": 1.0631,
      "step": 2625
    },
    {
      "epoch": 13.73056994818653,
      "grad_norm": 0.5557442307472229,
      "learning_rate": 3.733247726923039e-06,
      "loss": 0.9943,
      "step": 2650
    },
    {
      "epoch": 13.860103626943005,
      "grad_norm": 0.4786410927772522,
      "learning_rate": 3.013888795328057e-06,
      "loss": 1.0843,
      "step": 2675
    },
    {
      "epoch": 13.989637305699482,
      "grad_norm": 0.5947442054748535,
      "learning_rate": 2.3703992880066638e-06,
      "loss": 0.9759,
      "step": 2700
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3244444131851196,
      "eval_runtime": 104.5856,
      "eval_samples_per_second": 7.343,
      "eval_steps_per_second": 7.343,
      "step": 2702
    },
    {
      "epoch": 14.119170984455959,
      "grad_norm": 0.4882095158100128,
      "learning_rate": 1.8032825881530213e-06,
      "loss": 1.0828,
      "step": 2725
    },
    {
      "epoch": 14.248704663212436,
      "grad_norm": 0.6484671831130981,
      "learning_rate": 1.3129823347271753e-06,
      "loss": 0.968,
      "step": 2750
    },
    {
      "epoch": 14.378238341968911,
      "grad_norm": 0.4827427268028259,
      "learning_rate": 8.998820754091531e-07,
      "loss": 1.0823,
      "step": 2775
    },
    {
      "epoch": 14.507772020725389,
      "grad_norm": 0.413180947303772,
      "learning_rate": 5.643049665607691e-07,
      "loss": 0.9739,
      "step": 2800
    },
    {
      "epoch": 14.637305699481866,
      "grad_norm": 0.47069406509399414,
      "learning_rate": 3.065135204296965e-07,
      "loss": 1.0694,
      "step": 2825
    },
    {
      "epoch": 14.766839378238341,
      "grad_norm": 0.4387302100658417,
      "learning_rate": 1.2670939979384512e-07,
      "loss": 0.9847,
      "step": 2850
    },
    {
      "epoch": 14.896373056994818,
      "grad_norm": 0.47916552424430847,
      "learning_rate": 2.5033260206275277e-08,
      "loss": 1.0696,
      "step": 2875
    }
  ],
  "logging_steps": 25,
  "max_steps": 2895,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.362416053670707e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
