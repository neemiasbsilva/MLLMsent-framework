{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06377551020408163,
      "grad_norm": 0.5281851887702942,
      "learning_rate": 4.2372881355932206e-05,
      "loss": 1.4476,
      "step": 25
    },
    {
      "epoch": 0.12755102040816327,
      "grad_norm": 1.9786076545715332,
      "learning_rate": 8.474576271186441e-05,
      "loss": 2.4532,
      "step": 50
    },
    {
      "epoch": 0.1913265306122449,
      "grad_norm": 0.4961831867694855,
      "learning_rate": 0.0001271186440677966,
      "loss": 0.7165,
      "step": 75
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 3.983914375305176,
      "learning_rate": 0.00016949152542372882,
      "loss": 1.1856,
      "step": 100
    },
    {
      "epoch": 0.31887755102040816,
      "grad_norm": 0.40804871916770935,
      "learning_rate": 0.00019999832721396613,
      "loss": 0.6498,
      "step": 125
    },
    {
      "epoch": 0.3826530612244898,
      "grad_norm": 0.8775190711021423,
      "learning_rate": 0.00019996504412499123,
      "loss": 0.9522,
      "step": 150
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.3656468093395233,
      "learning_rate": 0.00019988910423768903,
      "loss": 0.5708,
      "step": 175
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.5680199861526489,
      "learning_rate": 0.00019977053995691156,
      "loss": 0.9033,
      "step": 200
    },
    {
      "epoch": 0.5739795918367347,
      "grad_norm": 0.3152208626270294,
      "learning_rate": 0.00019960940187607027,
      "loss": 0.4973,
      "step": 225
    },
    {
      "epoch": 0.6377551020408163,
      "grad_norm": 0.5420590043067932,
      "learning_rate": 0.00019940575875554715,
      "loss": 0.9395,
      "step": 250
    },
    {
      "epoch": 0.701530612244898,
      "grad_norm": 0.3605727553367615,
      "learning_rate": 0.00019915969749335343,
      "loss": 0.5813,
      "step": 275
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 0.6009392738342285,
      "learning_rate": 0.0001988713230880486,
      "loss": 0.8925,
      "step": 300
    },
    {
      "epoch": 0.8290816326530612,
      "grad_norm": 0.3258940279483795,
      "learning_rate": 0.00019854075859393588,
      "loss": 0.6068,
      "step": 325
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.42924463748931885,
      "learning_rate": 0.00019816814506855277,
      "loss": 0.9098,
      "step": 350
    },
    {
      "epoch": 0.9566326530612245,
      "grad_norm": 0.32024946808815,
      "learning_rate": 0.0001977536415124794,
      "loss": 0.6223,
      "step": 375
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7820391058921814,
      "eval_runtime": 170.3477,
      "eval_samples_per_second": 4.591,
      "eval_steps_per_second": 4.591,
      "step": 392
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.09519480168819427,
      "learning_rate": 0.00019729742480149013,
      "loss": 0.6709,
      "step": 400
    },
    {
      "epoch": 1.0841836734693877,
      "grad_norm": 0.36134371161460876,
      "learning_rate": 0.00019679968961107793,
      "loss": 0.7823,
      "step": 425
    },
    {
      "epoch": 1.1479591836734695,
      "grad_norm": 0.1251785010099411,
      "learning_rate": 0.0001962606483333827,
      "loss": 0.6383,
      "step": 450
    },
    {
      "epoch": 1.211734693877551,
      "grad_norm": 0.40047112107276917,
      "learning_rate": 0.00019568053098655992,
      "loss": 0.7938,
      "step": 475
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 0.10466346144676208,
      "learning_rate": 0.00019505958511662828,
      "loss": 0.6456,
      "step": 500
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.35623738169670105,
      "learning_rate": 0.00019439807569183713,
      "loss": 0.8053,
      "step": 525
    },
    {
      "epoch": 1.403061224489796,
      "grad_norm": 0.10819216072559357,
      "learning_rate": 0.00019369628498960032,
      "loss": 0.6183,
      "step": 550
    },
    {
      "epoch": 1.4668367346938775,
      "grad_norm": 0.38028982281684875,
      "learning_rate": 0.00019295451247604333,
      "loss": 0.7843,
      "step": 575
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 0.11267933994531631,
      "learning_rate": 0.00019217307467821616,
      "loss": 0.6392,
      "step": 600
    },
    {
      "epoch": 1.5943877551020407,
      "grad_norm": 0.3834671378135681,
      "learning_rate": 0.00019135230504902564,
      "loss": 0.7134,
      "step": 625
    },
    {
      "epoch": 1.6581632653061225,
      "grad_norm": 0.10490263253450394,
      "learning_rate": 0.00019049255382494544,
      "loss": 0.6165,
      "step": 650
    },
    {
      "epoch": 1.7219387755102042,
      "grad_norm": 0.3672287166118622,
      "learning_rate": 0.0001895941878765642,
      "loss": 0.7566,
      "step": 675
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.08814244717359543,
      "learning_rate": 0.00018865759055203542,
      "loss": 0.6155,
      "step": 700
    },
    {
      "epoch": 1.8494897959183674,
      "grad_norm": 0.41579124331474304,
      "learning_rate": 0.00018768316151349638,
      "loss": 0.7966,
      "step": 725
    },
    {
      "epoch": 1.913265306122449,
      "grad_norm": 0.10038013011217117,
      "learning_rate": 0.00018667131656652537,
      "loss": 0.6094,
      "step": 750
    },
    {
      "epoch": 1.9770408163265305,
      "grad_norm": 0.3874039947986603,
      "learning_rate": 0.00018562248748271035,
      "loss": 0.836,
      "step": 775
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7426061630249023,
      "eval_runtime": 170.4033,
      "eval_samples_per_second": 4.589,
      "eval_steps_per_second": 4.589,
      "step": 784
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.47724857926368713,
      "learning_rate": 0.00018453712181540455,
      "loss": 0.4441,
      "step": 800
    },
    {
      "epoch": 2.104591836734694,
      "grad_norm": 0.3897963762283325,
      "learning_rate": 0.0001834156827087479,
      "loss": 0.9291,
      "step": 825
    },
    {
      "epoch": 2.1683673469387754,
      "grad_norm": 0.07805618643760681,
      "learning_rate": 0.00018225864870003542,
      "loss": 0.3878,
      "step": 850
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.3807835876941681,
      "learning_rate": 0.00018106651351551705,
      "loss": 0.9053,
      "step": 875
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 0.40305396914482117,
      "learning_rate": 0.0001798397858597164,
      "loss": 0.479,
      "step": 900
    },
    {
      "epoch": 2.3596938775510203,
      "grad_norm": 0.4373268187046051,
      "learning_rate": 0.00017857898919835768,
      "loss": 0.904,
      "step": 925
    },
    {
      "epoch": 2.423469387755102,
      "grad_norm": 0.2774886190891266,
      "learning_rate": 0.00017728466153499382,
      "loss": 0.4098,
      "step": 950
    },
    {
      "epoch": 2.487244897959184,
      "grad_norm": 0.3614439368247986,
      "learning_rate": 0.00017595735518143135,
      "loss": 0.8978,
      "step": 975
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.09913966059684753,
      "learning_rate": 0.00017459763652204928,
      "loss": 0.3769,
      "step": 1000
    },
    {
      "epoch": 2.614795918367347,
      "grad_norm": 0.43978896737098694,
      "learning_rate": 0.0001732060857721133,
      "loss": 0.9142,
      "step": 1025
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.1195891946554184,
      "learning_rate": 0.00017178329673018792,
      "loss": 0.3871,
      "step": 1050
    },
    {
      "epoch": 2.74234693877551,
      "grad_norm": 0.3820701241493225,
      "learning_rate": 0.00017032987652475248,
      "loss": 0.9455,
      "step": 1075
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 0.08915320783853531,
      "learning_rate": 0.0001688464453551289,
      "loss": 0.4026,
      "step": 1100
    },
    {
      "epoch": 2.8698979591836737,
      "grad_norm": 0.4586983323097229,
      "learning_rate": 0.00016733363622683216,
      "loss": 0.9027,
      "step": 1125
    },
    {
      "epoch": 2.933673469387755,
      "grad_norm": 0.44452711939811707,
      "learning_rate": 0.0001657920946814559,
      "loss": 0.4523,
      "step": 1150
    },
    {
      "epoch": 2.997448979591837,
      "grad_norm": 0.399065226316452,
      "learning_rate": 0.00016422247852120885,
      "loss": 0.8466,
      "step": 1175
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.718148410320282,
      "eval_runtime": 170.3559,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 1176
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 0.38088351488113403,
      "learning_rate": 0.00016262545752821912,
      "loss": 0.479,
      "step": 1200
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.41061168909072876,
      "learning_rate": 0.00016100171317872696,
      "loss": 0.7659,
      "step": 1225
    },
    {
      "epoch": 3.188775510204082,
      "grad_norm": 0.36301568150520325,
      "learning_rate": 0.000159351938352287,
      "loss": 0.4761,
      "step": 1250
    },
    {
      "epoch": 3.252551020408163,
      "grad_norm": 0.4627607762813568,
      "learning_rate": 0.00015767683703610464,
      "loss": 0.7674,
      "step": 1275
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 0.3978857696056366,
      "learning_rate": 0.00015597712402463284,
      "loss": 0.4748,
      "step": 1300
    },
    {
      "epoch": 3.3801020408163267,
      "grad_norm": 0.4411039352416992,
      "learning_rate": 0.00015425352461455677,
      "loss": 0.7608,
      "step": 1325
    },
    {
      "epoch": 3.443877551020408,
      "grad_norm": 0.39140257239341736,
      "learning_rate": 0.00015250677429529756,
      "loss": 0.401,
      "step": 1350
    },
    {
      "epoch": 3.50765306122449,
      "grad_norm": 0.4649566113948822,
      "learning_rate": 0.00015073761843516619,
      "loss": 0.7626,
      "step": 1375
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.3945479094982147,
      "learning_rate": 0.0001489468119633021,
      "loss": 0.4926,
      "step": 1400
    },
    {
      "epoch": 3.635204081632653,
      "grad_norm": 0.4894166588783264,
      "learning_rate": 0.00014713511904753196,
      "loss": 0.7341,
      "step": 1425
    },
    {
      "epoch": 3.6989795918367347,
      "grad_norm": 0.4123924672603607,
      "learning_rate": 0.0001453033127682862,
      "loss": 0.4658,
      "step": 1450
    },
    {
      "epoch": 3.762755102040816,
      "grad_norm": 0.5092061758041382,
      "learning_rate": 0.00014345217478871228,
      "loss": 0.7713,
      "step": 1475
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 0.4211513102054596,
      "learning_rate": 0.0001415824950211257,
      "loss": 0.4696,
      "step": 1500
    },
    {
      "epoch": 3.8903061224489797,
      "grad_norm": 0.5247188210487366,
      "learning_rate": 0.00013969507128994078,
      "loss": 0.7846,
      "step": 1525
    },
    {
      "epoch": 3.954081632653061,
      "grad_norm": 0.3977999985218048,
      "learning_rate": 0.00013779070899122537,
      "loss": 0.5313,
      "step": 1550
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7060846090316772,
      "eval_runtime": 170.3057,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 1568
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.08065599948167801,
      "learning_rate": 0.00013587022074902443,
      "loss": 0.5715,
      "step": 1575
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.4075610339641571,
      "learning_rate": 0.00013393442606859964,
      "loss": 0.5688,
      "step": 1600
    },
    {
      "epoch": 4.145408163265306,
      "grad_norm": 0.10875722020864487,
      "learning_rate": 0.00013198415098673223,
      "loss": 0.5421,
      "step": 1625
    },
    {
      "epoch": 4.209183673469388,
      "grad_norm": 0.4367210268974304,
      "learning_rate": 0.00013002022771923898,
      "loss": 0.6346,
      "step": 1650
    },
    {
      "epoch": 4.2729591836734695,
      "grad_norm": 0.10888873785734177,
      "learning_rate": 0.0001280434943058516,
      "loss": 0.5721,
      "step": 1675
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 0.4414932429790497,
      "learning_rate": 0.00012605479425261052,
      "loss": 0.618,
      "step": 1700
    },
    {
      "epoch": 4.400510204081632,
      "grad_norm": 0.16719846427440643,
      "learning_rate": 0.0001240549761719268,
      "loss": 0.5233,
      "step": 1725
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.4815792143344879,
      "learning_rate": 0.00012204489342046424,
      "loss": 0.6443,
      "step": 1750
    },
    {
      "epoch": 4.528061224489796,
      "grad_norm": 0.1182737722992897,
      "learning_rate": 0.00012002540373499775,
      "loss": 0.505,
      "step": 1775
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 0.4524924159049988,
      "learning_rate": 0.00011799736886640227,
      "loss": 0.5413,
      "step": 1800
    },
    {
      "epoch": 4.655612244897959,
      "grad_norm": 0.10247183591127396,
      "learning_rate": 0.00011596165421192889,
      "loss": 0.5251,
      "step": 1825
    },
    {
      "epoch": 4.719387755102041,
      "grad_norm": 0.47206664085388184,
      "learning_rate": 0.00011391912844592499,
      "loss": 0.6417,
      "step": 1850
    },
    {
      "epoch": 4.783163265306122,
      "grad_norm": 0.11119382083415985,
      "learning_rate": 0.00011187066314915607,
      "loss": 0.5189,
      "step": 1875
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 0.47973063588142395,
      "learning_rate": 0.00010981713243688716,
      "loss": 0.6703,
      "step": 1900
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 0.11776383221149445,
      "learning_rate": 0.00010775941258588303,
      "loss": 0.5194,
      "step": 1925
    },
    {
      "epoch": 4.974489795918368,
      "grad_norm": 0.4254400432109833,
      "learning_rate": 0.00010569838166048573,
      "loss": 0.6618,
      "step": 1950
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7029793858528137,
      "eval_runtime": 170.3195,
      "eval_samples_per_second": 4.591,
      "eval_steps_per_second": 4.591,
      "step": 1960
    },
    {
      "epoch": 5.038265306122449,
      "grad_norm": 0.13352066278457642,
      "learning_rate": 0.00010363491913792955,
      "loss": 0.3544,
      "step": 1975
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 0.544868528842926,
      "learning_rate": 0.00010156990553305295,
      "loss": 0.7357,
      "step": 2000
    },
    {
      "epoch": 5.165816326530612,
      "grad_norm": 0.11018427461385727,
      "learning_rate": 9.950422202256781e-05,
      "loss": 0.3244,
      "step": 2025
    },
    {
      "epoch": 5.229591836734694,
      "grad_norm": 0.6517260074615479,
      "learning_rate": 9.743875006904625e-05,
      "loss": 0.6929,
      "step": 2050
    },
    {
      "epoch": 5.293367346938775,
      "grad_norm": 0.47824665904045105,
      "learning_rate": 9.537437104478538e-05,
      "loss": 0.3641,
      "step": 2075
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.5410290360450745,
      "learning_rate": 9.331196585571065e-05,
      "loss": 0.745,
      "step": 2100
    },
    {
      "epoch": 5.420918367346939,
      "grad_norm": 0.16622918844223022,
      "learning_rate": 9.125241456547825e-05,
      "loss": 0.3454,
      "step": 2125
    },
    {
      "epoch": 5.48469387755102,
      "grad_norm": 0.5060716867446899,
      "learning_rate": 8.91965960199367e-05,
      "loss": 0.7551,
      "step": 2150
    },
    {
      "epoch": 5.548469387755102,
      "grad_norm": 0.14398983120918274,
      "learning_rate": 8.714538747210847e-05,
      "loss": 0.3321,
      "step": 2175
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 0.5254843831062317,
      "learning_rate": 8.509966420785086e-05,
      "loss": 0.7133,
      "step": 2200
    },
    {
      "epoch": 5.676020408163265,
      "grad_norm": 0.11021094024181366,
      "learning_rate": 8.30602991723567e-05,
      "loss": 0.3294,
      "step": 2225
    },
    {
      "epoch": 5.739795918367347,
      "grad_norm": 0.5544053316116333,
      "learning_rate": 8.102816259765353e-05,
      "loss": 0.729,
      "step": 2250
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 0.11555442214012146,
      "learning_rate": 7.900412163126081e-05,
      "loss": 0.3173,
      "step": 2275
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 0.5743670463562012,
      "learning_rate": 7.698903996616302e-05,
      "loss": 0.7347,
      "step": 2300
    },
    {
      "epoch": 5.9311224489795915,
      "grad_norm": 0.526512861251831,
      "learning_rate": 7.498377747225725e-05,
      "loss": 0.4004,
      "step": 2325
    },
    {
      "epoch": 5.994897959183674,
      "grad_norm": 0.5339639782905579,
      "learning_rate": 7.298918982943185e-05,
      "loss": 0.6888,
      "step": 2350
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7155053019523621,
      "eval_runtime": 170.1474,
      "eval_samples_per_second": 4.596,
      "eval_steps_per_second": 4.596,
      "step": 2352
    },
    {
      "epoch": 6.058673469387755,
      "grad_norm": 0.5386434197425842,
      "learning_rate": 7.100612816243317e-05,
      "loss": 0.3545,
      "step": 2375
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 0.6188796758651733,
      "learning_rate": 6.903543867767607e-05,
      "loss": 0.6334,
      "step": 2400
    },
    {
      "epoch": 6.186224489795919,
      "grad_norm": 0.597209632396698,
      "learning_rate": 6.70779623021531e-05,
      "loss": 0.4217,
      "step": 2425
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.661479115486145,
      "learning_rate": 6.513453432459662e-05,
      "loss": 0.5945,
      "step": 2450
    },
    {
      "epoch": 6.313775510204081,
      "grad_norm": 0.6221080422401428,
      "learning_rate": 6.320598403904654e-05,
      "loss": 0.3589,
      "step": 2475
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 0.6178356409072876,
      "learning_rate": 6.129313439097663e-05,
      "loss": 0.6127,
      "step": 2500
    },
    {
      "epoch": 6.441326530612245,
      "grad_norm": 0.6458457708358765,
      "learning_rate": 5.939680162612943e-05,
      "loss": 0.3844,
      "step": 2525
    },
    {
      "epoch": 6.505102040816326,
      "grad_norm": 0.6938912868499756,
      "learning_rate": 5.75177949422102e-05,
      "loss": 0.6261,
      "step": 2550
    },
    {
      "epoch": 6.5688775510204085,
      "grad_norm": 0.5588723421096802,
      "learning_rate": 5.5656916143588364e-05,
      "loss": 0.3716,
      "step": 2575
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 0.7113167643547058,
      "learning_rate": 5.38149592991539e-05,
      "loss": 0.6162,
      "step": 2600
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 0.6319745779037476,
      "learning_rate": 5.199271040347451e-05,
      "loss": 0.3705,
      "step": 2625
    },
    {
      "epoch": 6.760204081632653,
      "grad_norm": 0.754370927810669,
      "learning_rate": 5.0190947041398216e-05,
      "loss": 0.6019,
      "step": 2650
    },
    {
      "epoch": 6.823979591836735,
      "grad_norm": 0.5819749236106873,
      "learning_rate": 4.841043805624463e-05,
      "loss": 0.3584,
      "step": 2675
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 0.6413406729698181,
      "learning_rate": 4.6651943221726294e-05,
      "loss": 0.6099,
      "step": 2700
    },
    {
      "epoch": 6.951530612244898,
      "grad_norm": 0.6418020725250244,
      "learning_rate": 4.491621291774022e-05,
      "loss": 0.4836,
      "step": 2725
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7282225489616394,
      "eval_runtime": 170.3064,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 2744
    },
    {
      "epoch": 7.01530612244898,
      "grad_norm": 0.13398778438568115,
      "learning_rate": 4.320398781016793e-05,
      "loss": 0.4716,
      "step": 2750
    },
    {
      "epoch": 7.079081632653061,
      "grad_norm": 0.624974250793457,
      "learning_rate": 4.1515998534820657e-05,
      "loss": 0.5284,
      "step": 2775
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.14885643124580383,
      "learning_rate": 3.9852965385664344e-05,
      "loss": 0.4403,
      "step": 2800
    },
    {
      "epoch": 7.206632653061225,
      "grad_norm": 0.667662501335144,
      "learning_rate": 3.8215598007458106e-05,
      "loss": 0.5375,
      "step": 2825
    },
    {
      "epoch": 7.270408163265306,
      "grad_norm": 0.18434743583202362,
      "learning_rate": 3.660459509293652e-05,
      "loss": 0.4375,
      "step": 2850
    },
    {
      "epoch": 7.334183673469388,
      "grad_norm": 0.6918783187866211,
      "learning_rate": 3.502064408466543e-05,
      "loss": 0.5053,
      "step": 2875
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 0.18554799258708954,
      "learning_rate": 3.346442088169847e-05,
      "loss": 0.4141,
      "step": 2900
    },
    {
      "epoch": 7.461734693877551,
      "grad_norm": 0.7049129009246826,
      "learning_rate": 3.193658955115932e-05,
      "loss": 0.5049,
      "step": 2925
    },
    {
      "epoch": 7.525510204081632,
      "grad_norm": 0.1672225296497345,
      "learning_rate": 3.043780204487292e-05,
      "loss": 0.4331,
      "step": 2950
    },
    {
      "epoch": 7.589285714285714,
      "grad_norm": 0.6666156053543091,
      "learning_rate": 2.8968697921166356e-05,
      "loss": 0.492,
      "step": 2975
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 0.16706030070781708,
      "learning_rate": 2.7529904071958467e-05,
      "loss": 0.4477,
      "step": 3000
    },
    {
      "epoch": 7.716836734693878,
      "grad_norm": 0.7291491627693176,
      "learning_rate": 2.612203445525424e-05,
      "loss": 0.4782,
      "step": 3025
    },
    {
      "epoch": 7.780612244897959,
      "grad_norm": 0.159367635846138,
      "learning_rate": 2.474568983315845e-05,
      "loss": 0.4505,
      "step": 3050
    },
    {
      "epoch": 7.844387755102041,
      "grad_norm": 0.7621157169342041,
      "learning_rate": 2.340145751552011e-05,
      "loss": 0.5171,
      "step": 3075
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 0.16365009546279907,
      "learning_rate": 2.2089911109317364e-05,
      "loss": 0.44,
      "step": 3100
    },
    {
      "epoch": 7.971938775510204,
      "grad_norm": 0.6952479481697083,
      "learning_rate": 2.0811610273889492e-05,
      "loss": 0.4878,
      "step": 3125
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7456454038619995,
      "eval_runtime": 170.2305,
      "eval_samples_per_second": 4.594,
      "eval_steps_per_second": 4.594,
      "step": 3136
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.17165179550647736,
      "learning_rate": 1.9567100482120672e-05,
      "loss": 0.305,
      "step": 3150
    },
    {
      "epoch": 8.099489795918368,
      "grad_norm": 0.7505248785018921,
      "learning_rate": 1.8356912787677415e-05,
      "loss": 0.6022,
      "step": 3175
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.15643297135829926,
      "learning_rate": 1.7181563598398786e-05,
      "loss": 0.2963,
      "step": 3200
    },
    {
      "epoch": 8.22704081632653,
      "grad_norm": 0.7444223165512085,
      "learning_rate": 1.6041554455936392e-05,
      "loss": 0.6296,
      "step": 3225
    },
    {
      "epoch": 8.290816326530612,
      "grad_norm": 0.14946691691875458,
      "learning_rate": 1.4937371821737888e-05,
      "loss": 0.3013,
      "step": 3250
    },
    {
      "epoch": 8.354591836734693,
      "grad_norm": 0.7091114521026611,
      "learning_rate": 1.3869486869465598e-05,
      "loss": 0.5946,
      "step": 3275
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 0.15887810289859772,
      "learning_rate": 1.2838355283938574e-05,
      "loss": 0.2959,
      "step": 3300
    },
    {
      "epoch": 8.482142857142858,
      "grad_norm": 0.8197536468505859,
      "learning_rate": 1.1844417066684154e-05,
      "loss": 0.6209,
      "step": 3325
    },
    {
      "epoch": 8.545918367346939,
      "grad_norm": 0.1573232263326645,
      "learning_rate": 1.0888096348181686e-05,
      "loss": 0.2935,
      "step": 3350
    },
    {
      "epoch": 8.60969387755102,
      "grad_norm": 0.7538822889328003,
      "learning_rate": 9.969801206878782e-06,
      "loss": 0.6397,
      "step": 3375
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 0.16181834042072296,
      "learning_rate": 9.08992349505734e-06,
      "loss": 0.2947,
      "step": 3400
    },
    {
      "epoch": 8.737244897959183,
      "grad_norm": 0.7137073874473572,
      "learning_rate": 8.24883867162336e-06,
      "loss": 0.5978,
      "step": 3425
    },
    {
      "epoch": 8.801020408163264,
      "grad_norm": 0.1537083089351654,
      "learning_rate": 7.4469056418922216e-06,
      "loss": 0.2959,
      "step": 3450
    },
    {
      "epoch": 8.864795918367347,
      "grad_norm": 0.7275494337081909,
      "learning_rate": 6.684466604437667e-06,
      "loss": 0.5939,
      "step": 3475
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.16593246161937714,
      "learning_rate": 5.961846905069712e-06,
      "loss": 0.2928,
      "step": 3500
    },
    {
      "epoch": 8.99234693877551,
      "grad_norm": 0.7913603186607361,
      "learning_rate": 5.279354898004119e-06,
      "loss": 0.5897,
      "step": 3525
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7538079023361206,
      "eval_runtime": 170.2885,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 3528
    },
    {
      "epoch": 9.056122448979592,
      "grad_norm": 0.7010271549224854,
      "learning_rate": 4.637281814282291e-06,
      "loss": 0.2805,
      "step": 3550
    },
    {
      "epoch": 9.119897959183673,
      "grad_norm": 0.7423923015594482,
      "learning_rate": 4.035901637498052e-06,
      "loss": 0.5617,
      "step": 3575
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 0.667708694934845,
      "learning_rate": 3.475470986884066e-06,
      "loss": 0.3477,
      "step": 3600
    },
    {
      "epoch": 9.247448979591837,
      "grad_norm": 0.7417333722114563,
      "learning_rate": 2.956229007808098e-06,
      "loss": 0.5333,
      "step": 3625
    },
    {
      "epoch": 9.311224489795919,
      "grad_norm": 0.6718477606773376,
      "learning_rate": 2.47839726972553e-06,
      "loss": 0.3502,
      "step": 3650
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.8060951828956604,
      "learning_rate": 2.0421796716319054e-06,
      "loss": 0.5496,
      "step": 3675
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 0.7250353097915649,
      "learning_rate": 1.6477623550557041e-06,
      "loss": 0.3452,
      "step": 3700
    },
    {
      "epoch": 9.502551020408163,
      "grad_norm": 0.7229783535003662,
      "learning_rate": 1.2953136246285914e-06,
      "loss": 0.5383,
      "step": 3725
    },
    {
      "epoch": 9.566326530612244,
      "grad_norm": 0.7145611643791199,
      "learning_rate": 9.849838762669095e-07,
      "loss": 0.3263,
      "step": 3750
    },
    {
      "epoch": 9.630102040816327,
      "grad_norm": 0.7214715480804443,
      "learning_rate": 7.169055329952046e-07,
      "loss": 0.5585,
      "step": 3775
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 0.6972310543060303,
      "learning_rate": 4.911929884390043e-07,
      "loss": 0.3362,
      "step": 3800
    },
    {
      "epoch": 9.75765306122449,
      "grad_norm": 0.7273784875869751,
      "learning_rate": 3.079425580111428e-07,
      "loss": 0.5766,
      "step": 3825
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.7242356538772583,
      "learning_rate": 1.6723243781228138e-07,
      "loss": 0.361,
      "step": 3850
    },
    {
      "epoch": 9.885204081632653,
      "grad_norm": 0.8328737020492554,
      "learning_rate": 6.912267126334416e-08,
      "loss": 0.5578,
      "step": 3875
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 0.7244930863380432,
      "learning_rate": 1.3655123483891086e-08,
      "loss": 0.4045,
      "step": 3900
    }
  ],
  "logging_steps": 25,
  "max_steps": 3920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.195338399611699e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
