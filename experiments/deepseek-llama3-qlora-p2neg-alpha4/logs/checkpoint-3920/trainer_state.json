{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06377551020408163,
      "grad_norm": 0.5953238606452942,
      "learning_rate": 4.2372881355932206e-05,
      "loss": 1.41,
      "step": 25
    },
    {
      "epoch": 0.12755102040816327,
      "grad_norm": 1.5577324628829956,
      "learning_rate": 8.474576271186441e-05,
      "loss": 2.3264,
      "step": 50
    },
    {
      "epoch": 0.1913265306122449,
      "grad_norm": 0.5646654963493347,
      "learning_rate": 0.0001271186440677966,
      "loss": 0.7143,
      "step": 75
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 2.2830893993377686,
      "learning_rate": 0.00016949152542372882,
      "loss": 1.1817,
      "step": 100
    },
    {
      "epoch": 0.31887755102040816,
      "grad_norm": 0.46890386939048767,
      "learning_rate": 0.00019999832721396613,
      "loss": 0.6463,
      "step": 125
    },
    {
      "epoch": 0.3826530612244898,
      "grad_norm": 1.094425916671753,
      "learning_rate": 0.00019996504412499123,
      "loss": 0.9519,
      "step": 150
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.3535616993904114,
      "learning_rate": 0.00019988910423768903,
      "loss": 0.5761,
      "step": 175
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.5129173994064331,
      "learning_rate": 0.00019977053995691156,
      "loss": 0.906,
      "step": 200
    },
    {
      "epoch": 0.5739795918367347,
      "grad_norm": 0.31635499000549316,
      "learning_rate": 0.00019960940187607027,
      "loss": 0.4983,
      "step": 225
    },
    {
      "epoch": 0.6377551020408163,
      "grad_norm": 0.5005261301994324,
      "learning_rate": 0.00019940575875554715,
      "loss": 0.9399,
      "step": 250
    },
    {
      "epoch": 0.701530612244898,
      "grad_norm": 0.34395185112953186,
      "learning_rate": 0.00019915969749335343,
      "loss": 0.5807,
      "step": 275
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 0.591691792011261,
      "learning_rate": 0.0001988713230880486,
      "loss": 0.8919,
      "step": 300
    },
    {
      "epoch": 0.8290816326530612,
      "grad_norm": 0.3195318579673767,
      "learning_rate": 0.00019854075859393588,
      "loss": 0.6073,
      "step": 325
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.41595908999443054,
      "learning_rate": 0.00019816814506855277,
      "loss": 0.9124,
      "step": 350
    },
    {
      "epoch": 0.9566326530612245,
      "grad_norm": 0.3291161358356476,
      "learning_rate": 0.0001977536415124794,
      "loss": 0.6224,
      "step": 375
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7865948677062988,
      "eval_runtime": 171.1108,
      "eval_samples_per_second": 4.57,
      "eval_steps_per_second": 4.57,
      "step": 392
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.09685405343770981,
      "learning_rate": 0.00019729742480149013,
      "loss": 0.6695,
      "step": 400
    },
    {
      "epoch": 1.0841836734693877,
      "grad_norm": 0.35960495471954346,
      "learning_rate": 0.00019679968961107793,
      "loss": 0.7825,
      "step": 425
    },
    {
      "epoch": 1.1479591836734695,
      "grad_norm": 0.12848886847496033,
      "learning_rate": 0.0001962606483333827,
      "loss": 0.6383,
      "step": 450
    },
    {
      "epoch": 1.211734693877551,
      "grad_norm": 0.3947743773460388,
      "learning_rate": 0.00019568053098655992,
      "loss": 0.795,
      "step": 475
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 0.10612457990646362,
      "learning_rate": 0.00019505958511662828,
      "loss": 0.6446,
      "step": 500
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.3560848832130432,
      "learning_rate": 0.00019439807569183713,
      "loss": 0.8052,
      "step": 525
    },
    {
      "epoch": 1.403061224489796,
      "grad_norm": 0.1059538945555687,
      "learning_rate": 0.00019369628498960032,
      "loss": 0.6171,
      "step": 550
    },
    {
      "epoch": 1.4668367346938775,
      "grad_norm": 0.3826468884944916,
      "learning_rate": 0.00019295451247604333,
      "loss": 0.7857,
      "step": 575
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 0.11401160061359406,
      "learning_rate": 0.00019217307467821616,
      "loss": 0.6388,
      "step": 600
    },
    {
      "epoch": 1.5943877551020407,
      "grad_norm": 0.3714558482170105,
      "learning_rate": 0.00019135230504902564,
      "loss": 0.7144,
      "step": 625
    },
    {
      "epoch": 1.6581632653061225,
      "grad_norm": 0.10088565945625305,
      "learning_rate": 0.00019049255382494544,
      "loss": 0.6173,
      "step": 650
    },
    {
      "epoch": 1.7219387755102042,
      "grad_norm": 0.37086930871009827,
      "learning_rate": 0.0001895941878765642,
      "loss": 0.7566,
      "step": 675
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.08756031841039658,
      "learning_rate": 0.00018865759055203542,
      "loss": 0.6155,
      "step": 700
    },
    {
      "epoch": 1.8494897959183674,
      "grad_norm": 0.4055725932121277,
      "learning_rate": 0.00018768316151349638,
      "loss": 0.7954,
      "step": 725
    },
    {
      "epoch": 1.913265306122449,
      "grad_norm": 0.09948127716779709,
      "learning_rate": 0.00018667131656652537,
      "loss": 0.6108,
      "step": 750
    },
    {
      "epoch": 1.9770408163265305,
      "grad_norm": 0.3818497061729431,
      "learning_rate": 0.00018562248748271035,
      "loss": 0.8341,
      "step": 775
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7491507530212402,
      "eval_runtime": 171.1566,
      "eval_samples_per_second": 4.569,
      "eval_steps_per_second": 4.569,
      "step": 784
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.4571950435638428,
      "learning_rate": 0.00018453712181540455,
      "loss": 0.4453,
      "step": 800
    },
    {
      "epoch": 2.104591836734694,
      "grad_norm": 0.3876557946205139,
      "learning_rate": 0.0001834156827087479,
      "loss": 0.9264,
      "step": 825
    },
    {
      "epoch": 2.1683673469387754,
      "grad_norm": 0.08176185190677643,
      "learning_rate": 0.00018225864870003542,
      "loss": 0.3877,
      "step": 850
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.3840004801750183,
      "learning_rate": 0.00018106651351551705,
      "loss": 0.9056,
      "step": 875
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 0.4084119498729706,
      "learning_rate": 0.0001798397858597164,
      "loss": 0.4781,
      "step": 900
    },
    {
      "epoch": 2.3596938775510203,
      "grad_norm": 0.43348750472068787,
      "learning_rate": 0.00017857898919835768,
      "loss": 0.9027,
      "step": 925
    },
    {
      "epoch": 2.423469387755102,
      "grad_norm": 0.277789831161499,
      "learning_rate": 0.00017728466153499382,
      "loss": 0.4111,
      "step": 950
    },
    {
      "epoch": 2.487244897959184,
      "grad_norm": 0.3578042984008789,
      "learning_rate": 0.00017595735518143135,
      "loss": 0.898,
      "step": 975
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.10002673417329788,
      "learning_rate": 0.00017459763652204928,
      "loss": 0.3772,
      "step": 1000
    },
    {
      "epoch": 2.614795918367347,
      "grad_norm": 0.4451944828033447,
      "learning_rate": 0.0001732060857721133,
      "loss": 0.9131,
      "step": 1025
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.11720047146081924,
      "learning_rate": 0.00017178329673018792,
      "loss": 0.3866,
      "step": 1050
    },
    {
      "epoch": 2.74234693877551,
      "grad_norm": 0.37411394715309143,
      "learning_rate": 0.00017032987652475248,
      "loss": 0.9454,
      "step": 1075
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 0.09227655827999115,
      "learning_rate": 0.0001688464453551289,
      "loss": 0.4011,
      "step": 1100
    },
    {
      "epoch": 2.8698979591836737,
      "grad_norm": 0.4675222337245941,
      "learning_rate": 0.00016733363622683216,
      "loss": 0.9019,
      "step": 1125
    },
    {
      "epoch": 2.933673469387755,
      "grad_norm": 0.44463834166526794,
      "learning_rate": 0.0001657920946814559,
      "loss": 0.4516,
      "step": 1150
    },
    {
      "epoch": 2.997448979591837,
      "grad_norm": 0.4053709805011749,
      "learning_rate": 0.00016422247852120885,
      "loss": 0.8475,
      "step": 1175
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7251479029655457,
      "eval_runtime": 171.1755,
      "eval_samples_per_second": 4.568,
      "eval_steps_per_second": 4.568,
      "step": 1176
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 0.3818656802177429,
      "learning_rate": 0.00016262545752821912,
      "loss": 0.4797,
      "step": 1200
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.4188673496246338,
      "learning_rate": 0.00016100171317872696,
      "loss": 0.766,
      "step": 1225
    },
    {
      "epoch": 3.188775510204082,
      "grad_norm": 0.3684835135936737,
      "learning_rate": 0.000159351938352287,
      "loss": 0.4743,
      "step": 1250
    },
    {
      "epoch": 3.252551020408163,
      "grad_norm": 0.46269845962524414,
      "learning_rate": 0.00015767683703610464,
      "loss": 0.7678,
      "step": 1275
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 0.40331852436065674,
      "learning_rate": 0.00015597712402463284,
      "loss": 0.4747,
      "step": 1300
    },
    {
      "epoch": 3.3801020408163267,
      "grad_norm": 0.4421415328979492,
      "learning_rate": 0.00015425352461455677,
      "loss": 0.7608,
      "step": 1325
    },
    {
      "epoch": 3.443877551020408,
      "grad_norm": 0.39310482144355774,
      "learning_rate": 0.00015250677429529756,
      "loss": 0.4011,
      "step": 1350
    },
    {
      "epoch": 3.50765306122449,
      "grad_norm": 0.4775925576686859,
      "learning_rate": 0.00015073761843516619,
      "loss": 0.7618,
      "step": 1375
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.3916723430156708,
      "learning_rate": 0.0001489468119633021,
      "loss": 0.4917,
      "step": 1400
    },
    {
      "epoch": 3.635204081632653,
      "grad_norm": 0.4951566159725189,
      "learning_rate": 0.00014713511904753196,
      "loss": 0.7327,
      "step": 1425
    },
    {
      "epoch": 3.6989795918367347,
      "grad_norm": 0.41367778182029724,
      "learning_rate": 0.0001453033127682862,
      "loss": 0.4643,
      "step": 1450
    },
    {
      "epoch": 3.762755102040816,
      "grad_norm": 0.5095522999763489,
      "learning_rate": 0.00014345217478871228,
      "loss": 0.7705,
      "step": 1475
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 0.42195215821266174,
      "learning_rate": 0.0001415824950211257,
      "loss": 0.4694,
      "step": 1500
    },
    {
      "epoch": 3.8903061224489797,
      "grad_norm": 0.5293307304382324,
      "learning_rate": 0.00013969507128994078,
      "loss": 0.7827,
      "step": 1525
    },
    {
      "epoch": 3.954081632653061,
      "grad_norm": 0.40967994928359985,
      "learning_rate": 0.00013779070899122537,
      "loss": 0.5304,
      "step": 1550
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.714120090007782,
      "eval_runtime": 171.1143,
      "eval_samples_per_second": 4.57,
      "eval_steps_per_second": 4.57,
      "step": 1568
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.08279921114444733,
      "learning_rate": 0.00013587022074902443,
      "loss": 0.5706,
      "step": 1575
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.41020670533180237,
      "learning_rate": 0.00013393442606859964,
      "loss": 0.5682,
      "step": 1600
    },
    {
      "epoch": 4.145408163265306,
      "grad_norm": 0.11253069341182709,
      "learning_rate": 0.00013198415098673223,
      "loss": 0.5409,
      "step": 1625
    },
    {
      "epoch": 4.209183673469388,
      "grad_norm": 0.448798269033432,
      "learning_rate": 0.00013002022771923898,
      "loss": 0.6351,
      "step": 1650
    },
    {
      "epoch": 4.2729591836734695,
      "grad_norm": 0.1085432767868042,
      "learning_rate": 0.0001280434943058516,
      "loss": 0.5714,
      "step": 1675
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 0.44270890951156616,
      "learning_rate": 0.00012605479425261052,
      "loss": 0.6158,
      "step": 1700
    },
    {
      "epoch": 4.400510204081632,
      "grad_norm": 0.16975684463977814,
      "learning_rate": 0.0001240549761719268,
      "loss": 0.5217,
      "step": 1725
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.48417001962661743,
      "learning_rate": 0.00012204489342046424,
      "loss": 0.6453,
      "step": 1750
    },
    {
      "epoch": 4.528061224489796,
      "grad_norm": 0.12070275843143463,
      "learning_rate": 0.00012002540373499775,
      "loss": 0.5068,
      "step": 1775
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 0.45694056153297424,
      "learning_rate": 0.00011799736886640227,
      "loss": 0.5409,
      "step": 1800
    },
    {
      "epoch": 4.655612244897959,
      "grad_norm": 0.10420920699834824,
      "learning_rate": 0.00011596165421192889,
      "loss": 0.5252,
      "step": 1825
    },
    {
      "epoch": 4.719387755102041,
      "grad_norm": 0.46367812156677246,
      "learning_rate": 0.00011391912844592499,
      "loss": 0.6428,
      "step": 1850
    },
    {
      "epoch": 4.783163265306122,
      "grad_norm": 0.109563909471035,
      "learning_rate": 0.00011187066314915607,
      "loss": 0.5182,
      "step": 1875
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 0.48203638195991516,
      "learning_rate": 0.00010981713243688716,
      "loss": 0.669,
      "step": 1900
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 0.12064063549041748,
      "learning_rate": 0.00010775941258588303,
      "loss": 0.5193,
      "step": 1925
    },
    {
      "epoch": 4.974489795918368,
      "grad_norm": 0.43016335368156433,
      "learning_rate": 0.00010569838166048573,
      "loss": 0.6612,
      "step": 1950
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7122482657432556,
      "eval_runtime": 170.3028,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 1960
    },
    {
      "epoch": 5.038265306122449,
      "grad_norm": 0.12848734855651855,
      "learning_rate": 0.00010363491913792955,
      "loss": 0.3544,
      "step": 1975
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 0.5641379952430725,
      "learning_rate": 0.00010156990553305295,
      "loss": 0.7359,
      "step": 2000
    },
    {
      "epoch": 5.165816326530612,
      "grad_norm": 0.1096828281879425,
      "learning_rate": 9.950422202256781e-05,
      "loss": 0.3237,
      "step": 2025
    },
    {
      "epoch": 5.229591836734694,
      "grad_norm": 0.7608056664466858,
      "learning_rate": 9.743875006904625e-05,
      "loss": 0.6952,
      "step": 2050
    },
    {
      "epoch": 5.293367346938775,
      "grad_norm": 0.4786533713340759,
      "learning_rate": 9.537437104478538e-05,
      "loss": 0.3634,
      "step": 2075
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.5451685786247253,
      "learning_rate": 9.331196585571065e-05,
      "loss": 0.7461,
      "step": 2100
    },
    {
      "epoch": 5.420918367346939,
      "grad_norm": 0.15632891654968262,
      "learning_rate": 9.125241456547825e-05,
      "loss": 0.3453,
      "step": 2125
    },
    {
      "epoch": 5.48469387755102,
      "grad_norm": 0.5133522748947144,
      "learning_rate": 8.91965960199367e-05,
      "loss": 0.7552,
      "step": 2150
    },
    {
      "epoch": 5.548469387755102,
      "grad_norm": 0.14271824061870575,
      "learning_rate": 8.714538747210847e-05,
      "loss": 0.3315,
      "step": 2175
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 0.5318772792816162,
      "learning_rate": 8.509966420785086e-05,
      "loss": 0.7115,
      "step": 2200
    },
    {
      "epoch": 5.676020408163265,
      "grad_norm": 0.1127631813287735,
      "learning_rate": 8.30602991723567e-05,
      "loss": 0.3296,
      "step": 2225
    },
    {
      "epoch": 5.739795918367347,
      "grad_norm": 0.5503025054931641,
      "learning_rate": 8.102816259765353e-05,
      "loss": 0.7293,
      "step": 2250
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 0.11406441032886505,
      "learning_rate": 7.900412163126081e-05,
      "loss": 0.3161,
      "step": 2275
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 0.580036997795105,
      "learning_rate": 7.698903996616302e-05,
      "loss": 0.7332,
      "step": 2300
    },
    {
      "epoch": 5.9311224489795915,
      "grad_norm": 0.5259156227111816,
      "learning_rate": 7.498377747225725e-05,
      "loss": 0.3998,
      "step": 2325
    },
    {
      "epoch": 5.994897959183674,
      "grad_norm": 0.5285922288894653,
      "learning_rate": 7.298918982943185e-05,
      "loss": 0.6871,
      "step": 2350
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7257190942764282,
      "eval_runtime": 170.2453,
      "eval_samples_per_second": 4.593,
      "eval_steps_per_second": 4.593,
      "step": 2352
    },
    {
      "epoch": 6.058673469387755,
      "grad_norm": 0.5473044514656067,
      "learning_rate": 7.100612816243317e-05,
      "loss": 0.354,
      "step": 2375
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 0.5886393785476685,
      "learning_rate": 6.903543867767607e-05,
      "loss": 0.6338,
      "step": 2400
    },
    {
      "epoch": 6.186224489795919,
      "grad_norm": 0.5700528025627136,
      "learning_rate": 6.70779623021531e-05,
      "loss": 0.4214,
      "step": 2425
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.6701704859733582,
      "learning_rate": 6.513453432459662e-05,
      "loss": 0.5897,
      "step": 2450
    },
    {
      "epoch": 6.313775510204081,
      "grad_norm": 0.6266833543777466,
      "learning_rate": 6.320598403904654e-05,
      "loss": 0.3581,
      "step": 2475
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 0.6167418956756592,
      "learning_rate": 6.129313439097663e-05,
      "loss": 0.6121,
      "step": 2500
    },
    {
      "epoch": 6.441326530612245,
      "grad_norm": 0.6549040675163269,
      "learning_rate": 5.939680162612943e-05,
      "loss": 0.3836,
      "step": 2525
    },
    {
      "epoch": 6.505102040816326,
      "grad_norm": 0.7179965376853943,
      "learning_rate": 5.75177949422102e-05,
      "loss": 0.6272,
      "step": 2550
    },
    {
      "epoch": 6.5688775510204085,
      "grad_norm": 0.5776106119155884,
      "learning_rate": 5.5656916143588364e-05,
      "loss": 0.37,
      "step": 2575
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 0.7159318923950195,
      "learning_rate": 5.38149592991539e-05,
      "loss": 0.6151,
      "step": 2600
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 0.6399040222167969,
      "learning_rate": 5.199271040347451e-05,
      "loss": 0.3704,
      "step": 2625
    },
    {
      "epoch": 6.760204081632653,
      "grad_norm": 0.8030701279640198,
      "learning_rate": 5.0190947041398216e-05,
      "loss": 0.601,
      "step": 2650
    },
    {
      "epoch": 6.823979591836735,
      "grad_norm": 0.5863262414932251,
      "learning_rate": 4.841043805624463e-05,
      "loss": 0.3578,
      "step": 2675
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 0.615317702293396,
      "learning_rate": 4.6651943221726294e-05,
      "loss": 0.612,
      "step": 2700
    },
    {
      "epoch": 6.951530612244898,
      "grad_norm": 0.6411616802215576,
      "learning_rate": 4.491621291774022e-05,
      "loss": 0.4805,
      "step": 2725
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7370984554290771,
      "eval_runtime": 170.3173,
      "eval_samples_per_second": 4.591,
      "eval_steps_per_second": 4.591,
      "step": 2744
    },
    {
      "epoch": 7.01530612244898,
      "grad_norm": 0.135055273771286,
      "learning_rate": 4.320398781016793e-05,
      "loss": 0.4714,
      "step": 2750
    },
    {
      "epoch": 7.079081632653061,
      "grad_norm": 0.6175318956375122,
      "learning_rate": 4.1515998534820657e-05,
      "loss": 0.5279,
      "step": 2775
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.14931106567382812,
      "learning_rate": 3.9852965385664344e-05,
      "loss": 0.4387,
      "step": 2800
    },
    {
      "epoch": 7.206632653061225,
      "grad_norm": 0.6606913805007935,
      "learning_rate": 3.8215598007458106e-05,
      "loss": 0.5354,
      "step": 2825
    },
    {
      "epoch": 7.270408163265306,
      "grad_norm": 0.1739584356546402,
      "learning_rate": 3.660459509293652e-05,
      "loss": 0.4371,
      "step": 2850
    },
    {
      "epoch": 7.334183673469388,
      "grad_norm": 0.7085737586021423,
      "learning_rate": 3.502064408466543e-05,
      "loss": 0.5046,
      "step": 2875
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 0.17884035408496857,
      "learning_rate": 3.346442088169847e-05,
      "loss": 0.4118,
      "step": 2900
    },
    {
      "epoch": 7.461734693877551,
      "grad_norm": 0.7171963453292847,
      "learning_rate": 3.193658955115932e-05,
      "loss": 0.5044,
      "step": 2925
    },
    {
      "epoch": 7.525510204081632,
      "grad_norm": 0.17312252521514893,
      "learning_rate": 3.043780204487292e-05,
      "loss": 0.4345,
      "step": 2950
    },
    {
      "epoch": 7.589285714285714,
      "grad_norm": 0.6892876625061035,
      "learning_rate": 2.8968697921166356e-05,
      "loss": 0.4934,
      "step": 2975
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 0.16877886652946472,
      "learning_rate": 2.7529904071958467e-05,
      "loss": 0.4496,
      "step": 3000
    },
    {
      "epoch": 7.716836734693878,
      "grad_norm": 0.742387056350708,
      "learning_rate": 2.612203445525424e-05,
      "loss": 0.4777,
      "step": 3025
    },
    {
      "epoch": 7.780612244897959,
      "grad_norm": 0.16005349159240723,
      "learning_rate": 2.474568983315845e-05,
      "loss": 0.4507,
      "step": 3050
    },
    {
      "epoch": 7.844387755102041,
      "grad_norm": 0.7734966278076172,
      "learning_rate": 2.340145751552011e-05,
      "loss": 0.5144,
      "step": 3075
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 0.16483432054519653,
      "learning_rate": 2.2089911109317364e-05,
      "loss": 0.4378,
      "step": 3100
    },
    {
      "epoch": 7.971938775510204,
      "grad_norm": 0.7117676138877869,
      "learning_rate": 2.0811610273889492e-05,
      "loss": 0.4872,
      "step": 3125
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7549358010292053,
      "eval_runtime": 170.2818,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 3136
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.1748768389225006,
      "learning_rate": 1.9567100482120672e-05,
      "loss": 0.3042,
      "step": 3150
    },
    {
      "epoch": 8.099489795918368,
      "grad_norm": 0.7495355606079102,
      "learning_rate": 1.8356912787677415e-05,
      "loss": 0.6019,
      "step": 3175
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.15595613420009613,
      "learning_rate": 1.7181563598398786e-05,
      "loss": 0.2967,
      "step": 3200
    },
    {
      "epoch": 8.22704081632653,
      "grad_norm": 0.791640043258667,
      "learning_rate": 1.6041554455936392e-05,
      "loss": 0.6311,
      "step": 3225
    },
    {
      "epoch": 8.290816326530612,
      "grad_norm": 0.14474517107009888,
      "learning_rate": 1.4937371821737888e-05,
      "loss": 0.3016,
      "step": 3250
    },
    {
      "epoch": 8.354591836734693,
      "grad_norm": 0.7005167603492737,
      "learning_rate": 1.3869486869465598e-05,
      "loss": 0.5927,
      "step": 3275
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 0.1650804728269577,
      "learning_rate": 1.2838355283938574e-05,
      "loss": 0.2945,
      "step": 3300
    },
    {
      "epoch": 8.482142857142858,
      "grad_norm": 0.8338432908058167,
      "learning_rate": 1.1844417066684154e-05,
      "loss": 0.62,
      "step": 3325
    },
    {
      "epoch": 8.545918367346939,
      "grad_norm": 0.161856010556221,
      "learning_rate": 1.0888096348181686e-05,
      "loss": 0.2927,
      "step": 3350
    },
    {
      "epoch": 8.60969387755102,
      "grad_norm": 0.7498207092285156,
      "learning_rate": 9.969801206878782e-06,
      "loss": 0.6395,
      "step": 3375
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 0.16427643597126007,
      "learning_rate": 9.08992349505734e-06,
      "loss": 0.2938,
      "step": 3400
    },
    {
      "epoch": 8.737244897959183,
      "grad_norm": 0.7366524338722229,
      "learning_rate": 8.24883867162336e-06,
      "loss": 0.5943,
      "step": 3425
    },
    {
      "epoch": 8.801020408163264,
      "grad_norm": 0.16218288242816925,
      "learning_rate": 7.4469056418922216e-06,
      "loss": 0.2926,
      "step": 3450
    },
    {
      "epoch": 8.864795918367347,
      "grad_norm": 0.7640029191970825,
      "learning_rate": 6.684466604437667e-06,
      "loss": 0.597,
      "step": 3475
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.16705913841724396,
      "learning_rate": 5.961846905069712e-06,
      "loss": 0.2889,
      "step": 3500
    },
    {
      "epoch": 8.99234693877551,
      "grad_norm": 0.7839002013206482,
      "learning_rate": 5.279354898004119e-06,
      "loss": 0.5893,
      "step": 3525
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7636027932167053,
      "eval_runtime": 170.354,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 3528
    },
    {
      "epoch": 9.056122448979592,
      "grad_norm": 0.6988080739974976,
      "learning_rate": 4.637281814282291e-06,
      "loss": 0.2795,
      "step": 3550
    },
    {
      "epoch": 9.119897959183673,
      "grad_norm": 0.7609276175498962,
      "learning_rate": 4.035901637498052e-06,
      "loss": 0.5615,
      "step": 3575
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 0.6603087782859802,
      "learning_rate": 3.475470986884066e-06,
      "loss": 0.3464,
      "step": 3600
    },
    {
      "epoch": 9.247448979591837,
      "grad_norm": 0.7417860627174377,
      "learning_rate": 2.956229007808098e-06,
      "loss": 0.5351,
      "step": 3625
    },
    {
      "epoch": 9.311224489795919,
      "grad_norm": 0.6828466057777405,
      "learning_rate": 2.47839726972553e-06,
      "loss": 0.3479,
      "step": 3650
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.8160576820373535,
      "learning_rate": 2.0421796716319054e-06,
      "loss": 0.5479,
      "step": 3675
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 0.7101137042045593,
      "learning_rate": 1.6477623550557041e-06,
      "loss": 0.3436,
      "step": 3700
    },
    {
      "epoch": 9.502551020408163,
      "grad_norm": 0.7392879724502563,
      "learning_rate": 1.2953136246285914e-06,
      "loss": 0.5378,
      "step": 3725
    },
    {
      "epoch": 9.566326530612244,
      "grad_norm": 0.689434826374054,
      "learning_rate": 9.849838762669095e-07,
      "loss": 0.3237,
      "step": 3750
    },
    {
      "epoch": 9.630102040816327,
      "grad_norm": 0.7260082364082336,
      "learning_rate": 7.169055329952046e-07,
      "loss": 0.5606,
      "step": 3775
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 0.6863254308700562,
      "learning_rate": 4.911929884390043e-07,
      "loss": 0.3342,
      "step": 3800
    },
    {
      "epoch": 9.75765306122449,
      "grad_norm": 0.7447724342346191,
      "learning_rate": 3.079425580111428e-07,
      "loss": 0.5773,
      "step": 3825
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.7347894310951233,
      "learning_rate": 1.6723243781228138e-07,
      "loss": 0.3605,
      "step": 3850
    },
    {
      "epoch": 9.885204081632653,
      "grad_norm": 0.784686267375946,
      "learning_rate": 6.912267126334416e-08,
      "loss": 0.5522,
      "step": 3875
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 0.7166805267333984,
      "learning_rate": 1.3655123483891086e-08,
      "loss": 0.4044,
      "step": 3900
    }
  ],
  "logging_steps": 25,
  "max_steps": 3920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1856854757289984e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
