{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1930,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12953367875647667,
      "grad_norm": 0.3349147140979767,
      "learning_rate": 8.620689655172413e-05,
      "loss": 2.4143,
      "step": 25
    },
    {
      "epoch": 0.25906735751295334,
      "grad_norm": 0.40778234601020813,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.931,
      "step": 50
    },
    {
      "epoch": 0.38860103626943004,
      "grad_norm": 0.3054356575012207,
      "learning_rate": 0.00019995930636864802,
      "loss": 1.5714,
      "step": 75
    },
    {
      "epoch": 0.5181347150259067,
      "grad_norm": 0.667050302028656,
      "learning_rate": 0.00019975169993441627,
      "loss": 1.4439,
      "step": 100
    },
    {
      "epoch": 0.6476683937823834,
      "grad_norm": 0.2914445996284485,
      "learning_rate": 0.00019936853386331858,
      "loss": 1.4464,
      "step": 125
    },
    {
      "epoch": 0.7772020725388601,
      "grad_norm": 0.3774029612541199,
      "learning_rate": 0.0001988104825147528,
      "loss": 1.3977,
      "step": 150
    },
    {
      "epoch": 0.9067357512953368,
      "grad_norm": 0.2996307909488678,
      "learning_rate": 0.00019807852804032305,
      "loss": 1.399,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4115413427352905,
      "eval_runtime": 166.3206,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 193
    },
    {
      "epoch": 1.0362694300518134,
      "grad_norm": 0.27316761016845703,
      "learning_rate": 0.00019717395865528602,
      "loss": 1.3667,
      "step": 200
    },
    {
      "epoch": 1.16580310880829,
      "grad_norm": 0.3143042325973511,
      "learning_rate": 0.0001960983663713353,
      "loss": 1.3642,
      "step": 225
    },
    {
      "epoch": 1.2953367875647668,
      "grad_norm": 0.32677212357521057,
      "learning_rate": 0.00019485364419471454,
      "loss": 1.3644,
      "step": 250
    },
    {
      "epoch": 1.4248704663212435,
      "grad_norm": 0.32596302032470703,
      "learning_rate": 0.00019344198279459,
      "loss": 1.3571,
      "step": 275
    },
    {
      "epoch": 1.5544041450777202,
      "grad_norm": 0.33421406149864197,
      "learning_rate": 0.0001918658666475465,
      "loss": 1.3617,
      "step": 300
    },
    {
      "epoch": 1.6839378238341969,
      "grad_norm": 0.35140496492385864,
      "learning_rate": 0.00019012806966499217,
      "loss": 1.3322,
      "step": 325
    },
    {
      "epoch": 1.8134715025906736,
      "grad_norm": 0.30676040053367615,
      "learning_rate": 0.0001882316503111678,
      "loss": 1.3661,
      "step": 350
    },
    {
      "epoch": 1.9430051813471503,
      "grad_norm": 0.2944931983947754,
      "learning_rate": 0.00018617994622035253,
      "loss": 1.3348,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.37176513671875,
      "eval_runtime": 166.3324,
      "eval_samples_per_second": 4.617,
      "eval_steps_per_second": 4.617,
      "step": 386
    },
    {
      "epoch": 2.0725388601036268,
      "grad_norm": 0.3196185529232025,
      "learning_rate": 0.0001839765683227398,
      "loss": 1.341,
      "step": 400
    },
    {
      "epoch": 2.2020725388601035,
      "grad_norm": 0.3228852152824402,
      "learning_rate": 0.00018162539448932164,
      "loss": 1.2998,
      "step": 425
    },
    {
      "epoch": 2.33160621761658,
      "grad_norm": 0.32183268666267395,
      "learning_rate": 0.0001791305627069662,
      "loss": 1.3244,
      "step": 450
    },
    {
      "epoch": 2.461139896373057,
      "grad_norm": 0.323556512594223,
      "learning_rate": 0.0001764964637957,
      "loss": 1.2762,
      "step": 475
    },
    {
      "epoch": 2.5906735751295336,
      "grad_norm": 0.32699963450431824,
      "learning_rate": 0.0001737277336810124,
      "loss": 1.3466,
      "step": 500
    },
    {
      "epoch": 2.7202072538860103,
      "grad_norm": 0.34384021162986755,
      "learning_rate": 0.00017082924523478262,
      "loss": 1.296,
      "step": 525
    },
    {
      "epoch": 2.849740932642487,
      "grad_norm": 0.3124217391014099,
      "learning_rate": 0.0001678060996991891,
      "loss": 1.3345,
      "step": 550
    },
    {
      "epoch": 2.9792746113989637,
      "grad_norm": 0.30890268087387085,
      "learning_rate": 0.00016466361770869494,
      "loss": 1.2666,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3539018630981445,
      "eval_runtime": 166.3313,
      "eval_samples_per_second": 4.617,
      "eval_steps_per_second": 4.617,
      "step": 579
    },
    {
      "epoch": 3.1088082901554404,
      "grad_norm": 0.3081100285053253,
      "learning_rate": 0.0001614073299259101,
      "loss": 1.3298,
      "step": 600
    },
    {
      "epoch": 3.238341968911917,
      "grad_norm": 0.36248430609703064,
      "learning_rate": 0.00015804296730781135,
      "loss": 1.2422,
      "step": 625
    },
    {
      "epoch": 3.3678756476683938,
      "grad_norm": 0.2998872995376587,
      "learning_rate": 0.00015457645101945046,
      "loss": 1.3213,
      "step": 650
    },
    {
      "epoch": 3.4974093264248705,
      "grad_norm": 0.3841119706630707,
      "learning_rate": 0.0001510138820129033,
      "loss": 1.223,
      "step": 675
    },
    {
      "epoch": 3.626943005181347,
      "grad_norm": 0.32713350653648376,
      "learning_rate": 0.00014736153028979893,
      "loss": 1.3176,
      "step": 700
    },
    {
      "epoch": 3.756476683937824,
      "grad_norm": 0.3543325662612915,
      "learning_rate": 0.00014362582386632798,
      "loss": 1.2377,
      "step": 725
    },
    {
      "epoch": 3.8860103626943006,
      "grad_norm": 0.3040606677532196,
      "learning_rate": 0.0001398133374601501,
      "loss": 1.3028,
      "step": 750
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3400659561157227,
      "eval_runtime": 166.3895,
      "eval_samples_per_second": 4.616,
      "eval_steps_per_second": 4.616,
      "step": 772
    },
    {
      "epoch": 4.015544041450777,
      "grad_norm": 0.3487117886543274,
      "learning_rate": 0.00013593078091911218,
      "loss": 1.2333,
      "step": 775
    },
    {
      "epoch": 4.1450777202072535,
      "grad_norm": 0.32947903871536255,
      "learning_rate": 0.00013198498741214166,
      "loss": 1.2712,
      "step": 800
    },
    {
      "epoch": 4.274611398963731,
      "grad_norm": 0.3769703209400177,
      "learning_rate": 0.00012798290140309923,
      "loss": 1.226,
      "step": 825
    },
    {
      "epoch": 4.404145077720207,
      "grad_norm": 0.3296460807323456,
      "learning_rate": 0.0001239315664287558,
      "loss": 1.2657,
      "step": 850
    },
    {
      "epoch": 4.533678756476684,
      "grad_norm": 0.3486826419830322,
      "learning_rate": 0.00011983811270240484,
      "loss": 1.2392,
      "step": 875
    },
    {
      "epoch": 4.66321243523316,
      "grad_norm": 0.32542574405670166,
      "learning_rate": 0.00011570974456492678,
      "loss": 1.2542,
      "step": 900
    },
    {
      "epoch": 4.7927461139896375,
      "grad_norm": 0.3246398866176605,
      "learning_rate": 0.00011155372780539124,
      "loss": 1.2494,
      "step": 925
    },
    {
      "epoch": 4.922279792746114,
      "grad_norm": 0.33084210753440857,
      "learning_rate": 0.00010737737687351284,
      "loss": 1.2315,
      "step": 950
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.337689995765686,
      "eval_runtime": 166.4568,
      "eval_samples_per_second": 4.614,
      "eval_steps_per_second": 4.614,
      "step": 965
    },
    {
      "epoch": 5.051813471502591,
      "grad_norm": 0.30799350142478943,
      "learning_rate": 0.00010318804200646553,
      "loss": 1.2331,
      "step": 975
    },
    {
      "epoch": 5.181347150259067,
      "grad_norm": 0.37619900703430176,
      "learning_rate": 9.899309629271246e-05,
      "loss": 1.2025,
      "step": 1000
    },
    {
      "epoch": 5.310880829015544,
      "grad_norm": 0.34383028745651245,
      "learning_rate": 9.479992269561833e-05,
      "loss": 1.2273,
      "step": 1025
    },
    {
      "epoch": 5.4404145077720205,
      "grad_norm": 0.36908799409866333,
      "learning_rate": 9.061590105968208e-05,
      "loss": 1.2141,
      "step": 1050
    },
    {
      "epoch": 5.569948186528498,
      "grad_norm": 0.3599240481853485,
      "learning_rate": 8.644839512225886e-05,
      "loss": 1.2238,
      "step": 1075
    },
    {
      "epoch": 5.699481865284974,
      "grad_norm": 0.37681469321250916,
      "learning_rate": 8.23047395536298e-05,
      "loss": 1.1932,
      "step": 1100
    },
    {
      "epoch": 5.829015544041451,
      "grad_norm": 0.3268655836582184,
      "learning_rate": 7.819222704822937e-05,
      "loss": 1.2523,
      "step": 1125
    },
    {
      "epoch": 5.958549222797927,
      "grad_norm": 0.37561747431755066,
      "learning_rate": 7.411809548974792e-05,
      "loss": 1.1943,
      "step": 1150
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.328701376914978,
      "eval_runtime": 166.2965,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 1158
    },
    {
      "epoch": 6.0880829015544045,
      "grad_norm": 0.3415442705154419,
      "learning_rate": 7.008951521270037e-05,
      "loss": 1.2264,
      "step": 1175
    },
    {
      "epoch": 6.217616580310881,
      "grad_norm": 0.39172467589378357,
      "learning_rate": 6.611357638287823e-05,
      "loss": 1.1669,
      "step": 1200
    },
    {
      "epoch": 6.347150259067358,
      "grad_norm": 0.3613507151603699,
      "learning_rate": 6.219727651889646e-05,
      "loss": 1.2234,
      "step": 1225
    },
    {
      "epoch": 6.476683937823834,
      "grad_norm": 0.39938071370124817,
      "learning_rate": 5.834750817679606e-05,
      "loss": 1.1595,
      "step": 1250
    },
    {
      "epoch": 6.606217616580311,
      "grad_norm": 0.3655507266521454,
      "learning_rate": 5.457104681937706e-05,
      "loss": 1.2359,
      "step": 1275
    },
    {
      "epoch": 6.7357512953367875,
      "grad_norm": 0.4246789813041687,
      "learning_rate": 5.087453889161229e-05,
      "loss": 1.1518,
      "step": 1300
    },
    {
      "epoch": 6.865284974093264,
      "grad_norm": 0.3852677643299103,
      "learning_rate": 4.726449012312726e-05,
      "loss": 1.242,
      "step": 1325
    },
    {
      "epoch": 6.994818652849741,
      "grad_norm": 0.49612054228782654,
      "learning_rate": 4.374725407833532e-05,
      "loss": 1.143,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3256771564483643,
      "eval_runtime": 166.3588,
      "eval_samples_per_second": 4.617,
      "eval_steps_per_second": 4.617,
      "step": 1351
    },
    {
      "epoch": 7.124352331606218,
      "grad_norm": 0.361299067735672,
      "learning_rate": 4.0329020974377596e-05,
      "loss": 1.24,
      "step": 1375
    },
    {
      "epoch": 7.253886010362694,
      "grad_norm": 0.34217727184295654,
      "learning_rate": 3.701580678654925e-05,
      "loss": 1.1324,
      "step": 1400
    },
    {
      "epoch": 7.383419689119171,
      "grad_norm": 0.38745132088661194,
      "learning_rate": 3.381344266038518e-05,
      "loss": 1.2275,
      "step": 1425
    },
    {
      "epoch": 7.512953367875648,
      "grad_norm": 0.38299280405044556,
      "learning_rate": 3.072756464904006e-05,
      "loss": 1.1418,
      "step": 1450
    },
    {
      "epoch": 7.642487046632124,
      "grad_norm": 0.3955706059932709,
      "learning_rate": 2.776360379402445e-05,
      "loss": 1.2042,
      "step": 1475
    },
    {
      "epoch": 7.772020725388601,
      "grad_norm": 0.39030492305755615,
      "learning_rate": 2.492677656675414e-05,
      "loss": 1.149,
      "step": 1500
    },
    {
      "epoch": 7.901554404145077,
      "grad_norm": 0.4007301330566406,
      "learning_rate": 2.2222075687736187e-05,
      "loss": 1.2046,
      "step": 1525
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.325485348701477,
      "eval_runtime": 166.4157,
      "eval_samples_per_second": 4.615,
      "eval_steps_per_second": 4.615,
      "step": 1544
    },
    {
      "epoch": 8.031088082901555,
      "grad_norm": 0.3983784317970276,
      "learning_rate": 1.965426133954854e-05,
      "loss": 1.1618,
      "step": 1550
    },
    {
      "epoch": 8.160621761658032,
      "grad_norm": 0.40597614645957947,
      "learning_rate": 1.7227852789078913e-05,
      "loss": 1.1827,
      "step": 1575
    },
    {
      "epoch": 8.290155440414507,
      "grad_norm": 0.4104224741458893,
      "learning_rate": 1.4947120433767047e-05,
      "loss": 1.1635,
      "step": 1600
    },
    {
      "epoch": 8.419689119170984,
      "grad_norm": 0.40233683586120605,
      "learning_rate": 1.2816078285848799e-05,
      "loss": 1.1671,
      "step": 1625
    },
    {
      "epoch": 8.549222797927461,
      "grad_norm": 0.38690561056137085,
      "learning_rate": 1.083847690782972e-05,
      "loss": 1.1707,
      "step": 1650
    },
    {
      "epoch": 8.678756476683938,
      "grad_norm": 0.41091564297676086,
      "learning_rate": 9.017796811621049e-06,
      "loss": 1.1719,
      "step": 1675
    },
    {
      "epoch": 8.808290155440414,
      "grad_norm": 0.3977980315685272,
      "learning_rate": 7.357242332955916e-06,
      "loss": 1.1691,
      "step": 1700
    },
    {
      "epoch": 8.937823834196891,
      "grad_norm": 0.41347405314445496,
      "learning_rate": 5.859735991866166e-06,
      "loss": 1.1538,
      "step": 1725
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3228411674499512,
      "eval_runtime": 166.4568,
      "eval_samples_per_second": 4.614,
      "eval_steps_per_second": 4.614,
      "step": 1737
    },
    {
      "epoch": 9.067357512953368,
      "grad_norm": 0.37410348653793335,
      "learning_rate": 4.527913349145441e-06,
      "loss": 1.1864,
      "step": 1750
    },
    {
      "epoch": 9.196891191709845,
      "grad_norm": 0.4213084876537323,
      "learning_rate": 3.3641183678508327e-06,
      "loss": 1.1412,
      "step": 1775
    },
    {
      "epoch": 9.32642487046632,
      "grad_norm": 0.413829505443573,
      "learning_rate": 2.3703992880066638e-06,
      "loss": 1.1863,
      "step": 1800
    },
    {
      "epoch": 9.455958549222798,
      "grad_norm": 0.42595356702804565,
      "learning_rate": 1.5485050217710295e-06,
      "loss": 1.1393,
      "step": 1825
    },
    {
      "epoch": 9.585492227979275,
      "grad_norm": 0.3883333206176758,
      "learning_rate": 8.998820754091531e-07,
      "loss": 1.1754,
      "step": 1850
    },
    {
      "epoch": 9.715025906735752,
      "grad_norm": 0.41860148310661316,
      "learning_rate": 4.256720034910511e-07,
      "loss": 1.1461,
      "step": 1875
    },
    {
      "epoch": 9.844559585492227,
      "grad_norm": 0.4088102877140045,
      "learning_rate": 1.2670939979384512e-07,
      "loss": 1.1925,
      "step": 1900
    },
    {
      "epoch": 9.974093264248705,
      "grad_norm": 0.4682769179344177,
      "learning_rate": 3.520428444825363e-09,
      "loss": 1.1281,
      "step": 1925
    }
  ],
  "logging_steps": 25,
  "max_steps": 1930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8251227394686976e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
