{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3850,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06493506493506493,
      "grad_norm": 0.4790535569190979,
      "learning_rate": 4.3103448275862066e-05,
      "loss": 1.2831,
      "step": 25
    },
    {
      "epoch": 0.12987012987012986,
      "grad_norm": 1.7695093154907227,
      "learning_rate": 8.620689655172413e-05,
      "loss": 2.4051,
      "step": 50
    },
    {
      "epoch": 0.19480519480519481,
      "grad_norm": 0.5006155371665955,
      "learning_rate": 0.0001293103448275862,
      "loss": 0.8065,
      "step": 75
    },
    {
      "epoch": 0.2597402597402597,
      "grad_norm": 1.2388397455215454,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.126,
      "step": 100
    },
    {
      "epoch": 0.3246753246753247,
      "grad_norm": 0.5231978297233582,
      "learning_rate": 0.0001999971331559675,
      "loss": 0.5776,
      "step": 125
    },
    {
      "epoch": 0.38961038961038963,
      "grad_norm": 0.7450110912322998,
      "learning_rate": 0.00019995908812899443,
      "loss": 0.9795,
      "step": 150
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.4003479480743408,
      "learning_rate": 0.0001998768212008659,
      "loss": 0.6263,
      "step": 175
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 0.5315017700195312,
      "learning_rate": 0.00019975036876647138,
      "loss": 0.9631,
      "step": 200
    },
    {
      "epoch": 0.5844155844155844,
      "grad_norm": 0.3545549511909485,
      "learning_rate": 0.00019957978676836858,
      "loss": 0.5747,
      "step": 225
    },
    {
      "epoch": 0.6493506493506493,
      "grad_norm": 0.6528022289276123,
      "learning_rate": 0.00019936515067203443,
      "loss": 0.9399,
      "step": 250
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.367571622133255,
      "learning_rate": 0.00019910655543247917,
      "loss": 0.6026,
      "step": 275
    },
    {
      "epoch": 0.7792207792207793,
      "grad_norm": 0.48811063170433044,
      "learning_rate": 0.00019880411545223825,
      "loss": 0.9005,
      "step": 300
    },
    {
      "epoch": 0.8441558441558441,
      "grad_norm": 0.30307328701019287,
      "learning_rate": 0.00019845796453076063,
      "loss": 0.4936,
      "step": 325
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.45982760190963745,
      "learning_rate": 0.0001980682558052159,
      "loss": 0.8944,
      "step": 350
    },
    {
      "epoch": 0.974025974025974,
      "grad_norm": 0.3403560519218445,
      "learning_rate": 0.00019763516168274655,
      "loss": 0.7367,
      "step": 375
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7737217545509338,
      "eval_runtime": 167.3191,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 385
    },
    {
      "epoch": 1.0389610389610389,
      "grad_norm": 0.09053230285644531,
      "learning_rate": 0.00019715887376419472,
      "loss": 0.4732,
      "step": 400
    },
    {
      "epoch": 1.103896103896104,
      "grad_norm": 0.395198792219162,
      "learning_rate": 0.00019663960275933837,
      "loss": 0.9804,
      "step": 425
    },
    {
      "epoch": 1.1688311688311688,
      "grad_norm": 0.05725064128637314,
      "learning_rate": 0.00019607757839367292,
      "loss": 0.4201,
      "step": 450
    },
    {
      "epoch": 1.2337662337662338,
      "grad_norm": 0.3625730276107788,
      "learning_rate": 0.00019547304930678095,
      "loss": 0.9803,
      "step": 475
    },
    {
      "epoch": 1.2987012987012987,
      "grad_norm": 0.07861869782209396,
      "learning_rate": 0.00019482628294233397,
      "loss": 0.432,
      "step": 500
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.42756831645965576,
      "learning_rate": 0.0001941375654297752,
      "loss": 1.0119,
      "step": 525
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.0985531136393547,
      "learning_rate": 0.00019340720145773617,
      "loss": 0.4324,
      "step": 550
    },
    {
      "epoch": 1.4935064935064934,
      "grad_norm": 0.36101385951042175,
      "learning_rate": 0.00019263551413924222,
      "loss": 1.0278,
      "step": 575
    },
    {
      "epoch": 1.5584415584415585,
      "grad_norm": 0.09186074882745743,
      "learning_rate": 0.00019182284486876747,
      "loss": 0.4395,
      "step": 600
    },
    {
      "epoch": 1.6233766233766234,
      "grad_norm": 0.3240305781364441,
      "learning_rate": 0.00019096955317120178,
      "loss": 0.9251,
      "step": 625
    },
    {
      "epoch": 1.6883116883116882,
      "grad_norm": 0.07687355577945709,
      "learning_rate": 0.00019007601654279696,
      "loss": 0.4564,
      "step": 650
    },
    {
      "epoch": 1.7532467532467533,
      "grad_norm": 0.40946048498153687,
      "learning_rate": 0.00018914263028416248,
      "loss": 0.9265,
      "step": 675
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.17780403792858124,
      "learning_rate": 0.00018816980732538454,
      "loss": 0.4459,
      "step": 700
    },
    {
      "epoch": 1.883116883116883,
      "grad_norm": 0.3578890562057495,
      "learning_rate": 0.00018715797804334553,
      "loss": 0.974,
      "step": 725
    },
    {
      "epoch": 1.948051948051948,
      "grad_norm": 0.42171406745910645,
      "learning_rate": 0.0001861075900713256,
      "loss": 0.5986,
      "step": 750
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7256019711494446,
      "eval_runtime": 167.237,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 770
    },
    {
      "epoch": 2.012987012987013,
      "grad_norm": 0.08866972476243973,
      "learning_rate": 0.00018501910810096953,
      "loss": 0.7582,
      "step": 775
    },
    {
      "epoch": 2.0779220779220777,
      "grad_norm": 0.3587210476398468,
      "learning_rate": 0.0001838930136767072,
      "loss": 0.595,
      "step": 800
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.13310229778289795,
      "learning_rate": 0.00018272980498271828,
      "loss": 0.6734,
      "step": 825
    },
    {
      "epoch": 2.207792207792208,
      "grad_norm": 0.3508085012435913,
      "learning_rate": 0.00018152999662253555,
      "loss": 0.6597,
      "step": 850
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.14442217350006104,
      "learning_rate": 0.00018029411939138443,
      "loss": 0.6901,
      "step": 875
    },
    {
      "epoch": 2.3376623376623376,
      "grad_norm": 0.3406849801540375,
      "learning_rate": 0.00017902272004135896,
      "loss": 0.6751,
      "step": 900
    },
    {
      "epoch": 2.4025974025974026,
      "grad_norm": 0.09924248605966568,
      "learning_rate": 0.00017771636103953883,
      "loss": 0.67,
      "step": 925
    },
    {
      "epoch": 2.4675324675324677,
      "grad_norm": 0.3832428455352783,
      "learning_rate": 0.00017637562031915384,
      "loss": 0.6818,
      "step": 950
    },
    {
      "epoch": 2.5324675324675323,
      "grad_norm": 0.09754052758216858,
      "learning_rate": 0.00017500109102390625,
      "loss": 0.666,
      "step": 975
    },
    {
      "epoch": 2.5974025974025974,
      "grad_norm": 0.36527490615844727,
      "learning_rate": 0.00017359338124556416,
      "loss": 0.6149,
      "step": 1000
    },
    {
      "epoch": 2.6623376623376624,
      "grad_norm": 0.10797370225191116,
      "learning_rate": 0.00017215311375494142,
      "loss": 0.6632,
      "step": 1025
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.37972164154052734,
      "learning_rate": 0.00017068092572638412,
      "loss": 0.6685,
      "step": 1050
    },
    {
      "epoch": 2.792207792207792,
      "grad_norm": 0.08183637261390686,
      "learning_rate": 0.00016917746845588442,
      "loss": 0.6577,
      "step": 1075
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.3655187487602234,
      "learning_rate": 0.0001676434070729473,
      "loss": 0.6696,
      "step": 1100
    },
    {
      "epoch": 2.9220779220779223,
      "grad_norm": 0.09911451488733292,
      "learning_rate": 0.00016607942024633732,
      "loss": 0.6547,
      "step": 1125
    },
    {
      "epoch": 2.987012987012987,
      "grad_norm": 0.3936910033226013,
      "learning_rate": 0.0001644861998838354,
      "loss": 0.7607,
      "step": 1150
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7044839859008789,
      "eval_runtime": 167.4159,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 1155
    },
    {
      "epoch": 3.051948051948052,
      "grad_norm": 0.34693241119384766,
      "learning_rate": 0.00016286445082613896,
      "loss": 0.3868,
      "step": 1175
    },
    {
      "epoch": 3.116883116883117,
      "grad_norm": 0.44275540113449097,
      "learning_rate": 0.00016121489053504034,
      "loss": 0.8059,
      "step": 1200
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 0.41162925958633423,
      "learning_rate": 0.00015953824877602168,
      "loss": 0.4614,
      "step": 1225
    },
    {
      "epoch": 3.2467532467532467,
      "grad_norm": 0.46951642632484436,
      "learning_rate": 0.0001578352672954067,
      "loss": 0.8092,
      "step": 1250
    },
    {
      "epoch": 3.311688311688312,
      "grad_norm": 0.4241025447845459,
      "learning_rate": 0.00015610669949221205,
      "loss": 0.4181,
      "step": 1275
    },
    {
      "epoch": 3.3766233766233764,
      "grad_norm": 0.42678093910217285,
      "learning_rate": 0.0001543533100848437,
      "loss": 0.7893,
      "step": 1300
    },
    {
      "epoch": 3.4415584415584415,
      "grad_norm": 0.4094551205635071,
      "learning_rate": 0.0001525758747727854,
      "loss": 0.3933,
      "step": 1325
    },
    {
      "epoch": 3.5064935064935066,
      "grad_norm": 0.4066378176212311,
      "learning_rate": 0.00015077517989342933,
      "loss": 0.8223,
      "step": 1350
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.4515649080276489,
      "learning_rate": 0.00014895202207420026,
      "loss": 0.4235,
      "step": 1375
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 0.46544593572616577,
      "learning_rate": 0.00014710720788012782,
      "loss": 0.8004,
      "step": 1400
    },
    {
      "epoch": 3.7012987012987013,
      "grad_norm": 0.41299065947532654,
      "learning_rate": 0.00014524155345702194,
      "loss": 0.4939,
      "step": 1425
    },
    {
      "epoch": 3.7662337662337664,
      "grad_norm": 0.44818058609962463,
      "learning_rate": 0.00014335588417040994,
      "loss": 0.8273,
      "step": 1450
    },
    {
      "epoch": 3.8311688311688314,
      "grad_norm": 0.4142442047595978,
      "learning_rate": 0.00014145103424039495,
      "loss": 0.4183,
      "step": 1475
    },
    {
      "epoch": 3.896103896103896,
      "grad_norm": 0.4958381950855255,
      "learning_rate": 0.0001395278463725968,
      "loss": 0.8022,
      "step": 1500
    },
    {
      "epoch": 3.961038961038961,
      "grad_norm": 0.4389549195766449,
      "learning_rate": 0.00013758717138533916,
      "loss": 0.5411,
      "step": 1525
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6993935108184814,
      "eval_runtime": 167.4966,
      "eval_samples_per_second": 4.585,
      "eval_steps_per_second": 4.585,
      "step": 1540
    },
    {
      "epoch": 4.025974025974026,
      "grad_norm": 0.11141732335090637,
      "learning_rate": 0.0001356298678332474,
      "loss": 0.4976,
      "step": 1550
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 0.4147472083568573,
      "learning_rate": 0.000133656801627424,
      "loss": 0.6564,
      "step": 1575
    },
    {
      "epoch": 4.1558441558441555,
      "grad_norm": 0.08805418759584427,
      "learning_rate": 0.00013166884565236965,
      "loss": 0.4632,
      "step": 1600
    },
    {
      "epoch": 4.220779220779221,
      "grad_norm": 0.4721658527851105,
      "learning_rate": 0.00012966687937981903,
      "loss": 0.6963,
      "step": 1625
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.10380276292562485,
      "learning_rate": 0.00012765178847966242,
      "loss": 0.4664,
      "step": 1650
    },
    {
      "epoch": 4.35064935064935,
      "grad_norm": 0.4963855445384979,
      "learning_rate": 0.0001256244644281255,
      "loss": 0.6758,
      "step": 1675
    },
    {
      "epoch": 4.415584415584416,
      "grad_norm": 0.10355981439352036,
      "learning_rate": 0.00012358580411338021,
      "loss": 0.4507,
      "step": 1700
    },
    {
      "epoch": 4.48051948051948,
      "grad_norm": 0.504457950592041,
      "learning_rate": 0.00012153670943876131,
      "loss": 0.6878,
      "step": 1725
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.10643747448921204,
      "learning_rate": 0.00011947808692376452,
      "loss": 0.4475,
      "step": 1750
    },
    {
      "epoch": 4.6103896103896105,
      "grad_norm": 0.48837435245513916,
      "learning_rate": 0.0001174108473030021,
      "loss": 0.7041,
      "step": 1775
    },
    {
      "epoch": 4.675324675324675,
      "grad_norm": 0.11017852276563644,
      "learning_rate": 0.00011533590512329407,
      "loss": 0.482,
      "step": 1800
    },
    {
      "epoch": 4.740259740259741,
      "grad_norm": 0.47316697239875793,
      "learning_rate": 0.00011325417833907248,
      "loss": 0.6819,
      "step": 1825
    },
    {
      "epoch": 4.805194805194805,
      "grad_norm": 0.11276821047067642,
      "learning_rate": 0.00011116658790627845,
      "loss": 0.4517,
      "step": 1850
    },
    {
      "epoch": 4.87012987012987,
      "grad_norm": 0.4524179697036743,
      "learning_rate": 0.00010907405737493135,
      "loss": 0.6607,
      "step": 1875
    },
    {
      "epoch": 4.935064935064935,
      "grad_norm": 0.11210495978593826,
      "learning_rate": 0.0001069775124805501,
      "loss": 0.4632,
      "step": 1900
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.012153148651123,
      "learning_rate": 0.00010487788073460785,
      "loss": 0.7589,
      "step": 1925
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6982927322387695,
      "eval_runtime": 167.2637,
      "eval_samples_per_second": 4.592,
      "eval_steps_per_second": 4.592,
      "step": 1925
    },
    {
      "epoch": 5.064935064935065,
      "grad_norm": 0.4728931784629822,
      "learning_rate": 0.00010277609101420094,
      "loss": 0.4169,
      "step": 1950
    },
    {
      "epoch": 5.12987012987013,
      "grad_norm": 0.6127818822860718,
      "learning_rate": 0.00010067307315111359,
      "loss": 0.6474,
      "step": 1975
    },
    {
      "epoch": 5.194805194805195,
      "grad_norm": 0.5517804026603699,
      "learning_rate": 9.856975752046037e-05,
      "loss": 0.4487,
      "step": 2000
    },
    {
      "epoch": 5.259740259740259,
      "grad_norm": 0.6237858533859253,
      "learning_rate": 9.64670746290882e-05,
      "loss": 0.6475,
      "step": 2025
    },
    {
      "epoch": 5.324675324675325,
      "grad_norm": 0.5480496883392334,
      "learning_rate": 9.43659547039202e-05,
      "loss": 0.4689,
      "step": 2050
    },
    {
      "epoch": 5.3896103896103895,
      "grad_norm": 0.5911468863487244,
      "learning_rate": 9.226732728042312e-05,
      "loss": 0.6168,
      "step": 2075
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 0.5082380771636963,
      "learning_rate": 9.017212079138104e-05,
      "loss": 0.375,
      "step": 2100
    },
    {
      "epoch": 5.51948051948052,
      "grad_norm": 0.6352981925010681,
      "learning_rate": 8.808126215615669e-05,
      "loss": 0.6389,
      "step": 2125
    },
    {
      "epoch": 5.584415584415584,
      "grad_norm": 0.5478692054748535,
      "learning_rate": 8.599567637062202e-05,
      "loss": 0.4489,
      "step": 2150
    },
    {
      "epoch": 5.64935064935065,
      "grad_norm": 0.5485904216766357,
      "learning_rate": 8.391628609794044e-05,
      "loss": 0.6115,
      "step": 2175
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.5705159306526184,
      "learning_rate": 8.184401126038044e-05,
      "loss": 0.4494,
      "step": 2200
    },
    {
      "epoch": 5.779220779220779,
      "grad_norm": 0.6156154870986938,
      "learning_rate": 7.977976863234184e-05,
      "loss": 0.6597,
      "step": 2225
    },
    {
      "epoch": 5.8441558441558445,
      "grad_norm": 0.563079833984375,
      "learning_rate": 7.772447143477506e-05,
      "loss": 0.4361,
      "step": 2250
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 0.5912641882896423,
      "learning_rate": 7.56790289311719e-05,
      "loss": 0.6107,
      "step": 2275
    },
    {
      "epoch": 5.974025974025974,
      "grad_norm": 0.5687406063079834,
      "learning_rate": 7.364434602530757e-05,
      "loss": 0.476,
      "step": 2300
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.713608980178833,
      "eval_runtime": 167.4184,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 2310
    },
    {
      "epoch": 6.038961038961039,
      "grad_norm": 0.2729048728942871,
      "learning_rate": 7.162132286091123e-05,
      "loss": 0.3468,
      "step": 2325
    },
    {
      "epoch": 6.103896103896104,
      "grad_norm": 0.6036502718925476,
      "learning_rate": 6.961085442344221e-05,
      "loss": 0.6686,
      "step": 2350
    },
    {
      "epoch": 6.1688311688311686,
      "grad_norm": 0.11028733849525452,
      "learning_rate": 6.76138301441487e-05,
      "loss": 0.3145,
      "step": 2375
    },
    {
      "epoch": 6.233766233766234,
      "grad_norm": 0.6825254559516907,
      "learning_rate": 6.563113350658321e-05,
      "loss": 0.6481,
      "step": 2400
    },
    {
      "epoch": 6.298701298701299,
      "grad_norm": 0.14527365565299988,
      "learning_rate": 6.366364165574937e-05,
      "loss": 0.3025,
      "step": 2425
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 0.6758158802986145,
      "learning_rate": 6.171222501005325e-05,
      "loss": 0.6927,
      "step": 2450
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.6401920318603516,
      "learning_rate": 5.97777468762299e-05,
      "loss": 0.3532,
      "step": 2475
    },
    {
      "epoch": 6.4935064935064934,
      "grad_norm": 0.622506856918335,
      "learning_rate": 5.786106306741672e-05,
      "loss": 0.7009,
      "step": 2500
    },
    {
      "epoch": 6.558441558441558,
      "grad_norm": 0.14076119661331177,
      "learning_rate": 5.5963021524541656e-05,
      "loss": 0.3068,
      "step": 2525
    },
    {
      "epoch": 6.623376623376624,
      "grad_norm": 0.6400268077850342,
      "learning_rate": 5.408446194119396e-05,
      "loss": 0.6652,
      "step": 2550
    },
    {
      "epoch": 6.688311688311688,
      "grad_norm": 0.1404123455286026,
      "learning_rate": 5.2226215392144026e-05,
      "loss": 0.303,
      "step": 2575
    },
    {
      "epoch": 6.753246753246753,
      "grad_norm": 0.7330589890480042,
      "learning_rate": 5.038910396567571e-05,
      "loss": 0.6759,
      "step": 2600
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.13231365382671356,
      "learning_rate": 4.8573940399894434e-05,
      "loss": 0.3075,
      "step": 2625
    },
    {
      "epoch": 6.883116883116883,
      "grad_norm": 0.7113979458808899,
      "learning_rate": 4.6781527723172044e-05,
      "loss": 0.6851,
      "step": 2650
    },
    {
      "epoch": 6.948051948051948,
      "grad_norm": 0.66189044713974,
      "learning_rate": 4.501265889888693e-05,
      "loss": 0.3957,
      "step": 2675
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7290565371513367,
      "eval_runtime": 167.4198,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 2695
    },
    {
      "epoch": 7.012987012987013,
      "grad_norm": 0.13195590674877167,
      "learning_rate": 4.326811647461692e-05,
      "loss": 0.5359,
      "step": 2700
    },
    {
      "epoch": 7.077922077922078,
      "grad_norm": 0.6080443263053894,
      "learning_rate": 4.1548672235940466e-05,
      "loss": 0.4973,
      "step": 2725
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.18330614268779755,
      "learning_rate": 3.985508686499846e-05,
      "loss": 0.4644,
      "step": 2750
    },
    {
      "epoch": 7.207792207792208,
      "grad_norm": 0.6571714282035828,
      "learning_rate": 3.8188109603968684e-05,
      "loss": 0.4811,
      "step": 2775
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.1409766972064972,
      "learning_rate": 3.65484779236008e-05,
      "loss": 0.4502,
      "step": 2800
    },
    {
      "epoch": 7.337662337662338,
      "grad_norm": 0.6937630772590637,
      "learning_rate": 3.493691719695958e-05,
      "loss": 0.4689,
      "step": 2825
    },
    {
      "epoch": 7.402597402597403,
      "grad_norm": 0.14832374453544617,
      "learning_rate": 3.335414037851957e-05,
      "loss": 0.4615,
      "step": 2850
    },
    {
      "epoch": 7.467532467532467,
      "grad_norm": 0.6641846895217896,
      "learning_rate": 3.180084768875429e-05,
      "loss": 0.4775,
      "step": 2875
    },
    {
      "epoch": 7.532467532467533,
      "grad_norm": 0.159820556640625,
      "learning_rate": 3.0277726304358434e-05,
      "loss": 0.436,
      "step": 2900
    },
    {
      "epoch": 7.597402597402597,
      "grad_norm": 0.6974029541015625,
      "learning_rate": 2.8785450054241148e-05,
      "loss": 0.4602,
      "step": 2925
    },
    {
      "epoch": 7.662337662337662,
      "grad_norm": 0.17138008773326874,
      "learning_rate": 2.732467912142398e-05,
      "loss": 0.4487,
      "step": 2950
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 0.7249014377593994,
      "learning_rate": 2.5896059750975822e-05,
      "loss": 0.494,
      "step": 2975
    },
    {
      "epoch": 7.792207792207792,
      "grad_norm": 0.1761624664068222,
      "learning_rate": 2.4500223964114333e-05,
      "loss": 0.4566,
      "step": 3000
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.7315008640289307,
      "learning_rate": 2.3137789278599488e-05,
      "loss": 0.4854,
      "step": 3025
    },
    {
      "epoch": 7.922077922077922,
      "grad_norm": 0.1405416578054428,
      "learning_rate": 2.1809358435543915e-05,
      "loss": 0.4535,
      "step": 3050
    },
    {
      "epoch": 7.987012987012987,
      "grad_norm": 0.6750388145446777,
      "learning_rate": 2.051551913276014e-05,
      "loss": 0.5466,
      "step": 3075
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7478497624397278,
      "eval_runtime": 167.1354,
      "eval_samples_per_second": 4.595,
      "eval_steps_per_second": 4.595,
      "step": 3080
    },
    {
      "epoch": 8.051948051948052,
      "grad_norm": 0.6780393123626709,
      "learning_rate": 1.925684376476302e-05,
      "loss": 0.3567,
      "step": 3100
    },
    {
      "epoch": 8.116883116883116,
      "grad_norm": 0.7610811591148376,
      "learning_rate": 1.8033889169542505e-05,
      "loss": 0.5564,
      "step": 3125
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 0.6536206007003784,
      "learning_rate": 1.68471963822185e-05,
      "loss": 0.3091,
      "step": 3150
    },
    {
      "epoch": 8.246753246753247,
      "grad_norm": 0.8599332571029663,
      "learning_rate": 1.569729039568678e-05,
      "loss": 0.5786,
      "step": 3175
    },
    {
      "epoch": 8.311688311688311,
      "grad_norm": 0.6886890530586243,
      "learning_rate": 1.4584679928362366e-05,
      "loss": 0.3323,
      "step": 3200
    },
    {
      "epoch": 8.376623376623376,
      "grad_norm": 0.7507830262184143,
      "learning_rate": 1.3509857199122311e-05,
      "loss": 0.5731,
      "step": 3225
    },
    {
      "epoch": 8.441558441558442,
      "grad_norm": 0.6662683486938477,
      "learning_rate": 1.2473297709548104e-05,
      "loss": 0.2938,
      "step": 3250
    },
    {
      "epoch": 8.506493506493506,
      "grad_norm": 0.6606976389884949,
      "learning_rate": 1.1475460033563846e-05,
      "loss": 0.5617,
      "step": 3275
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.7459450364112854,
      "learning_rate": 1.0516785614563018e-05,
      "loss": 0.3249,
      "step": 3300
    },
    {
      "epoch": 8.636363636363637,
      "grad_norm": 0.8074725270271301,
      "learning_rate": 9.597698570114044e-06,
      "loss": 0.5647,
      "step": 3325
    },
    {
      "epoch": 8.7012987012987,
      "grad_norm": 0.7470917701721191,
      "learning_rate": 8.718605504330612e-06,
      "loss": 0.3262,
      "step": 3350
    },
    {
      "epoch": 8.766233766233766,
      "grad_norm": 0.7764881253242493,
      "learning_rate": 7.879895327989994e-06,
      "loss": 0.5882,
      "step": 3375
    },
    {
      "epoch": 8.831168831168831,
      "grad_norm": 0.724899411201477,
      "learning_rate": 7.081939086478972e-06,
      "loss": 0.3521,
      "step": 3400
    },
    {
      "epoch": 8.896103896103895,
      "grad_norm": 0.774677038192749,
      "learning_rate": 6.325089795643335e-06,
      "loss": 0.5846,
      "step": 3425
    },
    {
      "epoch": 8.96103896103896,
      "grad_norm": 0.8466323614120483,
      "learning_rate": 5.609682285613604e-06,
      "loss": 0.421,
      "step": 3450
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7563206553459167,
      "eval_runtime": 167.3275,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 3465
    },
    {
      "epoch": 9.025974025974026,
      "grad_norm": 0.16530576348304749,
      "learning_rate": 4.936033052676325e-06,
      "loss": 0.3606,
      "step": 3475
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.7464303374290466,
      "learning_rate": 4.304440119255915e-06,
      "loss": 0.5487,
      "step": 3500
    },
    {
      "epoch": 9.155844155844155,
      "grad_norm": 0.1716950237751007,
      "learning_rate": 3.7151829020697583e-06,
      "loss": 0.3421,
      "step": 3525
    },
    {
      "epoch": 9.220779220779221,
      "grad_norm": 0.7252309918403625,
      "learning_rate": 3.1685220885140367e-06,
      "loss": 0.554,
      "step": 3550
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.18889403343200684,
      "learning_rate": 2.6646995213358006e-06,
      "loss": 0.3512,
      "step": 3575
    },
    {
      "epoch": 9.35064935064935,
      "grad_norm": 0.7902368307113647,
      "learning_rate": 2.2039380916415995e-06,
      "loss": 0.517,
      "step": 3600
    },
    {
      "epoch": 9.415584415584416,
      "grad_norm": 0.175469309091568,
      "learning_rate": 1.7864416402905704e-06,
      "loss": 0.3344,
      "step": 3625
    },
    {
      "epoch": 9.480519480519481,
      "grad_norm": 0.780781626701355,
      "learning_rate": 1.4123948677151498e-06,
      "loss": 0.5215,
      "step": 3650
    },
    {
      "epoch": 9.545454545454545,
      "grad_norm": 0.1641235500574112,
      "learning_rate": 1.081963252209639e-06,
      "loss": 0.3449,
      "step": 3675
    },
    {
      "epoch": 9.61038961038961,
      "grad_norm": 0.7453537583351135,
      "learning_rate": 7.952929767226391e-07,
      "loss": 0.5664,
      "step": 3700
    },
    {
      "epoch": 9.675324675324676,
      "grad_norm": 0.17446362972259521,
      "learning_rate": 5.525108641856181e-07,
      "loss": 0.3573,
      "step": 3725
    },
    {
      "epoch": 9.74025974025974,
      "grad_norm": 0.8986365795135498,
      "learning_rate": 3.537243214065566e-07,
      "loss": 0.5744,
      "step": 3750
    },
    {
      "epoch": 9.805194805194805,
      "grad_norm": 0.16516277194023132,
      "learning_rate": 1.9902129155311422e-07,
      "loss": 0.3398,
      "step": 3775
    },
    {
      "epoch": 9.87012987012987,
      "grad_norm": 0.7516262531280518,
      "learning_rate": 8.847021524657217e-08,
      "loss": 0.4942,
      "step": 3800
    },
    {
      "epoch": 9.935064935064934,
      "grad_norm": 0.20029288530349731,
      "learning_rate": 2.212000028370964e-08,
      "loss": 0.3591,
      "step": 3825
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.9626283645629883,
      "learning_rate": 0.0,
      "loss": 0.5435,
      "step": 3850
    }
  ],
  "logging_steps": 25,
  "max_steps": 3850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.117021960855552e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
