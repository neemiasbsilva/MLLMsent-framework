{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.5217493772506714,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.3812,
      "step": 25
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3585882186889648,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.6081,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.493024617433548,
      "learning_rate": 0.0001,
      "loss": 0.7742,
      "step": 75
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8437996506690979,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.2181,
      "step": 100
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.633566677570343,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.5969,
      "step": 125
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9838812351226807,
      "learning_rate": 0.0002,
      "loss": 0.9884,
      "step": 150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.42502152919769287,
      "learning_rate": 0.00019998688836656323,
      "loss": 0.6488,
      "step": 175
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6540848016738892,
      "learning_rate": 0.00019994755690455152,
      "loss": 0.9556,
      "step": 200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3528238832950592,
      "learning_rate": 0.0001998820159279591,
      "loss": 0.5357,
      "step": 225
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5526399612426758,
      "learning_rate": 0.00019979028262377118,
      "loss": 0.9259,
      "step": 250
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.33860981464385986,
      "learning_rate": 0.00019967238104745696,
      "loss": 0.6049,
      "step": 275
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5711782574653625,
      "learning_rate": 0.0001995283421166614,
      "loss": 0.9125,
      "step": 300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3605576157569885,
      "learning_rate": 0.00019935820360309777,
      "loss": 0.5878,
      "step": 325
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5837223529815674,
      "learning_rate": 0.00019916201012264254,
      "loss": 0.919,
      "step": 350
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3492891490459442,
      "learning_rate": 0.00019893981312363562,
      "loss": 0.5821,
      "step": 375
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7227370142936707,
      "learning_rate": 0.00019869167087338907,
      "loss": 0.8918,
      "step": 400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3197798728942871,
      "learning_rate": 0.00019841764844290744,
      "loss": 0.4801,
      "step": 425
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4872809946537018,
      "learning_rate": 0.0001981178176898239,
      "loss": 0.9105,
      "step": 450
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.33781856298446655,
      "learning_rate": 0.00019779225723955707,
      "loss": 0.5517,
      "step": 475
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.40125179290771484,
      "learning_rate": 0.00019744105246469263,
      "loss": 0.8729,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8139565587043762,
      "eval_runtime": 219.5207,
      "eval_samples_per_second": 4.555,
      "eval_steps_per_second": 4.555,
      "step": 500
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2995608448982239,
      "learning_rate": 0.00019706429546259593,
      "loss": 0.5115,
      "step": 525
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5883857011795044,
      "learning_rate": 0.00019666208503126112,
      "loss": 0.8764,
      "step": 550
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.3391435444355011,
      "learning_rate": 0.00019623452664340306,
      "loss": 0.5806,
      "step": 575
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.4991052448749542,
      "learning_rate": 0.00019578173241879872,
      "loss": 0.8473,
      "step": 600
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.31854599714279175,
      "learning_rate": 0.0001953038210948861,
      "loss": 0.5533,
      "step": 625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.3851209580898285,
      "learning_rate": 0.00019480091799562704,
      "loss": 0.8784,
      "step": 650
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.3154122233390808,
      "learning_rate": 0.00019427315499864344,
      "loss": 0.5468,
      "step": 675
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.542729914188385,
      "learning_rate": 0.00019372067050063438,
      "loss": 0.8447,
      "step": 700
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.326457142829895,
      "learning_rate": 0.00019314360938108425,
      "loss": 0.5122,
      "step": 725
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5115891098976135,
      "learning_rate": 0.00019254212296427044,
      "loss": 0.86,
      "step": 750
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.32953977584838867,
      "learning_rate": 0.00019191636897958122,
      "loss": 0.5757,
      "step": 775
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.43951216340065,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8507,
      "step": 800
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.32362955808639526,
      "learning_rate": 0.0001905927209998447,
      "loss": 0.5374,
      "step": 825
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5141394734382629,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.847,
      "step": 850
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.31430110335350037,
      "learning_rate": 0.00018917405376582145,
      "loss": 0.5306,
      "step": 875
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.450622022151947,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.8198,
      "step": 900
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.31080862879753113,
      "learning_rate": 0.0001876618552635348,
      "loss": 0.4673,
      "step": 925
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.4159400165081024,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.8755,
      "step": 950
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.3535349667072296,
      "learning_rate": 0.00018605771158039253,
      "loss": 0.525,
      "step": 975
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4089491069316864,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.854,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7203688025474548,
      "eval_runtime": 219.4853,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 1000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.32315847277641296,
      "learning_rate": 0.00018436330524160047,
      "loss": 0.5015,
      "step": 1025
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.4984952509403229,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.7944,
      "step": 1050
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.3520779013633728,
      "learning_rate": 0.00018258041344542566,
      "loss": 0.4757,
      "step": 1075
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.44643962383270264,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.8102,
      "step": 1100
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3620586097240448,
      "learning_rate": 0.00018071090619916093,
      "loss": 0.5013,
      "step": 1125
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.5130744576454163,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.7775,
      "step": 1150
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.32463595271110535,
      "learning_rate": 0.00017875674435774547,
      "loss": 0.5574,
      "step": 1175
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.44411197304725647,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.8092,
      "step": 1200
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3500864803791046,
      "learning_rate": 0.00017671997756709863,
      "loss": 0.444,
      "step": 1225
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.4474102854728699,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.8241,
      "step": 1250
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3402213454246521,
      "learning_rate": 0.0001746027421143246,
      "loss": 0.5426,
      "step": 1275
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5129525065422058,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.7936,
      "step": 1300
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.3394829332828522,
      "learning_rate": 0.00017240725868704218,
      "loss": 0.4893,
      "step": 1325
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.4567195177078247,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.7852,
      "step": 1350
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.3430050313472748,
      "learning_rate": 0.00017013583004418993,
      "loss": 0.5289,
      "step": 1375
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.49926698207855225,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.7812,
      "step": 1400
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.35916632413864136,
      "learning_rate": 0.00016779083860075033,
      "loss": 0.5003,
      "step": 1425
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5304590463638306,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.8055,
      "step": 1450
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.36190521717071533,
      "learning_rate": 0.00016537474392892528,
      "loss": 0.4496,
      "step": 1475
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.41981610655784607,
      "learning_rate": 0.000164140821963114,
      "loss": 0.7844,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7096384167671204,
      "eval_runtime": 219.4684,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 1500
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.3640426695346832,
      "learning_rate": 0.00016289008017838445,
      "loss": 0.4518,
      "step": 1525
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.48537540435791016,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.7526,
      "step": 1550
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.3829689025878906,
      "learning_rate": 0.00016033945341829248,
      "loss": 0.4545,
      "step": 1575
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.49646827578544617,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.754,
      "step": 1600
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.3610093295574188,
      "learning_rate": 0.00015772553890390197,
      "loss": 0.4664,
      "step": 1625
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.5531775951385498,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.7148,
      "step": 1650
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.4037811756134033,
      "learning_rate": 0.00015505107827058036,
      "loss": 0.4731,
      "step": 1675
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.5374586582183838,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.7567,
      "step": 1700
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.4198489189147949,
      "learning_rate": 0.000152318876658213,
      "loss": 0.4707,
      "step": 1725
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.5000444650650024,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.7324,
      "step": 1750
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.4276421070098877,
      "learning_rate": 0.00014953179976899878,
      "loss": 0.5064,
      "step": 1775
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.43669819831848145,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.7213,
      "step": 1800
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.41623440384864807,
      "learning_rate": 0.00014669277086172406,
      "loss": 0.4709,
      "step": 1825
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.43820616602897644,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.7411,
      "step": 1850
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.39658182859420776,
      "learning_rate": 0.00014380476768566824,
      "loss": 0.5044,
      "step": 1875
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.5378613471984863,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.7386,
      "step": 1900
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.4330134689807892,
      "learning_rate": 0.00014087081935735564,
      "loss": 0.4805,
      "step": 1925
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.4538745880126953,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.7367,
      "step": 1950
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.4098741114139557,
      "learning_rate": 0.00013789400318343068,
      "loss": 0.4246,
      "step": 1975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.5136722326278687,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.7413,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.696414589881897,
      "eval_runtime": 219.4807,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 2000
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.38714900612831116,
      "learning_rate": 0.00013487744143298822,
      "loss": 0.4855,
      "step": 2025
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.47079604864120483,
      "learning_rate": 0.00013335524316508208,
      "loss": 0.6872,
      "step": 2050
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.4405066967010498,
      "learning_rate": 0.0001318242980627444,
      "loss": 0.3794,
      "step": 2075
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.5225964188575745,
      "learning_rate": 0.00013028500758979506,
      "loss": 0.6863,
      "step": 2100
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.4266376495361328,
      "learning_rate": 0.00012873777539848283,
      "loss": 0.4783,
      "step": 2125
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.5270522832870483,
      "learning_rate": 0.0001271830072236343,
      "loss": 0.6755,
      "step": 2150
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.4532109200954437,
      "learning_rate": 0.00012562111077625722,
      "loss": 0.4427,
      "step": 2175
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.543566107749939,
      "learning_rate": 0.00012405249563662537,
      "loss": 0.6931,
      "step": 2200
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.4814315140247345,
      "learning_rate": 0.00012247757314687297,
      "loss": 0.4453,
      "step": 2225
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.47970452904701233,
      "learning_rate": 0.00012089675630312754,
      "loss": 0.6742,
      "step": 2250
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.46641838550567627,
      "learning_rate": 0.00011931045964720881,
      "loss": 0.4476,
      "step": 2275
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.5698740482330322,
      "learning_rate": 0.0001177190991579223,
      "loss": 0.7054,
      "step": 2300
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.4715231955051422,
      "learning_rate": 0.00011612309214197599,
      "loss": 0.447,
      "step": 2325
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.5376561880111694,
      "learning_rate": 0.00011452285712454904,
      "loss": 0.6914,
      "step": 2350
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.4385790526866913,
      "learning_rate": 0.00011291881373954065,
      "loss": 0.4641,
      "step": 2375
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.5154180526733398,
      "learning_rate": 0.00011131138261952845,
      "loss": 0.6739,
      "step": 2400
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.472663551568985,
      "learning_rate": 0.00010970098528546481,
      "loss": 0.3974,
      "step": 2425
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.5942836403846741,
      "learning_rate": 0.00010808804403614043,
      "loss": 0.6681,
      "step": 2450
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.5201991200447083,
      "learning_rate": 0.00010647298183744359,
      "loss": 0.4367,
      "step": 2475
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.5933477282524109,
      "learning_rate": 0.00010485622221144484,
      "loss": 0.6699,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7022653818130493,
      "eval_runtime": 219.4947,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 2500
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.4650670289993286,
      "learning_rate": 0.00010323818912533561,
      "loss": 0.4202,
      "step": 2525
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.5823483467102051,
      "learning_rate": 0.00010161930688025017,
      "loss": 0.6311,
      "step": 2550
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.5272555947303772,
      "learning_rate": 0.0001,
      "loss": 0.3677,
      "step": 2575
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.5865519642829895,
      "learning_rate": 9.838069311974986e-05,
      "loss": 0.6269,
      "step": 2600
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.5256398916244507,
      "learning_rate": 9.676181087466444e-05,
      "loss": 0.4452,
      "step": 2625
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.5701631307601929,
      "learning_rate": 9.514377778855521e-05,
      "loss": 0.6103,
      "step": 2650
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.5221508741378784,
      "learning_rate": 9.352701816255643e-05,
      "loss": 0.4393,
      "step": 2675
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.6412554383277893,
      "learning_rate": 9.19119559638596e-05,
      "loss": 0.6174,
      "step": 2700
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.5401676893234253,
      "learning_rate": 9.02990147145352e-05,
      "loss": 0.4198,
      "step": 2725
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.6556180119514465,
      "learning_rate": 8.868861738047158e-05,
      "loss": 0.6374,
      "step": 2750
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.5277167558670044,
      "learning_rate": 8.70811862604594e-05,
      "loss": 0.45,
      "step": 2775
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.6136420369148254,
      "learning_rate": 8.5477142875451e-05,
      "loss": 0.6117,
      "step": 2800
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.5283671021461487,
      "learning_rate": 8.387690785802402e-05,
      "loss": 0.4357,
      "step": 2825
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.5591272711753845,
      "learning_rate": 8.228090084207774e-05,
      "loss": 0.6226,
      "step": 2850
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.548346996307373,
      "learning_rate": 8.068954035279121e-05,
      "loss": 0.4135,
      "step": 2875
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.6013931035995483,
      "learning_rate": 7.91032436968725e-05,
      "loss": 0.6341,
      "step": 2900
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.5630117654800415,
      "learning_rate": 7.75224268531271e-05,
      "loss": 0.403,
      "step": 2925
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.6462228298187256,
      "learning_rate": 7.594750436337467e-05,
      "loss": 0.6299,
      "step": 2950
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.5768854022026062,
      "learning_rate": 7.437888922374276e-05,
      "loss": 0.3911,
      "step": 2975
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.5622871518135071,
      "learning_rate": 7.281699277636572e-05,
      "loss": 0.6509,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.713441014289856,
      "eval_runtime": 219.4641,
      "eval_samples_per_second": 4.557,
      "eval_steps_per_second": 4.557,
      "step": 3000
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.514452338218689,
      "learning_rate": 7.126222460151719e-05,
      "loss": 0.4422,
      "step": 3025
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.625095009803772,
      "learning_rate": 6.971499241020495e-05,
      "loss": 0.5653,
      "step": 3050
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.6404606103897095,
      "learning_rate": 6.817570193725564e-05,
      "loss": 0.3742,
      "step": 3075
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.5835877656936646,
      "learning_rate": 6.664475683491796e-05,
      "loss": 0.5525,
      "step": 3100
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.6331908702850342,
      "learning_rate": 6.512255856701177e-05,
      "loss": 0.4213,
      "step": 3125
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.5579814314842224,
      "learning_rate": 6.360950630365126e-05,
      "loss": 0.5792,
      "step": 3150
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.6096397042274475,
      "learning_rate": 6.210599681656933e-05,
      "loss": 0.4027,
      "step": 3175
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.6229028105735779,
      "learning_rate": 6.061242437507131e-05,
      "loss": 0.5737,
      "step": 3200
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.6198211908340454,
      "learning_rate": 5.9129180642644414e-05,
      "loss": 0.4348,
      "step": 3225
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.6900286674499512,
      "learning_rate": 5.765665457425102e-05,
      "loss": 0.5929,
      "step": 3250
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.593080461025238,
      "learning_rate": 5.6195232314331766e-05,
      "loss": 0.4013,
      "step": 3275
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.6643621325492859,
      "learning_rate": 5.474529709554612e-05,
      "loss": 0.5936,
      "step": 3300
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.5864590406417847,
      "learning_rate": 5.3307229138275936e-05,
      "loss": 0.3635,
      "step": 3325
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.49607354402542114,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 0.592,
      "step": 3350
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.6114656925201416,
      "learning_rate": 5.0468200231001286e-05,
      "loss": 0.3647,
      "step": 3375
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.6351804137229919,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 0.5972,
      "step": 3400
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.5630666613578796,
      "learning_rate": 4.768112334178699e-05,
      "loss": 0.4099,
      "step": 3425
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.7084890007972717,
      "learning_rate": 4.630798263510162e-05,
      "loss": 0.5981,
      "step": 3450
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.6090997457504272,
      "learning_rate": 4.494892172941965e-05,
      "loss": 0.3548,
      "step": 3475
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.636232852935791,
      "learning_rate": 4.360429701490934e-05,
      "loss": 0.5665,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7292665839195251,
      "eval_runtime": 219.4186,
      "eval_samples_per_second": 4.557,
      "eval_steps_per_second": 4.557,
      "step": 3500
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.6562859416007996,
      "learning_rate": 4.227446109609809e-05,
      "loss": 0.4018,
      "step": 3525
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.6255120038986206,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 0.5297,
      "step": 3550
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.6483391523361206,
      "learning_rate": 3.966054658170754e-05,
      "loss": 0.4039,
      "step": 3575
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.6233877539634705,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 0.5418,
      "step": 3600
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.6885980367660522,
      "learning_rate": 3.710991982161555e-05,
      "loss": 0.3514,
      "step": 3625
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.682543933391571,
      "learning_rate": 3.585917803688603e-05,
      "loss": 0.5508,
      "step": 3650
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.6974108815193176,
      "learning_rate": 3.4625256071074773e-05,
      "loss": 0.3647,
      "step": 3675
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.6740803122520447,
      "learning_rate": 3.340847749883191e-05,
      "loss": 0.5364,
      "step": 3700
    },
    {
      "epoch": 7.45,
      "grad_norm": 0.6873512268066406,
      "learning_rate": 3.2209161399249674e-05,
      "loss": 0.3833,
      "step": 3725
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.5760952830314636,
      "learning_rate": 3.102762227218957e-05,
      "loss": 0.5211,
      "step": 3750
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.6844961643218994,
      "learning_rate": 2.9864169955810084e-05,
      "loss": 0.3857,
      "step": 3775
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.7450054883956909,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 0.5593,
      "step": 3800
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.7161986827850342,
      "learning_rate": 2.759274131295787e-05,
      "loss": 0.41,
      "step": 3825
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.7438632845878601,
      "learning_rate": 2.6485360629279987e-05,
      "loss": 0.5212,
      "step": 3850
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.6955397129058838,
      "learning_rate": 2.5397257885675397e-05,
      "loss": 0.3673,
      "step": 3875
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.6392484903335571,
      "learning_rate": 2.432871841823047e-05,
      "loss": 0.54,
      "step": 3900
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.6415512561798096,
      "learning_rate": 2.3280022432901383e-05,
      "loss": 0.3583,
      "step": 3925
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.7180774807929993,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 0.5527,
      "step": 3950
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.6936122179031372,
      "learning_rate": 2.1243255642254578e-05,
      "loss": 0.3915,
      "step": 3975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.6981480717658997,
      "learning_rate": 2.025571894372794e-05,
      "loss": 0.559,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7377501130104065,
      "eval_runtime": 219.4374,
      "eval_samples_per_second": 4.557,
      "eval_steps_per_second": 4.557,
      "step": 4000
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.7132310271263123,
      "learning_rate": 1.9289093800839066e-05,
      "loss": 0.3548,
      "step": 4025
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.7450364828109741,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 0.538,
      "step": 4050
    },
    {
      "epoch": 8.15,
      "grad_norm": 0.6819972991943359,
      "learning_rate": 1.741958655457436e-05,
      "loss": 0.3677,
      "step": 4075
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7632412314414978,
      "learning_rate": 1.65171946970729e-05,
      "loss": 0.511,
      "step": 4100
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.7000929117202759,
      "learning_rate": 1.563669475839956e-05,
      "loss": 0.3723,
      "step": 4125
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.5895439982414246,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 0.5165,
      "step": 4150
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.7236286401748657,
      "learning_rate": 1.3942288419607475e-05,
      "loss": 0.3903,
      "step": 4175
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.7147305011749268,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 0.5053,
      "step": 4200
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.6466398239135742,
      "learning_rate": 1.233814473646524e-05,
      "loss": 0.3476,
      "step": 4225
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.638232946395874,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 0.5141,
      "step": 4250
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.768681526184082,
      "learning_rate": 1.0825946234178574e-05,
      "loss": 0.3871,
      "step": 4275
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.6176967024803162,
      "learning_rate": 1.010482589146048e-05,
      "loss": 0.5309,
      "step": 4300
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.7643241286277771,
      "learning_rate": 9.407279000155312e-06,
      "loss": 0.4077,
      "step": 4325
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.6441059112548828,
      "learning_rate": 8.733488479845997e-06,
      "loss": 0.5026,
      "step": 4350
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.7302922606468201,
      "learning_rate": 8.083631020418791e-06,
      "loss": 0.3342,
      "step": 4375
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.6341302394866943,
      "learning_rate": 7.457877035729588e-06,
      "loss": 0.523,
      "step": 4400
    },
    {
      "epoch": 8.85,
      "grad_norm": 0.6840615272521973,
      "learning_rate": 6.856390618915775e-06,
      "loss": 0.3768,
      "step": 4425
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.7526153326034546,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 0.504,
      "step": 4450
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.7701978087425232,
      "learning_rate": 5.726845001356573e-06,
      "loss": 0.3729,
      "step": 4475
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.6790098547935486,
      "learning_rate": 5.199082004372957e-06,
      "loss": 0.5189,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7495197653770447,
      "eval_runtime": 219.3649,
      "eval_samples_per_second": 4.559,
      "eval_steps_per_second": 4.559,
      "step": 4500
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.7334341406822205,
      "learning_rate": 4.6961789051139124e-06,
      "loss": 0.3686,
      "step": 4525
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.6861687302589417,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 0.5081,
      "step": 4550
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.7296100854873657,
      "learning_rate": 3.7654733565969826e-06,
      "loss": 0.34,
      "step": 4575
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.656581461429596,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 0.4976,
      "step": 4600
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.7179223895072937,
      "learning_rate": 2.9357045374040825e-06,
      "loss": 0.381,
      "step": 4625
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.715011715888977,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 0.4985,
      "step": 4650
    },
    {
      "epoch": 9.35,
      "grad_norm": 0.739278256893158,
      "learning_rate": 2.2077427604429433e-06,
      "loss": 0.3691,
      "step": 4675
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.6550459265708923,
      "learning_rate": 1.882182310176095e-06,
      "loss": 0.4929,
      "step": 4700
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.7388045191764832,
      "learning_rate": 1.5823515570925763e-06,
      "loss": 0.3629,
      "step": 4725
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.7269207239151001,
      "learning_rate": 1.30832912661093e-06,
      "loss": 0.5279,
      "step": 4750
    },
    {
      "epoch": 9.55,
      "grad_norm": 0.7131984829902649,
      "learning_rate": 1.0601868763643996e-06,
      "loss": 0.3839,
      "step": 4775
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.6503021717071533,
      "learning_rate": 8.379898773574924e-07,
      "loss": 0.4969,
      "step": 4800
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.7435158491134644,
      "learning_rate": 6.41796396902239e-07,
      "loss": 0.3533,
      "step": 4825
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.7361478209495544,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 0.51,
      "step": 4850
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.7075026035308838,
      "learning_rate": 3.2761895254306287e-07,
      "loss": 0.3426,
      "step": 4875
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.5946741104125977,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 0.4876,
      "step": 4900
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.7046828269958496,
      "learning_rate": 1.179840720409331e-07,
      "loss": 0.3903,
      "step": 4925
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.6721842885017395,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 0.5197,
      "step": 4950
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.7546064853668213,
      "learning_rate": 1.3111633436779791e-08,
      "loss": 0.3604,
      "step": 4975
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.6290971636772156,
      "learning_rate": 0.0,
      "loss": 0.5182,
      "step": 5000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.076336194751693e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
