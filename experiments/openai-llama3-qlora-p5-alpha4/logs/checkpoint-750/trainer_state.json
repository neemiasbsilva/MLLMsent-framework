{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.3987978994846344,
      "learning_rate": 0.00019999626527854967,
      "loss": 2.3138,
      "step": 25
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.3254483640193939,
      "learning_rate": 0.00019932011458567315,
      "loss": 1.6454,
      "step": 50
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8004218935966492,
      "learning_rate": 0.00019748591813099456,
      "loss": 1.463,
      "step": 75
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.44535231590271,
      "eval_runtime": 64.3537,
      "eval_samples_per_second": 4.615,
      "eval_steps_per_second": 4.615,
      "step": 75
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.29952162504196167,
      "learning_rate": 0.00019451506215072107,
      "loss": 1.4264,
      "step": 100
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.3234497606754303,
      "learning_rate": 0.00019044218602471275,
      "loss": 1.3911,
      "step": 125
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.8929505944252014,
      "learning_rate": 0.0001853147783906514,
      "loss": 1.3703,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.388182520866394,
      "eval_runtime": 64.3601,
      "eval_samples_per_second": 4.615,
      "eval_steps_per_second": 4.615,
      "step": 150
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.35177263617515564,
      "learning_rate": 0.00017919262343932678,
      "loss": 1.3716,
      "step": 175
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.37034666538238525,
      "learning_rate": 0.0001721471038470885,
      "loss": 1.3485,
      "step": 200
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.9576855301856995,
      "learning_rate": 0.00016426036847308286,
      "loss": 1.3138,
      "step": 225
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.380739450454712,
      "eval_runtime": 64.4148,
      "eval_samples_per_second": 4.611,
      "eval_steps_per_second": 4.611,
      "step": 225
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.35910478234291077,
      "learning_rate": 0.0001556243745257003,
      "loss": 1.3162,
      "step": 250
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.4181671738624573,
      "learning_rate": 0.00014633981536631512,
      "loss": 1.3061,
      "step": 275
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.0738718509674072,
      "learning_rate": 0.0001365149464518364,
      "loss": 1.296,
      "step": 300
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3663437366485596,
      "eval_runtime": 64.4981,
      "eval_samples_per_second": 4.605,
      "eval_steps_per_second": 4.605,
      "step": 300
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.34937694668769836,
      "learning_rate": 0.0001262643231052632,
      "loss": 1.2965,
      "step": 325
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.4381631314754486,
      "learning_rate": 0.00011570746483149997,
      "loss": 1.267,
      "step": 350
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.095045566558838,
      "learning_rate": 0.00010496746175214868,
      "loss": 1.2663,
      "step": 375
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3608324527740479,
      "eval_runtime": 64.4079,
      "eval_samples_per_second": 4.611,
      "eval_steps_per_second": 4.611,
      "step": 375
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.41072729229927063,
      "learning_rate": 9.416953940787324e-05,
      "loss": 1.2621,
      "step": 400
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 0.4285873770713806,
      "learning_rate": 8.343959866235283e-05,
      "loss": 1.2414,
      "step": 425
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.163896918296814,
      "learning_rate": 7.290274773215132e-05,
      "loss": 1.2431,
      "step": 450
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3593100309371948,
      "eval_runtime": 64.3851,
      "eval_samples_per_second": 4.613,
      "eval_steps_per_second": 4.613,
      "step": 450
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 0.4435593783855438,
      "learning_rate": 6.268184345863835e-05,
      "loss": 1.233,
      "step": 475
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.45549413561820984,
      "learning_rate": 5.289605883033792e-05,
      "loss": 1.2286,
      "step": 500
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.2145980596542358,
      "learning_rate": 4.365949345800856e-05,
      "loss": 1.2036,
      "step": 525
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.358007550239563,
      "eval_runtime": 64.3784,
      "eval_samples_per_second": 4.613,
      "eval_steps_per_second": 4.613,
      "step": 525
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 0.4362705945968628,
      "learning_rate": 3.507984320394012e-05,
      "loss": 1.2287,
      "step": 550
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 0.4674491882324219,
      "learning_rate": 2.7257144477231756e-05,
      "loss": 1.2004,
      "step": 575
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.3626981973648071,
      "learning_rate": 2.028260783622914e-05,
      "loss": 1.1911,
      "step": 600
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.361463189125061,
      "eval_runtime": 64.3854,
      "eval_samples_per_second": 4.613,
      "eval_steps_per_second": 4.613,
      "step": 600
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.43436312675476074,
      "learning_rate": 1.4237554498002425e-05,
      "loss": 1.224,
      "step": 625
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.526199996471405,
      "learning_rate": 9.192468154877187e-06,
      "loss": 1.1836,
      "step": 650
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.5611907243728638,
      "learning_rate": 5.206173153582705e-06,
      "loss": 1.1861,
      "step": 675
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3604785203933716,
      "eval_runtime": 64.4108,
      "eval_samples_per_second": 4.611,
      "eval_steps_per_second": 4.611,
      "step": 675
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 0.4377369284629822,
      "learning_rate": 2.3251486192267578e-06,
      "loss": 1.2097,
      "step": 700
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 0.5148259401321411,
      "learning_rate": 5.829865212263474e-07,
      "loss": 1.1943,
      "step": 725
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.4796980619430542,
      "learning_rate": 0.0,
      "loss": 1.1693,
      "step": 750
    }
  ],
  "logging_steps": 25,
  "max_steps": 750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0957146767818752e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
