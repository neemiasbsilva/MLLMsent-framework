{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1790,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13966480446927373,
      "grad_norm": 0.639079749584198,
      "learning_rate": 9.25925925925926e-05,
      "loss": 1.8689,
      "step": 25
    },
    {
      "epoch": 0.27932960893854747,
      "grad_norm": 0.5725597143173218,
      "learning_rate": 0.0001851851851851852,
      "loss": 1.3216,
      "step": 50
    },
    {
      "epoch": 0.41899441340782123,
      "grad_norm": 0.5737536549568176,
      "learning_rate": 0.00019992779676965885,
      "loss": 0.8337,
      "step": 75
    },
    {
      "epoch": 0.5586592178770949,
      "grad_norm": 0.30673620104789734,
      "learning_rate": 0.00019965371381818598,
      "loss": 0.7472,
      "step": 100
    },
    {
      "epoch": 0.6983240223463687,
      "grad_norm": 0.2954711616039276,
      "learning_rate": 0.00019917569212703367,
      "loss": 0.6789,
      "step": 125
    },
    {
      "epoch": 0.8379888268156425,
      "grad_norm": 0.2667810320854187,
      "learning_rate": 0.00019849470995518992,
      "loss": 0.7111,
      "step": 150
    },
    {
      "epoch": 0.9776536312849162,
      "grad_norm": 0.3604191541671753,
      "learning_rate": 0.00019761216091500043,
      "loss": 0.6544,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7077717781066895,
      "eval_runtime": 135.3884,
      "eval_samples_per_second": 5.266,
      "eval_steps_per_second": 5.266,
      "step": 179
    },
    {
      "epoch": 1.1173184357541899,
      "grad_norm": 0.2873147130012512,
      "learning_rate": 0.000196529851120177,
      "loss": 0.6886,
      "step": 200
    },
    {
      "epoch": 1.2569832402234637,
      "grad_norm": 0.5607085824012756,
      "learning_rate": 0.00019524999548963274,
      "loss": 0.6301,
      "step": 225
    },
    {
      "epoch": 1.3966480446927374,
      "grad_norm": 0.2770809531211853,
      "learning_rate": 0.00019377521321470805,
      "loss": 0.655,
      "step": 250
    },
    {
      "epoch": 1.536312849162011,
      "grad_norm": 0.2695387303829193,
      "learning_rate": 0.00019210852239906332,
      "loss": 0.651,
      "step": 275
    },
    {
      "epoch": 1.675977653631285,
      "grad_norm": 0.2636210322380066,
      "learning_rate": 0.0001902533338822082,
      "loss": 0.6337,
      "step": 300
    },
    {
      "epoch": 1.8156424581005588,
      "grad_norm": 0.2800334692001343,
      "learning_rate": 0.00018821344425930714,
      "loss": 0.6386,
      "step": 325
    },
    {
      "epoch": 1.9553072625698324,
      "grad_norm": 0.2824663519859314,
      "learning_rate": 0.00018599302811154572,
      "loss": 0.6143,
      "step": 350
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.66645747423172,
      "eval_runtime": 135.4391,
      "eval_samples_per_second": 5.264,
      "eval_steps_per_second": 5.264,
      "step": 358
    },
    {
      "epoch": 2.094972067039106,
      "grad_norm": 0.3163987100124359,
      "learning_rate": 0.0001835966294629586,
      "loss": 0.6384,
      "step": 375
    },
    {
      "epoch": 2.2346368715083798,
      "grad_norm": 0.30938106775283813,
      "learning_rate": 0.00018102915248120237,
      "loss": 0.5805,
      "step": 400
    },
    {
      "epoch": 2.3743016759776534,
      "grad_norm": 0.3084370195865631,
      "learning_rate": 0.00017829585144130356,
      "loss": 0.6373,
      "step": 425
    },
    {
      "epoch": 2.5139664804469275,
      "grad_norm": 0.4288509488105774,
      "learning_rate": 0.00017540231997292114,
      "loss": 0.5977,
      "step": 450
    },
    {
      "epoch": 2.653631284916201,
      "grad_norm": 0.2940915822982788,
      "learning_rate": 0.00017235447961312861,
      "loss": 0.6046,
      "step": 475
    },
    {
      "epoch": 2.793296089385475,
      "grad_norm": 0.2836802303791046,
      "learning_rate": 0.00016915856768814197,
      "loss": 0.588,
      "step": 500
    },
    {
      "epoch": 2.9329608938547485,
      "grad_norm": 0.3271314203739166,
      "learning_rate": 0.00016582112454879348,
      "loss": 0.5703,
      "step": 525
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6346681714057922,
      "eval_runtime": 135.3049,
      "eval_samples_per_second": 5.27,
      "eval_steps_per_second": 5.27,
      "step": 537
    },
    {
      "epoch": 3.0726256983240225,
      "grad_norm": 0.2927284240722656,
      "learning_rate": 0.00016234898018587337,
      "loss": 0.5902,
      "step": 550
    },
    {
      "epoch": 3.212290502793296,
      "grad_norm": 0.32246601581573486,
      "learning_rate": 0.00015874924025273087,
      "loss": 0.5476,
      "step": 575
    },
    {
      "epoch": 3.35195530726257,
      "grad_norm": 0.3047339916229248,
      "learning_rate": 0.00015502927152373914,
      "loss": 0.5959,
      "step": 600
    },
    {
      "epoch": 3.4916201117318435,
      "grad_norm": 0.3670424818992615,
      "learning_rate": 0.00015119668681838245,
      "loss": 0.5458,
      "step": 625
    },
    {
      "epoch": 3.631284916201117,
      "grad_norm": 0.3499419093132019,
      "learning_rate": 0.00014725932942181872,
      "loss": 0.5845,
      "step": 650
    },
    {
      "epoch": 3.770949720670391,
      "grad_norm": 0.3549374043941498,
      "learning_rate": 0.0001432252570338,
      "loss": 0.5544,
      "step": 675
    },
    {
      "epoch": 3.910614525139665,
      "grad_norm": 0.36368685960769653,
      "learning_rate": 0.00013910272527879898,
      "loss": 0.5594,
      "step": 700
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6345822811126709,
      "eval_runtime": 135.7192,
      "eval_samples_per_second": 5.253,
      "eval_steps_per_second": 5.253,
      "step": 716
    },
    {
      "epoch": 4.050279329608939,
      "grad_norm": 0.27198123931884766,
      "learning_rate": 0.0001349001708110876,
      "loss": 0.5519,
      "step": 725
    },
    {
      "epoch": 4.189944134078212,
      "grad_norm": 0.3295210599899292,
      "learning_rate": 0.00013062619404934317,
      "loss": 0.5221,
      "step": 750
    },
    {
      "epoch": 4.329608938547486,
      "grad_norm": 0.2827010154724121,
      "learning_rate": 0.0001262895415761145,
      "loss": 0.5499,
      "step": 775
    },
    {
      "epoch": 4.4692737430167595,
      "grad_norm": 0.37203678488731384,
      "learning_rate": 0.00012189908823816774,
      "loss": 0.5158,
      "step": 800
    },
    {
      "epoch": 4.608938547486034,
      "grad_norm": 0.3182765245437622,
      "learning_rate": 0.00011746381898434289,
      "loss": 0.5642,
      "step": 825
    },
    {
      "epoch": 4.748603351955307,
      "grad_norm": 0.38295987248420715,
      "learning_rate": 0.00011299281047808877,
      "loss": 0.5207,
      "step": 850
    },
    {
      "epoch": 4.888268156424581,
      "grad_norm": 0.3436114192008972,
      "learning_rate": 0.00010849521252230716,
      "loss": 0.5508,
      "step": 875
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6230135560035706,
      "eval_runtime": 135.7654,
      "eval_samples_per_second": 5.252,
      "eval_steps_per_second": 5.252,
      "step": 895
    },
    {
      "epoch": 5.027932960893855,
      "grad_norm": 0.35672831535339355,
      "learning_rate": 0.00010398022933451837,
      "loss": 0.5274,
      "step": 900
    },
    {
      "epoch": 5.167597765363128,
      "grad_norm": 0.3375990390777588,
      "learning_rate": 9.94571007106689e-05,
      "loss": 0.5045,
      "step": 925
    },
    {
      "epoch": 5.307262569832402,
      "grad_norm": 0.3356684148311615,
      "learning_rate": 9.493508311612874e-05,
      "loss": 0.5235,
      "step": 950
    },
    {
      "epoch": 5.446927374301676,
      "grad_norm": 0.3606075644493103,
      "learning_rate": 9.042343074257538e-05,
      "loss": 0.492,
      "step": 975
    },
    {
      "epoch": 5.58659217877095,
      "grad_norm": 0.3166176676750183,
      "learning_rate": 8.593137656953037e-05,
      "loss": 0.5316,
      "step": 1000
    },
    {
      "epoch": 5.726256983240224,
      "grad_norm": 0.4118523597717285,
      "learning_rate": 8.146811346930653e-05,
      "loss": 0.4894,
      "step": 1025
    },
    {
      "epoch": 5.865921787709497,
      "grad_norm": 0.3332236409187317,
      "learning_rate": 7.704277539403304e-05,
      "loss": 0.546,
      "step": 1050
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.619317889213562,
      "eval_runtime": 135.3772,
      "eval_samples_per_second": 5.267,
      "eval_steps_per_second": 5.267,
      "step": 1074
    },
    {
      "epoch": 6.005586592178771,
      "grad_norm": 0.30997133255004883,
      "learning_rate": 7.266441868325962e-05,
      "loss": 0.4988,
      "step": 1075
    },
    {
      "epoch": 6.145251396648045,
      "grad_norm": 0.3631134331226349,
      "learning_rate": 6.834200353039258e-05,
      "loss": 0.5101,
      "step": 1100
    },
    {
      "epoch": 6.284916201117318,
      "grad_norm": 0.3968529999256134,
      "learning_rate": 6.40843756458913e-05,
      "loss": 0.4975,
      "step": 1125
    },
    {
      "epoch": 6.424581005586592,
      "grad_norm": 0.36308029294013977,
      "learning_rate": 5.9900248154751616e-05,
      "loss": 0.4928,
      "step": 1150
    },
    {
      "epoch": 6.564245810055866,
      "grad_norm": 0.3312523066997528,
      "learning_rate": 5.579818376532131e-05,
      "loss": 0.5031,
      "step": 1175
    },
    {
      "epoch": 6.70391061452514,
      "grad_norm": 0.4235427975654602,
      "learning_rate": 5.1786577245939784e-05,
      "loss": 0.4836,
      "step": 1200
    },
    {
      "epoch": 6.843575418994414,
      "grad_norm": 0.36816906929016113,
      "learning_rate": 4.787363824526244e-05,
      "loss": 0.5054,
      "step": 1225
    },
    {
      "epoch": 6.983240223463687,
      "grad_norm": 0.4986415207386017,
      "learning_rate": 4.406737449142769e-05,
      "loss": 0.4613,
      "step": 1250
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.6236502528190613,
      "eval_runtime": 135.351,
      "eval_samples_per_second": 5.268,
      "eval_steps_per_second": 5.268,
      "step": 1253
    },
    {
      "epoch": 7.122905027932961,
      "grad_norm": 0.35535627603530884,
      "learning_rate": 4.037557540444914e-05,
      "loss": 0.4948,
      "step": 1275
    },
    {
      "epoch": 7.262569832402234,
      "grad_norm": 0.47189560532569885,
      "learning_rate": 3.680579615536961e-05,
      "loss": 0.4662,
      "step": 1300
    },
    {
      "epoch": 7.402234636871508,
      "grad_norm": 0.36977073550224304,
      "learning_rate": 3.336534220479961e-05,
      "loss": 0.4832,
      "step": 1325
    },
    {
      "epoch": 7.5418994413407825,
      "grad_norm": 0.37792348861694336,
      "learning_rate": 3.0061254352481804e-05,
      "loss": 0.4847,
      "step": 1350
    },
    {
      "epoch": 7.681564245810056,
      "grad_norm": 0.4062694311141968,
      "learning_rate": 2.690029432847694e-05,
      "loss": 0.4717,
      "step": 1375
    },
    {
      "epoch": 7.82122905027933,
      "grad_norm": 0.4178277552127838,
      "learning_rate": 2.388893095545881e-05,
      "loss": 0.4923,
      "step": 1400
    },
    {
      "epoch": 7.960893854748603,
      "grad_norm": 0.48905816674232483,
      "learning_rate": 2.103332691043641e-05,
      "loss": 0.4522,
      "step": 1425
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.618340253829956,
      "eval_runtime": 135.3409,
      "eval_samples_per_second": 5.268,
      "eval_steps_per_second": 5.268,
      "step": 1432
    },
    {
      "epoch": 8.100558659217878,
      "grad_norm": 0.37598124146461487,
      "learning_rate": 1.8339326112995425e-05,
      "loss": 0.498,
      "step": 1450
    },
    {
      "epoch": 8.240223463687151,
      "grad_norm": 0.495459645986557,
      "learning_rate": 1.5812441765868292e-05,
      "loss": 0.4442,
      "step": 1475
    },
    {
      "epoch": 8.379888268156424,
      "grad_norm": 0.4089173376560211,
      "learning_rate": 1.3457845072308084e-05,
      "loss": 0.4866,
      "step": 1500
    },
    {
      "epoch": 8.519553072625698,
      "grad_norm": 0.38177114725112915,
      "learning_rate": 1.1280354653354929e-05,
      "loss": 0.4565,
      "step": 1525
    },
    {
      "epoch": 8.659217877094973,
      "grad_norm": 0.40016239881515503,
      "learning_rate": 9.284426686653303e-06,
      "loss": 0.4598,
      "step": 1550
    },
    {
      "epoch": 8.798882681564246,
      "grad_norm": 0.38755089044570923,
      "learning_rate": 7.474145787000087e-06,
      "loss": 0.4739,
      "step": 1575
    },
    {
      "epoch": 8.938547486033519,
      "grad_norm": 0.41241851449012756,
      "learning_rate": 5.853216647286197e-06,
      "loss": 0.4469,
      "step": 1600
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6167134642601013,
      "eval_runtime": 135.6772,
      "eval_samples_per_second": 5.255,
      "eval_steps_per_second": 5.255,
      "step": 1611
    },
    {
      "epoch": 9.078212290502794,
      "grad_norm": 0.4215626120567322,
      "learning_rate": 4.424956456938878e-06,
      "loss": 0.4782,
      "step": 1625
    },
    {
      "epoch": 9.217877094972067,
      "grad_norm": 0.41705945134162903,
      "learning_rate": 3.1922881133795825e-06,
      "loss": 0.4403,
      "step": 1650
    },
    {
      "epoch": 9.35754189944134,
      "grad_norm": 0.41395634412765503,
      "learning_rate": 2.15773424039013e-06,
      "loss": 0.4885,
      "step": 1675
    },
    {
      "epoch": 9.497206703910614,
      "grad_norm": 0.3420850932598114,
      "learning_rate": 1.323412025628712e-06,
      "loss": 0.4465,
      "step": 1700
    },
    {
      "epoch": 9.636871508379889,
      "grad_norm": 0.3838639259338379,
      "learning_rate": 6.910288878602456e-07,
      "loss": 0.4784,
      "step": 1725
    },
    {
      "epoch": 9.776536312849162,
      "grad_norm": 0.3825460374355316,
      "learning_rate": 2.6187898276813784e-07,
      "loss": 0.453,
      "step": 1750
    },
    {
      "epoch": 9.916201117318435,
      "grad_norm": 0.38667723536491394,
      "learning_rate": 3.6840554498274174e-08,
      "loss": 0.4474,
      "step": 1775
    }
  ],
  "logging_steps": 25,
  "max_steps": 1790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5391302478430208e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
