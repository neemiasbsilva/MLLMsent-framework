{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1905,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 0.3756851255893707,
      "learning_rate": 8.620689655172413e-05,
      "loss": 2.3906,
      "step": 25
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.3797982335090637,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.9076,
      "step": 50
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.4035528898239136,
      "learning_rate": 0.00019995819737621894,
      "loss": 1.5635,
      "step": 75
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.2797962725162506,
      "learning_rate": 0.00019974493560924895,
      "loss": 1.4503,
      "step": 100
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.3794000744819641,
      "learning_rate": 0.00019935134242983634,
      "loss": 1.393,
      "step": 125
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4281917810440063,
      "eval_runtime": 109.1625,
      "eval_samples_per_second": 4.635,
      "eval_steps_per_second": 4.635,
      "step": 127
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.30622705817222595,
      "learning_rate": 0.00019877812942512617,
      "loss": 1.3997,
      "step": 150
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.3077964782714844,
      "learning_rate": 0.00019802633292152584,
      "loss": 1.3923,
      "step": 175
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.3348962962627411,
      "learning_rate": 0.0001970973121111039,
      "loss": 1.3686,
      "step": 200
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.35092973709106445,
      "learning_rate": 0.00019599274659427228,
      "loss": 1.3648,
      "step": 225
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.35334512591362,
      "learning_rate": 0.0001947146333431937,
      "loss": 1.3517,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3885596990585327,
      "eval_runtime": 109.172,
      "eval_samples_per_second": 4.635,
      "eval_steps_per_second": 4.635,
      "step": 254
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.31318461894989014,
      "learning_rate": 0.00019326528309140478,
      "loss": 1.3462,
      "step": 275
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.3345852494239807,
      "learning_rate": 0.00019164731615618226,
      "loss": 1.3398,
      "step": 300
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.2997647225856781,
      "learning_rate": 0.00018986365770120412,
      "loss": 1.3237,
      "step": 325
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4186607897281647,
      "learning_rate": 0.00018791753244807184,
      "loss": 1.3222,
      "step": 350
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.34162095189094543,
      "learning_rate": 0.00018581245884625406,
      "loss": 1.3225,
      "step": 375
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3720118999481201,
      "eval_runtime": 109.1468,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 381
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.3373397886753082,
      "learning_rate": 0.00018355224271199188,
      "loss": 1.3008,
      "step": 400
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.3636999726295471,
      "learning_rate": 0.00018114097034766674,
      "loss": 1.308,
      "step": 425
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.30345720052719116,
      "learning_rate": 0.00017858300115407015,
      "loss": 1.278,
      "step": 450
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.3167237937450409,
      "learning_rate": 0.0001758829597489318,
      "loss": 1.2714,
      "step": 475
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.3673781156539917,
      "learning_rate": 0.00017304572760595528,
      "loss": 1.2995,
      "step": 500
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3685672283172607,
      "eval_runtime": 109.1615,
      "eval_samples_per_second": 4.635,
      "eval_steps_per_second": 4.635,
      "step": 508
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.35661745071411133,
      "learning_rate": 0.00017007643422947726,
      "loss": 1.2777,
      "step": 525
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.3478938639163971,
      "learning_rate": 0.00016698044788070592,
      "loss": 1.2479,
      "step": 550
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.38275253772735596,
      "learning_rate": 0.0001637633658723044,
      "loss": 1.2557,
      "step": 575
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.40850093960762024,
      "learning_rate": 0.00016043100444886673,
      "loss": 1.2433,
      "step": 600
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.3640328645706177,
      "learning_rate": 0.00015698938827158089,
      "loss": 1.2814,
      "step": 625
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3617571592330933,
      "eval_runtime": 109.1028,
      "eval_samples_per_second": 4.638,
      "eval_steps_per_second": 4.638,
      "step": 635
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.3724489212036133,
      "learning_rate": 0.00015344473952609005,
      "loss": 1.2498,
      "step": 650
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.3526361286640167,
      "learning_rate": 0.00014980346667324484,
      "loss": 1.2279,
      "step": 675
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.437858521938324,
      "learning_rate": 0.00014607215286308316,
      "loss": 1.1996,
      "step": 700
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.4306609332561493,
      "learning_rate": 0.00014225754403298556,
      "loss": 1.2229,
      "step": 725
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.4005732536315918,
      "learning_rate": 0.00013836653671152322,
      "loss": 1.2521,
      "step": 750
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3632862567901611,
      "eval_runtime": 109.1694,
      "eval_samples_per_second": 4.635,
      "eval_steps_per_second": 4.635,
      "step": 762
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.3788298964500427,
      "learning_rate": 0.00013440616555004768,
      "loss": 1.2314,
      "step": 775
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.42618274688720703,
      "learning_rate": 0.00013038359060456572,
      "loss": 1.181,
      "step": 800
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.36193734407424927,
      "learning_rate": 0.0001263060843908912,
      "loss": 1.1687,
      "step": 825
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.41896241903305054,
      "learning_rate": 0.00012218101873647842,
      "loss": 1.2122,
      "step": 850
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.4107866585254669,
      "learning_rate": 0.00011801585145270741,
      "loss": 1.2158,
      "step": 875
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3610337972640991,
      "eval_runtime": 109.1553,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 889
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.390434592962265,
      "learning_rate": 0.00011381811285171633,
      "loss": 1.1807,
      "step": 900
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.4388130307197571,
      "learning_rate": 0.00010959539213215832,
      "loss": 1.157,
      "step": 925
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.5179879069328308,
      "learning_rate": 0.00010535532365849566,
      "loss": 1.1397,
      "step": 950
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.4259627163410187,
      "learning_rate": 0.00010110557315863762,
      "loss": 1.1889,
      "step": 975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.4221698045730591,
      "learning_rate": 9.685382386487555e-05,
      "loss": 1.1776,
      "step": 1000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.370873212814331,
      "eval_runtime": 109.1458,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 1016
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.42297661304473877,
      "learning_rate": 9.260776262317117e-05,
      "loss": 1.1531,
      "step": 1025
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.5207340717315674,
      "learning_rate": 8.837506599591198e-05,
      "loss": 1.117,
      "step": 1050
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.5341467261314392,
      "learning_rate": 8.416338638325815e-05,
      "loss": 1.1355,
      "step": 1075
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.4803115725517273,
      "learning_rate": 7.998033818817327e-05,
      "loss": 1.1591,
      "step": 1100
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.442806601524353,
      "learning_rate": 7.583348405015099e-05,
      "loss": 1.157,
      "step": 1125
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.376487374305725,
      "eval_runtime": 109.1431,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 1143
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.45987668633461,
      "learning_rate": 7.173032117252643e-05,
      "loss": 1.1292,
      "step": 1150
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.45524024963378906,
      "learning_rate": 6.767826776809085e-05,
      "loss": 1.0854,
      "step": 1175
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.5030812621116638,
      "learning_rate": 6.368464964751575e-05,
      "loss": 1.1265,
      "step": 1200
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.48771387338638306,
      "learning_rate": 5.9756686974832985e-05,
      "loss": 1.1363,
      "step": 1225
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.5003126263618469,
      "learning_rate": 5.590148121391594e-05,
      "loss": 1.1309,
      "step": 1250
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3916438817977905,
      "eval_runtime": 109.1012,
      "eval_samples_per_second": 4.638,
      "eval_steps_per_second": 4.638,
      "step": 1270
    },
    {
      "epoch": 10.039370078740157,
      "grad_norm": 0.4373759329319,
      "learning_rate": 5.212600228956207e-05,
      "loss": 1.0978,
      "step": 1275
    },
    {
      "epoch": 10.236220472440944,
      "grad_norm": 0.5975074768066406,
      "learning_rate": 4.843707598638806e-05,
      "loss": 1.0722,
      "step": 1300
    },
    {
      "epoch": 10.433070866141732,
      "grad_norm": 0.5397534966468811,
      "learning_rate": 4.484137160831988e-05,
      "loss": 1.1282,
      "step": 1325
    },
    {
      "epoch": 10.62992125984252,
      "grad_norm": 0.5319319367408752,
      "learning_rate": 4.134538992098798e-05,
      "loss": 1.1081,
      "step": 1350
    },
    {
      "epoch": 10.826771653543307,
      "grad_norm": 0.4862057566642761,
      "learning_rate": 3.7955451398827434e-05,
      "loss": 1.1049,
      "step": 1375
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3977501392364502,
      "eval_runtime": 109.1556,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 1397
    },
    {
      "epoch": 11.023622047244094,
      "grad_norm": 0.5250544548034668,
      "learning_rate": 3.467768479813116e-05,
      "loss": 1.0805,
      "step": 1400
    },
    {
      "epoch": 11.220472440944881,
      "grad_norm": 0.5855162739753723,
      "learning_rate": 3.151801607671495e-05,
      "loss": 1.0733,
      "step": 1425
    },
    {
      "epoch": 11.417322834645669,
      "grad_norm": 0.5294381976127625,
      "learning_rate": 2.8482157680227307e-05,
      "loss": 1.1081,
      "step": 1450
    },
    {
      "epoch": 11.614173228346457,
      "grad_norm": 0.5096080899238586,
      "learning_rate": 2.5575598214473317e-05,
      "loss": 1.0923,
      "step": 1475
    },
    {
      "epoch": 11.811023622047244,
      "grad_norm": 0.536720871925354,
      "learning_rate": 2.2803592522424322e-05,
      "loss": 1.0857,
      "step": 1500
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3991318941116333,
      "eval_runtime": 109.2823,
      "eval_samples_per_second": 4.63,
      "eval_steps_per_second": 4.63,
      "step": 1524
    },
    {
      "epoch": 12.007874015748031,
      "grad_norm": 0.4340859055519104,
      "learning_rate": 2.017115218385318e-05,
      "loss": 1.0555,
      "step": 1525
    },
    {
      "epoch": 12.204724409448819,
      "grad_norm": 0.5436944961547852,
      "learning_rate": 1.7683036454771463e-05,
      "loss": 1.0855,
      "step": 1550
    },
    {
      "epoch": 12.401574803149606,
      "grad_norm": 0.5480276942253113,
      "learning_rate": 1.534374366304926e-05,
      "loss": 1.0903,
      "step": 1575
    },
    {
      "epoch": 12.598425196850394,
      "grad_norm": 0.5306785106658936,
      "learning_rate": 1.3157503075773359e-05,
      "loss": 1.0743,
      "step": 1600
    },
    {
      "epoch": 12.795275590551181,
      "grad_norm": 0.5052575469017029,
      "learning_rate": 1.112826725304752e-05,
      "loss": 1.075,
      "step": 1625
    },
    {
      "epoch": 12.992125984251969,
      "grad_norm": 0.5368393659591675,
      "learning_rate": 9.25970490205832e-06,
      "loss": 1.0472,
      "step": 1650
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3989284038543701,
      "eval_runtime": 109.2753,
      "eval_samples_per_second": 4.631,
      "eval_steps_per_second": 4.631,
      "step": 1651
    },
    {
      "epoch": 13.188976377952756,
      "grad_norm": 0.543077826499939,
      "learning_rate": 7.555194244325792e-06,
      "loss": 1.0991,
      "step": 1675
    },
    {
      "epoch": 13.385826771653543,
      "grad_norm": 0.5064535737037659,
      "learning_rate": 6.0178169081306575e-06,
      "loss": 1.0907,
      "step": 1700
    },
    {
      "epoch": 13.582677165354331,
      "grad_norm": 0.5286579132080078,
      "learning_rate": 4.650352357159982e-06,
      "loss": 1.0747,
      "step": 1725
    },
    {
      "epoch": 13.779527559055119,
      "grad_norm": 0.5121087431907654,
      "learning_rate": 3.455272865443859e-06,
      "loss": 1.0397,
      "step": 1750
    },
    {
      "epoch": 13.976377952755906,
      "grad_norm": 0.7146738171577454,
      "learning_rate": 2.4347390476682108e-06,
      "loss": 1.032,
      "step": 1775
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.4014393091201782,
      "eval_runtime": 109.1463,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 1778
    },
    {
      "epoch": 14.173228346456693,
      "grad_norm": 0.5363895893096924,
      "learning_rate": 1.5905959529443625e-06,
      "loss": 1.1034,
      "step": 1800
    },
    {
      "epoch": 14.37007874015748,
      "grad_norm": 0.5100600123405457,
      "learning_rate": 9.243697290977071e-07,
      "loss": 1.0569,
      "step": 1825
    },
    {
      "epoch": 14.566929133858268,
      "grad_norm": 0.5322865843772888,
      "learning_rate": 4.372648635061705e-07,
      "loss": 1.0606,
      "step": 1850
    },
    {
      "epoch": 14.763779527559056,
      "grad_norm": 0.5177187323570251,
      "learning_rate": 1.3016200547674163e-07,
      "loss": 1.0514,
      "step": 1875
    },
    {
      "epoch": 14.960629921259843,
      "grad_norm": 0.6242697238922119,
      "learning_rate": 3.616374097148434e-09,
      "loss": 1.0576,
      "step": 1900
    }
  ],
  "logging_steps": 25,
  "max_steps": 1905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7948088232583168e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
