{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1905,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 0.37040022015571594,
      "learning_rate": 8.620689655172413e-05,
      "loss": 2.3359,
      "step": 25
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.3330387771129608,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.8648,
      "step": 50
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.2709433436393738,
      "learning_rate": 0.00019995819737621894,
      "loss": 1.5121,
      "step": 75
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.28558528423309326,
      "learning_rate": 0.00019974493560924895,
      "loss": 1.4062,
      "step": 100
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.5461865067481995,
      "learning_rate": 0.00019935134242983634,
      "loss": 1.3704,
      "step": 125
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3683608770370483,
      "eval_runtime": 68.2715,
      "eval_samples_per_second": 7.412,
      "eval_steps_per_second": 7.412,
      "step": 127
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.2990606725215912,
      "learning_rate": 0.00019877812942512617,
      "loss": 1.3654,
      "step": 150
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.34195905923843384,
      "learning_rate": 0.00019802633292152584,
      "loss": 1.3574,
      "step": 175
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.34578466415405273,
      "learning_rate": 0.0001970973121111039,
      "loss": 1.338,
      "step": 200
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.32913121581077576,
      "learning_rate": 0.00019599274659427228,
      "loss": 1.3196,
      "step": 225
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.33047983050346375,
      "learning_rate": 0.0001947146333431937,
      "loss": 1.3035,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3285890817642212,
      "eval_runtime": 68.3574,
      "eval_samples_per_second": 7.402,
      "eval_steps_per_second": 7.402,
      "step": 254
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.3000498414039612,
      "learning_rate": 0.00019326528309140478,
      "loss": 1.3135,
      "step": 275
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.3330373466014862,
      "learning_rate": 0.00019164731615618226,
      "loss": 1.2957,
      "step": 300
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.31571468710899353,
      "learning_rate": 0.00018986365770120412,
      "loss": 1.2971,
      "step": 325
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4008658826351166,
      "learning_rate": 0.00018791753244807184,
      "loss": 1.2743,
      "step": 350
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.31446635723114014,
      "learning_rate": 0.00018581245884625406,
      "loss": 1.2908,
      "step": 375
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.312705397605896,
      "eval_runtime": 68.5781,
      "eval_samples_per_second": 7.378,
      "eval_steps_per_second": 7.378,
      "step": 381
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.3166082501411438,
      "learning_rate": 0.00018355224271199188,
      "loss": 1.2762,
      "step": 400
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.336391806602478,
      "learning_rate": 0.00018114097034766674,
      "loss": 1.2571,
      "step": 425
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.36105644702911377,
      "learning_rate": 0.00017858300115407015,
      "loss": 1.2519,
      "step": 450
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.3215217888355255,
      "learning_rate": 0.0001758829597489318,
      "loss": 1.2395,
      "step": 475
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.31610187888145447,
      "learning_rate": 0.00017304572760595528,
      "loss": 1.2566,
      "step": 500
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3056069612503052,
      "eval_runtime": 68.5544,
      "eval_samples_per_second": 7.381,
      "eval_steps_per_second": 7.381,
      "step": 508
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.3363676965236664,
      "learning_rate": 0.00017007643422947726,
      "loss": 1.2489,
      "step": 525
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.34508466720581055,
      "learning_rate": 0.00016698044788070592,
      "loss": 1.218,
      "step": 550
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.4031848907470703,
      "learning_rate": 0.0001637633658723044,
      "loss": 1.2181,
      "step": 575
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.38889265060424805,
      "learning_rate": 0.00016043100444886673,
      "loss": 1.2004,
      "step": 600
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.3439370095729828,
      "learning_rate": 0.00015698938827158089,
      "loss": 1.2395,
      "step": 625
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3011714220046997,
      "eval_runtime": 68.5071,
      "eval_samples_per_second": 7.386,
      "eval_steps_per_second": 7.386,
      "step": 635
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.35104525089263916,
      "learning_rate": 0.00015344473952609005,
      "loss": 1.2168,
      "step": 650
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.3510875105857849,
      "learning_rate": 0.00014980346667324484,
      "loss": 1.1844,
      "step": 675
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.4096704423427582,
      "learning_rate": 0.00014607215286308316,
      "loss": 1.1734,
      "step": 700
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.37759408354759216,
      "learning_rate": 0.00014225754403298556,
      "loss": 1.19,
      "step": 725
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.3880816102027893,
      "learning_rate": 0.00013836653671152322,
      "loss": 1.2171,
      "step": 750
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3037444353103638,
      "eval_runtime": 68.4901,
      "eval_samples_per_second": 7.388,
      "eval_steps_per_second": 7.388,
      "step": 762
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.3530571162700653,
      "learning_rate": 0.00013440616555004768,
      "loss": 1.1888,
      "step": 775
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.3764784336090088,
      "learning_rate": 0.00013038359060456572,
      "loss": 1.1523,
      "step": 800
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.3449339270591736,
      "learning_rate": 0.0001263060843908912,
      "loss": 1.1513,
      "step": 825
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.4151313006877899,
      "learning_rate": 0.00012218101873647842,
      "loss": 1.1728,
      "step": 850
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.4168862998485565,
      "learning_rate": 0.00011801585145270741,
      "loss": 1.1764,
      "step": 875
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3078203201293945,
      "eval_runtime": 68.533,
      "eval_samples_per_second": 7.383,
      "eval_steps_per_second": 7.383,
      "step": 889
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.3835373818874359,
      "learning_rate": 0.00011381811285171633,
      "loss": 1.1436,
      "step": 900
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.4515399932861328,
      "learning_rate": 0.00010959539213215832,
      "loss": 1.115,
      "step": 925
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.4555465579032898,
      "learning_rate": 0.00010535532365849566,
      "loss": 1.1039,
      "step": 950
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.4436454772949219,
      "learning_rate": 0.00010110557315863762,
      "loss": 1.1592,
      "step": 975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.3971792161464691,
      "learning_rate": 9.685382386487555e-05,
      "loss": 1.1545,
      "step": 1000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3081471920013428,
      "eval_runtime": 68.5141,
      "eval_samples_per_second": 7.385,
      "eval_steps_per_second": 7.385,
      "step": 1016
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.42873916029930115,
      "learning_rate": 9.260776262317117e-05,
      "loss": 1.1215,
      "step": 1025
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.4546332359313965,
      "learning_rate": 8.837506599591198e-05,
      "loss": 1.092,
      "step": 1050
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.5093407034873962,
      "learning_rate": 8.416338638325815e-05,
      "loss": 1.0971,
      "step": 1075
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.467671662569046,
      "learning_rate": 7.998033818817327e-05,
      "loss": 1.1345,
      "step": 1100
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.4311045706272125,
      "learning_rate": 7.583348405015099e-05,
      "loss": 1.1152,
      "step": 1125
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.316823959350586,
      "eval_runtime": 68.5188,
      "eval_samples_per_second": 7.385,
      "eval_steps_per_second": 7.385,
      "step": 1143
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.4212687909603119,
      "learning_rate": 7.173032117252643e-05,
      "loss": 1.0997,
      "step": 1150
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.4314176142215729,
      "learning_rate": 6.767826776809085e-05,
      "loss": 1.0577,
      "step": 1175
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.5052764415740967,
      "learning_rate": 6.368464964751575e-05,
      "loss": 1.103,
      "step": 1200
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.4832822382450104,
      "learning_rate": 5.9756686974832985e-05,
      "loss": 1.1045,
      "step": 1225
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.4663594961166382,
      "learning_rate": 5.590148121391594e-05,
      "loss": 1.0852,
      "step": 1250
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3268955945968628,
      "eval_runtime": 68.4043,
      "eval_samples_per_second": 7.397,
      "eval_steps_per_second": 7.397,
      "step": 1270
    },
    {
      "epoch": 10.039370078740157,
      "grad_norm": 0.45272400975227356,
      "learning_rate": 5.212600228956207e-05,
      "loss": 1.0814,
      "step": 1275
    },
    {
      "epoch": 10.236220472440944,
      "grad_norm": 0.5661892890930176,
      "learning_rate": 4.843707598638806e-05,
      "loss": 1.0369,
      "step": 1300
    },
    {
      "epoch": 10.433070866141732,
      "grad_norm": 0.49003398418426514,
      "learning_rate": 4.484137160831988e-05,
      "loss": 1.0907,
      "step": 1325
    },
    {
      "epoch": 10.62992125984252,
      "grad_norm": 0.5052348971366882,
      "learning_rate": 4.134538992098798e-05,
      "loss": 1.0851,
      "step": 1350
    },
    {
      "epoch": 10.826771653543307,
      "grad_norm": 0.4815233051776886,
      "learning_rate": 3.7955451398827434e-05,
      "loss": 1.0536,
      "step": 1375
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.331129550933838,
      "eval_runtime": 68.5215,
      "eval_samples_per_second": 7.385,
      "eval_steps_per_second": 7.385,
      "step": 1397
    },
    {
      "epoch": 11.023622047244094,
      "grad_norm": 0.5127527117729187,
      "learning_rate": 3.467768479813116e-05,
      "loss": 1.0662,
      "step": 1400
    },
    {
      "epoch": 11.220472440944881,
      "grad_norm": 0.5349923968315125,
      "learning_rate": 3.151801607671495e-05,
      "loss": 1.0521,
      "step": 1425
    },
    {
      "epoch": 11.417322834645669,
      "grad_norm": 0.5598950386047363,
      "learning_rate": 2.8482157680227307e-05,
      "loss": 1.072,
      "step": 1450
    },
    {
      "epoch": 11.614173228346457,
      "grad_norm": 0.5042483806610107,
      "learning_rate": 2.5575598214473317e-05,
      "loss": 1.0578,
      "step": 1475
    },
    {
      "epoch": 11.811023622047244,
      "grad_norm": 0.49358534812927246,
      "learning_rate": 2.2803592522424322e-05,
      "loss": 1.0592,
      "step": 1500
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3367538452148438,
      "eval_runtime": 68.5381,
      "eval_samples_per_second": 7.383,
      "eval_steps_per_second": 7.383,
      "step": 1524
    },
    {
      "epoch": 12.007874015748031,
      "grad_norm": 0.41227081418037415,
      "learning_rate": 2.017115218385318e-05,
      "loss": 1.0174,
      "step": 1525
    },
    {
      "epoch": 12.204724409448819,
      "grad_norm": 0.554608941078186,
      "learning_rate": 1.7683036454771463e-05,
      "loss": 1.0647,
      "step": 1550
    },
    {
      "epoch": 12.401574803149606,
      "grad_norm": 0.5030187368392944,
      "learning_rate": 1.534374366304926e-05,
      "loss": 1.0606,
      "step": 1575
    },
    {
      "epoch": 12.598425196850394,
      "grad_norm": 0.4867393672466278,
      "learning_rate": 1.3157503075773359e-05,
      "loss": 1.0426,
      "step": 1600
    },
    {
      "epoch": 12.795275590551181,
      "grad_norm": 0.48542720079421997,
      "learning_rate": 1.112826725304752e-05,
      "loss": 1.0407,
      "step": 1625
    },
    {
      "epoch": 12.992125984251969,
      "grad_norm": 0.5100423097610474,
      "learning_rate": 9.25970490205832e-06,
      "loss": 1.0111,
      "step": 1650
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3392192125320435,
      "eval_runtime": 68.5411,
      "eval_samples_per_second": 7.382,
      "eval_steps_per_second": 7.382,
      "step": 1651
    },
    {
      "epoch": 13.188976377952756,
      "grad_norm": 0.5567373633384705,
      "learning_rate": 7.555194244325792e-06,
      "loss": 1.0488,
      "step": 1675
    },
    {
      "epoch": 13.385826771653543,
      "grad_norm": 0.5027276277542114,
      "learning_rate": 6.0178169081306575e-06,
      "loss": 1.0517,
      "step": 1700
    },
    {
      "epoch": 13.582677165354331,
      "grad_norm": 0.5250419974327087,
      "learning_rate": 4.650352357159982e-06,
      "loss": 1.0487,
      "step": 1725
    },
    {
      "epoch": 13.779527559055119,
      "grad_norm": 0.492180198431015,
      "learning_rate": 3.455272865443859e-06,
      "loss": 1.0261,
      "step": 1750
    },
    {
      "epoch": 13.976377952755906,
      "grad_norm": 0.6558634042739868,
      "learning_rate": 2.4347390476682108e-06,
      "loss": 1.0143,
      "step": 1775
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3394099473953247,
      "eval_runtime": 68.5455,
      "eval_samples_per_second": 7.382,
      "eval_steps_per_second": 7.382,
      "step": 1778
    },
    {
      "epoch": 14.173228346456693,
      "grad_norm": 0.5147953629493713,
      "learning_rate": 1.5905959529443625e-06,
      "loss": 1.0643,
      "step": 1800
    },
    {
      "epoch": 14.37007874015748,
      "grad_norm": 0.5206266045570374,
      "learning_rate": 9.243697290977071e-07,
      "loss": 1.0352,
      "step": 1825
    },
    {
      "epoch": 14.566929133858268,
      "grad_norm": 0.4792124330997467,
      "learning_rate": 4.372648635061705e-07,
      "loss": 1.0317,
      "step": 1850
    },
    {
      "epoch": 14.763779527559056,
      "grad_norm": 0.4803102910518646,
      "learning_rate": 1.3016200547674163e-07,
      "loss": 1.034,
      "step": 1875
    },
    {
      "epoch": 14.960629921259843,
      "grad_norm": 0.5859208106994629,
      "learning_rate": 3.616374097148434e-09,
      "loss": 1.0243,
      "step": 1900
    }
  ],
  "logging_steps": 25,
  "max_steps": 1905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9028856621203456e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
