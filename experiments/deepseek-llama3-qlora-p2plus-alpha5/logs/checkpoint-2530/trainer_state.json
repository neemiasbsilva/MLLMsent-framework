{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2530,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09881422924901186,
      "grad_norm": 0.6038422584533691,
      "learning_rate": 6.578947368421054e-05,
      "loss": 1.3608,
      "step": 25
    },
    {
      "epoch": 0.1976284584980237,
      "grad_norm": 1.0495390892028809,
      "learning_rate": 0.00013157894736842108,
      "loss": 2.0461,
      "step": 50
    },
    {
      "epoch": 0.2964426877470356,
      "grad_norm": 0.5471618175506592,
      "learning_rate": 0.00019736842105263157,
      "loss": 0.7114,
      "step": 75
    },
    {
      "epoch": 0.3952569169960474,
      "grad_norm": 0.7835010290145874,
      "learning_rate": 0.00019995280359149149,
      "loss": 1.072,
      "step": 100
    },
    {
      "epoch": 0.49407114624505927,
      "grad_norm": 0.4005953073501587,
      "learning_rate": 0.00019980331539108542,
      "loss": 0.6474,
      "step": 125
    },
    {
      "epoch": 0.5928853754940712,
      "grad_norm": 0.6006360054016113,
      "learning_rate": 0.00019955160656305604,
      "loss": 0.9096,
      "step": 150
    },
    {
      "epoch": 0.691699604743083,
      "grad_norm": 0.35863277316093445,
      "learning_rate": 0.00019919793491281069,
      "loss": 0.539,
      "step": 175
    },
    {
      "epoch": 0.7905138339920948,
      "grad_norm": 0.6780962944030762,
      "learning_rate": 0.00019874266267819602,
      "loss": 0.9373,
      "step": 200
    },
    {
      "epoch": 0.8893280632411067,
      "grad_norm": 0.3540255129337311,
      "learning_rate": 0.00019818625615848664,
      "loss": 0.5365,
      "step": 225
    },
    {
      "epoch": 0.9881422924901185,
      "grad_norm": 0.5613662600517273,
      "learning_rate": 0.00019752928523679143,
      "loss": 0.9087,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8427107334136963,
      "eval_runtime": 109.7525,
      "eval_samples_per_second": 4.601,
      "eval_steps_per_second": 4.601,
      "step": 253
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.3390882611274719,
      "learning_rate": 0.0001967724227963677,
      "loss": 0.5135,
      "step": 275
    },
    {
      "epoch": 1.1857707509881423,
      "grad_norm": 0.40902721881866455,
      "learning_rate": 0.00019591644403143995,
      "loss": 0.9027,
      "step": 300
    },
    {
      "epoch": 1.2845849802371543,
      "grad_norm": 0.3463500142097473,
      "learning_rate": 0.00019496222565323015,
      "loss": 0.4777,
      "step": 325
    },
    {
      "epoch": 1.383399209486166,
      "grad_norm": 0.4492999017238617,
      "learning_rate": 0.00019391074499201154,
      "loss": 0.9409,
      "step": 350
    },
    {
      "epoch": 1.4822134387351777,
      "grad_norm": 0.3650916516780853,
      "learning_rate": 0.000192763078996107,
      "loss": 0.5337,
      "step": 375
    },
    {
      "epoch": 1.5810276679841897,
      "grad_norm": 0.45465901494026184,
      "learning_rate": 0.00019152040312885604,
      "loss": 0.8865,
      "step": 400
    },
    {
      "epoch": 1.6798418972332017,
      "grad_norm": 0.35380542278289795,
      "learning_rate": 0.00019018399016468084,
      "loss": 0.5147,
      "step": 425
    },
    {
      "epoch": 1.7786561264822134,
      "grad_norm": 0.41658321022987366,
      "learning_rate": 0.00018875520888548438,
      "loss": 0.8806,
      "step": 450
    },
    {
      "epoch": 1.8774703557312253,
      "grad_norm": 0.3482291102409363,
      "learning_rate": 0.00018723552267871555,
      "loss": 0.5442,
      "step": 475
    },
    {
      "epoch": 1.9762845849802373,
      "grad_norm": 0.3579534888267517,
      "learning_rate": 0.0001856264880385372,
      "loss": 0.8804,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.83918297290802,
      "eval_runtime": 109.7242,
      "eval_samples_per_second": 4.602,
      "eval_steps_per_second": 4.602,
      "step": 506
    },
    {
      "epoch": 2.075098814229249,
      "grad_norm": 0.37765640020370483,
      "learning_rate": 0.0001839297529716327,
      "loss": 0.3905,
      "step": 525
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.4398999512195587,
      "learning_rate": 0.0001821470553092832,
      "loss": 0.8769,
      "step": 550
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.4751380980014801,
      "learning_rate": 0.00018028022092744482,
      "loss": 0.5113,
      "step": 575
    },
    {
      "epoch": 2.3715415019762847,
      "grad_norm": 0.40546977519989014,
      "learning_rate": 0.00017833116187664848,
      "loss": 0.8881,
      "step": 600
    },
    {
      "epoch": 2.4703557312252964,
      "grad_norm": 0.41446682810783386,
      "learning_rate": 0.00017630187442363798,
      "loss": 0.4741,
      "step": 625
    },
    {
      "epoch": 2.5691699604743086,
      "grad_norm": 0.39924055337905884,
      "learning_rate": 0.00017419443700675247,
      "loss": 0.8847,
      "step": 650
    },
    {
      "epoch": 2.6679841897233203,
      "grad_norm": 0.4144004285335541,
      "learning_rate": 0.0001720110081071465,
      "loss": 0.4285,
      "step": 675
    },
    {
      "epoch": 2.766798418972332,
      "grad_norm": 0.4873802661895752,
      "learning_rate": 0.00016975382403802878,
      "loss": 0.8948,
      "step": 700
    },
    {
      "epoch": 2.8656126482213438,
      "grad_norm": 0.47578302025794983,
      "learning_rate": 0.00016742519665418395,
      "loss": 0.4175,
      "step": 725
    },
    {
      "epoch": 2.9644268774703555,
      "grad_norm": 0.444751113653183,
      "learning_rate": 0.00016502751098412282,
      "loss": 0.8796,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7862866520881653,
      "eval_runtime": 109.6889,
      "eval_samples_per_second": 4.604,
      "eval_steps_per_second": 4.604,
      "step": 759
    },
    {
      "epoch": 3.0632411067193677,
      "grad_norm": 0.4049183130264282,
      "learning_rate": 0.0001625632227872865,
      "loss": 0.4132,
      "step": 775
    },
    {
      "epoch": 3.1620553359683794,
      "grad_norm": 0.4820430278778076,
      "learning_rate": 0.00016003485603880699,
      "loss": 0.8556,
      "step": 800
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 0.08215734362602234,
      "learning_rate": 0.00015744500034439902,
      "loss": 0.3727,
      "step": 825
    },
    {
      "epoch": 3.3596837944664033,
      "grad_norm": 0.5463587045669556,
      "learning_rate": 0.00015479630828803235,
      "loss": 0.8431,
      "step": 850
    },
    {
      "epoch": 3.458498023715415,
      "grad_norm": 0.4457347095012665,
      "learning_rate": 0.00015209149271510017,
      "loss": 0.4042,
      "step": 875
    },
    {
      "epoch": 3.5573122529644268,
      "grad_norm": 0.4352467954158783,
      "learning_rate": 0.00014933332395386653,
      "loss": 0.8658,
      "step": 900
    },
    {
      "epoch": 3.6561264822134385,
      "grad_norm": 0.1782086044549942,
      "learning_rate": 0.00014652462697803848,
      "loss": 0.3735,
      "step": 925
    },
    {
      "epoch": 3.7549407114624507,
      "grad_norm": 0.5228919386863708,
      "learning_rate": 0.00014366827851336963,
      "loss": 0.8725,
      "step": 950
    },
    {
      "epoch": 3.8537549407114624,
      "grad_norm": 0.16966938972473145,
      "learning_rate": 0.00014076720409125762,
      "loss": 0.3724,
      "step": 975
    },
    {
      "epoch": 3.9525691699604746,
      "grad_norm": 0.4863685965538025,
      "learning_rate": 0.0001378243750523543,
      "loss": 0.8742,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7738928198814392,
      "eval_runtime": 109.6959,
      "eval_samples_per_second": 4.604,
      "eval_steps_per_second": 4.604,
      "step": 1012
    },
    {
      "epoch": 4.051383399209486,
      "grad_norm": 0.08686085790395737,
      "learning_rate": 0.00013484280550325693,
      "loss": 0.4119,
      "step": 1025
    },
    {
      "epoch": 4.150197628458498,
      "grad_norm": 0.49185216426849365,
      "learning_rate": 0.00013182554922939747,
      "loss": 0.783,
      "step": 1050
    },
    {
      "epoch": 4.24901185770751,
      "grad_norm": 0.11721959710121155,
      "learning_rate": 0.00012877569656729243,
      "loss": 0.4023,
      "step": 1075
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.5302969813346863,
      "learning_rate": 0.0001256963712393558,
      "loss": 0.784,
      "step": 1100
    },
    {
      "epoch": 4.446640316205533,
      "grad_norm": 0.1314534693956375,
      "learning_rate": 0.00012259072715451778,
      "loss": 0.4067,
      "step": 1125
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.526792049407959,
      "learning_rate": 0.00011946194517792584,
      "loss": 0.7493,
      "step": 1150
    },
    {
      "epoch": 4.644268774703558,
      "grad_norm": 0.10191237181425095,
      "learning_rate": 0.0001163132298730365,
      "loss": 0.3977,
      "step": 1175
    },
    {
      "epoch": 4.743083003952569,
      "grad_norm": 0.5381762981414795,
      "learning_rate": 0.000113147806219435,
      "loss": 0.7505,
      "step": 1200
    },
    {
      "epoch": 4.841897233201581,
      "grad_norm": 0.11493796110153198,
      "learning_rate": 0.00010996891630974415,
      "loss": 0.3999,
      "step": 1225
    },
    {
      "epoch": 4.940711462450593,
      "grad_norm": 0.5361093878746033,
      "learning_rate": 0.00010677981602900589,
      "loss": 0.7312,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7590067386627197,
      "eval_runtime": 109.733,
      "eval_samples_per_second": 4.602,
      "eval_steps_per_second": 4.602,
      "step": 1265
    },
    {
      "epoch": 5.0395256916996045,
      "grad_norm": 0.11534181982278824,
      "learning_rate": 0.0001035837717199361,
      "loss": 0.4498,
      "step": 1275
    },
    {
      "epoch": 5.138339920948616,
      "grad_norm": 0.5405237078666687,
      "learning_rate": 0.00010038405683746867,
      "loss": 0.6338,
      "step": 1300
    },
    {
      "epoch": 5.237154150197629,
      "grad_norm": 0.13567952811717987,
      "learning_rate": 9.718394859601498e-05,
      "loss": 0.4497,
      "step": 1325
    },
    {
      "epoch": 5.335968379446641,
      "grad_norm": 0.5903122425079346,
      "learning_rate": 9.398672461287281e-05,
      "loss": 0.6516,
      "step": 1350
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.13834580779075623,
      "learning_rate": 9.07956595512227e-05,
      "loss": 0.4255,
      "step": 1375
    },
    {
      "epoch": 5.533596837944664,
      "grad_norm": 0.5552315711975098,
      "learning_rate": 8.761402176615002e-05,
      "loss": 0.6849,
      "step": 1400
    },
    {
      "epoch": 5.632411067193676,
      "grad_norm": 0.13659997284412384,
      "learning_rate": 8.444506995712768e-05,
      "loss": 0.4063,
      "step": 1425
    },
    {
      "epoch": 5.7312252964426875,
      "grad_norm": 0.5299218893051147,
      "learning_rate": 8.129204983038847e-05,
      "loss": 0.6379,
      "step": 1450
    },
    {
      "epoch": 5.830039525691699,
      "grad_norm": 0.12014542520046234,
      "learning_rate": 7.815819077460559e-05,
      "loss": 0.4432,
      "step": 1475
    },
    {
      "epoch": 5.928853754940711,
      "grad_norm": 0.6152757406234741,
      "learning_rate": 7.504670255328547e-05,
      "loss": 0.6753,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7536846995353699,
      "eval_runtime": 109.678,
      "eval_samples_per_second": 4.604,
      "eval_steps_per_second": 4.604,
      "step": 1518
    },
    {
      "epoch": 6.027667984189724,
      "grad_norm": 0.1212315633893013,
      "learning_rate": 7.196077201726148e-05,
      "loss": 0.445,
      "step": 1525
    },
    {
      "epoch": 6.126482213438735,
      "grad_norm": 0.5930674076080322,
      "learning_rate": 6.890355984065508e-05,
      "loss": 0.5605,
      "step": 1550
    },
    {
      "epoch": 6.225296442687747,
      "grad_norm": 0.17195908725261688,
      "learning_rate": 6.587819728364784e-05,
      "loss": 0.4527,
      "step": 1575
    },
    {
      "epoch": 6.324110671936759,
      "grad_norm": 0.578987717628479,
      "learning_rate": 6.288778298537967e-05,
      "loss": 0.5764,
      "step": 1600
    },
    {
      "epoch": 6.4229249011857705,
      "grad_norm": 0.13495469093322754,
      "learning_rate": 5.9935379790258326e-05,
      "loss": 0.4516,
      "step": 1625
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.6089807152748108,
      "learning_rate": 5.70240116109306e-05,
      "loss": 0.5501,
      "step": 1650
    },
    {
      "epoch": 6.620553359683795,
      "grad_norm": 0.1592414677143097,
      "learning_rate": 5.4156660331128225e-05,
      "loss": 0.4753,
      "step": 1675
    },
    {
      "epoch": 6.719367588932807,
      "grad_norm": 0.5989831686019897,
      "learning_rate": 5.133626275156055e-05,
      "loss": 0.5581,
      "step": 1700
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.13979969918727875,
      "learning_rate": 4.8565707581982386e-05,
      "loss": 0.4506,
      "step": 1725
    },
    {
      "epoch": 6.91699604743083,
      "grad_norm": 0.5729612708091736,
      "learning_rate": 4.5847832482517386e-05,
      "loss": 0.5374,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7594316005706787,
      "eval_runtime": 109.7174,
      "eval_samples_per_second": 4.603,
      "eval_steps_per_second": 4.603,
      "step": 1771
    },
    {
      "epoch": 7.015810276679842,
      "grad_norm": 0.16566023230552673,
      "learning_rate": 4.318542115726779e-05,
      "loss": 0.4827,
      "step": 1775
    },
    {
      "epoch": 7.1146245059288535,
      "grad_norm": 0.6004563570022583,
      "learning_rate": 4.05812005031868e-05,
      "loss": 0.5151,
      "step": 1800
    },
    {
      "epoch": 7.213438735177865,
      "grad_norm": 0.1578831821680069,
      "learning_rate": 3.803783781713411e-05,
      "loss": 0.4783,
      "step": 1825
    },
    {
      "epoch": 7.312252964426877,
      "grad_norm": 0.6849813461303711,
      "learning_rate": 3.55579380639751e-05,
      "loss": 0.4618,
      "step": 1850
    },
    {
      "epoch": 7.41106719367589,
      "grad_norm": 0.1626678854227066,
      "learning_rate": 3.314404120852175e-05,
      "loss": 0.4579,
      "step": 1875
    },
    {
      "epoch": 7.509881422924901,
      "grad_norm": 0.7010613083839417,
      "learning_rate": 3.079861961404789e-05,
      "loss": 0.4514,
      "step": 1900
    },
    {
      "epoch": 7.608695652173913,
      "grad_norm": 0.20018000900745392,
      "learning_rate": 2.852407551004349e-05,
      "loss": 0.4788,
      "step": 1925
    },
    {
      "epoch": 7.707509881422925,
      "grad_norm": 0.6802932620048523,
      "learning_rate": 2.6322738531801317e-05,
      "loss": 0.4362,
      "step": 1950
    },
    {
      "epoch": 7.8063241106719365,
      "grad_norm": 0.16448043286800385,
      "learning_rate": 2.419686333435606e-05,
      "loss": 0.4981,
      "step": 1975
    },
    {
      "epoch": 7.905138339920948,
      "grad_norm": 0.673801600933075,
      "learning_rate": 2.214862728321987e-05,
      "loss": 0.5068,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7666455507278442,
      "eval_runtime": 109.7274,
      "eval_samples_per_second": 4.602,
      "eval_steps_per_second": 4.602,
      "step": 2024
    },
    {
      "epoch": 8.003952569169961,
      "grad_norm": 0.1486501395702362,
      "learning_rate": 2.0180128224279417e-05,
      "loss": 0.5104,
      "step": 2025
    },
    {
      "epoch": 8.102766798418973,
      "grad_norm": 0.6878421306610107,
      "learning_rate": 1.829338233513853e-05,
      "loss": 0.4571,
      "step": 2050
    },
    {
      "epoch": 8.201581027667984,
      "grad_norm": 0.16572731733322144,
      "learning_rate": 1.6490322060107298e-05,
      "loss": 0.5151,
      "step": 2075
    },
    {
      "epoch": 8.300395256916996,
      "grad_norm": 0.6757746934890747,
      "learning_rate": 1.4772794130952417e-05,
      "loss": 0.4005,
      "step": 2100
    },
    {
      "epoch": 8.399209486166008,
      "grad_norm": 0.2057822048664093,
      "learning_rate": 1.3142557675436262e-05,
      "loss": 0.5214,
      "step": 2125
    },
    {
      "epoch": 8.49802371541502,
      "grad_norm": 0.7697651386260986,
      "learning_rate": 1.1601282415581628e-05,
      "loss": 0.3975,
      "step": 2150
    },
    {
      "epoch": 8.596837944664031,
      "grad_norm": 0.17398136854171753,
      "learning_rate": 1.015054695750779e-05,
      "loss": 0.5026,
      "step": 2175
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.760092556476593,
      "learning_rate": 8.791837174589402e-06,
      "loss": 0.3936,
      "step": 2200
    },
    {
      "epoch": 8.794466403162055,
      "grad_norm": 0.1672936975955963,
      "learning_rate": 7.5265446855940615e-06,
      "loss": 0.5051,
      "step": 2225
    },
    {
      "epoch": 8.893280632411066,
      "grad_norm": 0.7137538194656372,
      "learning_rate": 6.355965429357514e-06,
      "loss": 0.4175,
      "step": 2250
    },
    {
      "epoch": 8.992094861660078,
      "grad_norm": 0.1434115618467331,
      "learning_rate": 5.2812983374562195e-06,
      "loss": 0.4911,
      "step": 2275
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.77366703748703,
      "eval_runtime": 109.752,
      "eval_samples_per_second": 4.601,
      "eval_steps_per_second": 4.601,
      "step": 2277
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.6916406750679016,
      "learning_rate": 4.303644106236704e-06,
      "loss": 0.3529,
      "step": 2300
    },
    {
      "epoch": 9.189723320158103,
      "grad_norm": 0.7404142022132874,
      "learning_rate": 3.4240040694594413e-06,
      "loss": 0.5505,
      "step": 2325
    },
    {
      "epoch": 9.288537549407115,
      "grad_norm": 0.6839035153388977,
      "learning_rate": 2.6432791727121984e-06,
      "loss": 0.3808,
      "step": 2350
    },
    {
      "epoch": 9.387351778656127,
      "grad_norm": 0.7783017158508301,
      "learning_rate": 1.9622690506426956e-06,
      "loss": 0.5328,
      "step": 2375
    },
    {
      "epoch": 9.486166007905139,
      "grad_norm": 0.7662539482116699,
      "learning_rate": 1.3816712079563033e-06,
      "loss": 0.38,
      "step": 2400
    },
    {
      "epoch": 9.58498023715415,
      "grad_norm": 0.7138351798057556,
      "learning_rate": 9.020803050172055e-07,
      "loss": 0.5303,
      "step": 2425
    },
    {
      "epoch": 9.683794466403162,
      "grad_norm": 0.7719981670379639,
      "learning_rate": 5.239875487848877e-07,
      "loss": 0.3448,
      "step": 2450
    },
    {
      "epoch": 9.782608695652174,
      "grad_norm": 0.6707159876823425,
      "learning_rate": 2.477801897097898e-07,
      "loss": 0.5306,
      "step": 2475
    },
    {
      "epoch": 9.881422924901186,
      "grad_norm": 0.7685490846633911,
      "learning_rate": 7.374112510339926e-08,
      "loss": 0.3665,
      "step": 2500
    },
    {
      "epoch": 9.980237154150197,
      "grad_norm": 0.6726630926132202,
      "learning_rate": 2.048609388860534e-09,
      "loss": 0.5489,
      "step": 2525
    }
  ],
  "logging_steps": 25,
  "max_steps": 2530,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0591141933531136e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
