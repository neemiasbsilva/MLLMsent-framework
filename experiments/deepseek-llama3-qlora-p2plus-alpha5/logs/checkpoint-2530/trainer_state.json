{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2530,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09881422924901186,
      "grad_norm": 0.5613126158714294,
      "learning_rate": 6.578947368421054e-05,
      "loss": 1.319,
      "step": 25
    },
    {
      "epoch": 0.1976284584980237,
      "grad_norm": 1.4544497728347778,
      "learning_rate": 0.00013157894736842108,
      "loss": 1.9481,
      "step": 50
    },
    {
      "epoch": 0.2964426877470356,
      "grad_norm": 0.5918697118759155,
      "learning_rate": 0.00019736842105263157,
      "loss": 0.709,
      "step": 75
    },
    {
      "epoch": 0.3952569169960474,
      "grad_norm": 0.858651340007782,
      "learning_rate": 0.00019995280359149149,
      "loss": 1.0711,
      "step": 100
    },
    {
      "epoch": 0.49407114624505927,
      "grad_norm": 0.4583289623260498,
      "learning_rate": 0.00019980331539108542,
      "loss": 0.6488,
      "step": 125
    },
    {
      "epoch": 0.5928853754940712,
      "grad_norm": 0.5327804684638977,
      "learning_rate": 0.00019955160656305604,
      "loss": 0.9138,
      "step": 150
    },
    {
      "epoch": 0.691699604743083,
      "grad_norm": 0.3500029444694519,
      "learning_rate": 0.00019919793491281069,
      "loss": 0.5414,
      "step": 175
    },
    {
      "epoch": 0.7905138339920948,
      "grad_norm": 0.6783750057220459,
      "learning_rate": 0.00019874266267819602,
      "loss": 0.9421,
      "step": 200
    },
    {
      "epoch": 0.8893280632411067,
      "grad_norm": 0.35250991582870483,
      "learning_rate": 0.00019818625615848664,
      "loss": 0.5384,
      "step": 225
    },
    {
      "epoch": 0.9881422924901185,
      "grad_norm": 0.5291622281074524,
      "learning_rate": 0.00019752928523679143,
      "loss": 0.9109,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8501394987106323,
      "eval_runtime": 108.9974,
      "eval_samples_per_second": 4.633,
      "eval_steps_per_second": 4.633,
      "step": 253
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.33976423740386963,
      "learning_rate": 0.0001967724227963677,
      "loss": 0.5148,
      "step": 275
    },
    {
      "epoch": 1.1857707509881423,
      "grad_norm": 0.4196534752845764,
      "learning_rate": 0.00019591644403143995,
      "loss": 0.91,
      "step": 300
    },
    {
      "epoch": 1.2845849802371543,
      "grad_norm": 0.34583961963653564,
      "learning_rate": 0.00019496222565323015,
      "loss": 0.4793,
      "step": 325
    },
    {
      "epoch": 1.383399209486166,
      "grad_norm": 0.43123093247413635,
      "learning_rate": 0.00019391074499201154,
      "loss": 0.9447,
      "step": 350
    },
    {
      "epoch": 1.4822134387351777,
      "grad_norm": 0.36524996161460876,
      "learning_rate": 0.000192763078996107,
      "loss": 0.5351,
      "step": 375
    },
    {
      "epoch": 1.5810276679841897,
      "grad_norm": 0.4504973888397217,
      "learning_rate": 0.00019152040312885604,
      "loss": 0.8889,
      "step": 400
    },
    {
      "epoch": 1.6798418972332017,
      "grad_norm": 0.3532029092311859,
      "learning_rate": 0.00019018399016468084,
      "loss": 0.5152,
      "step": 425
    },
    {
      "epoch": 1.7786561264822134,
      "grad_norm": 0.42145290970802307,
      "learning_rate": 0.00018875520888548438,
      "loss": 0.886,
      "step": 450
    },
    {
      "epoch": 1.8774703557312253,
      "grad_norm": 0.3391079604625702,
      "learning_rate": 0.00018723552267871555,
      "loss": 0.5467,
      "step": 475
    },
    {
      "epoch": 1.9762845849802373,
      "grad_norm": 0.3561188578605652,
      "learning_rate": 0.0001856264880385372,
      "loss": 0.8838,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8450709581375122,
      "eval_runtime": 108.9872,
      "eval_samples_per_second": 4.634,
      "eval_steps_per_second": 4.634,
      "step": 506
    },
    {
      "epoch": 2.075098814229249,
      "grad_norm": 0.3723365068435669,
      "learning_rate": 0.0001839297529716327,
      "loss": 0.3885,
      "step": 525
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.4330441951751709,
      "learning_rate": 0.0001821470553092832,
      "loss": 0.8787,
      "step": 550
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.4822789430618286,
      "learning_rate": 0.00018028022092744482,
      "loss": 0.5124,
      "step": 575
    },
    {
      "epoch": 2.3715415019762847,
      "grad_norm": 0.40998321771621704,
      "learning_rate": 0.00017833116187664848,
      "loss": 0.8911,
      "step": 600
    },
    {
      "epoch": 2.4703557312252964,
      "grad_norm": 0.4278038442134857,
      "learning_rate": 0.00017630187442363798,
      "loss": 0.4757,
      "step": 625
    },
    {
      "epoch": 2.5691699604743086,
      "grad_norm": 0.40855249762535095,
      "learning_rate": 0.00017419443700675247,
      "loss": 0.8878,
      "step": 650
    },
    {
      "epoch": 2.6679841897233203,
      "grad_norm": 0.4144395589828491,
      "learning_rate": 0.0001720110081071465,
      "loss": 0.4295,
      "step": 675
    },
    {
      "epoch": 2.766798418972332,
      "grad_norm": 0.5095853805541992,
      "learning_rate": 0.00016975382403802878,
      "loss": 0.8974,
      "step": 700
    },
    {
      "epoch": 2.8656126482213438,
      "grad_norm": 0.4788878858089447,
      "learning_rate": 0.00016742519665418395,
      "loss": 0.4178,
      "step": 725
    },
    {
      "epoch": 2.9644268774703555,
      "grad_norm": 0.47318652272224426,
      "learning_rate": 0.00016502751098412282,
      "loss": 0.8813,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7894872426986694,
      "eval_runtime": 108.9911,
      "eval_samples_per_second": 4.633,
      "eval_steps_per_second": 4.633,
      "step": 759
    },
    {
      "epoch": 3.0632411067193677,
      "grad_norm": 0.4127369821071625,
      "learning_rate": 0.0001625632227872865,
      "loss": 0.4119,
      "step": 775
    },
    {
      "epoch": 3.1620553359683794,
      "grad_norm": 0.5078181624412537,
      "learning_rate": 0.00016003485603880699,
      "loss": 0.853,
      "step": 800
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 0.08115895092487335,
      "learning_rate": 0.00015744500034439902,
      "loss": 0.3727,
      "step": 825
    },
    {
      "epoch": 3.3596837944664033,
      "grad_norm": 0.5543953776359558,
      "learning_rate": 0.00015479630828803235,
      "loss": 0.8438,
      "step": 850
    },
    {
      "epoch": 3.458498023715415,
      "grad_norm": 0.4390927255153656,
      "learning_rate": 0.00015209149271510017,
      "loss": 0.4049,
      "step": 875
    },
    {
      "epoch": 3.5573122529644268,
      "grad_norm": 0.4504380524158478,
      "learning_rate": 0.00014933332395386653,
      "loss": 0.864,
      "step": 900
    },
    {
      "epoch": 3.6561264822134385,
      "grad_norm": 0.1862277090549469,
      "learning_rate": 0.00014652462697803848,
      "loss": 0.372,
      "step": 925
    },
    {
      "epoch": 3.7549407114624507,
      "grad_norm": 0.5237205624580383,
      "learning_rate": 0.00014366827851336963,
      "loss": 0.872,
      "step": 950
    },
    {
      "epoch": 3.8537549407114624,
      "grad_norm": 0.16407503187656403,
      "learning_rate": 0.00014076720409125762,
      "loss": 0.3736,
      "step": 975
    },
    {
      "epoch": 3.9525691699604746,
      "grad_norm": 0.4839409291744232,
      "learning_rate": 0.0001378243750523543,
      "loss": 0.873,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7808451056480408,
      "eval_runtime": 108.9365,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 1012
    },
    {
      "epoch": 4.051383399209486,
      "grad_norm": 0.0890776664018631,
      "learning_rate": 0.00013484280550325693,
      "loss": 0.4123,
      "step": 1025
    },
    {
      "epoch": 4.150197628458498,
      "grad_norm": 0.49763908982276917,
      "learning_rate": 0.00013182554922939747,
      "loss": 0.7804,
      "step": 1050
    },
    {
      "epoch": 4.24901185770751,
      "grad_norm": 0.11988621950149536,
      "learning_rate": 0.00012877569656729243,
      "loss": 0.4037,
      "step": 1075
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.5333576798439026,
      "learning_rate": 0.0001256963712393558,
      "loss": 0.7843,
      "step": 1100
    },
    {
      "epoch": 4.446640316205533,
      "grad_norm": 0.1339329481124878,
      "learning_rate": 0.00012259072715451778,
      "loss": 0.4054,
      "step": 1125
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.5189340710639954,
      "learning_rate": 0.00011946194517792584,
      "loss": 0.7482,
      "step": 1150
    },
    {
      "epoch": 4.644268774703558,
      "grad_norm": 0.10162127763032913,
      "learning_rate": 0.0001163132298730365,
      "loss": 0.399,
      "step": 1175
    },
    {
      "epoch": 4.743083003952569,
      "grad_norm": 0.537072479724884,
      "learning_rate": 0.000113147806219435,
      "loss": 0.7484,
      "step": 1200
    },
    {
      "epoch": 4.841897233201581,
      "grad_norm": 0.11320153623819351,
      "learning_rate": 0.00010996891630974415,
      "loss": 0.3984,
      "step": 1225
    },
    {
      "epoch": 4.940711462450593,
      "grad_norm": 0.5632925629615784,
      "learning_rate": 0.00010677981602900589,
      "loss": 0.7288,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7652599215507507,
      "eval_runtime": 108.9727,
      "eval_samples_per_second": 4.634,
      "eval_steps_per_second": 4.634,
      "step": 1265
    },
    {
      "epoch": 5.0395256916996045,
      "grad_norm": 0.1157621219754219,
      "learning_rate": 0.0001035837717199361,
      "loss": 0.4495,
      "step": 1275
    },
    {
      "epoch": 5.138339920948616,
      "grad_norm": 0.5289652347564697,
      "learning_rate": 0.00010038405683746867,
      "loss": 0.6319,
      "step": 1300
    },
    {
      "epoch": 5.237154150197629,
      "grad_norm": 0.13858744502067566,
      "learning_rate": 9.718394859601498e-05,
      "loss": 0.4471,
      "step": 1325
    },
    {
      "epoch": 5.335968379446641,
      "grad_norm": 0.598298192024231,
      "learning_rate": 9.398672461287281e-05,
      "loss": 0.6503,
      "step": 1350
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.14170876145362854,
      "learning_rate": 9.07956595512227e-05,
      "loss": 0.4249,
      "step": 1375
    },
    {
      "epoch": 5.533596837944664,
      "grad_norm": 0.5593284964561462,
      "learning_rate": 8.761402176615002e-05,
      "loss": 0.6821,
      "step": 1400
    },
    {
      "epoch": 5.632411067193676,
      "grad_norm": 0.13588613271713257,
      "learning_rate": 8.444506995712768e-05,
      "loss": 0.4064,
      "step": 1425
    },
    {
      "epoch": 5.7312252964426875,
      "grad_norm": 0.5654502511024475,
      "learning_rate": 8.129204983038847e-05,
      "loss": 0.6385,
      "step": 1450
    },
    {
      "epoch": 5.830039525691699,
      "grad_norm": 0.1204262375831604,
      "learning_rate": 7.815819077460559e-05,
      "loss": 0.4426,
      "step": 1475
    },
    {
      "epoch": 5.928853754940711,
      "grad_norm": 0.6255179643630981,
      "learning_rate": 7.504670255328547e-05,
      "loss": 0.6739,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7608872056007385,
      "eval_runtime": 108.939,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 1518
    },
    {
      "epoch": 6.027667984189724,
      "grad_norm": 0.12062565982341766,
      "learning_rate": 7.196077201726148e-05,
      "loss": 0.4453,
      "step": 1525
    },
    {
      "epoch": 6.126482213438735,
      "grad_norm": 0.5914627313613892,
      "learning_rate": 6.890355984065508e-05,
      "loss": 0.5581,
      "step": 1550
    },
    {
      "epoch": 6.225296442687747,
      "grad_norm": 0.172902449965477,
      "learning_rate": 6.587819728364784e-05,
      "loss": 0.4528,
      "step": 1575
    },
    {
      "epoch": 6.324110671936759,
      "grad_norm": 0.6003716588020325,
      "learning_rate": 6.288778298537967e-05,
      "loss": 0.5731,
      "step": 1600
    },
    {
      "epoch": 6.4229249011857705,
      "grad_norm": 0.13582879304885864,
      "learning_rate": 5.9935379790258326e-05,
      "loss": 0.4511,
      "step": 1625
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.6103720664978027,
      "learning_rate": 5.70240116109306e-05,
      "loss": 0.5486,
      "step": 1650
    },
    {
      "epoch": 6.620553359683795,
      "grad_norm": 0.16218766570091248,
      "learning_rate": 5.4156660331128225e-05,
      "loss": 0.472,
      "step": 1675
    },
    {
      "epoch": 6.719367588932807,
      "grad_norm": 0.6010125279426575,
      "learning_rate": 5.133626275156055e-05,
      "loss": 0.5551,
      "step": 1700
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.1403711885213852,
      "learning_rate": 4.8565707581982386e-05,
      "loss": 0.4483,
      "step": 1725
    },
    {
      "epoch": 6.91699604743083,
      "grad_norm": 0.565972089767456,
      "learning_rate": 4.5847832482517386e-05,
      "loss": 0.5367,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.767068088054657,
      "eval_runtime": 108.9488,
      "eval_samples_per_second": 4.635,
      "eval_steps_per_second": 4.635,
      "step": 1771
    },
    {
      "epoch": 7.015810276679842,
      "grad_norm": 0.16559718549251556,
      "learning_rate": 4.318542115726779e-05,
      "loss": 0.4828,
      "step": 1775
    },
    {
      "epoch": 7.1146245059288535,
      "grad_norm": 0.6177219748497009,
      "learning_rate": 4.05812005031868e-05,
      "loss": 0.5115,
      "step": 1800
    },
    {
      "epoch": 7.213438735177865,
      "grad_norm": 0.15858793258666992,
      "learning_rate": 3.803783781713411e-05,
      "loss": 0.4755,
      "step": 1825
    },
    {
      "epoch": 7.312252964426877,
      "grad_norm": 0.7065454125404358,
      "learning_rate": 3.55579380639751e-05,
      "loss": 0.4604,
      "step": 1850
    },
    {
      "epoch": 7.41106719367589,
      "grad_norm": 0.17086480557918549,
      "learning_rate": 3.314404120852175e-05,
      "loss": 0.4567,
      "step": 1875
    },
    {
      "epoch": 7.509881422924901,
      "grad_norm": 0.7000169157981873,
      "learning_rate": 3.079861961404789e-05,
      "loss": 0.4499,
      "step": 1900
    },
    {
      "epoch": 7.608695652173913,
      "grad_norm": 0.20080554485321045,
      "learning_rate": 2.852407551004349e-05,
      "loss": 0.4779,
      "step": 1925
    },
    {
      "epoch": 7.707509881422925,
      "grad_norm": 0.6400796175003052,
      "learning_rate": 2.6322738531801317e-05,
      "loss": 0.4339,
      "step": 1950
    },
    {
      "epoch": 7.8063241106719365,
      "grad_norm": 0.15761828422546387,
      "learning_rate": 2.419686333435606e-05,
      "loss": 0.4984,
      "step": 1975
    },
    {
      "epoch": 7.905138339920948,
      "grad_norm": 0.7002106308937073,
      "learning_rate": 2.214862728321987e-05,
      "loss": 0.5042,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7772077918052673,
      "eval_runtime": 108.9826,
      "eval_samples_per_second": 4.634,
      "eval_steps_per_second": 4.634,
      "step": 2024
    },
    {
      "epoch": 8.003952569169961,
      "grad_norm": 0.14922301471233368,
      "learning_rate": 2.0180128224279417e-05,
      "loss": 0.5046,
      "step": 2025
    },
    {
      "epoch": 8.102766798418973,
      "grad_norm": 0.699785590171814,
      "learning_rate": 1.829338233513853e-05,
      "loss": 0.4546,
      "step": 2050
    },
    {
      "epoch": 8.201581027667984,
      "grad_norm": 0.17154720425605774,
      "learning_rate": 1.6490322060107298e-05,
      "loss": 0.5137,
      "step": 2075
    },
    {
      "epoch": 8.300395256916996,
      "grad_norm": 0.703231155872345,
      "learning_rate": 1.4772794130952417e-05,
      "loss": 0.3977,
      "step": 2100
    },
    {
      "epoch": 8.399209486166008,
      "grad_norm": 0.2116570919752121,
      "learning_rate": 1.3142557675436262e-05,
      "loss": 0.5209,
      "step": 2125
    },
    {
      "epoch": 8.49802371541502,
      "grad_norm": 0.7639946937561035,
      "learning_rate": 1.1601282415581628e-05,
      "loss": 0.3935,
      "step": 2150
    },
    {
      "epoch": 8.596837944664031,
      "grad_norm": 0.1864967793226242,
      "learning_rate": 1.015054695750779e-05,
      "loss": 0.4975,
      "step": 2175
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.7782554626464844,
      "learning_rate": 8.791837174589402e-06,
      "loss": 0.3914,
      "step": 2200
    },
    {
      "epoch": 8.794466403162055,
      "grad_norm": 0.16319558024406433,
      "learning_rate": 7.5265446855940615e-06,
      "loss": 0.5039,
      "step": 2225
    },
    {
      "epoch": 8.893280632411066,
      "grad_norm": 0.696027398109436,
      "learning_rate": 6.355965429357514e-06,
      "loss": 0.4163,
      "step": 2250
    },
    {
      "epoch": 8.992094861660078,
      "grad_norm": 0.14888069033622742,
      "learning_rate": 5.2812983374562195e-06,
      "loss": 0.4873,
      "step": 2275
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7834083437919617,
      "eval_runtime": 109.0366,
      "eval_samples_per_second": 4.631,
      "eval_steps_per_second": 4.631,
      "step": 2277
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.6916599869728088,
      "learning_rate": 4.303644106236704e-06,
      "loss": 0.3514,
      "step": 2300
    },
    {
      "epoch": 9.189723320158103,
      "grad_norm": 0.7484297156333923,
      "learning_rate": 3.4240040694594413e-06,
      "loss": 0.5444,
      "step": 2325
    },
    {
      "epoch": 9.288537549407115,
      "grad_norm": 0.7185102105140686,
      "learning_rate": 2.6432791727121984e-06,
      "loss": 0.3779,
      "step": 2350
    },
    {
      "epoch": 9.387351778656127,
      "grad_norm": 0.7957330346107483,
      "learning_rate": 1.9622690506426956e-06,
      "loss": 0.5285,
      "step": 2375
    },
    {
      "epoch": 9.486166007905139,
      "grad_norm": 0.7645449638366699,
      "learning_rate": 1.3816712079563033e-06,
      "loss": 0.3772,
      "step": 2400
    },
    {
      "epoch": 9.58498023715415,
      "grad_norm": 0.7053667306900024,
      "learning_rate": 9.020803050172055e-07,
      "loss": 0.5285,
      "step": 2425
    },
    {
      "epoch": 9.683794466403162,
      "grad_norm": 0.7788327932357788,
      "learning_rate": 5.239875487848877e-07,
      "loss": 0.3431,
      "step": 2450
    },
    {
      "epoch": 9.782608695652174,
      "grad_norm": 0.6958379149436951,
      "learning_rate": 2.477801897097898e-07,
      "loss": 0.53,
      "step": 2475
    },
    {
      "epoch": 9.881422924901186,
      "grad_norm": 0.805690348148346,
      "learning_rate": 7.374112510339926e-08,
      "loss": 0.3673,
      "step": 2500
    },
    {
      "epoch": 9.980237154150197,
      "grad_norm": 0.6904903054237366,
      "learning_rate": 2.048609388860534e-09,
      "loss": 0.5441,
      "step": 2525
    }
  ],
  "logging_steps": 25,
  "max_steps": 2530,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0528888288526336e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
