{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1490,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16778523489932887,
      "grad_norm": 0.656412661075592,
      "learning_rate": 0.00011111111111111112,
      "loss": 1.4168,
      "step": 25
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 0.669676661491394,
      "learning_rate": 0.00019999409160138693,
      "loss": 0.9793,
      "step": 50
    },
    {
      "epoch": 0.5033557046979866,
      "grad_norm": 0.7649125456809998,
      "learning_rate": 0.00019978737094995526,
      "loss": 0.9289,
      "step": 75
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 0.40487775206565857,
      "learning_rate": 0.0001992859281805935,
      "loss": 0.679,
      "step": 100
    },
    {
      "epoch": 0.8389261744966443,
      "grad_norm": 0.5247874855995178,
      "learning_rate": 0.0001984912443051131,
      "loss": 0.5155,
      "step": 125
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6959255337715149,
      "eval_runtime": 65.5022,
      "eval_samples_per_second": 4.519,
      "eval_steps_per_second": 4.519,
      "step": 149
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 0.16622722148895264,
      "learning_rate": 0.00019740566642327867,
      "loss": 0.7926,
      "step": 150
    },
    {
      "epoch": 1.174496644295302,
      "grad_norm": 0.34284910559654236,
      "learning_rate": 0.00019603240079064604,
      "loss": 0.6207,
      "step": 175
    },
    {
      "epoch": 1.342281879194631,
      "grad_norm": 0.48253685235977173,
      "learning_rate": 0.00019437550334888278,
      "loss": 0.5093,
      "step": 200
    },
    {
      "epoch": 1.5100671140939599,
      "grad_norm": 0.16422997415065765,
      "learning_rate": 0.00019243986774653956,
      "loss": 0.6963,
      "step": 225
    },
    {
      "epoch": 1.6778523489932886,
      "grad_norm": 0.34459322690963745,
      "learning_rate": 0.00019023121088565352,
      "loss": 0.6544,
      "step": 250
    },
    {
      "epoch": 1.8456375838926173,
      "grad_norm": 0.4132344126701355,
      "learning_rate": 0.00018775605603687127,
      "loss": 0.4847,
      "step": 275
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6462180018424988,
      "eval_runtime": 65.462,
      "eval_samples_per_second": 4.522,
      "eval_steps_per_second": 4.522,
      "step": 298
    },
    {
      "epoch": 2.0134228187919465,
      "grad_norm": 0.09944576770067215,
      "learning_rate": 0.00018502171357296144,
      "loss": 0.6838,
      "step": 300
    },
    {
      "epoch": 2.1812080536912752,
      "grad_norm": 0.31155699491500854,
      "learning_rate": 0.0001820362593776198,
      "loss": 0.5822,
      "step": 325
    },
    {
      "epoch": 2.348993288590604,
      "grad_norm": 0.3741479516029358,
      "learning_rate": 0.00017880851099333762,
      "loss": 0.4783,
      "step": 350
    },
    {
      "epoch": 2.5167785234899327,
      "grad_norm": 0.15266281366348267,
      "learning_rate": 0.00017534800157877918,
      "loss": 0.6494,
      "step": 375
    },
    {
      "epoch": 2.684563758389262,
      "grad_norm": 0.3402675688266754,
      "learning_rate": 0.00017166495175258652,
      "loss": 0.572,
      "step": 400
    },
    {
      "epoch": 2.8523489932885906,
      "grad_norm": 0.3539336025714874,
      "learning_rate": 0.00016777023940677034,
      "loss": 0.5205,
      "step": 425
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6232921481132507,
      "eval_runtime": 65.4707,
      "eval_samples_per_second": 4.521,
      "eval_steps_per_second": 4.521,
      "step": 447
    },
    {
      "epoch": 3.0201342281879193,
      "grad_norm": 0.13429462909698486,
      "learning_rate": 0.00016367536757884286,
      "loss": 0.621,
      "step": 450
    },
    {
      "epoch": 3.1879194630872485,
      "grad_norm": 0.33860811591148376,
      "learning_rate": 0.0001593924304775831,
      "loss": 0.5769,
      "step": 475
    },
    {
      "epoch": 3.3557046979865772,
      "grad_norm": 0.4153597056865692,
      "learning_rate": 0.00015493407776277698,
      "loss": 0.4738,
      "step": 500
    },
    {
      "epoch": 3.523489932885906,
      "grad_norm": 0.13617676496505737,
      "learning_rate": 0.00015031347718443211,
      "loss": 0.5711,
      "step": 525
    },
    {
      "epoch": 3.6912751677852347,
      "grad_norm": 0.34235963225364685,
      "learning_rate": 0.0001455442756918126,
      "loss": 0.6145,
      "step": 550
    },
    {
      "epoch": 3.859060402684564,
      "grad_norm": 0.4571038484573364,
      "learning_rate": 0.00014064055912715845,
      "loss": 0.399,
      "step": 575
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5974721312522888,
      "eval_runtime": 65.4603,
      "eval_samples_per_second": 4.522,
      "eval_steps_per_second": 4.522,
      "step": 596
    },
    {
      "epoch": 4.026845637583893,
      "grad_norm": 0.0935625284910202,
      "learning_rate": 0.0001356168106231337,
      "loss": 0.5945,
      "step": 600
    },
    {
      "epoch": 4.194630872483222,
      "grad_norm": 0.4041731357574463,
      "learning_rate": 0.00013048786782687705,
      "loss": 0.5475,
      "step": 625
    },
    {
      "epoch": 4.3624161073825505,
      "grad_norm": 0.4151343107223511,
      "learning_rate": 0.00012526887907699348,
      "loss": 0.4349,
      "step": 650
    },
    {
      "epoch": 4.530201342281879,
      "grad_norm": 0.1657288372516632,
      "learning_rate": 0.00011997525866291841,
      "loss": 0.5041,
      "step": 675
    },
    {
      "epoch": 4.697986577181208,
      "grad_norm": 0.42152640223503113,
      "learning_rate": 0.00011462264129879554,
      "loss": 0.573,
      "step": 700
    },
    {
      "epoch": 4.865771812080537,
      "grad_norm": 0.43994271755218506,
      "learning_rate": 0.00010922683594633021,
      "loss": 0.4392,
      "step": 725
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.5987721085548401,
      "eval_runtime": 65.4729,
      "eval_samples_per_second": 4.521,
      "eval_steps_per_second": 4.521,
      "step": 745
    },
    {
      "epoch": 5.033557046979865,
      "grad_norm": 0.10176374763250351,
      "learning_rate": 0.0001038037791230023,
      "loss": 0.4956,
      "step": 750
    },
    {
      "epoch": 5.201342281879195,
      "grad_norm": 0.427773118019104,
      "learning_rate": 9.836948783354309e-05,
      "loss": 0.5037,
      "step": 775
    },
    {
      "epoch": 5.369127516778524,
      "grad_norm": 0.4748443067073822,
      "learning_rate": 9.294001226369282e-05,
      "loss": 0.4411,
      "step": 800
    },
    {
      "epoch": 5.5369127516778525,
      "grad_norm": 0.13201546669006348,
      "learning_rate": 8.753138837595817e-05,
      "loss": 0.4562,
      "step": 825
    },
    {
      "epoch": 5.704697986577181,
      "grad_norm": 0.5000185966491699,
      "learning_rate": 8.215959054737817e-05,
      "loss": 0.5355,
      "step": 850
    },
    {
      "epoch": 5.87248322147651,
      "grad_norm": 0.5033459663391113,
      "learning_rate": 7.684048438918248e-05,
      "loss": 0.4107,
      "step": 875
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6074031591415405,
      "eval_runtime": 65.5004,
      "eval_samples_per_second": 4.519,
      "eval_steps_per_second": 4.519,
      "step": 894
    },
    {
      "epoch": 6.040268456375839,
      "grad_norm": 0.14184755086898804,
      "learning_rate": 7.158977988769023e-05,
      "loss": 0.4424,
      "step": 900
    },
    {
      "epoch": 6.208053691275167,
      "grad_norm": 0.4549795091152191,
      "learning_rate": 6.642298500484658e-05,
      "loss": 0.5239,
      "step": 925
    },
    {
      "epoch": 6.375838926174497,
      "grad_norm": 0.530257523059845,
      "learning_rate": 6.135535987543899e-05,
      "loss": 0.3581,
      "step": 950
    },
    {
      "epoch": 6.543624161073826,
      "grad_norm": 0.1770602911710739,
      "learning_rate": 5.64018717362711e-05,
      "loss": 0.3975,
      "step": 975
    },
    {
      "epoch": 6.7114093959731544,
      "grad_norm": 0.5075198411941528,
      "learning_rate": 5.1577150720410935e-05,
      "loss": 0.5262,
      "step": 1000
    },
    {
      "epoch": 6.879194630872483,
      "grad_norm": 0.5692291855812073,
      "learning_rate": 4.6895446647076005e-05,
      "loss": 0.4124,
      "step": 1025
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.614953339099884,
      "eval_runtime": 65.5045,
      "eval_samples_per_second": 4.519,
      "eval_steps_per_second": 4.519,
      "step": 1043
    },
    {
      "epoch": 7.046979865771812,
      "grad_norm": 0.12982922792434692,
      "learning_rate": 4.237058693477499e-05,
      "loss": 0.4057,
      "step": 1050
    },
    {
      "epoch": 7.214765100671141,
      "grad_norm": 0.5208249092102051,
      "learning_rate": 3.801593576201118e-05,
      "loss": 0.5052,
      "step": 1075
    },
    {
      "epoch": 7.382550335570469,
      "grad_norm": 0.5815173387527466,
      "learning_rate": 3.384435459616536e-05,
      "loss": 0.3595,
      "step": 1100
    },
    {
      "epoch": 7.550335570469799,
      "grad_norm": 0.16400545835494995,
      "learning_rate": 2.9868164207136616e-05,
      "loss": 0.3612,
      "step": 1125
    },
    {
      "epoch": 7.718120805369128,
      "grad_norm": 0.5700702667236328,
      "learning_rate": 2.6099108277934103e-05,
      "loss": 0.4968,
      "step": 1150
    },
    {
      "epoch": 7.885906040268456,
      "grad_norm": 0.611295759677887,
      "learning_rate": 2.2548318719695182e-05,
      "loss": 0.4028,
      "step": 1175
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.62564617395401,
      "eval_runtime": 65.4688,
      "eval_samples_per_second": 4.521,
      "eval_steps_per_second": 4.521,
      "step": 1192
    },
    {
      "epoch": 8.053691275167786,
      "grad_norm": 0.15121176838874817,
      "learning_rate": 1.9226282793572924e-05,
      "loss": 0.3458,
      "step": 1200
    },
    {
      "epoch": 8.221476510067115,
      "grad_norm": 0.5675166249275208,
      "learning_rate": 1.6142812136597853e-05,
      "loss": 0.5004,
      "step": 1225
    },
    {
      "epoch": 8.389261744966444,
      "grad_norm": 0.6240449547767639,
      "learning_rate": 1.3307013782996235e-05,
      "loss": 0.3738,
      "step": 1250
    },
    {
      "epoch": 8.557046979865772,
      "grad_norm": 0.17569376528263092,
      "learning_rate": 1.0727263266554011e-05,
      "loss": 0.3354,
      "step": 1275
    },
    {
      "epoch": 8.724832214765101,
      "grad_norm": 0.5862452387809753,
      "learning_rate": 8.411179883467667e-06,
      "loss": 0.5008,
      "step": 1300
    },
    {
      "epoch": 8.89261744966443,
      "grad_norm": 0.6446925401687622,
      "learning_rate": 6.365604188743979e-06,
      "loss": 0.3492,
      "step": 1325
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6300283670425415,
      "eval_runtime": 65.5407,
      "eval_samples_per_second": 4.516,
      "eval_steps_per_second": 4.516,
      "step": 1341
    },
    {
      "epoch": 9.060402684563758,
      "grad_norm": 0.18025721609592438,
      "learning_rate": 4.596577792612755e-06,
      "loss": 0.3373,
      "step": 1350
    },
    {
      "epoch": 9.228187919463087,
      "grad_norm": 0.65809166431427,
      "learning_rate": 3.1093255166238176e-06,
      "loss": 0.4859,
      "step": 1375
    },
    {
      "epoch": 9.395973154362416,
      "grad_norm": 0.6034421920776367,
      "learning_rate": 1.908239962130476e-06,
      "loss": 0.386,
      "step": 1400
    },
    {
      "epoch": 9.563758389261745,
      "grad_norm": 0.19259078800678253,
      "learning_rate": 9.968685367361618e-07,
      "loss": 0.3102,
      "step": 1425
    },
    {
      "epoch": 9.731543624161073,
      "grad_norm": 0.5559461712837219,
      "learning_rate": 3.779029770219378e-07,
      "loss": 0.5061,
      "step": 1450
    },
    {
      "epoch": 9.899328859060402,
      "grad_norm": 0.6855120062828064,
      "learning_rate": 5.317139849928543e-08,
      "loss": 0.3542,
      "step": 1475
    }
  ],
  "logging_steps": 25,
  "max_steps": 1490,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3087737167904768e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
