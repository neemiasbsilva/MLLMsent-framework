{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 2940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12755102040816327,
      "grad_norm": 0.5036936402320862,
      "learning_rate": 5.6179775280898885e-05,
      "loss": 1.8662,
      "step": 25
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 0.3814745247364044,
      "learning_rate": 0.00011235955056179777,
      "loss": 1.5715,
      "step": 50
    },
    {
      "epoch": 0.3826530612244898,
      "grad_norm": 0.39669203758239746,
      "learning_rate": 0.00016853932584269662,
      "loss": 0.9158,
      "step": 75
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.5071896910667419,
      "learning_rate": 0.00019999265392482905,
      "loss": 0.7524,
      "step": 100
    },
    {
      "epoch": 0.6377551020408163,
      "grad_norm": 0.3313850164413452,
      "learning_rate": 0.0001999213274253263,
      "loss": 0.724,
      "step": 125
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 0.3111054003238678,
      "learning_rate": 0.00019977417529060088,
      "loss": 0.687,
      "step": 150
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.3325641453266144,
      "learning_rate": 0.0001995513091875449,
      "loss": 0.676,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6900253891944885,
      "eval_runtime": 146.6217,
      "eval_samples_per_second": 5.333,
      "eval_steps_per_second": 5.333,
      "step": 196
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.29248282313346863,
      "learning_rate": 0.00019925289823884994,
      "loss": 0.6406,
      "step": 200
    },
    {
      "epoch": 1.1479591836734695,
      "grad_norm": 0.26480552554130554,
      "learning_rate": 0.00019887916889466752,
      "loss": 0.6499,
      "step": 225
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 0.4483828842639923,
      "learning_rate": 0.00019843040476076685,
      "loss": 0.644,
      "step": 250
    },
    {
      "epoch": 1.403061224489796,
      "grad_norm": 0.27064967155456543,
      "learning_rate": 0.00019790694638331956,
      "loss": 0.6335,
      "step": 275
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 0.26228925585746765,
      "learning_rate": 0.0001973091909904751,
      "loss": 0.6238,
      "step": 300
    },
    {
      "epoch": 1.6581632653061225,
      "grad_norm": 0.28397420048713684,
      "learning_rate": 0.00019663759219092279,
      "loss": 0.6358,
      "step": 325
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.24893373250961304,
      "learning_rate": 0.00019589265962966938,
      "loss": 0.6401,
      "step": 350
    },
    {
      "epoch": 1.913265306122449,
      "grad_norm": 0.2789904475212097,
      "learning_rate": 0.00019507495860129326,
      "loss": 0.6107,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.64859539270401,
      "eval_runtime": 146.6541,
      "eval_samples_per_second": 5.332,
      "eval_steps_per_second": 5.332,
      "step": 392
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.2712653875350952,
      "learning_rate": 0.00019418510962096862,
      "loss": 0.6061,
      "step": 400
    },
    {
      "epoch": 2.1683673469387754,
      "grad_norm": 0.29446902871131897,
      "learning_rate": 0.00019322378795358564,
      "loss": 0.5908,
      "step": 425
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 0.24368879199028015,
      "learning_rate": 0.00019219172310132326,
      "loss": 0.5887,
      "step": 450
    },
    {
      "epoch": 2.423469387755102,
      "grad_norm": 0.27259793877601624,
      "learning_rate": 0.00019108969825006419,
      "loss": 0.579,
      "step": 475
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.23627132177352905,
      "learning_rate": 0.00018991854967507138,
      "loss": 0.5995,
      "step": 500
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.2549053132534027,
      "learning_rate": 0.00018867916610637808,
      "loss": 0.5705,
      "step": 525
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 0.24088627099990845,
      "learning_rate": 0.0001873724880543718,
      "loss": 0.6134,
      "step": 550
    },
    {
      "epoch": 2.933673469387755,
      "grad_norm": 0.30152076482772827,
      "learning_rate": 0.00018599950709608505,
      "loss": 0.5683,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.630346953868866,
      "eval_runtime": 146.8359,
      "eval_samples_per_second": 5.326,
      "eval_steps_per_second": 5.326,
      "step": 588
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 0.2648940682411194,
      "learning_rate": 0.0001845612651227335,
      "loss": 0.5871,
      "step": 600
    },
    {
      "epoch": 3.188775510204082,
      "grad_norm": 0.2703980803489685,
      "learning_rate": 0.0001830588535490736,
      "loss": 0.5445,
      "step": 625
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 0.2927404046058655,
      "learning_rate": 0.00018149341248517868,
      "loss": 0.5723,
      "step": 650
    },
    {
      "epoch": 3.443877551020408,
      "grad_norm": 0.300884485244751,
      "learning_rate": 0.00017986612987126263,
      "loss": 0.535,
      "step": 675
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.27146950364112854,
      "learning_rate": 0.00017817824057620745,
      "loss": 0.5802,
      "step": 700
    },
    {
      "epoch": 3.6989795918367347,
      "grad_norm": 0.2911843955516815,
      "learning_rate": 0.0001764310254604789,
      "loss": 0.5379,
      "step": 725
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 0.2672555148601532,
      "learning_rate": 0.00017462581040414118,
      "loss": 0.5781,
      "step": 750
    },
    {
      "epoch": 3.954081632653061,
      "grad_norm": 0.31119683384895325,
      "learning_rate": 0.00017276396530070836,
      "loss": 0.5309,
      "step": 775
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6207156777381897,
      "eval_runtime": 147.3352,
      "eval_samples_per_second": 5.308,
      "eval_steps_per_second": 5.308,
      "step": 784
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.29026105999946594,
      "learning_rate": 0.00017084690301759613,
      "loss": 0.5569,
      "step": 800
    },
    {
      "epoch": 4.209183673469388,
      "grad_norm": 0.2843187153339386,
      "learning_rate": 0.00016887607832396273,
      "loss": 0.506,
      "step": 825
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 0.3057526648044586,
      "learning_rate": 0.00016685298678675213,
      "loss": 0.5437,
      "step": 850
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.35024315118789673,
      "learning_rate": 0.00016477916363577845,
      "loss": 0.4962,
      "step": 875
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 0.3007190525531769,
      "learning_rate": 0.0001626561825987114,
      "loss": 0.5535,
      "step": 900
    },
    {
      "epoch": 4.719387755102041,
      "grad_norm": 0.3398476541042328,
      "learning_rate": 0.00016048565470684772,
      "loss": 0.5043,
      "step": 925
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 0.3009251058101654,
      "learning_rate": 0.00015826922707257488,
      "loss": 0.5646,
      "step": 950
    },
    {
      "epoch": 4.974489795918368,
      "grad_norm": 0.35267770290374756,
      "learning_rate": 0.0001560085816394541,
      "loss": 0.4907,
      "step": 975
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6212268471717834,
      "eval_runtime": 147.388,
      "eval_samples_per_second": 5.306,
      "eval_steps_per_second": 5.306,
      "step": 980
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 0.31892138719558716,
      "learning_rate": 0.00015370543390587192,
      "loss": 0.5449,
      "step": 1000
    },
    {
      "epoch": 5.229591836734694,
      "grad_norm": 0.34417879581451416,
      "learning_rate": 0.00015136153162322852,
      "loss": 0.4598,
      "step": 1025
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.30851778388023376,
      "learning_rate": 0.00014897865346965054,
      "loss": 0.5269,
      "step": 1050
    },
    {
      "epoch": 5.48469387755102,
      "grad_norm": 0.38589173555374146,
      "learning_rate": 0.00014655860770023535,
      "loss": 0.4679,
      "step": 1075
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 0.3242107629776001,
      "learning_rate": 0.00014410323077485056,
      "loss": 0.5335,
      "step": 1100
    },
    {
      "epoch": 5.739795918367347,
      "grad_norm": 0.367078572511673,
      "learning_rate": 0.0001416143859645303,
      "loss": 0.4816,
      "step": 1125
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 0.34024178981781006,
      "learning_rate": 0.00013909396193752556,
      "loss": 0.5342,
      "step": 1150
    },
    {
      "epoch": 5.994897959183674,
      "grad_norm": 0.37037205696105957,
      "learning_rate": 0.0001365438713260822,
      "loss": 0.4703,
      "step": 1175
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6213098168373108,
      "eval_runtime": 147.2556,
      "eval_samples_per_second": 5.31,
      "eval_steps_per_second": 5.31,
      "step": 1176
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 0.3461705148220062,
      "learning_rate": 0.00013396604927503337,
      "loss": 0.4966,
      "step": 1200
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.42777547240257263,
      "learning_rate": 0.00013136245197330836,
      "loss": 0.4552,
      "step": 1225
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 0.3461143374443054,
      "learning_rate": 0.0001287350551694721,
      "loss": 0.5018,
      "step": 1250
    },
    {
      "epoch": 6.505102040816326,
      "grad_norm": 0.43545231223106384,
      "learning_rate": 0.00012608585267242175,
      "loss": 0.46,
      "step": 1275
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 0.34882989525794983,
      "learning_rate": 0.00012341685483837798,
      "loss": 0.4962,
      "step": 1300
    },
    {
      "epoch": 6.760204081632653,
      "grad_norm": 0.36721956729888916,
      "learning_rate": 0.0001207300870453196,
      "loss": 0.4685,
      "step": 1325
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 0.36736151576042175,
      "learning_rate": 0.00011802758815601844,
      "loss": 0.4807,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.6299229264259338,
      "eval_runtime": 147.2029,
      "eval_samples_per_second": 5.312,
      "eval_steps_per_second": 5.312,
      "step": 1372
    },
    {
      "epoch": 7.01530612244898,
      "grad_norm": 0.36799484491348267,
      "learning_rate": 0.00011531140897084166,
      "loss": 0.4582,
      "step": 1375
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.37425288558006287,
      "learning_rate": 0.00011258361067149494,
      "loss": 0.4487,
      "step": 1400
    },
    {
      "epoch": 7.270408163265306,
      "grad_norm": 0.4136601388454437,
      "learning_rate": 0.00010984626325688778,
      "loss": 0.443,
      "step": 1425
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 0.36582550406455994,
      "learning_rate": 0.0001071014439723079,
      "loss": 0.4554,
      "step": 1450
    },
    {
      "epoch": 7.525510204081632,
      "grad_norm": 0.4102950394153595,
      "learning_rate": 0.00010435123573309669,
      "loss": 0.448,
      "step": 1475
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 0.38607028126716614,
      "learning_rate": 0.00010159772554402183,
      "loss": 0.4569,
      "step": 1500
    },
    {
      "epoch": 7.780612244897959,
      "grad_norm": 0.3803153336048126,
      "learning_rate": 9.884300291554685e-05,
      "loss": 0.464,
      "step": 1525
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 0.3972938656806946,
      "learning_rate": 9.608915827819884e-05,
      "loss": 0.4497,
      "step": 1550
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.6363205909729004,
      "eval_runtime": 147.1974,
      "eval_samples_per_second": 5.313,
      "eval_steps_per_second": 5.313,
      "step": 1568
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.3735925853252411,
      "learning_rate": 9.333828139623851e-05,
      "loss": 0.4488,
      "step": 1575
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.4258100092411041,
      "learning_rate": 9.059245978183544e-05,
      "loss": 0.42,
      "step": 1600
    },
    {
      "epoch": 8.290816326530612,
      "grad_norm": 0.3975760042667389,
      "learning_rate": 8.785377711095224e-05,
      "loss": 0.4356,
      "step": 1625
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 0.4391595423221588,
      "learning_rate": 8.51243116421404e-05,
      "loss": 0.4235,
      "step": 1650
    },
    {
      "epoch": 8.545918367346939,
      "grad_norm": 0.4069811701774597,
      "learning_rate": 8.240613463944659e-05,
      "loss": 0.4392,
      "step": 1675
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 0.42652133107185364,
      "learning_rate": 7.9701308800627e-05,
      "loss": 0.4191,
      "step": 1700
    },
    {
      "epoch": 8.801020408163264,
      "grad_norm": 0.3996190130710602,
      "learning_rate": 7.701188669186231e-05,
      "loss": 0.4388,
      "step": 1725
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.40744152665138245,
      "learning_rate": 7.433990919016067e-05,
      "loss": 0.4165,
      "step": 1750
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6423206925392151,
      "eval_runtime": 147.2264,
      "eval_samples_per_second": 5.312,
      "eval_steps_per_second": 5.312,
      "step": 1764
    },
    {
      "epoch": 9.056122448979592,
      "grad_norm": 0.35633084177970886,
      "learning_rate": 7.168740393463173e-05,
      "loss": 0.4399,
      "step": 1775
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 0.39221838116645813,
      "learning_rate": 6.905638378780558e-05,
      "loss": 0.3981,
      "step": 1800
    },
    {
      "epoch": 9.311224489795919,
      "grad_norm": 0.43221235275268555,
      "learning_rate": 6.644884530816531e-05,
      "loss": 0.4266,
      "step": 1825
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 0.40024256706237793,
      "learning_rate": 6.386676723505208e-05,
      "loss": 0.3914,
      "step": 1850
    },
    {
      "epoch": 9.566326530612244,
      "grad_norm": 0.4141356945037842,
      "learning_rate": 6.13121089870917e-05,
      "loss": 0.4243,
      "step": 1875
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 0.4694507122039795,
      "learning_rate": 5.878680917528374e-05,
      "loss": 0.3881,
      "step": 1900
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.4188860058784485,
      "learning_rate": 5.629278413187965e-05,
      "loss": 0.4237,
      "step": 1925
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 0.43602263927459717,
      "learning_rate": 5.3831926456167825e-05,
      "loss": 0.3972,
      "step": 1950
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6562514305114746,
      "eval_runtime": 147.1302,
      "eval_samples_per_second": 5.315,
      "eval_steps_per_second": 5.315,
      "step": 1960
    },
    {
      "epoch": 10.076530612244898,
      "grad_norm": 0.4323679208755493,
      "learning_rate": 5.1406103578268184e-05,
      "loss": 0.4214,
      "step": 1975
    },
    {
      "epoch": 10.204081632653061,
      "grad_norm": 0.4414743483066559,
      "learning_rate": 4.901715634202644e-05,
      "loss": 0.3712,
      "step": 2000
    },
    {
      "epoch": 10.331632653061224,
      "grad_norm": 0.46043041348457336,
      "learning_rate": 4.666689760808384e-05,
      "loss": 0.407,
      "step": 2025
    },
    {
      "epoch": 10.459183673469388,
      "grad_norm": 0.4755893647670746,
      "learning_rate": 4.4357110878181415e-05,
      "loss": 0.3765,
      "step": 2050
    },
    {
      "epoch": 10.58673469387755,
      "grad_norm": 0.4357263147830963,
      "learning_rate": 4.2089548941744026e-05,
      "loss": 0.4104,
      "step": 2075
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.49447107315063477,
      "learning_rate": 3.986593254577e-05,
      "loss": 0.3741,
      "step": 2100
    },
    {
      "epoch": 10.841836734693878,
      "grad_norm": 0.4507618546485901,
      "learning_rate": 3.7687949089036576e-05,
      "loss": 0.424,
      "step": 2125
    },
    {
      "epoch": 10.96938775510204,
      "grad_norm": 0.5067238211631775,
      "learning_rate": 3.555725134161165e-05,
      "loss": 0.3642,
      "step": 2150
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.663054883480072,
      "eval_runtime": 147.0629,
      "eval_samples_per_second": 5.317,
      "eval_steps_per_second": 5.317,
      "step": 2156
    },
    {
      "epoch": 11.096938775510203,
      "grad_norm": 0.44304224848747253,
      "learning_rate": 3.347545619064357e-05,
      "loss": 0.4133,
      "step": 2175
    },
    {
      "epoch": 11.224489795918368,
      "grad_norm": 0.48443731665611267,
      "learning_rate": 3.144414341338108e-05,
      "loss": 0.3602,
      "step": 2200
    },
    {
      "epoch": 11.35204081632653,
      "grad_norm": 0.46782559156417847,
      "learning_rate": 2.9464854478353875e-05,
      "loss": 0.3976,
      "step": 2225
    },
    {
      "epoch": 11.479591836734693,
      "grad_norm": 0.5374211668968201,
      "learning_rate": 2.753909137562405e-05,
      "loss": 0.3604,
      "step": 2250
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.4823892414569855,
      "learning_rate": 2.5668315476995997e-05,
      "loss": 0.4074,
      "step": 2275
    },
    {
      "epoch": 11.73469387755102,
      "grad_norm": 0.6215862035751343,
      "learning_rate": 2.3853946427049344e-05,
      "loss": 0.3565,
      "step": 2300
    },
    {
      "epoch": 11.862244897959183,
      "grad_norm": 0.4736177623271942,
      "learning_rate": 2.209736106583703e-05,
      "loss": 0.3999,
      "step": 2325
    },
    {
      "epoch": 11.989795918367347,
      "grad_norm": 0.5098312497138977,
      "learning_rate": 2.0399892384065578e-05,
      "loss": 0.3546,
      "step": 2350
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.6664642691612244,
      "eval_runtime": 147.045,
      "eval_samples_per_second": 5.318,
      "eval_steps_per_second": 5.318,
      "step": 2352
    },
    {
      "epoch": 12.11734693877551,
      "grad_norm": 0.4873293340206146,
      "learning_rate": 1.8762828511550457e-05,
      "loss": 0.3833,
      "step": 2375
    },
    {
      "epoch": 12.244897959183673,
      "grad_norm": 0.654788613319397,
      "learning_rate": 1.718741173971471e-05,
      "loss": 0.3478,
      "step": 2400
    },
    {
      "epoch": 12.372448979591837,
      "grad_norm": 0.5003310441970825,
      "learning_rate": 1.5674837578871693e-05,
      "loss": 0.3945,
      "step": 2425
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.5170144438743591,
      "learning_rate": 1.422625385100822e-05,
      "loss": 0.3482,
      "step": 2450
    },
    {
      "epoch": 12.627551020408163,
      "grad_norm": 0.48658961057662964,
      "learning_rate": 1.28427598187559e-05,
      "loss": 0.3898,
      "step": 2475
    },
    {
      "epoch": 12.755102040816327,
      "grad_norm": 0.5258813500404358,
      "learning_rate": 1.152540535121196e-05,
      "loss": 0.3662,
      "step": 2500
    },
    {
      "epoch": 12.88265306122449,
      "grad_norm": 0.4649859666824341,
      "learning_rate": 1.0275190127242696e-05,
      "loss": 0.3786,
      "step": 2525
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.672560453414917,
      "eval_runtime": 147.0839,
      "eval_samples_per_second": 5.317,
      "eval_steps_per_second": 5.317,
      "step": 2548
    },
    {
      "epoch": 13.010204081632653,
      "grad_norm": 0.48092886805534363,
      "learning_rate": 9.093062876873625e-06,
      "loss": 0.3597,
      "step": 2550
    },
    {
      "epoch": 13.137755102040817,
      "grad_norm": 0.4527183473110199,
      "learning_rate": 7.979920661342677e-06,
      "loss": 0.3746,
      "step": 2575
    },
    {
      "epoch": 13.26530612244898,
      "grad_norm": 0.4854509234428406,
      "learning_rate": 6.936608192362182e-06,
      "loss": 0.3578,
      "step": 2600
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.48165538907051086,
      "learning_rate": 5.963917191106494e-06,
      "loss": 0.3669,
      "step": 2625
    },
    {
      "epoch": 13.520408163265307,
      "grad_norm": 0.4947950541973114,
      "learning_rate": 5.062585787411833e-06,
      "loss": 0.3665,
      "step": 2650
    },
    {
      "epoch": 13.64795918367347,
      "grad_norm": 0.4889163672924042,
      "learning_rate": 4.233297959643912e-06,
      "loss": 0.3626,
      "step": 2675
    },
    {
      "epoch": 13.775510204081632,
      "grad_norm": 0.4774336516857147,
      "learning_rate": 3.476683015658644e-06,
      "loss": 0.3646,
      "step": 2700
    },
    {
      "epoch": 13.903061224489797,
      "grad_norm": 0.4906146228313446,
      "learning_rate": 2.793315115249806e-06,
      "loss": 0.3603,
      "step": 2725
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.676564633846283,
      "eval_runtime": 147.0788,
      "eval_samples_per_second": 5.317,
      "eval_steps_per_second": 5.317,
      "step": 2744
    },
    {
      "epoch": 14.03061224489796,
      "grad_norm": 0.4954254925251007,
      "learning_rate": 2.1837128344458723e-06,
      "loss": 0.3648,
      "step": 2750
    },
    {
      "epoch": 14.158163265306122,
      "grad_norm": 0.45030874013900757,
      "learning_rate": 1.648338771986957e-06,
      "loss": 0.3586,
      "step": 2775
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.4886986017227173,
      "learning_rate": 1.1875991982801093e-06,
      "loss": 0.3701,
      "step": 2800
    },
    {
      "epoch": 14.41326530612245,
      "grad_norm": 0.5135934352874756,
      "learning_rate": 8.018437470997176e-07,
      "loss": 0.3574,
      "step": 2825
    },
    {
      "epoch": 14.540816326530612,
      "grad_norm": 0.46448877453804016,
      "learning_rate": 4.913651502667094e-07,
      "loss": 0.37,
      "step": 2850
    },
    {
      "epoch": 14.668367346938776,
      "grad_norm": 0.5219371914863586,
      "learning_rate": 2.5639901550801317e-07,
      "loss": 0.3567,
      "step": 2875
    },
    {
      "epoch": 14.795918367346939,
      "grad_norm": 0.46652233600616455,
      "learning_rate": 9.712364766489845e-08,
      "loss": 0.3697,
      "step": 2900
    },
    {
      "epoch": 14.923469387755102,
      "grad_norm": 0.4676841199398041,
      "learning_rate": 1.36599133856663e-08,
      "loss": 0.3447,
      "step": 2925
    }
  ],
  "logging_steps": 25,
  "max_steps": 2940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5353708177211392e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
