{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3570,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0700280112044818,
      "grad_norm": 0.53331059217453,
      "learning_rate": 4.62962962962963e-05,
      "loss": 1.2231,
      "step": 25
    },
    {
      "epoch": 0.1400560224089636,
      "grad_norm": 1.3327527046203613,
      "learning_rate": 9.25925925925926e-05,
      "loss": 2.2488,
      "step": 50
    },
    {
      "epoch": 0.21008403361344538,
      "grad_norm": 0.5552486777305603,
      "learning_rate": 0.0001388888888888889,
      "loss": 0.6872,
      "step": 75
    },
    {
      "epoch": 0.2801120448179272,
      "grad_norm": 1.5483849048614502,
      "learning_rate": 0.0001851851851851852,
      "loss": 1.1517,
      "step": 100
    },
    {
      "epoch": 0.35014005602240894,
      "grad_norm": 0.44919440150260925,
      "learning_rate": 0.00019998810115375867,
      "loss": 0.6549,
      "step": 125
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 1.1954994201660156,
      "learning_rate": 0.0001999273790991967,
      "loss": 0.981,
      "step": 150
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.37879064679145813,
      "learning_rate": 0.00019981523000726255,
      "loss": 0.6219,
      "step": 175
    },
    {
      "epoch": 0.5602240896358543,
      "grad_norm": 0.7196980714797974,
      "learning_rate": 0.00019965171159482624,
      "loss": 0.959,
      "step": 200
    },
    {
      "epoch": 0.6302521008403361,
      "grad_norm": 0.4005589485168457,
      "learning_rate": 0.00019943690801567601,
      "loss": 0.6551,
      "step": 225
    },
    {
      "epoch": 0.7002801120448179,
      "grad_norm": 0.5892035365104675,
      "learning_rate": 0.00019917092981720932,
      "loss": 0.9155,
      "step": 250
    },
    {
      "epoch": 0.7703081232492998,
      "grad_norm": 0.31092068552970886,
      "learning_rate": 0.00019885391388354022,
      "loss": 0.5717,
      "step": 275
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 0.5168003439903259,
      "learning_rate": 0.00019848602336505262,
      "loss": 0.9333,
      "step": 300
    },
    {
      "epoch": 0.9103641456582633,
      "grad_norm": 0.3567239046096802,
      "learning_rate": 0.00019806744759443608,
      "loss": 0.55,
      "step": 325
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.6180636286735535,
      "learning_rate": 0.00019759840198924674,
      "loss": 0.9071,
      "step": 350
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7702755928039551,
      "eval_runtime": 162.5805,
      "eval_samples_per_second": 4.386,
      "eval_steps_per_second": 4.386,
      "step": 357
    },
    {
      "epoch": 1.050420168067227,
      "grad_norm": 0.3545789420604706,
      "learning_rate": 0.000197079127941044,
      "loss": 0.4242,
      "step": 375
    },
    {
      "epoch": 1.1204481792717087,
      "grad_norm": 0.39222484827041626,
      "learning_rate": 0.00019650989269115977,
      "loss": 0.9735,
      "step": 400
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.44488611817359924,
      "learning_rate": 0.00019589098919316425,
      "loss": 0.4552,
      "step": 425
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 0.4242912232875824,
      "learning_rate": 0.0001952227359620992,
      "loss": 0.9686,
      "step": 450
    },
    {
      "epoch": 1.330532212885154,
      "grad_norm": 0.4642033278942108,
      "learning_rate": 0.00019450547691055584,
      "loss": 0.4435,
      "step": 475
    },
    {
      "epoch": 1.4005602240896358,
      "grad_norm": 0.3661702871322632,
      "learning_rate": 0.00019373958117168248,
      "loss": 0.9546,
      "step": 500
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.34799546003341675,
      "learning_rate": 0.0001929254429092123,
      "loss": 0.4858,
      "step": 525
    },
    {
      "epoch": 1.5406162464985993,
      "grad_norm": 0.4561189115047455,
      "learning_rate": 0.00019206348111460914,
      "loss": 0.9371,
      "step": 550
    },
    {
      "epoch": 1.6106442577030813,
      "grad_norm": 0.41063132882118225,
      "learning_rate": 0.00019115413939143616,
      "loss": 0.6105,
      "step": 575
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 0.370425283908844,
      "learning_rate": 0.0001901978857270578,
      "loss": 0.9493,
      "step": 600
    },
    {
      "epoch": 1.7507002801120448,
      "grad_norm": 0.4607716500759125,
      "learning_rate": 0.0001891952122517929,
      "loss": 0.4092,
      "step": 625
    },
    {
      "epoch": 1.8207282913165266,
      "grad_norm": 0.36700478196144104,
      "learning_rate": 0.00018814663498564266,
      "loss": 0.9907,
      "step": 650
    },
    {
      "epoch": 1.8907563025210083,
      "grad_norm": 0.456678181886673,
      "learning_rate": 0.00018705269357272407,
      "loss": 0.4215,
      "step": 675
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.37322622537612915,
      "learning_rate": 0.00018591395100354513,
      "loss": 0.9817,
      "step": 700
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7331233024597168,
      "eval_runtime": 162.1627,
      "eval_samples_per_second": 4.397,
      "eval_steps_per_second": 4.397,
      "step": 714
    },
    {
      "epoch": 2.030812324929972,
      "grad_norm": 0.05670888349413872,
      "learning_rate": 0.00018473099332526517,
      "loss": 0.5081,
      "step": 725
    },
    {
      "epoch": 2.100840336134454,
      "grad_norm": 0.3773666322231293,
      "learning_rate": 0.0001835044293400892,
      "loss": 0.7578,
      "step": 750
    },
    {
      "epoch": 2.1708683473389354,
      "grad_norm": 0.08680887520313263,
      "learning_rate": 0.00018223489029195128,
      "loss": 0.5009,
      "step": 775
    },
    {
      "epoch": 2.2408963585434174,
      "grad_norm": 0.3685292899608612,
      "learning_rate": 0.0001809230295416486,
      "loss": 0.8859,
      "step": 800
    },
    {
      "epoch": 2.310924369747899,
      "grad_norm": 0.08331060409545898,
      "learning_rate": 0.00017956952223059332,
      "loss": 0.5301,
      "step": 825
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.40116119384765625,
      "learning_rate": 0.00017817506493335484,
      "loss": 0.8265,
      "step": 850
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 0.091191865503788,
      "learning_rate": 0.00017674037529917189,
      "loss": 0.5234,
      "step": 875
    },
    {
      "epoch": 2.5210084033613445,
      "grad_norm": 0.4361863434314728,
      "learning_rate": 0.00017526619168261855,
      "loss": 0.8481,
      "step": 900
    },
    {
      "epoch": 2.5910364145658265,
      "grad_norm": 0.10654067993164062,
      "learning_rate": 0.00017375327276361444,
      "loss": 0.5203,
      "step": 925
    },
    {
      "epoch": 2.661064425770308,
      "grad_norm": 0.3695918917655945,
      "learning_rate": 0.00017220239715697453,
      "loss": 0.8398,
      "step": 950
    },
    {
      "epoch": 2.73109243697479,
      "grad_norm": 0.08886135369539261,
      "learning_rate": 0.00017061436301169967,
      "loss": 0.5256,
      "step": 975
    },
    {
      "epoch": 2.8011204481792715,
      "grad_norm": 0.40605929493904114,
      "learning_rate": 0.00016898998760021377,
      "loss": 0.819,
      "step": 1000
    },
    {
      "epoch": 2.8711484593837535,
      "grad_norm": 0.10064513236284256,
      "learning_rate": 0.00016733010689775956,
      "loss": 0.5295,
      "step": 1025
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.3732752799987793,
      "learning_rate": 0.00016563557515216867,
      "loss": 0.7745,
      "step": 1050
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7146613001823425,
      "eval_runtime": 162.0775,
      "eval_samples_per_second": 4.399,
      "eval_steps_per_second": 4.399,
      "step": 1071
    },
    {
      "epoch": 3.011204481792717,
      "grad_norm": 0.10757507383823395,
      "learning_rate": 0.0001639072644442281,
      "loss": 0.631,
      "step": 1075
    },
    {
      "epoch": 3.081232492997199,
      "grad_norm": 0.38378968834877014,
      "learning_rate": 0.00016214606423886903,
      "loss": 0.6273,
      "step": 1100
    },
    {
      "epoch": 3.1512605042016806,
      "grad_norm": 0.09488368779420853,
      "learning_rate": 0.0001603528809274087,
      "loss": 0.6668,
      "step": 1125
    },
    {
      "epoch": 3.2212885154061626,
      "grad_norm": 0.3915688693523407,
      "learning_rate": 0.00015852863736108186,
      "loss": 0.6018,
      "step": 1150
    },
    {
      "epoch": 3.291316526610644,
      "grad_norm": 0.1117931604385376,
      "learning_rate": 0.00015667427237610036,
      "loss": 0.6405,
      "step": 1175
    },
    {
      "epoch": 3.361344537815126,
      "grad_norm": 0.37767377495765686,
      "learning_rate": 0.00015479074031048696,
      "loss": 0.5845,
      "step": 1200
    },
    {
      "epoch": 3.431372549019608,
      "grad_norm": 0.10955561697483063,
      "learning_rate": 0.0001528790105129306,
      "loss": 0.6537,
      "step": 1225
    },
    {
      "epoch": 3.5014005602240896,
      "grad_norm": 0.39760705828666687,
      "learning_rate": 0.0001509400668439172,
      "loss": 0.6185,
      "step": 1250
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.12014948576688766,
      "learning_rate": 0.0001489749071693912,
      "loss": 0.6659,
      "step": 1275
    },
    {
      "epoch": 3.641456582633053,
      "grad_norm": 0.39923903346061707,
      "learning_rate": 0.00014698454284721004,
      "loss": 0.5878,
      "step": 1300
    },
    {
      "epoch": 3.711484593837535,
      "grad_norm": 0.11456096172332764,
      "learning_rate": 0.00014496999820665476,
      "loss": 0.6573,
      "step": 1325
    },
    {
      "epoch": 3.7815126050420167,
      "grad_norm": 0.40830013155937195,
      "learning_rate": 0.0001429323100212647,
      "loss": 0.5834,
      "step": 1350
    },
    {
      "epoch": 3.8515406162464987,
      "grad_norm": 0.10069375485181808,
      "learning_rate": 0.0001408725269752685,
      "loss": 0.67,
      "step": 1375
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.3982393741607666,
      "learning_rate": 0.00013879170912388467,
      "loss": 0.6023,
      "step": 1400
    },
    {
      "epoch": 3.991596638655462,
      "grad_norm": 0.5382580757141113,
      "learning_rate": 0.00013669092734777037,
      "loss": 0.707,
      "step": 1425
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7174252271652222,
      "eval_runtime": 162.9458,
      "eval_samples_per_second": 4.376,
      "eval_steps_per_second": 4.376,
      "step": 1428
    },
    {
      "epoch": 4.061624649859944,
      "grad_norm": 0.3805369734764099,
      "learning_rate": 0.0001345712628018993,
      "loss": 0.4624,
      "step": 1450
    },
    {
      "epoch": 4.131652661064426,
      "grad_norm": 0.5059200525283813,
      "learning_rate": 0.00013243380635915127,
      "loss": 0.7352,
      "step": 1475
    },
    {
      "epoch": 4.201680672268908,
      "grad_norm": 0.4155157208442688,
      "learning_rate": 0.00013027965804890117,
      "loss": 0.4676,
      "step": 1500
    },
    {
      "epoch": 4.271708683473389,
      "grad_norm": 0.5090063810348511,
      "learning_rate": 0.00012810992649089524,
      "loss": 0.7343,
      "step": 1525
    },
    {
      "epoch": 4.341736694677871,
      "grad_norm": 0.4639725685119629,
      "learning_rate": 0.00012592572832470638,
      "loss": 0.4352,
      "step": 1550
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 0.5713862180709839,
      "learning_rate": 0.00012372818763506222,
      "loss": 0.7441,
      "step": 1575
    },
    {
      "epoch": 4.481792717086835,
      "grad_norm": 0.5114601850509644,
      "learning_rate": 0.00012151843537334162,
      "loss": 0.429,
      "step": 1600
    },
    {
      "epoch": 4.551820728291316,
      "grad_norm": 0.5849190354347229,
      "learning_rate": 0.00011929760877553707,
      "loss": 0.7542,
      "step": 1625
    },
    {
      "epoch": 4.621848739495798,
      "grad_norm": 0.5175236463546753,
      "learning_rate": 0.00011706685077698287,
      "loss": 0.3575,
      "step": 1650
    },
    {
      "epoch": 4.69187675070028,
      "grad_norm": 0.5295237302780151,
      "learning_rate": 0.00011482730942415037,
      "loss": 0.7594,
      "step": 1675
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.43552494049072266,
      "learning_rate": 0.0001125801372838124,
      "loss": 0.4699,
      "step": 1700
    },
    {
      "epoch": 4.831932773109243,
      "grad_norm": 0.5768522620201111,
      "learning_rate": 0.00011032649084988167,
      "loss": 0.7299,
      "step": 1725
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 0.452156126499176,
      "learning_rate": 0.00010806752994822806,
      "loss": 0.3994,
      "step": 1750
    },
    {
      "epoch": 4.971988795518207,
      "grad_norm": 0.5800697803497314,
      "learning_rate": 0.00010580441713978083,
      "loss": 0.7338,
      "step": 1775
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7120811343193054,
      "eval_runtime": 162.8043,
      "eval_samples_per_second": 4.379,
      "eval_steps_per_second": 4.379,
      "step": 1785
    },
    {
      "epoch": 5.042016806722689,
      "grad_norm": 0.08939191699028015,
      "learning_rate": 0.00010353831712222369,
      "loss": 0.3459,
      "step": 1800
    },
    {
      "epoch": 5.1120448179271705,
      "grad_norm": 0.5378556251525879,
      "learning_rate": 0.00010127039613059001,
      "loss": 0.7225,
      "step": 1825
    },
    {
      "epoch": 5.182072829131653,
      "grad_norm": 0.17897559702396393,
      "learning_rate": 9.900182133706665e-05,
      "loss": 0.3397,
      "step": 1850
    },
    {
      "epoch": 5.2521008403361344,
      "grad_norm": 0.5714902877807617,
      "learning_rate": 9.673376025031582e-05,
      "loss": 0.7745,
      "step": 1875
    },
    {
      "epoch": 5.322128851540616,
      "grad_norm": 0.13290154933929443,
      "learning_rate": 9.446738011462351e-05,
      "loss": 0.3386,
      "step": 1900
    },
    {
      "epoch": 5.392156862745098,
      "grad_norm": 0.547351062297821,
      "learning_rate": 9.220384730918421e-05,
      "loss": 0.7732,
      "step": 1925
    },
    {
      "epoch": 5.46218487394958,
      "grad_norm": 0.13518072664737701,
      "learning_rate": 8.994432674783058e-05,
      "loss": 0.3618,
      "step": 1950
    },
    {
      "epoch": 5.5322128851540615,
      "grad_norm": 0.5761244297027588,
      "learning_rate": 8.768998127951752e-05,
      "loss": 0.7341,
      "step": 1975
    },
    {
      "epoch": 5.602240896358543,
      "grad_norm": 0.1399143934249878,
      "learning_rate": 8.544197108986885e-05,
      "loss": 0.3249,
      "step": 2000
    },
    {
      "epoch": 5.6722689075630255,
      "grad_norm": 0.562263011932373,
      "learning_rate": 8.320145310409434e-05,
      "loss": 0.7643,
      "step": 2025
    },
    {
      "epoch": 5.742296918767507,
      "grad_norm": 0.1032608225941658,
      "learning_rate": 8.096958039158531e-05,
      "loss": 0.3515,
      "step": 2050
    },
    {
      "epoch": 5.812324929971989,
      "grad_norm": 0.5755723714828491,
      "learning_rate": 7.874750157249397e-05,
      "loss": 0.7319,
      "step": 2075
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.121239572763443,
      "learning_rate": 7.653636022660305e-05,
      "loss": 0.3451,
      "step": 2100
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.5775818228721619,
      "learning_rate": 7.4337294304789e-05,
      "loss": 0.7514,
      "step": 2125
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7226802110671997,
      "eval_runtime": 162.4809,
      "eval_samples_per_second": 4.388,
      "eval_steps_per_second": 4.388,
      "step": 2142
    },
    {
      "epoch": 6.022408963585434,
      "grad_norm": 0.1028793603181839,
      "learning_rate": 7.215143554338237e-05,
      "loss": 0.4257,
      "step": 2150
    },
    {
      "epoch": 6.092436974789916,
      "grad_norm": 0.5944544672966003,
      "learning_rate": 6.99799088817264e-05,
      "loss": 0.5989,
      "step": 2175
    },
    {
      "epoch": 6.162464985994398,
      "grad_norm": 0.1339336782693863,
      "learning_rate": 6.78238318832335e-05,
      "loss": 0.4496,
      "step": 2200
    },
    {
      "epoch": 6.23249299719888,
      "grad_norm": 0.5787060856819153,
      "learning_rate": 6.568431416023802e-05,
      "loss": 0.5613,
      "step": 2225
    },
    {
      "epoch": 6.302521008403361,
      "grad_norm": 0.1527089923620224,
      "learning_rate": 6.356245680294047e-05,
      "loss": 0.447,
      "step": 2250
    },
    {
      "epoch": 6.372549019607844,
      "grad_norm": 0.5781838893890381,
      "learning_rate": 6.14593518127383e-05,
      "loss": 0.5979,
      "step": 2275
    },
    {
      "epoch": 6.442577030812325,
      "grad_norm": 0.16064558923244476,
      "learning_rate": 5.937608154023352e-05,
      "loss": 0.4392,
      "step": 2300
    },
    {
      "epoch": 6.512605042016807,
      "grad_norm": 0.6336500644683838,
      "learning_rate": 5.731371812820742e-05,
      "loss": 0.5883,
      "step": 2325
    },
    {
      "epoch": 6.582633053221288,
      "grad_norm": 0.1336841732263565,
      "learning_rate": 5.5273322959848817e-05,
      "loss": 0.4407,
      "step": 2350
    },
    {
      "epoch": 6.652661064425771,
      "grad_norm": 0.6066780686378479,
      "learning_rate": 5.325594611251901e-05,
      "loss": 0.5848,
      "step": 2375
    },
    {
      "epoch": 6.722689075630252,
      "grad_norm": 0.1559421718120575,
      "learning_rate": 5.1262625817336055e-05,
      "loss": 0.4396,
      "step": 2400
    },
    {
      "epoch": 6.792717086834734,
      "grad_norm": 0.6149708032608032,
      "learning_rate": 4.929438792485498e-05,
      "loss": 0.552,
      "step": 2425
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.1628076285123825,
      "learning_rate": 4.7352245377119987e-05,
      "loss": 0.4398,
      "step": 2450
    },
    {
      "epoch": 6.932773109243698,
      "grad_norm": 0.6335301995277405,
      "learning_rate": 4.543719768635971e-05,
      "loss": 0.5713,
      "step": 2475
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7349729537963867,
      "eval_runtime": 162.5255,
      "eval_samples_per_second": 4.387,
      "eval_steps_per_second": 4.387,
      "step": 2499
    },
    {
      "epoch": 7.002801120448179,
      "grad_norm": 0.13708168268203735,
      "learning_rate": 4.355023042059416e-05,
      "loss": 0.5292,
      "step": 2500
    },
    {
      "epoch": 7.072829131652661,
      "grad_norm": 0.6161958575248718,
      "learning_rate": 4.1692314696417864e-05,
      "loss": 0.4025,
      "step": 2525
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.1521683782339096,
      "learning_rate": 3.9864406679220556e-05,
      "loss": 0.5251,
      "step": 2550
    },
    {
      "epoch": 7.212885154061625,
      "grad_norm": 0.6756187677383423,
      "learning_rate": 3.8067447091102326e-05,
      "loss": 0.3799,
      "step": 2575
    },
    {
      "epoch": 7.282913165266106,
      "grad_norm": 0.1650257110595703,
      "learning_rate": 3.630236072673624e-05,
      "loss": 0.5401,
      "step": 2600
    },
    {
      "epoch": 7.352941176470588,
      "grad_norm": 0.6686914563179016,
      "learning_rate": 3.457005597742854e-05,
      "loss": 0.4564,
      "step": 2625
    },
    {
      "epoch": 7.42296918767507,
      "grad_norm": 0.17086438834667206,
      "learning_rate": 3.287142436362023e-05,
      "loss": 0.5813,
      "step": 2650
    },
    {
      "epoch": 7.492997198879552,
      "grad_norm": 0.7431007623672485,
      "learning_rate": 3.120734007607134e-05,
      "loss": 0.4083,
      "step": 2675
    },
    {
      "epoch": 7.563025210084033,
      "grad_norm": 0.1800786852836609,
      "learning_rate": 2.9578659525963882e-05,
      "loss": 0.5609,
      "step": 2700
    },
    {
      "epoch": 7.633053221288515,
      "grad_norm": 0.630959689617157,
      "learning_rate": 2.798622090415479e-05,
      "loss": 0.4119,
      "step": 2725
    },
    {
      "epoch": 7.703081232492997,
      "grad_norm": 0.15133167803287506,
      "learning_rate": 2.643084374980589e-05,
      "loss": 0.5409,
      "step": 2750
    },
    {
      "epoch": 7.773109243697479,
      "grad_norm": 0.6525024771690369,
      "learning_rate": 2.4913328528613033e-05,
      "loss": 0.4272,
      "step": 2775
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 0.163091242313385,
      "learning_rate": 2.3434456220851153e-05,
      "loss": 0.547,
      "step": 2800
    },
    {
      "epoch": 7.913165266106443,
      "grad_norm": 0.7428805828094482,
      "learning_rate": 2.1994987919447098e-05,
      "loss": 0.4453,
      "step": 2825
    },
    {
      "epoch": 7.983193277310924,
      "grad_norm": 0.15960818529129028,
      "learning_rate": 2.059566443828793e-05,
      "loss": 0.5388,
      "step": 2850
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.748028576374054,
      "eval_runtime": 162.2165,
      "eval_samples_per_second": 4.395,
      "eval_steps_per_second": 4.395,
      "step": 2856
    },
    {
      "epoch": 8.053221288515406,
      "grad_norm": 0.6858755946159363,
      "learning_rate": 1.9237205930965296e-05,
      "loss": 0.3673,
      "step": 2875
    },
    {
      "epoch": 8.123249299719888,
      "grad_norm": 0.8159451484680176,
      "learning_rate": 1.792031152015261e-05,
      "loss": 0.5967,
      "step": 2900
    },
    {
      "epoch": 8.193277310924369,
      "grad_norm": 0.6489593386650085,
      "learning_rate": 1.6645658937805752e-05,
      "loss": 0.3114,
      "step": 2925
    },
    {
      "epoch": 8.263305322128852,
      "grad_norm": 0.7827545404434204,
      "learning_rate": 1.541390417637224e-05,
      "loss": 0.5989,
      "step": 2950
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.6871996521949768,
      "learning_rate": 1.4225681151188542e-05,
      "loss": 0.3004,
      "step": 2975
    },
    {
      "epoch": 8.403361344537815,
      "grad_norm": 0.8208513855934143,
      "learning_rate": 1.3081601374239439e-05,
      "loss": 0.6193,
      "step": 3000
    },
    {
      "epoch": 8.473389355742297,
      "grad_norm": 0.632821261882782,
      "learning_rate": 1.1982253639446817e-05,
      "loss": 0.3151,
      "step": 3025
    },
    {
      "epoch": 8.543417366946779,
      "grad_norm": 0.7482358813285828,
      "learning_rate": 1.0928203719650454e-05,
      "loss": 0.6048,
      "step": 3050
    },
    {
      "epoch": 8.61344537815126,
      "grad_norm": 0.6976940035820007,
      "learning_rate": 9.919994075436278e-06,
      "loss": 0.3815,
      "step": 3075
    },
    {
      "epoch": 8.683473389355742,
      "grad_norm": 0.7093305587768555,
      "learning_rate": 8.958143575962264e-06,
      "loss": 0.5948,
      "step": 3100
    },
    {
      "epoch": 8.753501400560225,
      "grad_norm": 0.6505499482154846,
      "learning_rate": 8.043147231925462e-06,
      "loss": 0.3247,
      "step": 3125
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.7777317762374878,
      "learning_rate": 7.175475940807674e-06,
      "loss": 0.6134,
      "step": 3150
    },
    {
      "epoch": 8.893557422969188,
      "grad_norm": 0.6676068902015686,
      "learning_rate": 6.355576244530837e-06,
      "loss": 0.3191,
      "step": 3175
    },
    {
      "epoch": 8.96358543417367,
      "grad_norm": 0.7089278101921082,
      "learning_rate": 5.583870099646782e-06,
      "loss": 0.6089,
      "step": 3200
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7517638802528381,
      "eval_runtime": 161.9928,
      "eval_samples_per_second": 4.401,
      "eval_steps_per_second": 4.401,
      "step": 3213
    },
    {
      "epoch": 9.033613445378151,
      "grad_norm": 0.15093648433685303,
      "learning_rate": 4.860754660179889e-06,
      "loss": 0.3026,
      "step": 3225
    },
    {
      "epoch": 9.103641456582633,
      "grad_norm": 0.7711154222488403,
      "learning_rate": 4.186602073234025e-06,
      "loss": 0.5704,
      "step": 3250
    },
    {
      "epoch": 9.173669467787114,
      "grad_norm": 0.16853076219558716,
      "learning_rate": 3.5617592874692797e-06,
      "loss": 0.3331,
      "step": 3275
    },
    {
      "epoch": 9.243697478991596,
      "grad_norm": 0.7104736566543579,
      "learning_rate": 2.98654787454683e-06,
      "loss": 0.5854,
      "step": 3300
    },
    {
      "epoch": 9.313725490196079,
      "grad_norm": 0.12418634444475174,
      "learning_rate": 2.4612638636340333e-06,
      "loss": 0.3056,
      "step": 3325
    },
    {
      "epoch": 9.38375350140056,
      "grad_norm": 0.8031472563743591,
      "learning_rate": 1.9861775890546942e-06,
      "loss": 0.5724,
      "step": 3350
    },
    {
      "epoch": 9.453781512605042,
      "grad_norm": 0.18758434057235718,
      "learning_rate": 1.5615335511631634e-06,
      "loss": 0.3354,
      "step": 3375
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.6986054182052612,
      "learning_rate": 1.1875502905136282e-06,
      "loss": 0.6544,
      "step": 3400
    },
    {
      "epoch": 9.593837535014005,
      "grad_norm": 0.16042660176753998,
      "learning_rate": 8.644202753894881e-07,
      "loss": 0.3289,
      "step": 3425
    },
    {
      "epoch": 9.663865546218487,
      "grad_norm": 0.7452031373977661,
      "learning_rate": 5.923098027507568e-07,
      "loss": 0.5545,
      "step": 3450
    },
    {
      "epoch": 9.733893557422968,
      "grad_norm": 0.16445527970790863,
      "learning_rate": 3.713589126502215e-07,
      "loss": 0.3183,
      "step": 3475
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.7525863647460938,
      "learning_rate": 2.0168131616272734e-07,
      "loss": 0.5783,
      "step": 3500
    },
    {
      "epoch": 9.873949579831933,
      "grad_norm": 0.1545349359512329,
      "learning_rate": 8.336433686438883e-08,
      "loss": 0.3282,
      "step": 3525
    },
    {
      "epoch": 9.943977591036415,
      "grad_norm": 0.7379457950592041,
      "learning_rate": 1.6468865892060868e-08,
      "loss": 0.5876,
      "step": 3550
    }
  ],
  "logging_steps": 25,
  "max_steps": 3570,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8775403085627392e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
