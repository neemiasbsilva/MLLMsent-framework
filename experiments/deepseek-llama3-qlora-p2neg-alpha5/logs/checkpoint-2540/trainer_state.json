{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0984251968503937,
      "grad_norm": 0.48307904601097107,
      "learning_rate": 6.493506493506494e-05,
      "loss": 1.1075,
      "step": 25
    },
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 0.9855955839157104,
      "learning_rate": 0.00012987012987012987,
      "loss": 1.9611,
      "step": 50
    },
    {
      "epoch": 0.2952755905511811,
      "grad_norm": 0.48928698897361755,
      "learning_rate": 0.0001948051948051948,
      "loss": 0.7772,
      "step": 75
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.8486606478691101,
      "learning_rate": 0.0001999569705841918,
      "loss": 1.0439,
      "step": 100
    },
    {
      "epoch": 0.4921259842519685,
      "grad_norm": 0.45978450775146484,
      "learning_rate": 0.00019981263531593422,
      "loss": 0.5778,
      "step": 125
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.6642244458198547,
      "learning_rate": 0.0001995668155607342,
      "loss": 0.9676,
      "step": 150
    },
    {
      "epoch": 0.6889763779527559,
      "grad_norm": 0.35339054465293884,
      "learning_rate": 0.0001992197612558032,
      "loss": 0.4791,
      "step": 175
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.42573755979537964,
      "learning_rate": 0.00019877182526857086,
      "loss": 0.9397,
      "step": 200
    },
    {
      "epoch": 0.8858267716535433,
      "grad_norm": 0.33716490864753723,
      "learning_rate": 0.0001982234630379073,
      "loss": 0.6026,
      "step": 225
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.6152977347373962,
      "learning_rate": 0.00019757523211105555,
      "loss": 0.9068,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8999096751213074,
      "eval_runtime": 108.0646,
      "eval_samples_per_second": 4.682,
      "eval_steps_per_second": 4.682,
      "step": 254
    },
    {
      "epoch": 1.0826771653543308,
      "grad_norm": 0.31519508361816406,
      "learning_rate": 0.00019682779157674537,
      "loss": 0.5072,
      "step": 275
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.4212491512298584,
      "learning_rate": 0.00019598190139506508,
      "loss": 0.9136,
      "step": 300
    },
    {
      "epoch": 1.279527559055118,
      "grad_norm": 0.42957499623298645,
      "learning_rate": 0.00019503842162477204,
      "loss": 0.4222,
      "step": 325
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.3785298764705658,
      "learning_rate": 0.00019399831154882796,
      "loss": 0.9398,
      "step": 350
    },
    {
      "epoch": 1.4763779527559056,
      "grad_norm": 0.48703494668006897,
      "learning_rate": 0.00019286262869904828,
      "loss": 0.4818,
      "step": 375
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.43893003463745117,
      "learning_rate": 0.00019163252778085646,
      "loss": 0.9303,
      "step": 400
    },
    {
      "epoch": 1.673228346456693,
      "grad_norm": 0.38120031356811523,
      "learning_rate": 0.00019030925949923777,
      "loss": 0.504,
      "step": 425
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.44246694445610046,
      "learning_rate": 0.00018889416928708465,
      "loss": 0.949,
      "step": 450
    },
    {
      "epoch": 1.8700787401574803,
      "grad_norm": 0.3958439230918884,
      "learning_rate": 0.00018738869593722842,
      "loss": 0.4979,
      "step": 475
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.3650818467140198,
      "learning_rate": 0.0001857943701395464,
      "loss": 0.9003,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8518569469451904,
      "eval_runtime": 108.0464,
      "eval_samples_per_second": 4.683,
      "eval_steps_per_second": 4.683,
      "step": 508
    },
    {
      "epoch": 2.0669291338582676,
      "grad_norm": 0.33109766244888306,
      "learning_rate": 0.00018411281292463345,
      "loss": 0.3947,
      "step": 525
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.41433557868003845,
      "learning_rate": 0.00018234573401561914,
      "loss": 0.9049,
      "step": 550
    },
    {
      "epoch": 2.263779527559055,
      "grad_norm": 0.47452351450920105,
      "learning_rate": 0.00018049493008980686,
      "loss": 0.4419,
      "step": 575
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.45032021403312683,
      "learning_rate": 0.00017856228295190252,
      "loss": 0.9225,
      "step": 600
    },
    {
      "epoch": 2.4606299212598426,
      "grad_norm": 0.19245865941047668,
      "learning_rate": 0.0001765497576206896,
      "loss": 0.3933,
      "step": 625
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.42074641585350037,
      "learning_rate": 0.0001744594003310967,
      "loss": 0.9412,
      "step": 650
    },
    {
      "epoch": 2.65748031496063,
      "grad_norm": 0.5456386208534241,
      "learning_rate": 0.00017229333645368833,
      "loss": 0.4028,
      "step": 675
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4214754104614258,
      "learning_rate": 0.00017005376833369442,
      "loss": 0.9533,
      "step": 700
    },
    {
      "epoch": 2.8543307086614176,
      "grad_norm": 0.1361411213874817,
      "learning_rate": 0.0001677429730517763,
      "loss": 0.3718,
      "step": 725
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.4600743353366852,
      "learning_rate": 0.00016536330010880502,
      "loss": 0.9372,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7924472689628601,
      "eval_runtime": 108.1269,
      "eval_samples_per_second": 4.68,
      "eval_steps_per_second": 4.68,
      "step": 762
    },
    {
      "epoch": 3.0511811023622046,
      "grad_norm": 0.08235616236925125,
      "learning_rate": 0.00016291716903700656,
      "loss": 0.4141,
      "step": 775
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.4424484670162201,
      "learning_rate": 0.0001604070669399027,
      "loss": 0.7862,
      "step": 800
    },
    {
      "epoch": 3.248031496062992,
      "grad_norm": 0.08846678584814072,
      "learning_rate": 0.00015783554596354883,
      "loss": 0.4322,
      "step": 825
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.4313627779483795,
      "learning_rate": 0.00015520522070163964,
      "loss": 0.8284,
      "step": 850
    },
    {
      "epoch": 3.4448818897637796,
      "grad_norm": 0.09498339891433716,
      "learning_rate": 0.00015251876553712128,
      "loss": 0.4322,
      "step": 875
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.4780270755290985,
      "learning_rate": 0.00014977891192301265,
      "loss": 0.8088,
      "step": 900
    },
    {
      "epoch": 3.6417322834645667,
      "grad_norm": 0.09981980174779892,
      "learning_rate": 0.00014698844560520106,
      "loss": 0.4352,
      "step": 925
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.4372212290763855,
      "learning_rate": 0.00014415020379003512,
      "loss": 0.7881,
      "step": 950
    },
    {
      "epoch": 3.838582677165354,
      "grad_norm": 0.11754103749990463,
      "learning_rate": 0.0001412670722595956,
      "loss": 0.4544,
      "step": 975
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.46615633368492126,
      "learning_rate": 0.0001383419824375768,
      "loss": 0.8551,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7957851886749268,
      "eval_runtime": 108.0506,
      "eval_samples_per_second": 4.683,
      "eval_steps_per_second": 4.683,
      "step": 1016
    },
    {
      "epoch": 4.035433070866142,
      "grad_norm": 0.0933055654168129,
      "learning_rate": 0.0001353779084087618,
      "loss": 0.4795,
      "step": 1025
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.44804632663726807,
      "learning_rate": 0.0001323778638951219,
      "loss": 0.6264,
      "step": 1050
    },
    {
      "epoch": 4.232283464566929,
      "grad_norm": 0.11430689692497253,
      "learning_rate": 0.0001293448991916154,
      "loss": 0.501,
      "step": 1075
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.48665982484817505,
      "learning_rate": 0.00012628209806480023,
      "loss": 0.7284,
      "step": 1100
    },
    {
      "epoch": 4.429133858267717,
      "grad_norm": 0.12390920519828796,
      "learning_rate": 0.0001231925746174148,
      "loss": 0.4868,
      "step": 1125
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.48762190341949463,
      "learning_rate": 0.00012007947012211418,
      "loss": 0.6656,
      "step": 1150
    },
    {
      "epoch": 4.625984251968504,
      "grad_norm": 0.13696697354316711,
      "learning_rate": 0.00011694594982758164,
      "loss": 0.4958,
      "step": 1175
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.4934557378292084,
      "learning_rate": 0.00011379519974026224,
      "loss": 0.6749,
      "step": 1200
    },
    {
      "epoch": 4.822834645669292,
      "grad_norm": 0.11637217551469803,
      "learning_rate": 0.00011063042338499112,
      "loss": 0.4764,
      "step": 1225
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.5403733253479004,
      "learning_rate": 0.00010745483854780996,
      "loss": 0.6729,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7828546166419983,
      "eval_runtime": 108.0793,
      "eval_samples_per_second": 4.682,
      "eval_steps_per_second": 4.682,
      "step": 1270
    },
    {
      "epoch": 5.019685039370079,
      "grad_norm": 0.10542482137680054,
      "learning_rate": 0.0001042716740042833,
      "loss": 0.5431,
      "step": 1275
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.5009516477584839,
      "learning_rate": 0.0001010841662366414,
      "loss": 0.5437,
      "step": 1300
    },
    {
      "epoch": 5.216535433070866,
      "grad_norm": 0.15153154730796814,
      "learning_rate": 9.789555614308721e-05,
      "loss": 0.5185,
      "step": 1325
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.5567823052406311,
      "learning_rate": 9.470908574261332e-05,
      "loss": 0.5479,
      "step": 1350
    },
    {
      "epoch": 5.413385826771654,
      "grad_norm": 0.11506272852420807,
      "learning_rate": 9.15279948786798e-05,
      "loss": 0.5374,
      "step": 1375
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.5535933971405029,
      "learning_rate": 8.83555179251033e-05,
      "loss": 0.57,
      "step": 1400
    },
    {
      "epoch": 5.610236220472441,
      "grad_norm": 0.13224691152572632,
      "learning_rate": 8.519488049750807e-05,
      "loss": 0.5484,
      "step": 1425
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.5777331590652466,
      "learning_rate": 8.204929617368147e-05,
      "loss": 0.5541,
      "step": 1450
    },
    {
      "epoch": 5.807086614173229,
      "grad_norm": 0.11462707072496414,
      "learning_rate": 7.892196322616913e-05,
      "loss": 0.5293,
      "step": 1475
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.5560896396636963,
      "learning_rate": 7.581606137043167e-05,
      "loss": 0.5156,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7873623371124268,
      "eval_runtime": 108.1074,
      "eval_samples_per_second": 4.681,
      "eval_steps_per_second": 4.681,
      "step": 1524
    },
    {
      "epoch": 6.003937007874016,
      "grad_norm": 0.15873123705387115,
      "learning_rate": 7.273474853186922e-05,
      "loss": 0.6075,
      "step": 1525
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.5823205709457397,
      "learning_rate": 6.968115763500127e-05,
      "loss": 0.461,
      "step": 1550
    },
    {
      "epoch": 6.200787401574803,
      "grad_norm": 0.1844988316297531,
      "learning_rate": 6.66583934180658e-05,
      "loss": 0.5653,
      "step": 1575
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.6459530591964722,
      "learning_rate": 6.366952927627702e-05,
      "loss": 0.3985,
      "step": 1600
    },
    {
      "epoch": 6.397637795275591,
      "grad_norm": 0.15261369943618774,
      "learning_rate": 6.071760413695131e-05,
      "loss": 0.5949,
      "step": 1625
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.619976282119751,
      "learning_rate": 5.7805619369677785e-05,
      "loss": 0.4397,
      "step": 1650
    },
    {
      "epoch": 6.594488188976378,
      "grad_norm": 0.12748126685619354,
      "learning_rate": 5.4936535734676474e-05,
      "loss": 0.5725,
      "step": 1675
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.6057679653167725,
      "learning_rate": 5.211327037244533e-05,
      "loss": 0.3998,
      "step": 1700
    },
    {
      "epoch": 6.791338582677166,
      "grad_norm": 0.14072203636169434,
      "learning_rate": 4.933869383775809e-05,
      "loss": 0.5798,
      "step": 1725
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.6922526359558105,
      "learning_rate": 4.661562718102807e-05,
      "loss": 0.4444,
      "step": 1750
    },
    {
      "epoch": 6.988188976377953,
      "grad_norm": 0.17527690529823303,
      "learning_rate": 4.3946839080005234e-05,
      "loss": 0.576,
      "step": 1775
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7989044189453125,
      "eval_runtime": 108.1244,
      "eval_samples_per_second": 4.68,
      "eval_steps_per_second": 4.68,
      "step": 1778
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.6827700734138489,
      "learning_rate": 4.133504302472355e-05,
      "loss": 0.3669,
      "step": 1800
    },
    {
      "epoch": 7.18503937007874,
      "grad_norm": 0.68185955286026,
      "learning_rate": 3.878289455856014e-05,
      "loss": 0.5909,
      "step": 1825
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.7329676747322083,
      "learning_rate": 3.629298857821186e-05,
      "loss": 0.3607,
      "step": 1850
    },
    {
      "epoch": 7.381889763779528,
      "grad_norm": 0.7046678066253662,
      "learning_rate": 3.3867856695334464e-05,
      "loss": 0.5935,
      "step": 1875
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.6413925290107727,
      "learning_rate": 3.150996466252648e-05,
      "loss": 0.3723,
      "step": 1900
    },
    {
      "epoch": 7.578740157480315,
      "grad_norm": 0.7363340854644775,
      "learning_rate": 2.9221709866275726e-05,
      "loss": 0.5674,
      "step": 1925
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.762785017490387,
      "learning_rate": 2.7005418889416667e-05,
      "loss": 0.3831,
      "step": 1950
    },
    {
      "epoch": 7.775590551181102,
      "grad_norm": 0.741828203201294,
      "learning_rate": 2.486334514557761e-05,
      "loss": 0.5877,
      "step": 1975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.6867024302482605,
      "learning_rate": 2.2797666588022748e-05,
      "loss": 0.3421,
      "step": 2000
    },
    {
      "epoch": 7.97244094488189,
      "grad_norm": 0.7523146867752075,
      "learning_rate": 2.0810483495218135e-05,
      "loss": 0.6213,
      "step": 2025
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.8082883358001709,
      "eval_runtime": 108.0886,
      "eval_samples_per_second": 4.681,
      "eval_steps_per_second": 4.681,
      "step": 2032
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.6792795658111572,
      "learning_rate": 1.8903816335374046e-05,
      "loss": 0.3193,
      "step": 2050
    },
    {
      "epoch": 8.169291338582678,
      "grad_norm": 0.7170913219451904,
      "learning_rate": 1.7079603712133907e-05,
      "loss": 0.6035,
      "step": 2075
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.8536323308944702,
      "learning_rate": 1.5339700393499355e-05,
      "loss": 0.2774,
      "step": 2100
    },
    {
      "epoch": 8.366141732283465,
      "grad_norm": 0.7364782691001892,
      "learning_rate": 1.3685875425995065e-05,
      "loss": 0.6339,
      "step": 2125
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.5421273112297058,
      "learning_rate": 1.2119810335990788e-05,
      "loss": 0.2754,
      "step": 2150
    },
    {
      "epoch": 8.562992125984252,
      "grad_norm": 0.8348198533058167,
      "learning_rate": 1.0643097420009628e-05,
      "loss": 0.6141,
      "step": 2175
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.713909924030304,
      "learning_rate": 9.257238125760781e-06,
      "loss": 0.2796,
      "step": 2200
    },
    {
      "epoch": 8.759842519685039,
      "grad_norm": 0.6780005097389221,
      "learning_rate": 7.963641525542564e-06,
      "loss": 0.6197,
      "step": 2225
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.7090733051300049,
      "learning_rate": 6.763622883568521e-06,
      "loss": 0.3063,
      "step": 2250
    },
    {
      "epoch": 8.956692913385826,
      "grad_norm": 0.7669627666473389,
      "learning_rate": 5.658402318672418e-06,
      "loss": 0.6238,
      "step": 2275
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.8161782026290894,
      "eval_runtime": 108.0635,
      "eval_samples_per_second": 4.682,
      "eval_steps_per_second": 4.682,
      "step": 2286
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.17503708600997925,
      "learning_rate": 4.649103563752743e-06,
      "loss": 0.2903,
      "step": 2300
    },
    {
      "epoch": 9.153543307086615,
      "grad_norm": 0.9065236449241638,
      "learning_rate": 3.7367528232172597e-06,
      "loss": 0.5962,
      "step": 2325
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.16808611154556274,
      "learning_rate": 2.9222777295899063e-06,
      "loss": 0.2983,
      "step": 2350
    },
    {
      "epoch": 9.350393700787402,
      "grad_norm": 0.6882254481315613,
      "learning_rate": 2.206506400340369e-06,
      "loss": 0.6125,
      "step": 2375
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.15698593854904175,
      "learning_rate": 1.59016659589587e-06,
      "loss": 0.2946,
      "step": 2400
    },
    {
      "epoch": 9.547244094488189,
      "grad_norm": 0.8516087532043457,
      "learning_rate": 1.073884979690709e-06,
      "loss": 0.6108,
      "step": 2425
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.16026446223258972,
      "learning_rate": 6.581864810063732e-07,
      "loss": 0.292,
      "step": 2450
    },
    {
      "epoch": 9.744094488188976,
      "grad_norm": 0.8017967939376831,
      "learning_rate": 3.4349376124969134e-07,
      "loss": 0.6171,
      "step": 2475
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.15626373887062073,
      "learning_rate": 1.3012678421191472e-07,
      "loss": 0.2831,
      "step": 2500
    },
    {
      "epoch": 9.940944881889763,
      "grad_norm": 0.8296317458152771,
      "learning_rate": 1.8302490745503166e-08,
      "loss": 0.5845,
      "step": 2525
    }
  ],
  "logging_steps": 25,
  "max_steps": 2540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0983213585317888e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
