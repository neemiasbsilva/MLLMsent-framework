{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0984251968503937,
      "grad_norm": 0.5104728937149048,
      "learning_rate": 6.493506493506494e-05,
      "loss": 1.1358,
      "step": 25
    },
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 1.1545288562774658,
      "learning_rate": 0.00012987012987012987,
      "loss": 2.0332,
      "step": 50
    },
    {
      "epoch": 0.2952755905511811,
      "grad_norm": 0.4468299448490143,
      "learning_rate": 0.0001948051948051948,
      "loss": 0.7811,
      "step": 75
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.997063159942627,
      "learning_rate": 0.0001999569705841918,
      "loss": 1.0553,
      "step": 100
    },
    {
      "epoch": 0.4921259842519685,
      "grad_norm": 0.45691072940826416,
      "learning_rate": 0.00019981263531593422,
      "loss": 0.5825,
      "step": 125
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.6995363831520081,
      "learning_rate": 0.0001995668155607342,
      "loss": 0.9719,
      "step": 150
    },
    {
      "epoch": 0.6889763779527559,
      "grad_norm": 0.3456531763076782,
      "learning_rate": 0.0001992197612558032,
      "loss": 0.4775,
      "step": 175
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.44177863001823425,
      "learning_rate": 0.00019877182526857086,
      "loss": 0.9406,
      "step": 200
    },
    {
      "epoch": 0.8858267716535433,
      "grad_norm": 0.33309146761894226,
      "learning_rate": 0.0001982234630379073,
      "loss": 0.6037,
      "step": 225
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.7211430668830872,
      "learning_rate": 0.00019757523211105555,
      "loss": 0.9081,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8808798789978027,
      "eval_runtime": 108.3272,
      "eval_samples_per_second": 4.671,
      "eval_steps_per_second": 4.671,
      "step": 254
    },
    {
      "epoch": 1.0826771653543308,
      "grad_norm": 0.3120849132537842,
      "learning_rate": 0.00019682779157674537,
      "loss": 0.5093,
      "step": 275
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.42404425144195557,
      "learning_rate": 0.00019598190139506508,
      "loss": 0.9151,
      "step": 300
    },
    {
      "epoch": 1.279527559055118,
      "grad_norm": 0.4322189390659332,
      "learning_rate": 0.00019503842162477204,
      "loss": 0.4233,
      "step": 325
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.3736219108104706,
      "learning_rate": 0.00019399831154882796,
      "loss": 0.9405,
      "step": 350
    },
    {
      "epoch": 1.4763779527559056,
      "grad_norm": 0.453671395778656,
      "learning_rate": 0.00019286262869904828,
      "loss": 0.4812,
      "step": 375
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.4274296164512634,
      "learning_rate": 0.00019163252778085646,
      "loss": 0.9301,
      "step": 400
    },
    {
      "epoch": 1.673228346456693,
      "grad_norm": 0.38336673378944397,
      "learning_rate": 0.00019030925949923777,
      "loss": 0.5054,
      "step": 425
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.4394504725933075,
      "learning_rate": 0.00018889416928708465,
      "loss": 0.9493,
      "step": 450
    },
    {
      "epoch": 1.8700787401574803,
      "grad_norm": 0.40454423427581787,
      "learning_rate": 0.00018738869593722842,
      "loss": 0.499,
      "step": 475
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.3730993866920471,
      "learning_rate": 0.0001857943701395464,
      "loss": 0.9016,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8424334526062012,
      "eval_runtime": 108.301,
      "eval_samples_per_second": 4.672,
      "eval_steps_per_second": 4.672,
      "step": 508
    },
    {
      "epoch": 2.0669291338582676,
      "grad_norm": 0.3355940282344818,
      "learning_rate": 0.00018411281292463345,
      "loss": 0.3956,
      "step": 525
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.43589791655540466,
      "learning_rate": 0.00018234573401561914,
      "loss": 0.9089,
      "step": 550
    },
    {
      "epoch": 2.263779527559055,
      "grad_norm": 0.4938243329524994,
      "learning_rate": 0.00018049493008980686,
      "loss": 0.4426,
      "step": 575
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.42897069454193115,
      "learning_rate": 0.00017856228295190252,
      "loss": 0.924,
      "step": 600
    },
    {
      "epoch": 2.4606299212598426,
      "grad_norm": 0.1902947723865509,
      "learning_rate": 0.0001765497576206896,
      "loss": 0.394,
      "step": 625
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.41804006695747375,
      "learning_rate": 0.0001744594003310967,
      "loss": 0.9419,
      "step": 650
    },
    {
      "epoch": 2.65748031496063,
      "grad_norm": 0.540286123752594,
      "learning_rate": 0.00017229333645368833,
      "loss": 0.4034,
      "step": 675
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4214406907558441,
      "learning_rate": 0.00017005376833369442,
      "loss": 0.9552,
      "step": 700
    },
    {
      "epoch": 2.8543307086614176,
      "grad_norm": 0.13461372256278992,
      "learning_rate": 0.0001677429730517763,
      "loss": 0.3728,
      "step": 725
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.45349761843681335,
      "learning_rate": 0.00016536330010880502,
      "loss": 0.9377,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7822895646095276,
      "eval_runtime": 108.3465,
      "eval_samples_per_second": 4.67,
      "eval_steps_per_second": 4.67,
      "step": 762
    },
    {
      "epoch": 3.0511811023622046,
      "grad_norm": 0.08479920029640198,
      "learning_rate": 0.00016291716903700656,
      "loss": 0.4155,
      "step": 775
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.4512213468551636,
      "learning_rate": 0.0001604070669399027,
      "loss": 0.7874,
      "step": 800
    },
    {
      "epoch": 3.248031496062992,
      "grad_norm": 0.08286594599485397,
      "learning_rate": 0.00015783554596354883,
      "loss": 0.4326,
      "step": 825
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.4354827404022217,
      "learning_rate": 0.00015520522070163964,
      "loss": 0.8298,
      "step": 850
    },
    {
      "epoch": 3.4448818897637796,
      "grad_norm": 0.09625163674354553,
      "learning_rate": 0.00015251876553712128,
      "loss": 0.4318,
      "step": 875
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.47034040093421936,
      "learning_rate": 0.00014977891192301265,
      "loss": 0.8105,
      "step": 900
    },
    {
      "epoch": 3.6417322834645667,
      "grad_norm": 0.09992200136184692,
      "learning_rate": 0.00014698844560520106,
      "loss": 0.4365,
      "step": 925
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.432168185710907,
      "learning_rate": 0.00014415020379003512,
      "loss": 0.7907,
      "step": 950
    },
    {
      "epoch": 3.838582677165354,
      "grad_norm": 0.11955233663320541,
      "learning_rate": 0.0001412670722595956,
      "loss": 0.4552,
      "step": 975
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.46337735652923584,
      "learning_rate": 0.0001383419824375768,
      "loss": 0.8573,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7830890417098999,
      "eval_runtime": 108.3731,
      "eval_samples_per_second": 4.669,
      "eval_steps_per_second": 4.669,
      "step": 1016
    },
    {
      "epoch": 4.035433070866142,
      "grad_norm": 0.09139243513345718,
      "learning_rate": 0.0001353779084087618,
      "loss": 0.4808,
      "step": 1025
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.453967422246933,
      "learning_rate": 0.0001323778638951219,
      "loss": 0.628,
      "step": 1050
    },
    {
      "epoch": 4.232283464566929,
      "grad_norm": 0.11067376285791397,
      "learning_rate": 0.0001293448991916154,
      "loss": 0.5013,
      "step": 1075
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.49128609895706177,
      "learning_rate": 0.00012628209806480023,
      "loss": 0.7299,
      "step": 1100
    },
    {
      "epoch": 4.429133858267717,
      "grad_norm": 0.12532974779605865,
      "learning_rate": 0.0001231925746174148,
      "loss": 0.4874,
      "step": 1125
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.4804609417915344,
      "learning_rate": 0.00012007947012211418,
      "loss": 0.6668,
      "step": 1150
    },
    {
      "epoch": 4.625984251968504,
      "grad_norm": 0.14188794791698456,
      "learning_rate": 0.00011694594982758164,
      "loss": 0.4954,
      "step": 1175
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.483569473028183,
      "learning_rate": 0.00011379519974026224,
      "loss": 0.677,
      "step": 1200
    },
    {
      "epoch": 4.822834645669292,
      "grad_norm": 0.12236347794532776,
      "learning_rate": 0.00011063042338499112,
      "loss": 0.4792,
      "step": 1225
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.5369853377342224,
      "learning_rate": 0.00010745483854780996,
      "loss": 0.6748,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.773590087890625,
      "eval_runtime": 108.4092,
      "eval_samples_per_second": 4.668,
      "eval_steps_per_second": 4.668,
      "step": 1270
    },
    {
      "epoch": 5.019685039370079,
      "grad_norm": 0.10640714317560196,
      "learning_rate": 0.0001042716740042833,
      "loss": 0.5454,
      "step": 1275
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.4992091953754425,
      "learning_rate": 0.0001010841662366414,
      "loss": 0.5461,
      "step": 1300
    },
    {
      "epoch": 5.216535433070866,
      "grad_norm": 0.15625864267349243,
      "learning_rate": 9.789555614308721e-05,
      "loss": 0.52,
      "step": 1325
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.5432206392288208,
      "learning_rate": 9.470908574261332e-05,
      "loss": 0.5492,
      "step": 1350
    },
    {
      "epoch": 5.413385826771654,
      "grad_norm": 0.11472957581281662,
      "learning_rate": 9.15279948786798e-05,
      "loss": 0.5388,
      "step": 1375
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.5379071235656738,
      "learning_rate": 8.83555179251033e-05,
      "loss": 0.5748,
      "step": 1400
    },
    {
      "epoch": 5.610236220472441,
      "grad_norm": 0.13382583856582642,
      "learning_rate": 8.519488049750807e-05,
      "loss": 0.5493,
      "step": 1425
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.5702075362205505,
      "learning_rate": 8.204929617368147e-05,
      "loss": 0.5547,
      "step": 1450
    },
    {
      "epoch": 5.807086614173229,
      "grad_norm": 0.11600256711244583,
      "learning_rate": 7.892196322616913e-05,
      "loss": 0.5314,
      "step": 1475
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.552387535572052,
      "learning_rate": 7.581606137043167e-05,
      "loss": 0.515,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7781572341918945,
      "eval_runtime": 108.3638,
      "eval_samples_per_second": 4.669,
      "eval_steps_per_second": 4.669,
      "step": 1524
    },
    {
      "epoch": 6.003937007874016,
      "grad_norm": 0.1567659080028534,
      "learning_rate": 7.273474853186922e-05,
      "loss": 0.6101,
      "step": 1525
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.5799638032913208,
      "learning_rate": 6.968115763500127e-05,
      "loss": 0.4644,
      "step": 1550
    },
    {
      "epoch": 6.200787401574803,
      "grad_norm": 0.19012781977653503,
      "learning_rate": 6.66583934180658e-05,
      "loss": 0.5656,
      "step": 1575
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.6469338536262512,
      "learning_rate": 6.366952927627702e-05,
      "loss": 0.4004,
      "step": 1600
    },
    {
      "epoch": 6.397637795275591,
      "grad_norm": 0.14275342226028442,
      "learning_rate": 6.071760413695131e-05,
      "loss": 0.598,
      "step": 1625
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.626936137676239,
      "learning_rate": 5.7805619369677785e-05,
      "loss": 0.4406,
      "step": 1650
    },
    {
      "epoch": 6.594488188976378,
      "grad_norm": 0.12703174352645874,
      "learning_rate": 5.4936535734676474e-05,
      "loss": 0.5742,
      "step": 1675
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.6019919514656067,
      "learning_rate": 5.211327037244533e-05,
      "loss": 0.4023,
      "step": 1700
    },
    {
      "epoch": 6.791338582677166,
      "grad_norm": 0.13958145678043365,
      "learning_rate": 4.933869383775809e-05,
      "loss": 0.5846,
      "step": 1725
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.6811486482620239,
      "learning_rate": 4.661562718102807e-05,
      "loss": 0.4447,
      "step": 1750
    },
    {
      "epoch": 6.988188976377953,
      "grad_norm": 0.17691242694854736,
      "learning_rate": 4.3946839080005234e-05,
      "loss": 0.578,
      "step": 1775
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7901450991630554,
      "eval_runtime": 108.3574,
      "eval_samples_per_second": 4.67,
      "eval_steps_per_second": 4.67,
      "step": 1778
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.6559110879898071,
      "learning_rate": 4.133504302472355e-05,
      "loss": 0.3684,
      "step": 1800
    },
    {
      "epoch": 7.18503937007874,
      "grad_norm": 0.6584489345550537,
      "learning_rate": 3.878289455856014e-05,
      "loss": 0.5948,
      "step": 1825
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.6808236241340637,
      "learning_rate": 3.629298857821186e-05,
      "loss": 0.3625,
      "step": 1850
    },
    {
      "epoch": 7.381889763779528,
      "grad_norm": 0.7059219479560852,
      "learning_rate": 3.3867856695334464e-05,
      "loss": 0.595,
      "step": 1875
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.6350545883178711,
      "learning_rate": 3.150996466252648e-05,
      "loss": 0.3732,
      "step": 1900
    },
    {
      "epoch": 7.578740157480315,
      "grad_norm": 0.7229053974151611,
      "learning_rate": 2.9221709866275726e-05,
      "loss": 0.5691,
      "step": 1925
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.7658319473266602,
      "learning_rate": 2.7005418889416667e-05,
      "loss": 0.3866,
      "step": 1950
    },
    {
      "epoch": 7.775590551181102,
      "grad_norm": 0.7269761562347412,
      "learning_rate": 2.486334514557761e-05,
      "loss": 0.5925,
      "step": 1975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.6624476313591003,
      "learning_rate": 2.2797666588022748e-05,
      "loss": 0.3446,
      "step": 2000
    },
    {
      "epoch": 7.97244094488189,
      "grad_norm": 0.7489964365959167,
      "learning_rate": 2.0810483495218135e-05,
      "loss": 0.6274,
      "step": 2025
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7959200739860535,
      "eval_runtime": 108.3746,
      "eval_samples_per_second": 4.669,
      "eval_steps_per_second": 4.669,
      "step": 2032
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.6856494545936584,
      "learning_rate": 1.8903816335374046e-05,
      "loss": 0.3218,
      "step": 2050
    },
    {
      "epoch": 8.169291338582678,
      "grad_norm": 0.6947007775306702,
      "learning_rate": 1.7079603712133907e-05,
      "loss": 0.6091,
      "step": 2075
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.6892158389091492,
      "learning_rate": 1.5339700393499355e-05,
      "loss": 0.2791,
      "step": 2100
    },
    {
      "epoch": 8.366141732283465,
      "grad_norm": 0.7203675508499146,
      "learning_rate": 1.3685875425995065e-05,
      "loss": 0.64,
      "step": 2125
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.5454822182655334,
      "learning_rate": 1.2119810335990788e-05,
      "loss": 0.2762,
      "step": 2150
    },
    {
      "epoch": 8.562992125984252,
      "grad_norm": 0.8102627992630005,
      "learning_rate": 1.0643097420009628e-05,
      "loss": 0.6142,
      "step": 2175
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.7139165997505188,
      "learning_rate": 9.257238125760781e-06,
      "loss": 0.2796,
      "step": 2200
    },
    {
      "epoch": 8.759842519685039,
      "grad_norm": 0.6776406168937683,
      "learning_rate": 7.963641525542564e-06,
      "loss": 0.6238,
      "step": 2225
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.7272522449493408,
      "learning_rate": 6.763622883568521e-06,
      "loss": 0.3097,
      "step": 2250
    },
    {
      "epoch": 8.956692913385826,
      "grad_norm": 0.7288442850112915,
      "learning_rate": 5.658402318672418e-06,
      "loss": 0.628,
      "step": 2275
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.8048382997512817,
      "eval_runtime": 108.3394,
      "eval_samples_per_second": 4.671,
      "eval_steps_per_second": 4.671,
      "step": 2286
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.17496173083782196,
      "learning_rate": 4.649103563752743e-06,
      "loss": 0.2925,
      "step": 2300
    },
    {
      "epoch": 9.153543307086615,
      "grad_norm": 0.8192225694656372,
      "learning_rate": 3.7367528232172597e-06,
      "loss": 0.5999,
      "step": 2325
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.182682603597641,
      "learning_rate": 2.9222777295899063e-06,
      "loss": 0.2985,
      "step": 2350
    },
    {
      "epoch": 9.350393700787402,
      "grad_norm": 0.7265684604644775,
      "learning_rate": 2.206506400340369e-06,
      "loss": 0.6181,
      "step": 2375
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.15935441851615906,
      "learning_rate": 1.59016659589587e-06,
      "loss": 0.2966,
      "step": 2400
    },
    {
      "epoch": 9.547244094488189,
      "grad_norm": 0.8121016621589661,
      "learning_rate": 1.073884979690709e-06,
      "loss": 0.6131,
      "step": 2425
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.16415008902549744,
      "learning_rate": 6.581864810063732e-07,
      "loss": 0.2953,
      "step": 2450
    },
    {
      "epoch": 9.744094488188976,
      "grad_norm": 0.8033307194709778,
      "learning_rate": 3.4349376124969134e-07,
      "loss": 0.621,
      "step": 2475
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.14865709841251373,
      "learning_rate": 1.3012678421191472e-07,
      "loss": 0.2833,
      "step": 2500
    },
    {
      "epoch": 9.940944881889763,
      "grad_norm": 0.8158634305000305,
      "learning_rate": 1.8302490745503166e-08,
      "loss": 0.5914,
      "step": 2525
    }
  ],
  "logging_steps": 25,
  "max_steps": 2540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1045016116953088e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
