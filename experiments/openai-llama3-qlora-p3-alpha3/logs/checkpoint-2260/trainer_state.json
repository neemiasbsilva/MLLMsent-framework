{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2260,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11061946902654868,
      "grad_norm": 0.318066269159317,
      "learning_rate": 7.352941176470589e-05,
      "loss": 2.3605,
      "step": 25
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 0.6228177547454834,
      "learning_rate": 0.00014705882352941178,
      "loss": 1.9274,
      "step": 50
    },
    {
      "epoch": 0.33185840707964603,
      "grad_norm": 0.2793773412704468,
      "learning_rate": 0.00019999496753124154,
      "loss": 1.5555,
      "step": 75
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 0.45336538553237915,
      "learning_rate": 0.00019989484922416502,
      "loss": 1.3882,
      "step": 100
    },
    {
      "epoch": 0.5530973451327433,
      "grad_norm": 0.31211167573928833,
      "learning_rate": 0.0001996664992477767,
      "loss": 1.449,
      "step": 125
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 0.38191714882850647,
      "learning_rate": 0.00019931021072728657,
      "loss": 1.3056,
      "step": 150
    },
    {
      "epoch": 0.7743362831858407,
      "grad_norm": 0.27566003799438477,
      "learning_rate": 0.000198826441018325,
      "loss": 1.4166,
      "step": 175
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 0.36528247594833374,
      "learning_rate": 0.00019821581111985071,
      "loss": 1.3091,
      "step": 200
    },
    {
      "epoch": 0.995575221238938,
      "grad_norm": 0.38947731256484985,
      "learning_rate": 0.000197479104876995,
      "loss": 1.3634,
      "step": 225
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.353309154510498,
      "eval_runtime": 196.3776,
      "eval_samples_per_second": 4.588,
      "eval_steps_per_second": 4.588,
      "step": 226
    },
    {
      "epoch": 1.1061946902654867,
      "grad_norm": 0.2538503110408783,
      "learning_rate": 0.00019661726797486626,
      "loss": 1.3644,
      "step": 250
    },
    {
      "epoch": 1.2168141592920354,
      "grad_norm": 0.33914071321487427,
      "learning_rate": 0.00019563140672460559,
      "loss": 1.2695,
      "step": 275
    },
    {
      "epoch": 1.3274336283185841,
      "grad_norm": 0.2614161968231201,
      "learning_rate": 0.00019452278664325228,
      "loss": 1.3664,
      "step": 300
    },
    {
      "epoch": 1.4380530973451329,
      "grad_norm": 0.35017409920692444,
      "learning_rate": 0.00019329283082924198,
      "loss": 1.2881,
      "step": 325
    },
    {
      "epoch": 1.5486725663716814,
      "grad_norm": 0.27804747223854065,
      "learning_rate": 0.00019194311813562308,
      "loss": 1.3569,
      "step": 350
    },
    {
      "epoch": 1.6592920353982301,
      "grad_norm": 0.31729185581207275,
      "learning_rate": 0.00019047538114333584,
      "loss": 1.259,
      "step": 375
    },
    {
      "epoch": 1.7699115044247788,
      "grad_norm": 0.2476816624403,
      "learning_rate": 0.00018889150393715628,
      "loss": 1.355,
      "step": 400
    },
    {
      "epoch": 1.8805309734513274,
      "grad_norm": 0.3273264467716217,
      "learning_rate": 0.00018719351968715984,
      "loss": 1.2585,
      "step": 425
    },
    {
      "epoch": 1.991150442477876,
      "grad_norm": 0.3330605924129486,
      "learning_rate": 0.0001853836080388091,
      "loss": 1.298,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3177517652511597,
      "eval_runtime": 196.306,
      "eval_samples_per_second": 4.59,
      "eval_steps_per_second": 4.59,
      "step": 452
    },
    {
      "epoch": 2.101769911504425,
      "grad_norm": 0.2934458553791046,
      "learning_rate": 0.00018346409231501584,
      "loss": 1.3154,
      "step": 475
    },
    {
      "epoch": 2.2123893805309733,
      "grad_norm": 0.3532141149044037,
      "learning_rate": 0.00018143743653376942,
      "loss": 1.2371,
      "step": 500
    },
    {
      "epoch": 2.3230088495575223,
      "grad_norm": 0.2896069288253784,
      "learning_rate": 0.00017930624224515946,
      "loss": 1.3152,
      "step": 525
    },
    {
      "epoch": 2.433628318584071,
      "grad_norm": 0.3647473156452179,
      "learning_rate": 0.00017707324519185318,
      "loss": 1.235,
      "step": 550
    },
    {
      "epoch": 2.5442477876106193,
      "grad_norm": 0.28158247470855713,
      "learning_rate": 0.00017474131179731416,
      "loss": 1.3194,
      "step": 575
    },
    {
      "epoch": 2.6548672566371683,
      "grad_norm": 0.3156929910182953,
      "learning_rate": 0.00017231343548627083,
      "loss": 1.2211,
      "step": 600
    },
    {
      "epoch": 2.765486725663717,
      "grad_norm": 0.30018508434295654,
      "learning_rate": 0.00016979273284215734,
      "loss": 1.3173,
      "step": 625
    },
    {
      "epoch": 2.8761061946902657,
      "grad_norm": 0.31537187099456787,
      "learning_rate": 0.00016718243960645986,
      "loss": 1.2346,
      "step": 650
    },
    {
      "epoch": 2.9867256637168142,
      "grad_norm": 0.3113691508769989,
      "learning_rate": 0.00016448590652510384,
      "loss": 1.2553,
      "step": 675
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.306990385055542,
      "eval_runtime": 196.4247,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 678
    },
    {
      "epoch": 3.0973451327433628,
      "grad_norm": 0.3026978373527527,
      "learning_rate": 0.00016170659504721364,
      "loss": 1.2715,
      "step": 700
    },
    {
      "epoch": 3.2079646017699117,
      "grad_norm": 0.3411189615726471,
      "learning_rate": 0.00015884807288176639,
      "loss": 1.2003,
      "step": 725
    },
    {
      "epoch": 3.3185840707964602,
      "grad_norm": 0.3342800736427307,
      "learning_rate": 0.00015591400941784356,
      "loss": 1.2854,
      "step": 750
    },
    {
      "epoch": 3.4292035398230087,
      "grad_norm": 0.3293253779411316,
      "learning_rate": 0.0001529081710143593,
      "loss": 1.2074,
      "step": 775
    },
    {
      "epoch": 3.5398230088495577,
      "grad_norm": 0.3238617777824402,
      "learning_rate": 0.0001498344161653115,
      "loss": 1.2849,
      "step": 800
    },
    {
      "epoch": 3.650442477876106,
      "grad_norm": 0.3227859139442444,
      "learning_rate": 0.0001466966905467627,
      "loss": 1.1848,
      "step": 825
    },
    {
      "epoch": 3.7610619469026547,
      "grad_norm": 0.30508577823638916,
      "learning_rate": 0.00014349902195190777,
      "loss": 1.2672,
      "step": 850
    },
    {
      "epoch": 3.8716814159292037,
      "grad_norm": 0.3391004502773285,
      "learning_rate": 0.00014024551512073087,
      "loss": 1.1985,
      "step": 875
    },
    {
      "epoch": 3.982300884955752,
      "grad_norm": 0.35796311497688293,
      "learning_rate": 0.0001369403464708884,
      "loss": 1.2366,
      "step": 900
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.2962113618850708,
      "eval_runtime": 196.4334,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 904
    },
    {
      "epoch": 4.092920353982301,
      "grad_norm": 0.3175998032093048,
      "learning_rate": 0.00013358775873658152,
      "loss": 1.2359,
      "step": 925
    },
    {
      "epoch": 4.20353982300885,
      "grad_norm": 0.3385179936885834,
      "learning_rate": 0.00013019205552230057,
      "loss": 1.17,
      "step": 950
    },
    {
      "epoch": 4.314159292035399,
      "grad_norm": 0.3571745455265045,
      "learning_rate": 0.0001267575957784323,
      "loss": 1.2379,
      "step": 975
    },
    {
      "epoch": 4.424778761061947,
      "grad_norm": 0.34736689925193787,
      "learning_rate": 0.0001232887882058212,
      "loss": 1.1638,
      "step": 1000
    },
    {
      "epoch": 4.535398230088496,
      "grad_norm": 0.32236915826797485,
      "learning_rate": 0.00011979008559646824,
      "loss": 1.2465,
      "step": 1025
    },
    {
      "epoch": 4.646017699115045,
      "grad_norm": 0.33008888363838196,
      "learning_rate": 0.00011626597911763084,
      "loss": 1.1761,
      "step": 1050
    },
    {
      "epoch": 4.756637168141593,
      "grad_norm": 0.3190056085586548,
      "learning_rate": 0.0001127209925466621,
      "loss": 1.2469,
      "step": 1075
    },
    {
      "epoch": 4.867256637168142,
      "grad_norm": 0.33955860137939453,
      "learning_rate": 0.0001091596764639895,
      "loss": 1.1779,
      "step": 1100
    },
    {
      "epoch": 4.977876106194691,
      "grad_norm": 0.37946969270706177,
      "learning_rate": 0.0001055866024116873,
      "loss": 1.205,
      "step": 1125
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.2882319688796997,
      "eval_runtime": 196.4107,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 1130
    },
    {
      "epoch": 5.088495575221239,
      "grad_norm": 0.31798243522644043,
      "learning_rate": 0.00010200635702514114,
      "loss": 1.2189,
      "step": 1150
    },
    {
      "epoch": 5.199115044247788,
      "grad_norm": 0.3603823482990265,
      "learning_rate": 9.842353614533818e-05,
      "loss": 1.1587,
      "step": 1175
    },
    {
      "epoch": 5.3097345132743365,
      "grad_norm": 0.32253143191337585,
      "learning_rate": 9.484273891933982e-05,
      "loss": 1.2077,
      "step": 1200
    },
    {
      "epoch": 5.420353982300885,
      "grad_norm": 0.3621882498264313,
      "learning_rate": 9.126856189651092e-05,
      "loss": 1.1423,
      "step": 1225
    },
    {
      "epoch": 5.530973451327434,
      "grad_norm": 0.35759857296943665,
      "learning_rate": 8.770559312808356e-05,
      "loss": 1.203,
      "step": 1250
    },
    {
      "epoch": 5.6415929203539825,
      "grad_norm": 0.3628653883934021,
      "learning_rate": 8.415840627762919e-05,
      "loss": 1.1413,
      "step": 1275
    },
    {
      "epoch": 5.752212389380531,
      "grad_norm": 0.32605621218681335,
      "learning_rate": 8.063155475000037e-05,
      "loss": 1.2116,
      "step": 1300
    },
    {
      "epoch": 5.8628318584070795,
      "grad_norm": 0.352315217256546,
      "learning_rate": 7.712956584627726e-05,
      "loss": 1.1582,
      "step": 1325
    },
    {
      "epoch": 5.9734513274336285,
      "grad_norm": 0.38695141673088074,
      "learning_rate": 7.365693495222332e-05,
      "loss": 1.1839,
      "step": 1350
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.285001516342163,
      "eval_runtime": 196.3283,
      "eval_samples_per_second": 4.589,
      "eval_steps_per_second": 4.589,
      "step": 1356
    },
    {
      "epoch": 6.084070796460177,
      "grad_norm": 0.3430091142654419,
      "learning_rate": 7.021811976770897e-05,
      "loss": 1.1993,
      "step": 1375
    },
    {
      "epoch": 6.1946902654867255,
      "grad_norm": 0.37591278553009033,
      "learning_rate": 6.681753458451189e-05,
      "loss": 1.129,
      "step": 1400
    },
    {
      "epoch": 6.3053097345132745,
      "grad_norm": 0.3474019467830658,
      "learning_rate": 6.345954461983869e-05,
      "loss": 1.1923,
      "step": 1425
    },
    {
      "epoch": 6.415929203539823,
      "grad_norm": 0.38487672805786133,
      "learning_rate": 6.0148460412841676e-05,
      "loss": 1.1214,
      "step": 1450
    },
    {
      "epoch": 6.5265486725663715,
      "grad_norm": 0.3369550406932831,
      "learning_rate": 5.688853229132457e-05,
      "loss": 1.1813,
      "step": 1475
    },
    {
      "epoch": 6.6371681415929205,
      "grad_norm": 0.3845073878765106,
      "learning_rate": 5.368394491573876e-05,
      "loss": 1.1431,
      "step": 1500
    },
    {
      "epoch": 6.747787610619469,
      "grad_norm": 0.3623100519180298,
      "learning_rate": 5.053881190747547e-05,
      "loss": 1.1909,
      "step": 1525
    },
    {
      "epoch": 6.8584070796460175,
      "grad_norm": 0.38112935423851013,
      "learning_rate": 4.7457170568347285e-05,
      "loss": 1.1357,
      "step": 1550
    },
    {
      "epoch": 6.969026548672566,
      "grad_norm": 0.3854137659072876,
      "learning_rate": 4.444297669803981e-05,
      "loss": 1.1466,
      "step": 1575
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.2832838296890259,
      "eval_runtime": 196.4509,
      "eval_samples_per_second": 4.586,
      "eval_steps_per_second": 4.586,
      "step": 1582
    },
    {
      "epoch": 7.079646017699115,
      "grad_norm": 0.3502488434314728,
      "learning_rate": 4.1500099516183555e-05,
      "loss": 1.1811,
      "step": 1600
    },
    {
      "epoch": 7.1902654867256635,
      "grad_norm": 0.42822057008743286,
      "learning_rate": 3.863231669556687e-05,
      "loss": 1.1213,
      "step": 1625
    },
    {
      "epoch": 7.300884955752212,
      "grad_norm": 0.3604843318462372,
      "learning_rate": 3.5843309512863976e-05,
      "loss": 1.1733,
      "step": 1650
    },
    {
      "epoch": 7.411504424778761,
      "grad_norm": 0.4289816617965698,
      "learning_rate": 3.31366581231031e-05,
      "loss": 1.1238,
      "step": 1675
    },
    {
      "epoch": 7.522123893805309,
      "grad_norm": 0.35903844237327576,
      "learning_rate": 3.0515836963942056e-05,
      "loss": 1.1682,
      "step": 1700
    },
    {
      "epoch": 7.632743362831858,
      "grad_norm": 0.40652453899383545,
      "learning_rate": 2.798421029564865e-05,
      "loss": 1.1115,
      "step": 1725
    },
    {
      "epoch": 7.743362831858407,
      "grad_norm": 0.3585856556892395,
      "learning_rate": 2.554502788251274e-05,
      "loss": 1.1553,
      "step": 1750
    },
    {
      "epoch": 7.853982300884955,
      "grad_norm": 0.42296966910362244,
      "learning_rate": 2.3201420821232733e-05,
      "loss": 1.117,
      "step": 1775
    },
    {
      "epoch": 7.964601769911504,
      "grad_norm": 0.3828233480453491,
      "learning_rate": 2.0956397521631664e-05,
      "loss": 1.139,
      "step": 1800
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2827235460281372,
      "eval_runtime": 196.6101,
      "eval_samples_per_second": 4.583,
      "eval_steps_per_second": 4.583,
      "step": 1808
    },
    {
      "epoch": 8.075221238938052,
      "grad_norm": 0.37157613039016724,
      "learning_rate": 1.881283984486243e-05,
      "loss": 1.1614,
      "step": 1825
    },
    {
      "epoch": 8.185840707964601,
      "grad_norm": 0.41418373584747314,
      "learning_rate": 1.6773499404059156e-05,
      "loss": 1.1151,
      "step": 1850
    },
    {
      "epoch": 8.29646017699115,
      "grad_norm": 0.3861652612686157,
      "learning_rate": 1.4840994032183731e-05,
      "loss": 1.1526,
      "step": 1875
    },
    {
      "epoch": 8.4070796460177,
      "grad_norm": 0.42895007133483887,
      "learning_rate": 1.3017804421601298e-05,
      "loss": 1.1171,
      "step": 1900
    },
    {
      "epoch": 8.517699115044248,
      "grad_norm": 0.39318618178367615,
      "learning_rate": 1.1306270939698694e-05,
      "loss": 1.1548,
      "step": 1925
    },
    {
      "epoch": 8.628318584070797,
      "grad_norm": 0.40982455015182495,
      "learning_rate": 9.70859062463324e-06,
      "loss": 1.1092,
      "step": 1950
    },
    {
      "epoch": 8.738938053097344,
      "grad_norm": 0.38101890683174133,
      "learning_rate": 8.226814365068624e-06,
      "loss": 1.1577,
      "step": 1975
    },
    {
      "epoch": 8.849557522123893,
      "grad_norm": 0.41307201981544495,
      "learning_rate": 6.862844267517643e-06,
      "loss": 1.1122,
      "step": 2000
    },
    {
      "epoch": 8.960176991150442,
      "grad_norm": 0.3791332244873047,
      "learning_rate": 5.618431214672049e-06,
      "loss": 1.1251,
      "step": 2025
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.2850085496902466,
      "eval_runtime": 196.41,
      "eval_samples_per_second": 4.587,
      "eval_steps_per_second": 4.587,
      "step": 2034
    },
    {
      "epoch": 9.070796460176991,
      "grad_norm": 0.37306496500968933,
      "learning_rate": 4.495172617853038e-06,
      "loss": 1.1484,
      "step": 2050
    },
    {
      "epoch": 9.18141592920354,
      "grad_norm": 0.40532517433166504,
      "learning_rate": 3.4945103664678958e-06,
      "loss": 1.1128,
      "step": 2075
    },
    {
      "epoch": 9.29203539823009,
      "grad_norm": 0.3828970193862915,
      "learning_rate": 2.6177289771049274e-06,
      "loss": 1.1392,
      "step": 2100
    },
    {
      "epoch": 9.402654867256636,
      "grad_norm": 0.4066820740699768,
      "learning_rate": 1.8659539446424957e-06,
      "loss": 1.114,
      "step": 2125
    },
    {
      "epoch": 9.513274336283185,
      "grad_norm": 0.3896937072277069,
      "learning_rate": 1.2401502974890732e-06,
      "loss": 1.1455,
      "step": 2150
    },
    {
      "epoch": 9.623893805309734,
      "grad_norm": 0.39126840233802795,
      "learning_rate": 7.411213588085498e-07,
      "loss": 1.1011,
      "step": 2175
    },
    {
      "epoch": 9.734513274336283,
      "grad_norm": 0.37273702025413513,
      "learning_rate": 3.6950771532126006e-07,
      "loss": 1.1504,
      "step": 2200
    },
    {
      "epoch": 9.845132743362832,
      "grad_norm": 0.39401429891586304,
      "learning_rate": 1.2578639500425704e-07,
      "loss": 1.1212,
      "step": 2225
    },
    {
      "epoch": 9.955752212389381,
      "grad_norm": 0.38045957684516907,
      "learning_rate": 1.027025474648058e-08,
      "loss": 1.1135,
      "step": 2250
    }
  ],
  "logging_steps": 25,
  "max_steps": 2260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.4221027149021184e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
