{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1260,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 0.36245185136795044,
      "learning_rate": 0.00013157894736842108,
      "loss": 2.2259,
      "step": 25
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 0.30708396434783936,
      "learning_rate": 0.0001999524166093866,
      "loss": 1.6431,
      "step": 50
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.36858677864074707,
      "learning_rate": 0.00019954793248829695,
      "loss": 1.3925,
      "step": 75
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3292680978775024,
      "eval_runtime": 46.3247,
      "eval_samples_per_second": 7.232,
      "eval_steps_per_second": 7.232,
      "step": 84
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.26211556792259216,
      "learning_rate": 0.00019873237428991907,
      "loss": 1.3025,
      "step": 100
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 0.29384511709213257,
      "learning_rate": 0.000197509109787199,
      "loss": 1.2851,
      "step": 125
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.3345614969730377,
      "learning_rate": 0.00019588319033895623,
      "loss": 1.2803,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.274790644645691,
      "eval_runtime": 46.3142,
      "eval_samples_per_second": 7.233,
      "eval_steps_per_second": 7.233,
      "step": 168
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.2646004259586334,
      "learning_rate": 0.00019386133003075967,
      "loss": 1.269,
      "step": 175
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.33994489908218384,
      "learning_rate": 0.00019145187794972565,
      "loss": 1.246,
      "step": 200
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.3244553804397583,
      "learning_rate": 0.0001886647837077268,
      "loss": 1.226,
      "step": 225
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 0.32114169001579285,
      "learning_rate": 0.0001855115563553803,
      "loss": 1.2172,
      "step": 250
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.2594983577728271,
      "eval_runtime": 46.3171,
      "eval_samples_per_second": 7.233,
      "eval_steps_per_second": 7.233,
      "step": 252
    },
    {
      "epoch": 3.2738095238095237,
      "grad_norm": 0.43919458985328674,
      "learning_rate": 0.00018200521685647663,
      "loss": 1.1908,
      "step": 275
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.31507444381713867,
      "learning_rate": 0.00017816024431910115,
      "loss": 1.2061,
      "step": 300
    },
    {
      "epoch": 3.869047619047619,
      "grad_norm": 0.33338552713394165,
      "learning_rate": 0.0001739925162054823,
      "loss": 1.2038,
      "step": 325
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.2521214485168457,
      "eval_runtime": 46.31,
      "eval_samples_per_second": 7.234,
      "eval_steps_per_second": 7.234,
      "step": 336
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.34452342987060547,
      "learning_rate": 0.00016951924276746425,
      "loss": 1.1794,
      "step": 350
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.3661733865737915,
      "learning_rate": 0.00016475889597834695,
      "loss": 1.1623,
      "step": 375
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.39158743619918823,
      "learning_rate": 0.0001597311332545629,
      "loss": 1.1528,
      "step": 400
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.2471429109573364,
      "eval_runtime": 46.3111,
      "eval_samples_per_second": 7.234,
      "eval_steps_per_second": 7.234,
      "step": 420
    },
    {
      "epoch": 5.059523809523809,
      "grad_norm": 0.35616934299468994,
      "learning_rate": 0.00015445671628217466,
      "loss": 1.1865,
      "step": 425
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.3316464424133301,
      "learning_rate": 0.0001489574252833924,
      "loss": 1.1414,
      "step": 450
    },
    {
      "epoch": 5.654761904761905,
      "grad_norm": 0.42807963490486145,
      "learning_rate": 0.00014325596907713937,
      "loss": 1.1263,
      "step": 475
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.43732813000679016,
      "learning_rate": 0.00013737589130506246,
      "loss": 1.1368,
      "step": 500
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.2492716312408447,
      "eval_runtime": 46.3009,
      "eval_samples_per_second": 7.235,
      "eval_steps_per_second": 7.235,
      "step": 504
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.5084638595581055,
      "learning_rate": 0.00013134147321021829,
      "loss": 1.0875,
      "step": 525
    },
    {
      "epoch": 6.5476190476190474,
      "grad_norm": 0.42190852761268616,
      "learning_rate": 0.0001251776333699023,
      "loss": 1.128,
      "step": 550
    },
    {
      "epoch": 6.845238095238095,
      "grad_norm": 0.4115951359272003,
      "learning_rate": 0.00011890982479666412,
      "loss": 1.1146,
      "step": 575
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.2593507766723633,
      "eval_runtime": 46.3157,
      "eval_samples_per_second": 7.233,
      "eval_steps_per_second": 7.233,
      "step": 588
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.4400750994682312,
      "learning_rate": 0.00011256392983242143,
      "loss": 1.1025,
      "step": 600
    },
    {
      "epoch": 7.440476190476191,
      "grad_norm": 0.48530226945877075,
      "learning_rate": 0.00010616615326969767,
      "loss": 1.073,
      "step": 625
    },
    {
      "epoch": 7.738095238095238,
      "grad_norm": 0.5057825446128845,
      "learning_rate": 9.97429141413294e-05,
      "loss": 1.075,
      "step": 650
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2701536417007446,
      "eval_runtime": 46.3183,
      "eval_samples_per_second": 7.233,
      "eval_steps_per_second": 7.233,
      "step": 672
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.5036051273345947,
      "learning_rate": 9.332073662548784e-05,
      "loss": 1.0965,
      "step": 675
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.4521257281303406,
      "learning_rate": 8.692614051651242e-05,
      "loss": 1.0684,
      "step": 700
    },
    {
      "epoch": 8.630952380952381,
      "grad_norm": 0.4450386166572571,
      "learning_rate": 8.058553171384699e-05,
      "loss": 1.0673,
      "step": 725
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.5011941194534302,
      "learning_rate": 7.43250931812945e-05,
      "loss": 1.0543,
      "step": 750
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.2693042755126953,
      "eval_runtime": 46.3418,
      "eval_samples_per_second": 7.229,
      "eval_steps_per_second": 7.229,
      "step": 756
    },
    {
      "epoch": 9.226190476190476,
      "grad_norm": 0.5639282464981079,
      "learning_rate": 6.817067682686413e-05,
      "loss": 1.0236,
      "step": 775
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.5114668607711792,
      "learning_rate": 6.214769674968282e-05,
      "loss": 1.0341,
      "step": 800
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.48981404304504395,
      "learning_rate": 5.6281024294798864e-05,
      "loss": 1.0695,
      "step": 825
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.2742078304290771,
      "eval_runtime": 46.3331,
      "eval_samples_per_second": 7.23,
      "eval_steps_per_second": 7.23,
      "step": 840
    },
    {
      "epoch": 10.119047619047619,
      "grad_norm": 0.4961344599723816,
      "learning_rate": 5.059488534923831e-05,
      "loss": 1.0328,
      "step": 850
    },
    {
      "epoch": 10.416666666666666,
      "grad_norm": 0.496669203042984,
      "learning_rate": 4.51127603034217e-05,
      "loss": 1.0368,
      "step": 875
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.5411086082458496,
      "learning_rate": 3.985728709104041e-05,
      "loss": 1.0074,
      "step": 900
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.280956506729126,
      "eval_runtime": 46.3071,
      "eval_samples_per_second": 7.234,
      "eval_steps_per_second": 7.234,
      "step": 924
    },
    {
      "epoch": 11.011904761904763,
      "grad_norm": 0.4538774788379669,
      "learning_rate": 3.4850167707781256e-05,
      "loss": 1.0048,
      "step": 925
    },
    {
      "epoch": 11.30952380952381,
      "grad_norm": 0.4975718855857849,
      "learning_rate": 3.011207859492131e-05,
      "loss": 1.015,
      "step": 950
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.5106530785560608,
      "learning_rate": 2.5662585257855775e-05,
      "loss": 1.0233,
      "step": 975
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 0.5237392783164978,
      "learning_rate": 2.1520061472133902e-05,
      "loss": 0.997,
      "step": 1000
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.2814182043075562,
      "eval_runtime": 46.2928,
      "eval_samples_per_second": 7.237,
      "eval_steps_per_second": 7.237,
      "step": 1008
    },
    {
      "epoch": 12.202380952380953,
      "grad_norm": 0.515595018863678,
      "learning_rate": 1.7701613410634365e-05,
      "loss": 1.0061,
      "step": 1025
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.6884119510650635,
      "learning_rate": 1.4223009005189792e-05,
      "loss": 0.9812,
      "step": 1050
    },
    {
      "epoch": 12.797619047619047,
      "grad_norm": 0.502716064453125,
      "learning_rate": 1.1098612834355204e-05,
      "loss": 1.0186,
      "step": 1075
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.288570523262024,
      "eval_runtime": 46.3447,
      "eval_samples_per_second": 7.228,
      "eval_steps_per_second": 7.228,
      "step": 1092
    },
    {
      "epoch": 13.095238095238095,
      "grad_norm": 0.5598351955413818,
      "learning_rate": 8.34132680619546e-06,
      "loss": 0.9989,
      "step": 1100
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.5327116250991821,
      "learning_rate": 5.962536881036507e-06,
      "loss": 0.9909,
      "step": 1125
    },
    {
      "epoch": 13.69047619047619,
      "grad_norm": 0.5644116997718811,
      "learning_rate": 3.97206605418432e-06,
      "loss": 0.9855,
      "step": 1150
    },
    {
      "epoch": 13.988095238095237,
      "grad_norm": 0.5937101244926453,
      "learning_rate": 2.3781337927645585e-06,
      "loss": 0.9764,
      "step": 1175
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.289577603340149,
      "eval_runtime": 46.3165,
      "eval_samples_per_second": 7.233,
      "eval_steps_per_second": 7.233,
      "step": 1176
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.5260974764823914,
      "learning_rate": 1.1873220941853502e-06,
      "loss": 1.0062,
      "step": 1200
    },
    {
      "epoch": 14.583333333333334,
      "grad_norm": 0.5175996422767639,
      "learning_rate": 4.045483063813471e-07,
      "loss": 0.9929,
      "step": 1225
    },
    {
      "epoch": 14.880952380952381,
      "grad_norm": 0.5335696339607239,
      "learning_rate": 3.304482207533433e-08,
      "loss": 0.9901,
      "step": 1250
    }
  ],
  "logging_steps": 25,
  "max_steps": 1260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9695393182318592e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
