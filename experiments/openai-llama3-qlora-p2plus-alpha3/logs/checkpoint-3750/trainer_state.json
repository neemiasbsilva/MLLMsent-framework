{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 0.37169602513313293,
      "learning_rate": 4.4247787610619477e-05,
      "loss": 2.4213,
      "step": 25
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5408018827438354,
      "learning_rate": 8.849557522123895e-05,
      "loss": 2.144,
      "step": 50
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.38016045093536377,
      "learning_rate": 0.00013274336283185842,
      "loss": 1.7002,
      "step": 75
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.563262403011322,
      "learning_rate": 0.0001769911504424779,
      "loss": 1.4664,
      "step": 100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.32245659828186035,
      "learning_rate": 0.00019999462792890912,
      "loss": 1.4975,
      "step": 125
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.39641842246055603,
      "learning_rate": 0.00019994893190848555,
      "loss": 1.3938,
      "step": 150
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.292277991771698,
      "learning_rate": 0.00019985662853479525,
      "loss": 1.4605,
      "step": 175
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.476727694272995,
      "learning_rate": 0.00019971776084997842,
      "loss": 1.3604,
      "step": 200
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.30319374799728394,
      "learning_rate": 0.00019953239360965695,
      "loss": 1.4443,
      "step": 225
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4451679587364197,
      "learning_rate": 0.0001993006132527381,
      "loss": 1.3505,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4128780364990234,
      "eval_runtime": 218.195,
      "eval_samples_per_second": 4.583,
      "eval_steps_per_second": 4.583,
      "step": 250
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2890048325061798,
      "learning_rate": 0.000199022527861107,
      "loss": 1.3977,
      "step": 275
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3838208317756653,
      "learning_rate": 0.00019869826710922675,
      "loss": 1.2999,
      "step": 300
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.28351789712905884,
      "learning_rate": 0.00019832798220366978,
      "loss": 1.4107,
      "step": 325
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.4215654134750366,
      "learning_rate": 0.00019791184581260848,
      "loss": 1.3063,
      "step": 350
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.29372450709342957,
      "learning_rate": 0.00019745005198529799,
      "loss": 1.405,
      "step": 375
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.3679662048816681,
      "learning_rate": 0.00019694281606158864,
      "loss": 1.3033,
      "step": 400
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.29128894209861755,
      "learning_rate": 0.00019639037457151073,
      "loss": 1.4065,
      "step": 425
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.3903876841068268,
      "learning_rate": 0.00019579298512497758,
      "loss": 1.3089,
      "step": 450
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.28185591101646423,
      "learning_rate": 0.0001951509262916591,
      "loss": 1.3923,
      "step": 475
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.36518558859825134,
      "learning_rate": 0.0001944644974710816,
      "loss": 1.3003,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3830292224884033,
      "eval_runtime": 218.2507,
      "eval_samples_per_second": 4.582,
      "eval_steps_per_second": 4.582,
      "step": 500
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.28710678219795227,
      "learning_rate": 0.00019373401875301407,
      "loss": 1.3545,
      "step": 525
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.3495907783508301,
      "learning_rate": 0.00019295983076820687,
      "loss": 1.2586,
      "step": 550
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.30461782217025757,
      "learning_rate": 0.0001921422945295514,
      "loss": 1.359,
      "step": 575
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3760431110858917,
      "learning_rate": 0.00019128179126373567,
      "loss": 1.2505,
      "step": 600
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.29161661863327026,
      "learning_rate": 0.00019037872223347387,
      "loss": 1.3596,
      "step": 625
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3601655960083008,
      "learning_rate": 0.00018943350855039285,
      "loss": 1.2741,
      "step": 650
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2707713544368744,
      "learning_rate": 0.0001884465909786629,
      "loss": 1.3688,
      "step": 675
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.36615556478500366,
      "learning_rate": 0.0001874184297294641,
      "loss": 1.2765,
      "step": 700
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.26405176520347595,
      "learning_rate": 0.0001863495042463848,
      "loss": 1.3637,
      "step": 725
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.38244199752807617,
      "learning_rate": 0.0001852403129818511,
      "loss": 1.2431,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3634158372879028,
      "eval_runtime": 218.1628,
      "eval_samples_per_second": 4.584,
      "eval_steps_per_second": 4.584,
      "step": 750
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.2964743673801422,
      "learning_rate": 0.00018409137316469307,
      "loss": 1.3307,
      "step": 775
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.3887411057949066,
      "learning_rate": 0.00018290322055895453,
      "loss": 1.226,
      "step": 800
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.28492963314056396,
      "learning_rate": 0.00018167640921406023,
      "loss": 1.3279,
      "step": 825
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.3718589246273041,
      "learning_rate": 0.0001804115112064562,
      "loss": 1.2272,
      "step": 850
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.2951211929321289,
      "learning_rate": 0.00017910911637284357,
      "loss": 1.3283,
      "step": 875
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.396684855222702,
      "learning_rate": 0.00017776983203513113,
      "loss": 1.2197,
      "step": 900
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.3035682737827301,
      "learning_rate": 0.00017639428271723384,
      "loss": 1.3226,
      "step": 925
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.3823242485523224,
      "learning_rate": 0.00017498310985385008,
      "loss": 1.2206,
      "step": 950
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.29007619619369507,
      "learning_rate": 0.00017353697149135325,
      "loss": 1.3212,
      "step": 975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.39111393690109253,
      "learning_rate": 0.00017205654198093696,
      "loss": 1.2211,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.346049189567566,
      "eval_runtime": 218.1146,
      "eval_samples_per_second": 4.585,
      "eval_steps_per_second": 4.585,
      "step": 1000
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.30420172214508057,
      "learning_rate": 0.00017054251166415726,
      "loss": 1.2996,
      "step": 1025
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.38689127564430237,
      "learning_rate": 0.0001689955865510183,
      "loss": 1.1819,
      "step": 1050
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.33651700615882874,
      "learning_rate": 0.00016741648799075158,
      "loss": 1.3009,
      "step": 1075
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.3927822411060333,
      "learning_rate": 0.00016580595233544248,
      "loss": 1.1958,
      "step": 1100
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.32613980770111084,
      "learning_rate": 0.00016416473059666065,
      "loss": 1.286,
      "step": 1125
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.4127449691295624,
      "learning_rate": 0.00016249358809525456,
      "loss": 1.1885,
      "step": 1150
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.3162533640861511,
      "learning_rate": 0.00016079330410447335,
      "loss": 1.289,
      "step": 1175
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.39931508898735046,
      "learning_rate": 0.0001590646714865828,
      "loss": 1.1877,
      "step": 1200
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.328238844871521,
      "learning_rate": 0.00015730849632314428,
      "loss": 1.2897,
      "step": 1225
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.4136853516101837,
      "learning_rate": 0.00015552559753912953,
      "loss": 1.1893,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3452234268188477,
      "eval_runtime": 218.0608,
      "eval_samples_per_second": 4.586,
      "eval_steps_per_second": 4.586,
      "step": 1250
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.31322962045669556,
      "learning_rate": 0.00015371680652104643,
      "loss": 1.2592,
      "step": 1275
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.4363742172718048,
      "learning_rate": 0.00015188296672925377,
      "loss": 1.1592,
      "step": 1300
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.349565714597702,
      "learning_rate": 0.0001500249333046458,
      "loss": 1.2683,
      "step": 1325
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.43263882398605347,
      "learning_rate": 0.00014814357266989002,
      "loss": 1.1463,
      "step": 1350
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.33565208315849304,
      "learning_rate": 0.00014623976212540428,
      "loss": 1.265,
      "step": 1375
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.4325352609157562,
      "learning_rate": 0.00014431438944026133,
      "loss": 1.1535,
      "step": 1400
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.34539371728897095,
      "learning_rate": 0.00014236835243821167,
      "loss": 1.2646,
      "step": 1425
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.42404603958129883,
      "learning_rate": 0.00014040255857901798,
      "loss": 1.1579,
      "step": 1450
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.3649204969406128,
      "learning_rate": 0.00013841792453529581,
      "loss": 1.266,
      "step": 1475
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.4079347550868988,
      "learning_rate": 0.0001364153757650588,
      "loss": 1.152,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3404978513717651,
      "eval_runtime": 218.0898,
      "eval_samples_per_second": 4.585,
      "eval_steps_per_second": 4.585,
      "step": 1500
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.3831968605518341,
      "learning_rate": 0.00013439584608016653,
      "loss": 1.2287,
      "step": 1525
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.47410130500793457,
      "learning_rate": 0.00013236027721087723,
      "loss": 1.1117,
      "step": 1550
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.3600936532020569,
      "learning_rate": 0.00013030961836670794,
      "loss": 1.2414,
      "step": 1575
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.44782066345214844,
      "learning_rate": 0.00012824482579380716,
      "loss": 1.122,
      "step": 1600
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.40900272130966187,
      "learning_rate": 0.00012616686232904594,
      "loss": 1.244,
      "step": 1625
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.44914883375167847,
      "learning_rate": 0.000124076696951036,
      "loss": 1.1243,
      "step": 1650
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.37979722023010254,
      "learning_rate": 0.00012197530432828348,
      "loss": 1.2378,
      "step": 1675
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.4235226809978485,
      "learning_rate": 0.00011986366436468985,
      "loss": 1.1228,
      "step": 1700
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.3540840148925781,
      "learning_rate": 0.00011774276174261111,
      "loss": 1.232,
      "step": 1725
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.49059322476387024,
      "learning_rate": 0.00011561358546368905,
      "loss": 1.128,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3434103727340698,
      "eval_runtime": 218.3582,
      "eval_samples_per_second": 4.58,
      "eval_steps_per_second": 4.58,
      "step": 1750
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.3758980333805084,
      "learning_rate": 0.00011347712838766824,
      "loss": 1.2054,
      "step": 1775
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.47400522232055664,
      "learning_rate": 0.00011133438676941374,
      "loss": 1.0915,
      "step": 1800
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.38810282945632935,
      "learning_rate": 0.00010918635979434622,
      "loss": 1.2147,
      "step": 1825
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.46075940132141113,
      "learning_rate": 0.00010703404911250962,
      "loss": 1.0976,
      "step": 1850
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.3983657658100128,
      "learning_rate": 0.00010487845837149062,
      "loss": 1.2166,
      "step": 1875
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.47191280126571655,
      "learning_rate": 0.00010272059274840555,
      "loss": 1.0883,
      "step": 1900
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.3938014805316925,
      "learning_rate": 0.00010056145848117497,
      "loss": 1.2119,
      "step": 1925
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.48082777857780457,
      "learning_rate": 9.840206239930286e-05,
      "loss": 1.0979,
      "step": 1950
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.37773266434669495,
      "learning_rate": 9.624341145438053e-05,
      "loss": 1.2061,
      "step": 1975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.5113171935081482,
      "learning_rate": 9.408651225053314e-05,
      "loss": 1.0968,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.345851182937622,
      "eval_runtime": 220.5221,
      "eval_samples_per_second": 4.535,
      "eval_steps_per_second": 4.535,
      "step": 2000
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.40585798025131226,
      "learning_rate": 9.193237057502864e-05,
      "loss": 1.182,
      "step": 2025
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.5458347201347351,
      "learning_rate": 8.978199092926727e-05,
      "loss": 1.0663,
      "step": 2050
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.39651283621788025,
      "learning_rate": 8.763637606037097e-05,
      "loss": 1.1898,
      "step": 2075
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.5002798438072205,
      "learning_rate": 8.549652649359053e-05,
      "loss": 1.0626,
      "step": 2100
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.39925137162208557,
      "learning_rate": 8.336344006574916e-05,
      "loss": 1.1853,
      "step": 2125
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.5084433555603027,
      "learning_rate": 8.123811145993942e-05,
      "loss": 1.0673,
      "step": 2150
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.4196000099182129,
      "learning_rate": 7.912153174169099e-05,
      "loss": 1.189,
      "step": 2175
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.5225102305412292,
      "learning_rate": 7.70146878968251e-05,
      "loss": 1.0669,
      "step": 2200
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.4106650948524475,
      "learning_rate": 7.491856237121175e-05,
      "loss": 1.1901,
      "step": 2225
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.5457179546356201,
      "learning_rate": 7.283413261264342e-05,
      "loss": 1.0801,
      "step": 2250
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3499525785446167,
      "eval_runtime": 220.6308,
      "eval_samples_per_second": 4.532,
      "eval_steps_per_second": 4.532,
      "step": 2250
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.3985432982444763,
      "learning_rate": 7.076237061504007e-05,
      "loss": 1.1611,
      "step": 2275
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.5756726264953613,
      "learning_rate": 6.870424246519682e-05,
      "loss": 1.049,
      "step": 2300
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.4212642014026642,
      "learning_rate": 6.666070789228655e-05,
      "loss": 1.1672,
      "step": 2325
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.5390776991844177,
      "learning_rate": 6.463271982032695e-05,
      "loss": 1.0513,
      "step": 2350
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.4120035767555237,
      "learning_rate": 6.262122392382075e-05,
      "loss": 1.1762,
      "step": 2375
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.5352098345756531,
      "learning_rate": 6.062715818677696e-05,
      "loss": 1.0481,
      "step": 2400
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.4450266361236572,
      "learning_rate": 5.865145246531776e-05,
      "loss": 1.1652,
      "step": 2425
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.5522948503494263,
      "learning_rate": 5.669502805407591e-05,
      "loss": 1.0405,
      "step": 2450
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.4167713522911072,
      "learning_rate": 5.475879725658413e-05,
      "loss": 1.1625,
      "step": 2475
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.5967897772789001,
      "learning_rate": 5.284366295985741e-05,
      "loss": 1.0458,
      "step": 2500
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3592398166656494,
      "eval_runtime": 220.7342,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 4.53,
      "step": 2500
    },
    {
      "epoch": 10.1,
      "grad_norm": 0.43148568272590637,
      "learning_rate": 5.0950518213366314e-05,
      "loss": 1.1427,
      "step": 2525
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.5785082578659058,
      "learning_rate": 4.9080245812597434e-05,
      "loss": 1.0291,
      "step": 2550
    },
    {
      "epoch": 10.3,
      "grad_norm": 0.43101102113723755,
      "learning_rate": 4.72337178873958e-05,
      "loss": 1.1591,
      "step": 2575
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.5912007689476013,
      "learning_rate": 4.541179549528032e-05,
      "loss": 1.0189,
      "step": 2600
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.43146494030952454,
      "learning_rate": 4.361532821992258e-05,
      "loss": 1.1469,
      "step": 2625
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.5895994305610657,
      "learning_rate": 4.184515377497643e-05,
      "loss": 1.0353,
      "step": 2650
    },
    {
      "epoch": 10.7,
      "grad_norm": 0.45839932560920715,
      "learning_rate": 4.0102097613441916e-05,
      "loss": 1.1603,
      "step": 2675
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.5811671018600464,
      "learning_rate": 3.838697254274708e-05,
      "loss": 1.0325,
      "step": 2700
    },
    {
      "epoch": 10.9,
      "grad_norm": 0.4430941045284271,
      "learning_rate": 3.670057834572653e-05,
      "loss": 1.1405,
      "step": 2725
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.5990846753120422,
      "learning_rate": 3.504370140767297e-05,
      "loss": 1.0282,
      "step": 2750
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3645602464675903,
      "eval_runtime": 220.6647,
      "eval_samples_per_second": 4.532,
      "eval_steps_per_second": 4.532,
      "step": 2750
    },
    {
      "epoch": 11.1,
      "grad_norm": 0.466313898563385,
      "learning_rate": 3.341711434963703e-05,
      "loss": 1.1202,
      "step": 2775
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.6031376123428345,
      "learning_rate": 3.182157566814471e-05,
      "loss": 1.0166,
      "step": 2800
    },
    {
      "epoch": 11.3,
      "grad_norm": 0.4450531005859375,
      "learning_rate": 3.0257829381501725e-05,
      "loss": 1.1472,
      "step": 2825
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.5990397334098816,
      "learning_rate": 2.872660468284919e-05,
      "loss": 1.0097,
      "step": 2850
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.47557640075683594,
      "learning_rate": 2.722861560013208e-05,
      "loss": 1.1287,
      "step": 2875
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.5970078706741333,
      "learning_rate": 2.5764560663139893e-05,
      "loss": 1.02,
      "step": 2900
    },
    {
      "epoch": 11.7,
      "grad_norm": 0.46235060691833496,
      "learning_rate": 2.4335122577774072e-05,
      "loss": 1.143,
      "step": 2925
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.6256776452064514,
      "learning_rate": 2.2940967907694112e-05,
      "loss": 1.0215,
      "step": 2950
    },
    {
      "epoch": 11.9,
      "grad_norm": 0.4719662368297577,
      "learning_rate": 2.1582746763491245e-05,
      "loss": 1.1401,
      "step": 2975
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.5846702456474304,
      "learning_rate": 2.0261092499534285e-05,
      "loss": 1.0094,
      "step": 3000
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.368764042854309,
      "eval_runtime": 219.7671,
      "eval_samples_per_second": 4.55,
      "eval_steps_per_second": 4.55,
      "step": 3000
    },
    {
      "epoch": 12.1,
      "grad_norm": 0.46318405866622925,
      "learning_rate": 1.8976621418629047e-05,
      "loss": 1.1293,
      "step": 3025
    },
    {
      "epoch": 12.2,
      "grad_norm": 0.6458525061607361,
      "learning_rate": 1.7729932484629296e-05,
      "loss": 1.0138,
      "step": 3050
    },
    {
      "epoch": 12.3,
      "grad_norm": 0.4659789800643921,
      "learning_rate": 1.6521607043132714e-05,
      "loss": 1.1261,
      "step": 3075
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.5999153852462769,
      "learning_rate": 1.5352208550392743e-05,
      "loss": 1.0051,
      "step": 3100
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.4958246350288391,
      "learning_rate": 1.4222282310572465e-05,
      "loss": 1.1325,
      "step": 3125
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.5920441150665283,
      "learning_rate": 1.3132355221462778e-05,
      "loss": 0.9975,
      "step": 3150
    },
    {
      "epoch": 12.7,
      "grad_norm": 0.47868281602859497,
      "learning_rate": 1.208293552878379e-05,
      "loss": 1.1162,
      "step": 3175
    },
    {
      "epoch": 12.8,
      "grad_norm": 0.6253650784492493,
      "learning_rate": 1.1074512589184105e-05,
      "loss": 1.0079,
      "step": 3200
    },
    {
      "epoch": 12.9,
      "grad_norm": 0.45691853761672974,
      "learning_rate": 1.010755664204781e-05,
      "loss": 1.123,
      "step": 3225
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.672363817691803,
      "learning_rate": 9.182518590216615e-06,
      "loss": 1.0052,
      "step": 3250
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3692564964294434,
      "eval_runtime": 218.6921,
      "eval_samples_per_second": 4.573,
      "eval_steps_per_second": 4.573,
      "step": 3250
    },
    {
      "epoch": 13.1,
      "grad_norm": 0.4473426640033722,
      "learning_rate": 8.299829789728498e-06,
      "loss": 1.117,
      "step": 3275
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.6632729172706604,
      "learning_rate": 7.459901848671347e-06,
      "loss": 0.9976,
      "step": 3300
    },
    {
      "epoch": 13.3,
      "grad_norm": 0.48476946353912354,
      "learning_rate": 6.663126435245304e-06,
      "loss": 1.1233,
      "step": 3325
    },
    {
      "epoch": 13.4,
      "grad_norm": 0.6162264347076416,
      "learning_rate": 5.90987509512333e-06,
      "loss": 0.993,
      "step": 3350
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.49670058488845825,
      "learning_rate": 5.200499078195109e-06,
      "loss": 1.1167,
      "step": 3375
    },
    {
      "epoch": 13.6,
      "grad_norm": 0.6116730570793152,
      "learning_rate": 4.53532917477516e-06,
      "loss": 1.0052,
      "step": 3400
    },
    {
      "epoch": 13.7,
      "grad_norm": 0.4780794084072113,
      "learning_rate": 3.9146755613514e-06,
      "loss": 1.1171,
      "step": 3425
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.6264956593513489,
      "learning_rate": 3.338827655946253e-06,
      "loss": 0.9996,
      "step": 3450
    },
    {
      "epoch": 13.9,
      "grad_norm": 0.4944380819797516,
      "learning_rate": 2.8080539831576658e-06,
      "loss": 1.1249,
      "step": 3475
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.6581450700759888,
      "learning_rate": 2.3226020489429232e-06,
      "loss": 0.999,
      "step": 3500
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3710951805114746,
      "eval_runtime": 217.9826,
      "eval_samples_per_second": 4.588,
      "eval_steps_per_second": 4.588,
      "step": 3500
    },
    {
      "epoch": 14.1,
      "grad_norm": 0.466852605342865,
      "learning_rate": 1.8826982252037606e-06,
      "loss": 1.1288,
      "step": 3525
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.6630387306213379,
      "learning_rate": 1.48854764422649e-06,
      "loss": 0.9936,
      "step": 3550
    },
    {
      "epoch": 14.3,
      "grad_norm": 0.48058071732521057,
      "learning_rate": 1.1403341030264192e-06,
      "loss": 1.1176,
      "step": 3575
    },
    {
      "epoch": 14.4,
      "grad_norm": 0.5951873660087585,
      "learning_rate": 8.382199776411526e-07,
      "loss": 0.9884,
      "step": 3600
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.5072435736656189,
      "learning_rate": 5.8234614741276e-07,
      "loss": 1.1044,
      "step": 3625
    },
    {
      "epoch": 14.6,
      "grad_norm": 0.6013034582138062,
      "learning_rate": 3.7283192929412626e-07,
      "loss": 0.9975,
      "step": 3650
    },
    {
      "epoch": 14.7,
      "grad_norm": 0.47514551877975464,
      "learning_rate": 2.0977502221000145e-07,
      "loss": 1.1128,
      "step": 3675
    },
    {
      "epoch": 14.8,
      "grad_norm": 0.6404685974121094,
      "learning_rate": 9.325146149888886e-08,
      "loss": 0.9952,
      "step": 3700
    },
    {
      "epoch": 14.9,
      "grad_norm": 0.46767333149909973,
      "learning_rate": 2.331558345688434e-08,
      "loss": 1.1196,
      "step": 3725
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.6552240252494812,
      "learning_rate": 0.0,
      "loss": 1.0072,
      "step": 3750
    }
  ],
  "logging_steps": 25,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.508246719134925e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
