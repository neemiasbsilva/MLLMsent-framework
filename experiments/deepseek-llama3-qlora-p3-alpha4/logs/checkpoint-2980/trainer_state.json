{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2980,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08389261744966443,
      "grad_norm": 0.5478953719139099,
      "learning_rate": 5.555555555555556e-05,
      "loss": 1.3159,
      "step": 25
    },
    {
      "epoch": 0.16778523489932887,
      "grad_norm": 0.9416297674179077,
      "learning_rate": 0.00011111111111111112,
      "loss": 2.1028,
      "step": 50
    },
    {
      "epoch": 0.2516778523489933,
      "grad_norm": 0.4804108738899231,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.7417,
      "step": 75
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 0.6243675351142883,
      "learning_rate": 0.00019999409160138693,
      "loss": 1.0982,
      "step": 100
    },
    {
      "epoch": 0.41946308724832215,
      "grad_norm": 0.4439961314201355,
      "learning_rate": 0.0001999276301349302,
      "loss": 0.5772,
      "step": 125
    },
    {
      "epoch": 0.5033557046979866,
      "grad_norm": 0.5311598181724548,
      "learning_rate": 0.00019978737094995526,
      "loss": 0.9629,
      "step": 150
    },
    {
      "epoch": 0.587248322147651,
      "grad_norm": 0.33343571424484253,
      "learning_rate": 0.00019957341762950344,
      "loss": 0.5409,
      "step": 175
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 0.5207775831222534,
      "learning_rate": 0.0001992859281805935,
      "loss": 0.9385,
      "step": 200
    },
    {
      "epoch": 0.7550335570469798,
      "grad_norm": 0.3045423924922943,
      "learning_rate": 0.00019892511491753124,
      "loss": 0.598,
      "step": 225
    },
    {
      "epoch": 0.8389261744966443,
      "grad_norm": 0.542635440826416,
      "learning_rate": 0.0001984912443051131,
      "loss": 0.9096,
      "step": 250
    },
    {
      "epoch": 0.9228187919463087,
      "grad_norm": 0.3206506073474884,
      "learning_rate": 0.00019798463676183888,
      "loss": 0.611,
      "step": 275
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8716968297958374,
      "eval_runtime": 127.4586,
      "eval_samples_per_second": 4.668,
      "eval_steps_per_second": 4.668,
      "step": 298
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 0.18717636168003082,
      "learning_rate": 0.00019740566642327867,
      "loss": 0.8637,
      "step": 300
    },
    {
      "epoch": 1.0906040268456376,
      "grad_norm": 0.3189047873020172,
      "learning_rate": 0.00019675476086576972,
      "loss": 0.5298,
      "step": 325
    },
    {
      "epoch": 1.174496644295302,
      "grad_norm": 0.16097784042358398,
      "learning_rate": 0.00019603240079064604,
      "loss": 0.8422,
      "step": 350
    },
    {
      "epoch": 1.2583892617449663,
      "grad_norm": 0.38595184683799744,
      "learning_rate": 0.00019523911966923507,
      "loss": 0.656,
      "step": 375
    },
    {
      "epoch": 1.342281879194631,
      "grad_norm": 0.16213293373584747,
      "learning_rate": 0.00019437550334888278,
      "loss": 0.801,
      "step": 400
    },
    {
      "epoch": 1.4261744966442953,
      "grad_norm": 0.3550684452056885,
      "learning_rate": 0.00019344218962029857,
      "loss": 0.6203,
      "step": 425
    },
    {
      "epoch": 1.5100671140939599,
      "grad_norm": 0.19843308627605438,
      "learning_rate": 0.00019243986774653956,
      "loss": 0.7985,
      "step": 450
    },
    {
      "epoch": 1.5939597315436242,
      "grad_norm": 0.3592565655708313,
      "learning_rate": 0.00019136927795398157,
      "loss": 0.6134,
      "step": 475
    },
    {
      "epoch": 1.6778523489932886,
      "grad_norm": 0.15136630833148956,
      "learning_rate": 0.00019023121088565352,
      "loss": 0.8016,
      "step": 500
    },
    {
      "epoch": 1.761744966442953,
      "grad_norm": 0.35970672965049744,
      "learning_rate": 0.0001890265070173382,
      "loss": 0.6088,
      "step": 525
    },
    {
      "epoch": 1.8456375838926173,
      "grad_norm": 0.0899691954255104,
      "learning_rate": 0.00018775605603687127,
      "loss": 0.8025,
      "step": 550
    },
    {
      "epoch": 1.929530201342282,
      "grad_norm": 0.35491687059402466,
      "learning_rate": 0.00018642079618709628,
      "loss": 0.6857,
      "step": 575
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8095620274543762,
      "eval_runtime": 127.3725,
      "eval_samples_per_second": 4.671,
      "eval_steps_per_second": 4.671,
      "step": 596
    },
    {
      "epoch": 2.0134228187919465,
      "grad_norm": 0.11381206661462784,
      "learning_rate": 0.00018502171357296144,
      "loss": 0.7404,
      "step": 600
    },
    {
      "epoch": 2.097315436241611,
      "grad_norm": 0.36391040682792664,
      "learning_rate": 0.00018355984143326968,
      "loss": 0.7171,
      "step": 625
    },
    {
      "epoch": 2.1812080536912752,
      "grad_norm": 0.10159048438072205,
      "learning_rate": 0.0001820362593776198,
      "loss": 0.715,
      "step": 650
    },
    {
      "epoch": 2.2651006711409396,
      "grad_norm": 0.39477792382240295,
      "learning_rate": 0.0001804520925891021,
      "loss": 0.632,
      "step": 675
    },
    {
      "epoch": 2.348993288590604,
      "grad_norm": 0.08432398736476898,
      "learning_rate": 0.00017880851099333762,
      "loss": 0.7028,
      "step": 700
    },
    {
      "epoch": 2.4328859060402683,
      "grad_norm": 0.339966356754303,
      "learning_rate": 0.0001771067283944744,
      "loss": 0.593,
      "step": 725
    },
    {
      "epoch": 2.5167785234899327,
      "grad_norm": 0.10993341356515884,
      "learning_rate": 0.00017534800157877918,
      "loss": 0.7048,
      "step": 750
    },
    {
      "epoch": 2.600671140939597,
      "grad_norm": 0.3823133707046509,
      "learning_rate": 0.0001735336293864857,
      "loss": 0.6638,
      "step": 775
    },
    {
      "epoch": 2.684563758389262,
      "grad_norm": 0.12012112140655518,
      "learning_rate": 0.00017166495175258652,
      "loss": 0.6767,
      "step": 800
    },
    {
      "epoch": 2.7684563758389262,
      "grad_norm": 0.3839542865753174,
      "learning_rate": 0.00016974334871727517,
      "loss": 0.595,
      "step": 825
    },
    {
      "epoch": 2.8523489932885906,
      "grad_norm": 0.11306392401456833,
      "learning_rate": 0.00016777023940677034,
      "loss": 0.7015,
      "step": 850
    },
    {
      "epoch": 2.936241610738255,
      "grad_norm": 0.36922216415405273,
      "learning_rate": 0.0001657470809852749,
      "loss": 0.6428,
      "step": 875
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7808598875999451,
      "eval_runtime": 127.3237,
      "eval_samples_per_second": 4.673,
      "eval_steps_per_second": 4.673,
      "step": 894
    },
    {
      "epoch": 3.0201342281879193,
      "grad_norm": 0.08445122838020325,
      "learning_rate": 0.00016367536757884286,
      "loss": 0.6369,
      "step": 900
    },
    {
      "epoch": 3.1040268456375837,
      "grad_norm": 0.38364914059638977,
      "learning_rate": 0.00016155662917195017,
      "loss": 0.6519,
      "step": 925
    },
    {
      "epoch": 3.1879194630872485,
      "grad_norm": 0.1512281745672226,
      "learning_rate": 0.0001593924304775831,
      "loss": 0.5958,
      "step": 950
    },
    {
      "epoch": 3.271812080536913,
      "grad_norm": 0.39432841539382935,
      "learning_rate": 0.00015718436978167977,
      "loss": 0.6365,
      "step": 975
    },
    {
      "epoch": 3.3557046979865772,
      "grad_norm": 0.10406962782144547,
      "learning_rate": 0.00015493407776277698,
      "loss": 0.6041,
      "step": 1000
    },
    {
      "epoch": 3.4395973154362416,
      "grad_norm": 0.4103792905807495,
      "learning_rate": 0.0001526432162877356,
      "loss": 0.6487,
      "step": 1025
    },
    {
      "epoch": 3.523489932885906,
      "grad_norm": 0.12518750131130219,
      "learning_rate": 0.00015031347718443211,
      "loss": 0.5934,
      "step": 1050
    },
    {
      "epoch": 3.6073825503355703,
      "grad_norm": 0.39237767457962036,
      "learning_rate": 0.00014794658099232425,
      "loss": 0.6667,
      "step": 1075
    },
    {
      "epoch": 3.6912751677852347,
      "grad_norm": 0.12365555018186569,
      "learning_rate": 0.0001455442756918126,
      "loss": 0.5977,
      "step": 1100
    },
    {
      "epoch": 3.7751677852348995,
      "grad_norm": 0.41149842739105225,
      "learning_rate": 0.00014310833541333656,
      "loss": 0.6252,
      "step": 1125
    },
    {
      "epoch": 3.859060402684564,
      "grad_norm": 0.11646954715251923,
      "learning_rate": 0.00014064055912715845,
      "loss": 0.6097,
      "step": 1150
    },
    {
      "epoch": 3.942953020134228,
      "grad_norm": 0.4275994896888733,
      "learning_rate": 0.00013814276931480308,
      "loss": 0.6792,
      "step": 1175
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7669135928153992,
      "eval_runtime": 127.3664,
      "eval_samples_per_second": 4.672,
      "eval_steps_per_second": 4.672,
      "step": 1192
    },
    {
      "epoch": 4.026845637583893,
      "grad_norm": 0.0902826115489006,
      "learning_rate": 0.0001356168106231337,
      "loss": 0.5567,
      "step": 1200
    },
    {
      "epoch": 4.110738255033557,
      "grad_norm": 0.44000107049942017,
      "learning_rate": 0.00013306454850205913,
      "loss": 0.6138,
      "step": 1225
    },
    {
      "epoch": 4.194630872483222,
      "grad_norm": 0.11866381019353867,
      "learning_rate": 0.00013048786782687705,
      "loss": 0.5127,
      "step": 1250
    },
    {
      "epoch": 4.278523489932886,
      "grad_norm": 0.47348588705062866,
      "learning_rate": 0.00012788867150627161,
      "loss": 0.6693,
      "step": 1275
    },
    {
      "epoch": 4.3624161073825505,
      "grad_norm": 0.13115960359573364,
      "learning_rate": 0.00012526887907699348,
      "loss": 0.5127,
      "step": 1300
    },
    {
      "epoch": 4.446308724832215,
      "grad_norm": 0.5063433051109314,
      "learning_rate": 0.00012263042528625926,
      "loss": 0.6675,
      "step": 1325
    },
    {
      "epoch": 4.530201342281879,
      "grad_norm": 0.10418957471847534,
      "learning_rate": 0.00011997525866291841,
      "loss": 0.5206,
      "step": 1350
    },
    {
      "epoch": 4.614093959731544,
      "grad_norm": 0.4994547367095947,
      "learning_rate": 0.00011730534007844185,
      "loss": 0.6198,
      "step": 1375
    },
    {
      "epoch": 4.697986577181208,
      "grad_norm": 0.12347394227981567,
      "learning_rate": 0.00011462264129879554,
      "loss": 0.5185,
      "step": 1400
    },
    {
      "epoch": 4.781879194630872,
      "grad_norm": 0.48342105746269226,
      "learning_rate": 0.00011192914352826849,
      "loss": 0.6625,
      "step": 1425
    },
    {
      "epoch": 4.865771812080537,
      "grad_norm": 0.1137336939573288,
      "learning_rate": 0.00010922683594633021,
      "loss": 0.4788,
      "step": 1450
    },
    {
      "epoch": 4.949664429530201,
      "grad_norm": 0.5366086363792419,
      "learning_rate": 0.00010651771423859844,
      "loss": 0.6985,
      "step": 1475
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7649317383766174,
      "eval_runtime": 127.3671,
      "eval_samples_per_second": 4.672,
      "eval_steps_per_second": 4.672,
      "step": 1490
    },
    {
      "epoch": 5.033557046979865,
      "grad_norm": 0.11134125292301178,
      "learning_rate": 0.0001038037791230023,
      "loss": 0.471,
      "step": 1500
    },
    {
      "epoch": 5.117449664429531,
      "grad_norm": 0.47415614128112793,
      "learning_rate": 0.00010108703487222855,
      "loss": 0.6605,
      "step": 1525
    },
    {
      "epoch": 5.201342281879195,
      "grad_norm": 0.14218580722808838,
      "learning_rate": 9.836948783354309e-05,
      "loss": 0.4338,
      "step": 1550
    },
    {
      "epoch": 5.285234899328859,
      "grad_norm": 0.6192717552185059,
      "learning_rate": 9.565314494707995e-05,
      "loss": 0.6371,
      "step": 1575
    },
    {
      "epoch": 5.369127516778524,
      "grad_norm": 0.13334347307682037,
      "learning_rate": 9.294001226369282e-05,
      "loss": 0.4237,
      "step": 1600
    },
    {
      "epoch": 5.453020134228188,
      "grad_norm": 0.552236795425415,
      "learning_rate": 9.023209346346293e-05,
      "loss": 0.6475,
      "step": 1625
    },
    {
      "epoch": 5.5369127516778525,
      "grad_norm": 0.13200035691261292,
      "learning_rate": 8.753138837595817e-05,
      "loss": 0.4302,
      "step": 1650
    },
    {
      "epoch": 5.620805369127517,
      "grad_norm": 0.551263153553009,
      "learning_rate": 8.483989150333556e-05,
      "loss": 0.6228,
      "step": 1675
    },
    {
      "epoch": 5.704697986577181,
      "grad_norm": 0.11382421851158142,
      "learning_rate": 8.215959054737817e-05,
      "loss": 0.424,
      "step": 1700
    },
    {
      "epoch": 5.7885906040268456,
      "grad_norm": 0.586094856262207,
      "learning_rate": 7.949246494155421e-05,
      "loss": 0.6404,
      "step": 1725
    },
    {
      "epoch": 5.87248322147651,
      "grad_norm": 0.13365723192691803,
      "learning_rate": 7.684048438918248e-05,
      "loss": 0.4328,
      "step": 1750
    },
    {
      "epoch": 5.956375838926174,
      "grad_norm": 0.5849722623825073,
      "learning_rate": 7.420560740878334e-05,
      "loss": 0.7007,
      "step": 1775
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7661622166633606,
      "eval_runtime": 127.359,
      "eval_samples_per_second": 4.672,
      "eval_steps_per_second": 4.672,
      "step": 1788
    },
    {
      "epoch": 6.040268456375839,
      "grad_norm": 0.12092474848031998,
      "learning_rate": 7.158977988769023e-05,
      "loss": 0.3938,
      "step": 1800
    },
    {
      "epoch": 6.124161073825503,
      "grad_norm": 0.6355911493301392,
      "learning_rate": 6.899493364498883e-05,
      "loss": 0.637,
      "step": 1825
    },
    {
      "epoch": 6.208053691275167,
      "grad_norm": 0.15389136970043182,
      "learning_rate": 6.642298500484658e-05,
      "loss": 0.3617,
      "step": 1850
    },
    {
      "epoch": 6.291946308724833,
      "grad_norm": 0.6369646787643433,
      "learning_rate": 6.387583338128471e-05,
      "loss": 0.6426,
      "step": 1875
    },
    {
      "epoch": 6.375838926174497,
      "grad_norm": 0.15707291662693024,
      "learning_rate": 6.135535987543899e-05,
      "loss": 0.3577,
      "step": 1900
    },
    {
      "epoch": 6.459731543624161,
      "grad_norm": 0.6166618466377258,
      "learning_rate": 5.886342588634458e-05,
      "loss": 0.6455,
      "step": 1925
    },
    {
      "epoch": 6.543624161073826,
      "grad_norm": 0.14796777069568634,
      "learning_rate": 5.64018717362711e-05,
      "loss": 0.3668,
      "step": 1950
    },
    {
      "epoch": 6.62751677852349,
      "grad_norm": 0.6330173015594482,
      "learning_rate": 5.397251531162332e-05,
      "loss": 0.6517,
      "step": 1975
    },
    {
      "epoch": 6.7114093959731544,
      "grad_norm": 0.1559605747461319,
      "learning_rate": 5.1577150720410935e-05,
      "loss": 0.3669,
      "step": 2000
    },
    {
      "epoch": 6.795302013422819,
      "grad_norm": 0.7200533151626587,
      "learning_rate": 4.921754696727869e-05,
      "loss": 0.6475,
      "step": 2025
    },
    {
      "epoch": 6.879194630872483,
      "grad_norm": 0.16197986900806427,
      "learning_rate": 4.6895446647076005e-05,
      "loss": 0.3599,
      "step": 2050
    },
    {
      "epoch": 6.9630872483221475,
      "grad_norm": 0.6646918654441833,
      "learning_rate": 4.461256465793032e-05,
      "loss": 0.6449,
      "step": 2075
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7815540432929993,
      "eval_runtime": 127.4869,
      "eval_samples_per_second": 4.667,
      "eval_steps_per_second": 4.667,
      "step": 2086
    },
    {
      "epoch": 7.046979865771812,
      "grad_norm": 0.11271877586841583,
      "learning_rate": 4.237058693477499e-05,
      "loss": 0.3203,
      "step": 2100
    },
    {
      "epoch": 7.130872483221476,
      "grad_norm": 0.7119972109794617,
      "learning_rate": 4.017116920426651e-05,
      "loss": 0.6141,
      "step": 2125
    },
    {
      "epoch": 7.214765100671141,
      "grad_norm": 0.15523098409175873,
      "learning_rate": 3.801593576201118e-05,
      "loss": 0.3122,
      "step": 2150
    },
    {
      "epoch": 7.298657718120805,
      "grad_norm": 0.7206974029541016,
      "learning_rate": 3.590647827300405e-05,
      "loss": 0.6183,
      "step": 2175
    },
    {
      "epoch": 7.382550335570469,
      "grad_norm": 0.2507432699203491,
      "learning_rate": 3.384435459616536e-05,
      "loss": 0.3159,
      "step": 2200
    },
    {
      "epoch": 7.466442953020135,
      "grad_norm": 0.6928401589393616,
      "learning_rate": 3.1831087633844145e-05,
      "loss": 0.6786,
      "step": 2225
    },
    {
      "epoch": 7.550335570469799,
      "grad_norm": 0.14057141542434692,
      "learning_rate": 2.9868164207136616e-05,
      "loss": 0.3132,
      "step": 2250
    },
    {
      "epoch": 7.634228187919463,
      "grad_norm": 0.7453207969665527,
      "learning_rate": 2.795703395785184e-05,
      "loss": 0.6343,
      "step": 2275
    },
    {
      "epoch": 7.718120805369128,
      "grad_norm": 0.1688637137413025,
      "learning_rate": 2.6099108277934103e-05,
      "loss": 0.3164,
      "step": 2300
    },
    {
      "epoch": 7.802013422818792,
      "grad_norm": 0.7360662221908569,
      "learning_rate": 2.42957592671337e-05,
      "loss": 0.6347,
      "step": 2325
    },
    {
      "epoch": 7.885906040268456,
      "grad_norm": 0.1710026115179062,
      "learning_rate": 2.2548318719695182e-05,
      "loss": 0.3116,
      "step": 2350
    },
    {
      "epoch": 7.969798657718121,
      "grad_norm": 0.7492265105247498,
      "learning_rate": 2.085807714081195e-05,
      "loss": 0.6489,
      "step": 2375
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7924240231513977,
      "eval_runtime": 127.5031,
      "eval_samples_per_second": 4.667,
      "eval_steps_per_second": 4.667,
      "step": 2384
    },
    {
      "epoch": 8.053691275167786,
      "grad_norm": 0.21994446218013763,
      "learning_rate": 1.9226282793572924e-05,
      "loss": 0.2742,
      "step": 2400
    },
    {
      "epoch": 8.13758389261745,
      "grad_norm": 0.7222033143043518,
      "learning_rate": 1.7654140777105953e-05,
      "loss": 0.6505,
      "step": 2425
    },
    {
      "epoch": 8.221476510067115,
      "grad_norm": 0.618166983127594,
      "learning_rate": 1.6142812136597853e-05,
      "loss": 0.3016,
      "step": 2450
    },
    {
      "epoch": 8.305369127516778,
      "grad_norm": 0.7781349420547485,
      "learning_rate": 1.4693413005849143e-05,
      "loss": 0.612,
      "step": 2475
    },
    {
      "epoch": 8.389261744966444,
      "grad_norm": 0.5450497269630432,
      "learning_rate": 1.3307013782996235e-05,
      "loss": 0.2812,
      "step": 2500
    },
    {
      "epoch": 8.473154362416107,
      "grad_norm": 0.8293794393539429,
      "learning_rate": 1.1984638340009934e-05,
      "loss": 0.6308,
      "step": 2525
    },
    {
      "epoch": 8.557046979865772,
      "grad_norm": 0.3232908248901367,
      "learning_rate": 1.0727263266554011e-05,
      "loss": 0.2623,
      "step": 2550
    },
    {
      "epoch": 8.640939597315436,
      "grad_norm": 0.6997855305671692,
      "learning_rate": 9.535817148762461e-06,
      "loss": 0.6305,
      "step": 2575
    },
    {
      "epoch": 8.724832214765101,
      "grad_norm": 0.15123291313648224,
      "learning_rate": 8.411179883467667e-06,
      "loss": 0.2801,
      "step": 2600
    },
    {
      "epoch": 8.808724832214764,
      "grad_norm": 0.7714609503746033,
      "learning_rate": 7.354182028386591e-06,
      "loss": 0.6454,
      "step": 2625
    },
    {
      "epoch": 8.89261744966443,
      "grad_norm": 0.6510978937149048,
      "learning_rate": 6.365604188743979e-06,
      "loss": 0.3228,
      "step": 2650
    },
    {
      "epoch": 8.976510067114093,
      "grad_norm": 0.749659538269043,
      "learning_rate": 5.446176440786488e-06,
      "loss": 0.6064,
      "step": 2675
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.8002397418022156,
      "eval_runtime": 127.6058,
      "eval_samples_per_second": 4.663,
      "eval_steps_per_second": 4.663,
      "step": 2682
    },
    {
      "epoch": 9.060402684563758,
      "grad_norm": 0.7611191272735596,
      "learning_rate": 4.596577792612755e-06,
      "loss": 0.3574,
      "step": 2700
    },
    {
      "epoch": 9.144295302013424,
      "grad_norm": 0.7465654611587524,
      "learning_rate": 3.817435682718096e-06,
      "loss": 0.595,
      "step": 2725
    },
    {
      "epoch": 9.228187919463087,
      "grad_norm": 0.7630850672721863,
      "learning_rate": 3.1093255166238176e-06,
      "loss": 0.3211,
      "step": 2750
    },
    {
      "epoch": 9.312080536912752,
      "grad_norm": 0.7510876655578613,
      "learning_rate": 2.4727702419335864e-06,
      "loss": 0.5665,
      "step": 2775
    },
    {
      "epoch": 9.395973154362416,
      "grad_norm": 0.6974716186523438,
      "learning_rate": 1.908239962130476e-06,
      "loss": 0.2714,
      "step": 2800
    },
    {
      "epoch": 9.479865771812081,
      "grad_norm": 0.7550506591796875,
      "learning_rate": 1.4161515894001165e-06,
      "loss": 0.6191,
      "step": 2825
    },
    {
      "epoch": 9.563758389261745,
      "grad_norm": 0.759613573551178,
      "learning_rate": 9.968685367361618e-07,
      "loss": 0.291,
      "step": 2850
    },
    {
      "epoch": 9.64765100671141,
      "grad_norm": 0.7125621438026428,
      "learning_rate": 6.507004495555969e-07,
      "loss": 0.5927,
      "step": 2875
    },
    {
      "epoch": 9.731543624161073,
      "grad_norm": 0.7007909417152405,
      "learning_rate": 3.779029770219378e-07,
      "loss": 0.2673,
      "step": 2900
    },
    {
      "epoch": 9.815436241610739,
      "grad_norm": 0.7804751396179199,
      "learning_rate": 1.786775832454013e-07,
      "loss": 0.6,
      "step": 2925
    },
    {
      "epoch": 9.899328859060402,
      "grad_norm": 0.693761944770813,
      "learning_rate": 5.317139849928543e-08,
      "loss": 0.3259,
      "step": 2950
    },
    {
      "epoch": 9.983221476510067,
      "grad_norm": 0.8759872913360596,
      "learning_rate": 1.4771105625421834e-09,
      "loss": 0.581,
      "step": 2975
    }
  ],
  "logging_steps": 25,
  "max_steps": 2980,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4037526276665344e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
