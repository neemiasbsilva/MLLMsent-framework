{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2980,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08389261744966443,
      "grad_norm": 0.53410404920578,
      "learning_rate": 5.555555555555556e-05,
      "loss": 1.2969,
      "step": 25
    },
    {
      "epoch": 0.16778523489932887,
      "grad_norm": 1.3875629901885986,
      "learning_rate": 0.00011111111111111112,
      "loss": 2.0326,
      "step": 50
    },
    {
      "epoch": 0.2516778523489933,
      "grad_norm": 0.49678805470466614,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.7242,
      "step": 75
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 0.8821233510971069,
      "learning_rate": 0.00019999409160138693,
      "loss": 1.0391,
      "step": 100
    },
    {
      "epoch": 0.41946308724832215,
      "grad_norm": 0.4289461672306061,
      "learning_rate": 0.0001999276301349302,
      "loss": 0.5574,
      "step": 125
    },
    {
      "epoch": 0.5033557046979866,
      "grad_norm": 0.48233896493911743,
      "learning_rate": 0.00019978737094995526,
      "loss": 0.8887,
      "step": 150
    },
    {
      "epoch": 0.587248322147651,
      "grad_norm": 0.34638845920562744,
      "learning_rate": 0.00019957341762950344,
      "loss": 0.5216,
      "step": 175
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 0.42702168226242065,
      "learning_rate": 0.0001992859281805935,
      "loss": 0.8659,
      "step": 200
    },
    {
      "epoch": 0.7550335570469798,
      "grad_norm": 0.31124889850616455,
      "learning_rate": 0.00019892511491753124,
      "loss": 0.5747,
      "step": 225
    },
    {
      "epoch": 0.8389261744966443,
      "grad_norm": 0.602266788482666,
      "learning_rate": 0.0001984912443051131,
      "loss": 0.8365,
      "step": 250
    },
    {
      "epoch": 0.9228187919463087,
      "grad_norm": 0.2994256317615509,
      "learning_rate": 0.00019798463676183888,
      "loss": 0.589,
      "step": 275
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8150851130485535,
      "eval_runtime": 128.7793,
      "eval_samples_per_second": 4.62,
      "eval_steps_per_second": 4.62,
      "step": 298
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 0.19266334176063538,
      "learning_rate": 0.00019740566642327867,
      "loss": 0.7958,
      "step": 300
    },
    {
      "epoch": 1.0906040268456376,
      "grad_norm": 0.3065440356731415,
      "learning_rate": 0.00019675476086576972,
      "loss": 0.5082,
      "step": 325
    },
    {
      "epoch": 1.174496644295302,
      "grad_norm": 0.1480841338634491,
      "learning_rate": 0.00019603240079064604,
      "loss": 0.7767,
      "step": 350
    },
    {
      "epoch": 1.2583892617449663,
      "grad_norm": 0.36569371819496155,
      "learning_rate": 0.00019523911966923507,
      "loss": 0.6297,
      "step": 375
    },
    {
      "epoch": 1.342281879194631,
      "grad_norm": 0.16331689059734344,
      "learning_rate": 0.00019437550334888278,
      "loss": 0.7351,
      "step": 400
    },
    {
      "epoch": 1.4261744966442953,
      "grad_norm": 0.33568915724754333,
      "learning_rate": 0.00019344218962029857,
      "loss": 0.5953,
      "step": 425
    },
    {
      "epoch": 1.5100671140939599,
      "grad_norm": 0.2012006789445877,
      "learning_rate": 0.00019243986774653956,
      "loss": 0.7351,
      "step": 450
    },
    {
      "epoch": 1.5939597315436242,
      "grad_norm": 0.34008246660232544,
      "learning_rate": 0.00019136927795398157,
      "loss": 0.5863,
      "step": 475
    },
    {
      "epoch": 1.6778523489932886,
      "grad_norm": 0.144675612449646,
      "learning_rate": 0.00019023121088565352,
      "loss": 0.7374,
      "step": 500
    },
    {
      "epoch": 1.761744966442953,
      "grad_norm": 0.3273759186267853,
      "learning_rate": 0.0001890265070173382,
      "loss": 0.5865,
      "step": 525
    },
    {
      "epoch": 1.8456375838926173,
      "grad_norm": 0.09115555137395859,
      "learning_rate": 0.00018775605603687127,
      "loss": 0.7415,
      "step": 550
    },
    {
      "epoch": 1.929530201342282,
      "grad_norm": 0.3476157784461975,
      "learning_rate": 0.00018642079618709628,
      "loss": 0.6594,
      "step": 575
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7503705024719238,
      "eval_runtime": 128.8103,
      "eval_samples_per_second": 4.619,
      "eval_steps_per_second": 4.619,
      "step": 596
    },
    {
      "epoch": 2.0134228187919465,
      "grad_norm": 0.11613661050796509,
      "learning_rate": 0.00018502171357296144,
      "loss": 0.6804,
      "step": 600
    },
    {
      "epoch": 2.097315436241611,
      "grad_norm": 0.33549579977989197,
      "learning_rate": 0.00018355984143326968,
      "loss": 0.6843,
      "step": 625
    },
    {
      "epoch": 2.1812080536912752,
      "grad_norm": 0.10529676079750061,
      "learning_rate": 0.0001820362593776198,
      "loss": 0.6595,
      "step": 650
    },
    {
      "epoch": 2.2651006711409396,
      "grad_norm": 0.3698371946811676,
      "learning_rate": 0.0001804520925891021,
      "loss": 0.6059,
      "step": 675
    },
    {
      "epoch": 2.348993288590604,
      "grad_norm": 0.08813753724098206,
      "learning_rate": 0.00017880851099333762,
      "loss": 0.6494,
      "step": 700
    },
    {
      "epoch": 2.4328859060402683,
      "grad_norm": 0.3247196078300476,
      "learning_rate": 0.0001771067283944744,
      "loss": 0.5707,
      "step": 725
    },
    {
      "epoch": 2.5167785234899327,
      "grad_norm": 0.10933473706245422,
      "learning_rate": 0.00017534800157877918,
      "loss": 0.651,
      "step": 750
    },
    {
      "epoch": 2.600671140939597,
      "grad_norm": 0.3606303632259369,
      "learning_rate": 0.0001735336293864857,
      "loss": 0.6342,
      "step": 775
    },
    {
      "epoch": 2.684563758389262,
      "grad_norm": 0.11373177170753479,
      "learning_rate": 0.00017166495175258652,
      "loss": 0.6243,
      "step": 800
    },
    {
      "epoch": 2.7684563758389262,
      "grad_norm": 0.3618563413619995,
      "learning_rate": 0.00016974334871727517,
      "loss": 0.5703,
      "step": 825
    },
    {
      "epoch": 2.8523489932885906,
      "grad_norm": 0.11222750693559647,
      "learning_rate": 0.00016777023940677034,
      "loss": 0.646,
      "step": 850
    },
    {
      "epoch": 2.936241610738255,
      "grad_norm": 0.34770920872688293,
      "learning_rate": 0.0001657470809852749,
      "loss": 0.6157,
      "step": 875
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7241734266281128,
      "eval_runtime": 128.838,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 894
    },
    {
      "epoch": 3.0201342281879193,
      "grad_norm": 0.08578935265541077,
      "learning_rate": 0.00016367536757884286,
      "loss": 0.5877,
      "step": 900
    },
    {
      "epoch": 3.1040268456375837,
      "grad_norm": 0.3552192747592926,
      "learning_rate": 0.00016155662917195017,
      "loss": 0.623,
      "step": 925
    },
    {
      "epoch": 3.1879194630872485,
      "grad_norm": 0.1486162394285202,
      "learning_rate": 0.0001593924304775831,
      "loss": 0.5501,
      "step": 950
    },
    {
      "epoch": 3.271812080536913,
      "grad_norm": 0.37433797121047974,
      "learning_rate": 0.00015718436978167977,
      "loss": 0.6079,
      "step": 975
    },
    {
      "epoch": 3.3557046979865772,
      "grad_norm": 0.10462683439254761,
      "learning_rate": 0.00015493407776277698,
      "loss": 0.5583,
      "step": 1000
    },
    {
      "epoch": 3.4395973154362416,
      "grad_norm": 0.386425644159317,
      "learning_rate": 0.0001526432162877356,
      "loss": 0.6204,
      "step": 1025
    },
    {
      "epoch": 3.523489932885906,
      "grad_norm": 0.12717291712760925,
      "learning_rate": 0.00015031347718443211,
      "loss": 0.5473,
      "step": 1050
    },
    {
      "epoch": 3.6073825503355703,
      "grad_norm": 0.3739684820175171,
      "learning_rate": 0.00014794658099232425,
      "loss": 0.6357,
      "step": 1075
    },
    {
      "epoch": 3.6912751677852347,
      "grad_norm": 0.12663358449935913,
      "learning_rate": 0.0001455442756918126,
      "loss": 0.551,
      "step": 1100
    },
    {
      "epoch": 3.7751677852348995,
      "grad_norm": 0.37933576107025146,
      "learning_rate": 0.00014310833541333656,
      "loss": 0.5955,
      "step": 1125
    },
    {
      "epoch": 3.859060402684564,
      "grad_norm": 0.11786144971847534,
      "learning_rate": 0.00014064055912715845,
      "loss": 0.5626,
      "step": 1150
    },
    {
      "epoch": 3.942953020134228,
      "grad_norm": 0.4014246463775635,
      "learning_rate": 0.00013814276931480308,
      "loss": 0.6488,
      "step": 1175
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.713211715221405,
      "eval_runtime": 128.8421,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 1192
    },
    {
      "epoch": 4.026845637583893,
      "grad_norm": 0.09473663568496704,
      "learning_rate": 0.0001356168106231337,
      "loss": 0.5134,
      "step": 1200
    },
    {
      "epoch": 4.110738255033557,
      "grad_norm": 0.4091026484966278,
      "learning_rate": 0.00013306454850205913,
      "loss": 0.5868,
      "step": 1225
    },
    {
      "epoch": 4.194630872483222,
      "grad_norm": 0.11516470462083817,
      "learning_rate": 0.00013048786782687705,
      "loss": 0.4725,
      "step": 1250
    },
    {
      "epoch": 4.278523489932886,
      "grad_norm": 0.44678500294685364,
      "learning_rate": 0.00012788867150627161,
      "loss": 0.6375,
      "step": 1275
    },
    {
      "epoch": 4.3624161073825505,
      "grad_norm": 0.13506169617176056,
      "learning_rate": 0.00012526887907699348,
      "loss": 0.4747,
      "step": 1300
    },
    {
      "epoch": 4.446308724832215,
      "grad_norm": 0.4787741005420685,
      "learning_rate": 0.00012263042528625926,
      "loss": 0.6357,
      "step": 1325
    },
    {
      "epoch": 4.530201342281879,
      "grad_norm": 0.10411930084228516,
      "learning_rate": 0.00011997525866291841,
      "loss": 0.4812,
      "step": 1350
    },
    {
      "epoch": 4.614093959731544,
      "grad_norm": 0.4657116234302521,
      "learning_rate": 0.00011730534007844185,
      "loss": 0.5912,
      "step": 1375
    },
    {
      "epoch": 4.697986577181208,
      "grad_norm": 0.12395375967025757,
      "learning_rate": 0.00011462264129879554,
      "loss": 0.4805,
      "step": 1400
    },
    {
      "epoch": 4.781879194630872,
      "grad_norm": 0.45418044924736023,
      "learning_rate": 0.00011192914352826849,
      "loss": 0.6325,
      "step": 1425
    },
    {
      "epoch": 4.865771812080537,
      "grad_norm": 0.10748133063316345,
      "learning_rate": 0.00010922683594633021,
      "loss": 0.4416,
      "step": 1450
    },
    {
      "epoch": 4.949664429530201,
      "grad_norm": 0.49051713943481445,
      "learning_rate": 0.00010651771423859844,
      "loss": 0.6627,
      "step": 1475
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7086898684501648,
      "eval_runtime": 128.6552,
      "eval_samples_per_second": 4.625,
      "eval_steps_per_second": 4.625,
      "step": 1490
    },
    {
      "epoch": 5.033557046979865,
      "grad_norm": 0.11149043589830399,
      "learning_rate": 0.0001038037791230023,
      "loss": 0.4354,
      "step": 1500
    },
    {
      "epoch": 5.117449664429531,
      "grad_norm": 0.44025152921676636,
      "learning_rate": 0.00010108703487222855,
      "loss": 0.6277,
      "step": 1525
    },
    {
      "epoch": 5.201342281879195,
      "grad_norm": 0.14303801953792572,
      "learning_rate": 9.836948783354309e-05,
      "loss": 0.404,
      "step": 1550
    },
    {
      "epoch": 5.285234899328859,
      "grad_norm": 0.5534628033638,
      "learning_rate": 9.565314494707995e-05,
      "loss": 0.606,
      "step": 1575
    },
    {
      "epoch": 5.369127516778524,
      "grad_norm": 0.13063642382621765,
      "learning_rate": 9.294001226369282e-05,
      "loss": 0.3925,
      "step": 1600
    },
    {
      "epoch": 5.453020134228188,
      "grad_norm": 0.5246924757957458,
      "learning_rate": 9.023209346346293e-05,
      "loss": 0.6145,
      "step": 1625
    },
    {
      "epoch": 5.5369127516778525,
      "grad_norm": 0.12604714930057526,
      "learning_rate": 8.753138837595817e-05,
      "loss": 0.3988,
      "step": 1650
    },
    {
      "epoch": 5.620805369127517,
      "grad_norm": 0.501922070980072,
      "learning_rate": 8.483989150333556e-05,
      "loss": 0.59,
      "step": 1675
    },
    {
      "epoch": 5.704697986577181,
      "grad_norm": 0.11769215017557144,
      "learning_rate": 8.215959054737817e-05,
      "loss": 0.3927,
      "step": 1700
    },
    {
      "epoch": 5.7885906040268456,
      "grad_norm": 0.5472347736358643,
      "learning_rate": 7.949246494155421e-05,
      "loss": 0.6098,
      "step": 1725
    },
    {
      "epoch": 5.87248322147651,
      "grad_norm": 0.13734668493270874,
      "learning_rate": 7.684048438918248e-05,
      "loss": 0.4028,
      "step": 1750
    },
    {
      "epoch": 5.956375838926174,
      "grad_norm": 0.5431656837463379,
      "learning_rate": 7.420560740878334e-05,
      "loss": 0.6634,
      "step": 1775
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7103143930435181,
      "eval_runtime": 128.7972,
      "eval_samples_per_second": 4.62,
      "eval_steps_per_second": 4.62,
      "step": 1788
    },
    {
      "epoch": 6.040268456375839,
      "grad_norm": 0.13259606063365936,
      "learning_rate": 7.158977988769023e-05,
      "loss": 0.3651,
      "step": 1800
    },
    {
      "epoch": 6.124161073825503,
      "grad_norm": 0.5964462161064148,
      "learning_rate": 6.899493364498883e-05,
      "loss": 0.605,
      "step": 1825
    },
    {
      "epoch": 6.208053691275167,
      "grad_norm": 0.15439319610595703,
      "learning_rate": 6.642298500484658e-05,
      "loss": 0.3357,
      "step": 1850
    },
    {
      "epoch": 6.291946308724833,
      "grad_norm": 0.6123748421669006,
      "learning_rate": 6.387583338128471e-05,
      "loss": 0.6094,
      "step": 1875
    },
    {
      "epoch": 6.375838926174497,
      "grad_norm": 0.1525004506111145,
      "learning_rate": 6.135535987543899e-05,
      "loss": 0.3321,
      "step": 1900
    },
    {
      "epoch": 6.459731543624161,
      "grad_norm": 0.6066157817840576,
      "learning_rate": 5.886342588634458e-05,
      "loss": 0.6122,
      "step": 1925
    },
    {
      "epoch": 6.543624161073826,
      "grad_norm": 0.14529702067375183,
      "learning_rate": 5.64018717362711e-05,
      "loss": 0.3418,
      "step": 1950
    },
    {
      "epoch": 6.62751677852349,
      "grad_norm": 0.5904727578163147,
      "learning_rate": 5.397251531162332e-05,
      "loss": 0.6186,
      "step": 1975
    },
    {
      "epoch": 6.7114093959731544,
      "grad_norm": 0.15645341575145721,
      "learning_rate": 5.1577150720410935e-05,
      "loss": 0.3435,
      "step": 2000
    },
    {
      "epoch": 6.795302013422819,
      "grad_norm": 0.6716371178627014,
      "learning_rate": 4.921754696727869e-05,
      "loss": 0.613,
      "step": 2025
    },
    {
      "epoch": 6.879194630872483,
      "grad_norm": 0.16772538423538208,
      "learning_rate": 4.6895446647076005e-05,
      "loss": 0.3361,
      "step": 2050
    },
    {
      "epoch": 6.9630872483221475,
      "grad_norm": 0.6083711981773376,
      "learning_rate": 4.461256465793032e-05,
      "loss": 0.6088,
      "step": 2075
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7242537140846252,
      "eval_runtime": 128.7838,
      "eval_samples_per_second": 4.62,
      "eval_steps_per_second": 4.62,
      "step": 2086
    },
    {
      "epoch": 7.046979865771812,
      "grad_norm": 0.11257127672433853,
      "learning_rate": 4.237058693477499e-05,
      "loss": 0.3007,
      "step": 2100
    },
    {
      "epoch": 7.130872483221476,
      "grad_norm": 0.6546350717544556,
      "learning_rate": 4.017116920426651e-05,
      "loss": 0.579,
      "step": 2125
    },
    {
      "epoch": 7.214765100671141,
      "grad_norm": 0.15598243474960327,
      "learning_rate": 3.801593576201118e-05,
      "loss": 0.292,
      "step": 2150
    },
    {
      "epoch": 7.298657718120805,
      "grad_norm": 0.6568541526794434,
      "learning_rate": 3.590647827300405e-05,
      "loss": 0.5868,
      "step": 2175
    },
    {
      "epoch": 7.382550335570469,
      "grad_norm": 0.2519891858100891,
      "learning_rate": 3.384435459616536e-05,
      "loss": 0.2972,
      "step": 2200
    },
    {
      "epoch": 7.466442953020135,
      "grad_norm": 0.6329324841499329,
      "learning_rate": 3.1831087633844145e-05,
      "loss": 0.6423,
      "step": 2225
    },
    {
      "epoch": 7.550335570469799,
      "grad_norm": 0.13887910544872284,
      "learning_rate": 2.9868164207136616e-05,
      "loss": 0.2932,
      "step": 2250
    },
    {
      "epoch": 7.634228187919463,
      "grad_norm": 0.7056179642677307,
      "learning_rate": 2.795703395785184e-05,
      "loss": 0.5996,
      "step": 2275
    },
    {
      "epoch": 7.718120805369128,
      "grad_norm": 0.18025757372379303,
      "learning_rate": 2.6099108277934103e-05,
      "loss": 0.2994,
      "step": 2300
    },
    {
      "epoch": 7.802013422818792,
      "grad_norm": 0.6754766702651978,
      "learning_rate": 2.42957592671337e-05,
      "loss": 0.6048,
      "step": 2325
    },
    {
      "epoch": 7.885906040268456,
      "grad_norm": 0.16969235241413116,
      "learning_rate": 2.2548318719695182e-05,
      "loss": 0.2928,
      "step": 2350
    },
    {
      "epoch": 7.969798657718121,
      "grad_norm": 0.7245241403579712,
      "learning_rate": 2.085807714081195e-05,
      "loss": 0.6082,
      "step": 2375
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7358411550521851,
      "eval_runtime": 128.713,
      "eval_samples_per_second": 4.623,
      "eval_steps_per_second": 4.623,
      "step": 2384
    },
    {
      "epoch": 8.053691275167786,
      "grad_norm": 0.21446549892425537,
      "learning_rate": 1.9226282793572924e-05,
      "loss": 0.2575,
      "step": 2400
    },
    {
      "epoch": 8.13758389261745,
      "grad_norm": 0.6831245422363281,
      "learning_rate": 1.7654140777105953e-05,
      "loss": 0.6111,
      "step": 2425
    },
    {
      "epoch": 8.221476510067115,
      "grad_norm": 0.6012607216835022,
      "learning_rate": 1.6142812136597853e-05,
      "loss": 0.2842,
      "step": 2450
    },
    {
      "epoch": 8.305369127516778,
      "grad_norm": 0.729019820690155,
      "learning_rate": 1.4693413005849143e-05,
      "loss": 0.5764,
      "step": 2475
    },
    {
      "epoch": 8.389261744966444,
      "grad_norm": 0.571276068687439,
      "learning_rate": 1.3307013782996235e-05,
      "loss": 0.2631,
      "step": 2500
    },
    {
      "epoch": 8.473154362416107,
      "grad_norm": 0.7551524639129639,
      "learning_rate": 1.1984638340009934e-05,
      "loss": 0.596,
      "step": 2525
    },
    {
      "epoch": 8.557046979865772,
      "grad_norm": 0.3283151686191559,
      "learning_rate": 1.0727263266554011e-05,
      "loss": 0.248,
      "step": 2550
    },
    {
      "epoch": 8.640939597315436,
      "grad_norm": 0.681341290473938,
      "learning_rate": 9.535817148762461e-06,
      "loss": 0.5976,
      "step": 2575
    },
    {
      "epoch": 8.724832214765101,
      "grad_norm": 0.1553003489971161,
      "learning_rate": 8.411179883467667e-06,
      "loss": 0.2657,
      "step": 2600
    },
    {
      "epoch": 8.808724832214764,
      "grad_norm": 0.7199586629867554,
      "learning_rate": 7.354182028386591e-06,
      "loss": 0.6116,
      "step": 2625
    },
    {
      "epoch": 8.89261744966443,
      "grad_norm": 0.6578991413116455,
      "learning_rate": 6.365604188743979e-06,
      "loss": 0.307,
      "step": 2650
    },
    {
      "epoch": 8.976510067114093,
      "grad_norm": 0.7269738912582397,
      "learning_rate": 5.446176440786488e-06,
      "loss": 0.5687,
      "step": 2675
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7413215041160583,
      "eval_runtime": 128.6906,
      "eval_samples_per_second": 4.623,
      "eval_steps_per_second": 4.623,
      "step": 2682
    },
    {
      "epoch": 9.060402684563758,
      "grad_norm": 0.7233774065971375,
      "learning_rate": 4.596577792612755e-06,
      "loss": 0.3409,
      "step": 2700
    },
    {
      "epoch": 9.144295302013424,
      "grad_norm": 0.6357053518295288,
      "learning_rate": 3.817435682718096e-06,
      "loss": 0.5558,
      "step": 2725
    },
    {
      "epoch": 9.228187919463087,
      "grad_norm": 0.7516544461250305,
      "learning_rate": 3.1093255166238176e-06,
      "loss": 0.3048,
      "step": 2750
    },
    {
      "epoch": 9.312080536912752,
      "grad_norm": 0.6814177632331848,
      "learning_rate": 2.4727702419335864e-06,
      "loss": 0.5285,
      "step": 2775
    },
    {
      "epoch": 9.395973154362416,
      "grad_norm": 0.6737066507339478,
      "learning_rate": 1.908239962130476e-06,
      "loss": 0.2594,
      "step": 2800
    },
    {
      "epoch": 9.479865771812081,
      "grad_norm": 0.7203208804130554,
      "learning_rate": 1.4161515894001165e-06,
      "loss": 0.5834,
      "step": 2825
    },
    {
      "epoch": 9.563758389261745,
      "grad_norm": 0.7281469702720642,
      "learning_rate": 9.968685367361618e-07,
      "loss": 0.2763,
      "step": 2850
    },
    {
      "epoch": 9.64765100671141,
      "grad_norm": 0.6394795179367065,
      "learning_rate": 6.507004495555969e-07,
      "loss": 0.5605,
      "step": 2875
    },
    {
      "epoch": 9.731543624161073,
      "grad_norm": 0.6675708889961243,
      "learning_rate": 3.779029770219378e-07,
      "loss": 0.2531,
      "step": 2900
    },
    {
      "epoch": 9.815436241610739,
      "grad_norm": 0.6587285995483398,
      "learning_rate": 1.786775832454013e-07,
      "loss": 0.5665,
      "step": 2925
    },
    {
      "epoch": 9.899328859060402,
      "grad_norm": 0.674760639667511,
      "learning_rate": 5.317139849928543e-08,
      "loss": 0.3129,
      "step": 2950
    },
    {
      "epoch": 9.983221476510067,
      "grad_norm": 0.7908555865287781,
      "learning_rate": 1.4771105625421834e-09,
      "loss": 0.5456,
      "step": 2975
    }
  ],
  "logging_steps": 25,
  "max_steps": 2980,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4556929188155392e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
