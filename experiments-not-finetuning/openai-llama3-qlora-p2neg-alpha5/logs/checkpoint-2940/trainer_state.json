{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 2940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12755102040816327,
      "grad_norm": 0.3614782989025116,
      "learning_rate": 5.6179775280898885e-05,
      "loss": 2.35,
      "step": 25
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 0.28075671195983887,
      "learning_rate": 0.00011235955056179777,
      "loss": 2.0198,
      "step": 50
    },
    {
      "epoch": 0.3826530612244898,
      "grad_norm": 0.3462156653404236,
      "learning_rate": 0.00016853932584269662,
      "loss": 1.592,
      "step": 75
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.6713437438011169,
      "learning_rate": 0.00019999265392482905,
      "loss": 1.4287,
      "step": 100
    },
    {
      "epoch": 0.6377551020408163,
      "grad_norm": 0.3135395348072052,
      "learning_rate": 0.0001999213274253263,
      "loss": 1.4266,
      "step": 125
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 0.30341535806655884,
      "learning_rate": 0.00019977417529060088,
      "loss": 1.3656,
      "step": 150
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.3244628608226776,
      "learning_rate": 0.0001995513091875449,
      "loss": 1.3724,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3629565238952637,
      "eval_runtime": 106.4423,
      "eval_samples_per_second": 7.347,
      "eval_steps_per_second": 7.347,
      "step": 196
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.3185427784919739,
      "learning_rate": 0.00019925289823884994,
      "loss": 1.334,
      "step": 200
    },
    {
      "epoch": 1.1479591836734695,
      "grad_norm": 0.2897008955478668,
      "learning_rate": 0.00019887916889466752,
      "loss": 1.3502,
      "step": 225
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 0.3783699572086334,
      "learning_rate": 0.00019843040476076685,
      "loss": 1.3255,
      "step": 250
    },
    {
      "epoch": 1.403061224489796,
      "grad_norm": 0.327838659286499,
      "learning_rate": 0.00019790694638331956,
      "loss": 1.3275,
      "step": 275
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 0.32503533363342285,
      "learning_rate": 0.0001973091909904751,
      "loss": 1.3127,
      "step": 300
    },
    {
      "epoch": 1.6581632653061225,
      "grad_norm": 0.2835938036441803,
      "learning_rate": 0.00019663759219092279,
      "loss": 1.3209,
      "step": 325
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.3304169178009033,
      "learning_rate": 0.00019589265962966938,
      "loss": 1.3196,
      "step": 350
    },
    {
      "epoch": 1.913265306122449,
      "grad_norm": 0.3084571361541748,
      "learning_rate": 0.00019507495860129326,
      "loss": 1.3046,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3270364999771118,
      "eval_runtime": 106.4078,
      "eval_samples_per_second": 7.349,
      "eval_steps_per_second": 7.349,
      "step": 392
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.2829025983810425,
      "learning_rate": 0.00019418510962096862,
      "loss": 1.2934,
      "step": 400
    },
    {
      "epoch": 2.1683673469387754,
      "grad_norm": 0.2897942066192627,
      "learning_rate": 0.00019322378795358564,
      "loss": 1.2772,
      "step": 425
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 0.3191067576408386,
      "learning_rate": 0.00019219172310132326,
      "loss": 1.2896,
      "step": 450
    },
    {
      "epoch": 2.423469387755102,
      "grad_norm": 0.3333369791507721,
      "learning_rate": 0.00019108969825006419,
      "loss": 1.2808,
      "step": 475
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.32960373163223267,
      "learning_rate": 0.00018991854967507138,
      "loss": 1.2907,
      "step": 500
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.3025495409965515,
      "learning_rate": 0.00018867916610637808,
      "loss": 1.2599,
      "step": 525
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 0.29571348428726196,
      "learning_rate": 0.0001873724880543718,
      "loss": 1.284,
      "step": 550
    },
    {
      "epoch": 2.933673469387755,
      "grad_norm": 0.3189087212085724,
      "learning_rate": 0.00018599950709608505,
      "loss": 1.2553,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3119152784347534,
      "eval_runtime": 106.3866,
      "eval_samples_per_second": 7.351,
      "eval_steps_per_second": 7.351,
      "step": 588
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 0.3056214451789856,
      "learning_rate": 0.0001845612651227335,
      "loss": 1.2694,
      "step": 600
    },
    {
      "epoch": 3.188775510204082,
      "grad_norm": 0.3192959427833557,
      "learning_rate": 0.0001830588535490736,
      "loss": 1.2268,
      "step": 625
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 0.3486212193965912,
      "learning_rate": 0.00018149341248517868,
      "loss": 1.2688,
      "step": 650
    },
    {
      "epoch": 3.443877551020408,
      "grad_norm": 0.3328981399536133,
      "learning_rate": 0.00017986612987126263,
      "loss": 1.2283,
      "step": 675
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.2889304459095001,
      "learning_rate": 0.00017817824057620745,
      "loss": 1.2706,
      "step": 700
    },
    {
      "epoch": 3.6989795918367347,
      "grad_norm": 0.3222646415233612,
      "learning_rate": 0.0001764310254604789,
      "loss": 1.2266,
      "step": 725
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 0.2983824908733368,
      "learning_rate": 0.00017462581040414118,
      "loss": 1.2613,
      "step": 750
    },
    {
      "epoch": 3.954081632653061,
      "grad_norm": 0.31479597091674805,
      "learning_rate": 0.00017276396530070836,
      "loss": 1.1965,
      "step": 775
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3033231496810913,
      "eval_runtime": 106.3852,
      "eval_samples_per_second": 7.351,
      "eval_steps_per_second": 7.351,
      "step": 784
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.30120447278022766,
      "learning_rate": 0.00017084690301759613,
      "loss": 1.255,
      "step": 800
    },
    {
      "epoch": 4.209183673469388,
      "grad_norm": 0.3573090434074402,
      "learning_rate": 0.00016887607832396273,
      "loss": 1.1698,
      "step": 825
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 0.30842724442481995,
      "learning_rate": 0.00016685298678675213,
      "loss": 1.2351,
      "step": 850
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.33199915289878845,
      "learning_rate": 0.00016477916363577845,
      "loss": 1.1817,
      "step": 875
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 0.3646075427532196,
      "learning_rate": 0.0001626561825987114,
      "loss": 1.2452,
      "step": 900
    },
    {
      "epoch": 4.719387755102041,
      "grad_norm": 0.35207515954971313,
      "learning_rate": 0.00016048565470684772,
      "loss": 1.173,
      "step": 925
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 0.3116946816444397,
      "learning_rate": 0.00015826922707257488,
      "loss": 1.2647,
      "step": 950
    },
    {
      "epoch": 4.974489795918368,
      "grad_norm": 0.3760204315185547,
      "learning_rate": 0.0001560085816394541,
      "loss": 1.1609,
      "step": 975
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.2999722957611084,
      "eval_runtime": 106.4694,
      "eval_samples_per_second": 7.345,
      "eval_steps_per_second": 7.345,
      "step": 980
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 0.33652257919311523,
      "learning_rate": 0.00015370543390587192,
      "loss": 1.2347,
      "step": 1000
    },
    {
      "epoch": 5.229591836734694,
      "grad_norm": 0.40701818466186523,
      "learning_rate": 0.00015136153162322852,
      "loss": 1.1337,
      "step": 1025
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.354724645614624,
      "learning_rate": 0.00014897865346965054,
      "loss": 1.2217,
      "step": 1050
    },
    {
      "epoch": 5.48469387755102,
      "grad_norm": 0.4037845730781555,
      "learning_rate": 0.00014655860770023535,
      "loss": 1.1264,
      "step": 1075
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 0.3373859226703644,
      "learning_rate": 0.00014410323077485056,
      "loss": 1.2385,
      "step": 1100
    },
    {
      "epoch": 5.739795918367347,
      "grad_norm": 0.3206460177898407,
      "learning_rate": 0.0001416143859645303,
      "loss": 1.1317,
      "step": 1125
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 0.3230339288711548,
      "learning_rate": 0.00013909396193752556,
      "loss": 1.2286,
      "step": 1150
    },
    {
      "epoch": 5.994897959183674,
      "grad_norm": 0.39677631855010986,
      "learning_rate": 0.0001365438713260822,
      "loss": 1.1288,
      "step": 1175
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.304267406463623,
      "eval_runtime": 106.4334,
      "eval_samples_per_second": 7.347,
      "eval_steps_per_second": 7.347,
      "step": 1176
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 0.3631286025047302,
      "learning_rate": 0.00013396604927503337,
      "loss": 1.1936,
      "step": 1200
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.35820502042770386,
      "learning_rate": 0.00013136245197330836,
      "loss": 1.0996,
      "step": 1225
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 0.3526962399482727,
      "learning_rate": 0.0001287350551694721,
      "loss": 1.1943,
      "step": 1250
    },
    {
      "epoch": 6.505102040816326,
      "grad_norm": 0.41568654775619507,
      "learning_rate": 0.00012608585267242175,
      "loss": 1.1063,
      "step": 1275
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 0.38866758346557617,
      "learning_rate": 0.00012341685483837798,
      "loss": 1.1963,
      "step": 1300
    },
    {
      "epoch": 6.760204081632653,
      "grad_norm": 0.4376787841320038,
      "learning_rate": 0.0001207300870453196,
      "loss": 1.1265,
      "step": 1325
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 0.385017454624176,
      "learning_rate": 0.00011802758815601844,
      "loss": 1.1843,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3052129745483398,
      "eval_runtime": 106.4027,
      "eval_samples_per_second": 7.349,
      "eval_steps_per_second": 7.349,
      "step": 1372
    },
    {
      "epoch": 7.01530612244898,
      "grad_norm": 0.37693464756011963,
      "learning_rate": 0.00011531140897084166,
      "loss": 1.1205,
      "step": 1375
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.3790363669395447,
      "learning_rate": 0.00011258361067149494,
      "loss": 1.1635,
      "step": 1400
    },
    {
      "epoch": 7.270408163265306,
      "grad_norm": 0.4296123683452606,
      "learning_rate": 0.00010984626325688778,
      "loss": 1.0961,
      "step": 1425
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 0.40269845724105835,
      "learning_rate": 0.0001071014439723079,
      "loss": 1.1427,
      "step": 1450
    },
    {
      "epoch": 7.525510204081632,
      "grad_norm": 0.412614643573761,
      "learning_rate": 0.00010435123573309669,
      "loss": 1.1092,
      "step": 1475
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 0.40799570083618164,
      "learning_rate": 0.00010159772554402183,
      "loss": 1.1396,
      "step": 1500
    },
    {
      "epoch": 7.780612244897959,
      "grad_norm": 0.39917469024658203,
      "learning_rate": 9.884300291554685e-05,
      "loss": 1.1216,
      "step": 1525
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 0.41319534182548523,
      "learning_rate": 9.608915827819884e-05,
      "loss": 1.1203,
      "step": 1550
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3122042417526245,
      "eval_runtime": 106.4716,
      "eval_samples_per_second": 7.345,
      "eval_steps_per_second": 7.345,
      "step": 1568
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.3566397726535797,
      "learning_rate": 9.333828139623851e-05,
      "loss": 1.1162,
      "step": 1575
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.3896017074584961,
      "learning_rate": 9.059245978183544e-05,
      "loss": 1.1184,
      "step": 1600
    },
    {
      "epoch": 8.290816326530612,
      "grad_norm": 0.3800445795059204,
      "learning_rate": 8.785377711095224e-05,
      "loss": 1.1009,
      "step": 1625
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 0.4193876385688782,
      "learning_rate": 8.51243116421404e-05,
      "loss": 1.1028,
      "step": 1650
    },
    {
      "epoch": 8.545918367346939,
      "grad_norm": 0.4310135245323181,
      "learning_rate": 8.240613463944659e-05,
      "loss": 1.0993,
      "step": 1675
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 0.4155815839767456,
      "learning_rate": 7.9701308800627e-05,
      "loss": 1.1003,
      "step": 1700
    },
    {
      "epoch": 8.801020408163264,
      "grad_norm": 0.3784891963005066,
      "learning_rate": 7.701188669186231e-05,
      "loss": 1.1082,
      "step": 1725
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.44730132818222046,
      "learning_rate": 7.433990919016067e-05,
      "loss": 1.0792,
      "step": 1750
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3179476261138916,
      "eval_runtime": 106.477,
      "eval_samples_per_second": 7.344,
      "eval_steps_per_second": 7.344,
      "step": 1764
    },
    {
      "epoch": 9.056122448979592,
      "grad_norm": 0.402185320854187,
      "learning_rate": 7.168740393463173e-05,
      "loss": 1.0889,
      "step": 1775
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 0.46223247051239014,
      "learning_rate": 6.905638378780558e-05,
      "loss": 1.0658,
      "step": 1800
    },
    {
      "epoch": 9.311224489795919,
      "grad_norm": 0.4014389216899872,
      "learning_rate": 6.644884530816531e-05,
      "loss": 1.0991,
      "step": 1825
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 0.4789445996284485,
      "learning_rate": 6.386676723505208e-05,
      "loss": 1.0696,
      "step": 1850
    },
    {
      "epoch": 9.566326530612244,
      "grad_norm": 0.40437954664230347,
      "learning_rate": 6.13121089870917e-05,
      "loss": 1.0982,
      "step": 1875
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 0.4736518859863281,
      "learning_rate": 5.878680917528374e-05,
      "loss": 1.0551,
      "step": 1900
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.4289851784706116,
      "learning_rate": 5.629278413187965e-05,
      "loss": 1.0977,
      "step": 1925
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 0.45938724279403687,
      "learning_rate": 5.3831926456167825e-05,
      "loss": 1.0492,
      "step": 1950
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.323463797569275,
      "eval_runtime": 106.4882,
      "eval_samples_per_second": 7.344,
      "eval_steps_per_second": 7.344,
      "step": 1960
    },
    {
      "epoch": 10.076530612244898,
      "grad_norm": 0.42084309458732605,
      "learning_rate": 5.1406103578268184e-05,
      "loss": 1.0984,
      "step": 1975
    },
    {
      "epoch": 10.204081632653061,
      "grad_norm": 0.4796430170536041,
      "learning_rate": 4.901715634202644e-05,
      "loss": 1.0376,
      "step": 2000
    },
    {
      "epoch": 10.331632653061224,
      "grad_norm": 0.47132208943367004,
      "learning_rate": 4.666689760808384e-05,
      "loss": 1.0852,
      "step": 2025
    },
    {
      "epoch": 10.459183673469388,
      "grad_norm": 0.5166293978691101,
      "learning_rate": 4.4357110878181415e-05,
      "loss": 1.0354,
      "step": 2050
    },
    {
      "epoch": 10.58673469387755,
      "grad_norm": 0.4415954053401947,
      "learning_rate": 4.2089548941744026e-05,
      "loss": 1.1002,
      "step": 2075
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.5006690621376038,
      "learning_rate": 3.986593254577e-05,
      "loss": 1.0165,
      "step": 2100
    },
    {
      "epoch": 10.841836734693878,
      "grad_norm": 0.46521836519241333,
      "learning_rate": 3.7687949089036576e-05,
      "loss": 1.0989,
      "step": 2125
    },
    {
      "epoch": 10.96938775510204,
      "grad_norm": 0.5160689949989319,
      "learning_rate": 3.555725134161165e-05,
      "loss": 1.021,
      "step": 2150
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3304423093795776,
      "eval_runtime": 106.4997,
      "eval_samples_per_second": 7.343,
      "eval_steps_per_second": 7.343,
      "step": 2156
    },
    {
      "epoch": 11.096938775510203,
      "grad_norm": 0.46847525238990784,
      "learning_rate": 3.347545619064357e-05,
      "loss": 1.1031,
      "step": 2175
    },
    {
      "epoch": 11.224489795918368,
      "grad_norm": 0.5156263113021851,
      "learning_rate": 3.144414341338108e-05,
      "loss": 1.0156,
      "step": 2200
    },
    {
      "epoch": 11.35204081632653,
      "grad_norm": 0.46012452244758606,
      "learning_rate": 2.9464854478353875e-05,
      "loss": 1.0898,
      "step": 2225
    },
    {
      "epoch": 11.479591836734693,
      "grad_norm": 0.5594157576560974,
      "learning_rate": 2.753909137562405e-05,
      "loss": 0.9819,
      "step": 2250
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.4896301031112671,
      "learning_rate": 2.5668315476995997e-05,
      "loss": 1.0935,
      "step": 2275
    },
    {
      "epoch": 11.73469387755102,
      "grad_norm": 0.5999653935432434,
      "learning_rate": 2.3853946427049344e-05,
      "loss": 0.9964,
      "step": 2300
    },
    {
      "epoch": 11.862244897959183,
      "grad_norm": 0.45935922861099243,
      "learning_rate": 2.209736106583703e-05,
      "loss": 1.1092,
      "step": 2325
    },
    {
      "epoch": 11.989795918367347,
      "grad_norm": 0.48990121483802795,
      "learning_rate": 2.0399892384065578e-05,
      "loss": 0.9863,
      "step": 2350
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.332013726234436,
      "eval_runtime": 106.6238,
      "eval_samples_per_second": 7.334,
      "eval_steps_per_second": 7.334,
      "step": 2352
    },
    {
      "epoch": 12.11734693877551,
      "grad_norm": 0.48570555448532104,
      "learning_rate": 1.8762828511550457e-05,
      "loss": 1.0906,
      "step": 2375
    },
    {
      "epoch": 12.244897959183673,
      "grad_norm": 0.6125097870826721,
      "learning_rate": 1.718741173971471e-05,
      "loss": 0.9806,
      "step": 2400
    },
    {
      "epoch": 12.372448979591837,
      "grad_norm": 0.47158241271972656,
      "learning_rate": 1.5674837578871693e-05,
      "loss": 1.0783,
      "step": 2425
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.4420109689235687,
      "learning_rate": 1.422625385100822e-05,
      "loss": 0.9811,
      "step": 2450
    },
    {
      "epoch": 12.627551020408163,
      "grad_norm": 0.4905276894569397,
      "learning_rate": 1.28427598187559e-05,
      "loss": 1.1087,
      "step": 2475
    },
    {
      "epoch": 12.755102040816327,
      "grad_norm": 0.4590456783771515,
      "learning_rate": 1.152540535121196e-05,
      "loss": 1.0108,
      "step": 2500
    },
    {
      "epoch": 12.88265306122449,
      "grad_norm": 0.4615951180458069,
      "learning_rate": 1.0275190127242696e-05,
      "loss": 1.0729,
      "step": 2525
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3308759927749634,
      "eval_runtime": 106.5473,
      "eval_samples_per_second": 7.339,
      "eval_steps_per_second": 7.339,
      "step": 2548
    },
    {
      "epoch": 13.010204081632653,
      "grad_norm": 0.43507251143455505,
      "learning_rate": 9.093062876873625e-06,
      "loss": 0.9971,
      "step": 2550
    },
    {
      "epoch": 13.137755102040817,
      "grad_norm": 0.4882938265800476,
      "learning_rate": 7.979920661342677e-06,
      "loss": 1.0754,
      "step": 2575
    },
    {
      "epoch": 13.26530612244898,
      "grad_norm": 0.4593299329280853,
      "learning_rate": 6.936608192362182e-06,
      "loss": 0.994,
      "step": 2600
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.46545979380607605,
      "learning_rate": 5.963917191106494e-06,
      "loss": 1.0772,
      "step": 2625
    },
    {
      "epoch": 13.520408163265307,
      "grad_norm": 0.47057342529296875,
      "learning_rate": 5.062585787411833e-06,
      "loss": 1.0052,
      "step": 2650
    },
    {
      "epoch": 13.64795918367347,
      "grad_norm": 0.48100072145462036,
      "learning_rate": 4.233297959643912e-06,
      "loss": 1.0499,
      "step": 2675
    },
    {
      "epoch": 13.775510204081632,
      "grad_norm": 0.4764530658721924,
      "learning_rate": 3.476683015658644e-06,
      "loss": 1.0279,
      "step": 2700
    },
    {
      "epoch": 13.903061224489797,
      "grad_norm": 0.49298807978630066,
      "learning_rate": 2.793315115249806e-06,
      "loss": 1.0352,
      "step": 2725
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3314107656478882,
      "eval_runtime": 106.5758,
      "eval_samples_per_second": 7.338,
      "eval_steps_per_second": 7.338,
      "step": 2744
    },
    {
      "epoch": 14.03061224489796,
      "grad_norm": 0.462211549282074,
      "learning_rate": 2.1837128344458723e-06,
      "loss": 1.015,
      "step": 2750
    },
    {
      "epoch": 14.158163265306122,
      "grad_norm": 0.4886552095413208,
      "learning_rate": 1.648338771986957e-06,
      "loss": 1.0535,
      "step": 2775
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.45101138949394226,
      "learning_rate": 1.1875991982801093e-06,
      "loss": 1.0233,
      "step": 2800
    },
    {
      "epoch": 14.41326530612245,
      "grad_norm": 0.49184051156044006,
      "learning_rate": 8.018437470997176e-07,
      "loss": 1.0479,
      "step": 2825
    },
    {
      "epoch": 14.540816326530612,
      "grad_norm": 0.47644171118736267,
      "learning_rate": 4.913651502667094e-07,
      "loss": 1.027,
      "step": 2850
    },
    {
      "epoch": 14.668367346938776,
      "grad_norm": 0.49657660722732544,
      "learning_rate": 2.5639901550801317e-07,
      "loss": 1.023,
      "step": 2875
    },
    {
      "epoch": 14.795918367346939,
      "grad_norm": 0.4942190647125244,
      "learning_rate": 9.712364766489845e-08,
      "loss": 1.0264,
      "step": 2900
    },
    {
      "epoch": 14.923469387755102,
      "grad_norm": 0.5009911060333252,
      "learning_rate": 1.36599133856663e-08,
      "loss": 1.0143,
      "step": 2925
    }
  ],
  "logging_steps": 25,
  "max_steps": 2940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.4507314202640384e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
