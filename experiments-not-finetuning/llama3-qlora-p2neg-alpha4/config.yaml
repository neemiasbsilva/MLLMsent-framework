experiment_name: "Experiment using LLama3 Finetuning with QlORA"
learning_rate: 1e-3
batch_size: 16
epochs: 100
model_path: "nvidia/Llama3-ChatQA-1.5-8B"
model_name: "llama-qlora"
max_len: 1024
log_dir: "experiments-not-finetuning/llama3-qlora-p2neg-alpha4/logs"
checkpoint_dir: "checkpoints"