{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06377551020408163,
      "grad_norm": 0.5966088771820068,
      "learning_rate": 4.2372881355932206e-05,
      "loss": 1.2247,
      "step": 25
    },
    {
      "epoch": 0.12755102040816327,
      "grad_norm": 1.4774997234344482,
      "learning_rate": 8.474576271186441e-05,
      "loss": 2.3191,
      "step": 50
    },
    {
      "epoch": 0.1913265306122449,
      "grad_norm": 0.4824703633785248,
      "learning_rate": 0.0001271186440677966,
      "loss": 0.7561,
      "step": 75
    },
    {
      "epoch": 0.25510204081632654,
      "grad_norm": 1.348607063293457,
      "learning_rate": 0.00016949152542372882,
      "loss": 1.1259,
      "step": 100
    },
    {
      "epoch": 0.31887755102040816,
      "grad_norm": 0.7881049513816833,
      "learning_rate": 0.00019999832721396613,
      "loss": 0.6461,
      "step": 125
    },
    {
      "epoch": 0.3826530612244898,
      "grad_norm": 0.5594185590744019,
      "learning_rate": 0.00019996504412499123,
      "loss": 0.9961,
      "step": 150
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.41041460633277893,
      "learning_rate": 0.00019988910423768903,
      "loss": 0.5728,
      "step": 175
    },
    {
      "epoch": 0.5102040816326531,
      "grad_norm": 0.8379255533218384,
      "learning_rate": 0.00019977053995691156,
      "loss": 0.9073,
      "step": 200
    },
    {
      "epoch": 0.5739795918367347,
      "grad_norm": 0.3943566679954529,
      "learning_rate": 0.00019960940187607027,
      "loss": 0.6368,
      "step": 225
    },
    {
      "epoch": 0.6377551020408163,
      "grad_norm": 0.6704722046852112,
      "learning_rate": 0.00019940575875554715,
      "loss": 0.9156,
      "step": 250
    },
    {
      "epoch": 0.701530612244898,
      "grad_norm": 0.32276493310928345,
      "learning_rate": 0.00019915969749335343,
      "loss": 0.5163,
      "step": 275
    },
    {
      "epoch": 0.7653061224489796,
      "grad_norm": 0.5066909790039062,
      "learning_rate": 0.0001988713230880486,
      "loss": 0.9211,
      "step": 300
    },
    {
      "epoch": 0.8290816326530612,
      "grad_norm": 0.32851243019104004,
      "learning_rate": 0.00019854075859393588,
      "loss": 0.5795,
      "step": 325
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.9266241788864136,
      "learning_rate": 0.00019816814506855277,
      "loss": 0.8894,
      "step": 350
    },
    {
      "epoch": 0.9566326530612245,
      "grad_norm": 0.3365543484687805,
      "learning_rate": 0.0001977536415124794,
      "loss": 0.669,
      "step": 375
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8177659511566162,
      "eval_runtime": 174.4611,
      "eval_samples_per_second": 4.488,
      "eval_steps_per_second": 4.488,
      "step": 392
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.10270615667104721,
      "learning_rate": 0.00019729742480149013,
      "loss": 0.6859,
      "step": 400
    },
    {
      "epoch": 1.0841836734693877,
      "grad_norm": 0.35962149500846863,
      "learning_rate": 0.00019679968961107793,
      "loss": 0.7688,
      "step": 425
    },
    {
      "epoch": 1.1479591836734695,
      "grad_norm": 0.09015129506587982,
      "learning_rate": 0.0001962606483333827,
      "loss": 0.6365,
      "step": 450
    },
    {
      "epoch": 1.211734693877551,
      "grad_norm": 0.40111127495765686,
      "learning_rate": 0.00019568053098655992,
      "loss": 0.8091,
      "step": 475
    },
    {
      "epoch": 1.2755102040816326,
      "grad_norm": 0.10306020081043243,
      "learning_rate": 0.00019505958511662828,
      "loss": 0.6113,
      "step": 500
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.36426010727882385,
      "learning_rate": 0.00019439807569183713,
      "loss": 0.7648,
      "step": 525
    },
    {
      "epoch": 1.403061224489796,
      "grad_norm": 0.11241351068019867,
      "learning_rate": 0.00019369628498960032,
      "loss": 0.6408,
      "step": 550
    },
    {
      "epoch": 1.4668367346938775,
      "grad_norm": 0.38250041007995605,
      "learning_rate": 0.00019295451247604333,
      "loss": 0.7753,
      "step": 575
    },
    {
      "epoch": 1.5306122448979593,
      "grad_norm": 0.09220664948225021,
      "learning_rate": 0.00019217307467821616,
      "loss": 0.6581,
      "step": 600
    },
    {
      "epoch": 1.5943877551020407,
      "grad_norm": 0.37159422039985657,
      "learning_rate": 0.00019135230504902564,
      "loss": 0.7905,
      "step": 625
    },
    {
      "epoch": 1.6581632653061225,
      "grad_norm": 0.1059078574180603,
      "learning_rate": 0.00019049255382494544,
      "loss": 0.6093,
      "step": 650
    },
    {
      "epoch": 1.7219387755102042,
      "grad_norm": 0.38225257396698,
      "learning_rate": 0.0001895941878765642,
      "loss": 0.7564,
      "step": 675
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.1213507205247879,
      "learning_rate": 0.00018865759055203542,
      "loss": 0.6221,
      "step": 700
    },
    {
      "epoch": 1.8494897959183674,
      "grad_norm": 0.3746298849582672,
      "learning_rate": 0.00018768316151349638,
      "loss": 0.7904,
      "step": 725
    },
    {
      "epoch": 1.913265306122449,
      "grad_norm": 0.12849289178848267,
      "learning_rate": 0.00018667131656652537,
      "loss": 0.6293,
      "step": 750
    },
    {
      "epoch": 1.9770408163265305,
      "grad_norm": 0.3780854642391205,
      "learning_rate": 0.00018562248748271035,
      "loss": 0.8575,
      "step": 775
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7580245137214661,
      "eval_runtime": 174.4264,
      "eval_samples_per_second": 4.489,
      "eval_steps_per_second": 4.489,
      "step": 784
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.16421550512313843,
      "learning_rate": 0.00018453712181540455,
      "loss": 0.4042,
      "step": 800
    },
    {
      "epoch": 2.104591836734694,
      "grad_norm": 0.3844755291938782,
      "learning_rate": 0.0001834156827087479,
      "loss": 0.8818,
      "step": 825
    },
    {
      "epoch": 2.1683673469387754,
      "grad_norm": 0.1063128188252449,
      "learning_rate": 0.00018225864870003542,
      "loss": 0.3873,
      "step": 850
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.45037028193473816,
      "learning_rate": 0.00018106651351551705,
      "loss": 0.9121,
      "step": 875
    },
    {
      "epoch": 2.295918367346939,
      "grad_norm": 0.4148567020893097,
      "learning_rate": 0.0001798397858597164,
      "loss": 0.5015,
      "step": 900
    },
    {
      "epoch": 2.3596938775510203,
      "grad_norm": 0.3939257264137268,
      "learning_rate": 0.00017857898919835768,
      "loss": 0.8989,
      "step": 925
    },
    {
      "epoch": 2.423469387755102,
      "grad_norm": 0.3009501099586487,
      "learning_rate": 0.00017728466153499382,
      "loss": 0.3944,
      "step": 950
    },
    {
      "epoch": 2.487244897959184,
      "grad_norm": 0.4206462800502777,
      "learning_rate": 0.00017595735518143135,
      "loss": 0.9248,
      "step": 975
    },
    {
      "epoch": 2.5510204081632653,
      "grad_norm": 0.08360452204942703,
      "learning_rate": 0.00017459763652204928,
      "loss": 0.3959,
      "step": 1000
    },
    {
      "epoch": 2.614795918367347,
      "grad_norm": 0.41631126403808594,
      "learning_rate": 0.0001732060857721133,
      "loss": 0.8706,
      "step": 1025
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.2705481946468353,
      "learning_rate": 0.00017178329673018792,
      "loss": 0.4315,
      "step": 1050
    },
    {
      "epoch": 2.74234693877551,
      "grad_norm": 0.41790515184402466,
      "learning_rate": 0.00017032987652475248,
      "loss": 0.9062,
      "step": 1075
    },
    {
      "epoch": 2.806122448979592,
      "grad_norm": 0.07703805714845657,
      "learning_rate": 0.0001688464453551289,
      "loss": 0.3709,
      "step": 1100
    },
    {
      "epoch": 2.8698979591836737,
      "grad_norm": 0.43681883811950684,
      "learning_rate": 0.00016733363622683216,
      "loss": 0.9069,
      "step": 1125
    },
    {
      "epoch": 2.933673469387755,
      "grad_norm": 0.410645067691803,
      "learning_rate": 0.0001657920946814559,
      "loss": 0.4996,
      "step": 1150
    },
    {
      "epoch": 2.997448979591837,
      "grad_norm": 0.5219441056251526,
      "learning_rate": 0.00016422247852120885,
      "loss": 0.8505,
      "step": 1175
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7306146025657654,
      "eval_runtime": 174.6646,
      "eval_samples_per_second": 4.483,
      "eval_steps_per_second": 4.483,
      "step": 1176
    },
    {
      "epoch": 3.061224489795918,
      "grad_norm": 0.36409735679626465,
      "learning_rate": 0.00016262545752821912,
      "loss": 0.4503,
      "step": 1200
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.4686533510684967,
      "learning_rate": 0.00016100171317872696,
      "loss": 0.7729,
      "step": 1225
    },
    {
      "epoch": 3.188775510204082,
      "grad_norm": 0.3981759250164032,
      "learning_rate": 0.000159351938352287,
      "loss": 0.4463,
      "step": 1250
    },
    {
      "epoch": 3.252551020408163,
      "grad_norm": 0.47704023122787476,
      "learning_rate": 0.00015767683703610464,
      "loss": 0.7747,
      "step": 1275
    },
    {
      "epoch": 3.316326530612245,
      "grad_norm": 0.42207539081573486,
      "learning_rate": 0.00015597712402463284,
      "loss": 0.4309,
      "step": 1300
    },
    {
      "epoch": 3.3801020408163267,
      "grad_norm": 0.5247088670730591,
      "learning_rate": 0.00015425352461455677,
      "loss": 0.7437,
      "step": 1325
    },
    {
      "epoch": 3.443877551020408,
      "grad_norm": 0.40786364674568176,
      "learning_rate": 0.00015250677429529756,
      "loss": 0.4975,
      "step": 1350
    },
    {
      "epoch": 3.50765306122449,
      "grad_norm": 0.4883731007575989,
      "learning_rate": 0.00015073761843516619,
      "loss": 0.7518,
      "step": 1375
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.3982093632221222,
      "learning_rate": 0.0001489468119633021,
      "loss": 0.4289,
      "step": 1400
    },
    {
      "epoch": 3.635204081632653,
      "grad_norm": 0.5080313086509705,
      "learning_rate": 0.00014713511904753196,
      "loss": 0.7607,
      "step": 1425
    },
    {
      "epoch": 3.6989795918367347,
      "grad_norm": 0.4295051395893097,
      "learning_rate": 0.0001453033127682862,
      "loss": 0.5179,
      "step": 1450
    },
    {
      "epoch": 3.762755102040816,
      "grad_norm": 0.45285189151763916,
      "learning_rate": 0.00014345217478871228,
      "loss": 0.7423,
      "step": 1475
    },
    {
      "epoch": 3.826530612244898,
      "grad_norm": 0.4104611575603485,
      "learning_rate": 0.0001415824950211257,
      "loss": 0.5186,
      "step": 1500
    },
    {
      "epoch": 3.8903061224489797,
      "grad_norm": 0.5053865313529968,
      "learning_rate": 0.00013969507128994078,
      "loss": 0.7651,
      "step": 1525
    },
    {
      "epoch": 3.954081632653061,
      "grad_norm": 0.43168365955352783,
      "learning_rate": 0.00013779070899122537,
      "loss": 0.5498,
      "step": 1550
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7160555720329285,
      "eval_runtime": 174.6939,
      "eval_samples_per_second": 4.482,
      "eval_steps_per_second": 4.482,
      "step": 1568
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.10391318053007126,
      "learning_rate": 0.00013587022074902443,
      "loss": 0.5659,
      "step": 1575
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.4272443652153015,
      "learning_rate": 0.00013393442606859964,
      "loss": 0.5757,
      "step": 1600
    },
    {
      "epoch": 4.145408163265306,
      "grad_norm": 0.11848833411931992,
      "learning_rate": 0.00013198415098673223,
      "loss": 0.5119,
      "step": 1625
    },
    {
      "epoch": 4.209183673469388,
      "grad_norm": 0.4660876989364624,
      "learning_rate": 0.00013002022771923898,
      "loss": 0.6673,
      "step": 1650
    },
    {
      "epoch": 4.2729591836734695,
      "grad_norm": 0.10726013034582138,
      "learning_rate": 0.0001280434943058516,
      "loss": 0.5206,
      "step": 1675
    },
    {
      "epoch": 4.336734693877551,
      "grad_norm": 0.4430413842201233,
      "learning_rate": 0.00012605479425261052,
      "loss": 0.6037,
      "step": 1700
    },
    {
      "epoch": 4.400510204081632,
      "grad_norm": 0.1210990771651268,
      "learning_rate": 0.0001240549761719268,
      "loss": 0.536,
      "step": 1725
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.47605860233306885,
      "learning_rate": 0.00012204489342046424,
      "loss": 0.6149,
      "step": 1750
    },
    {
      "epoch": 4.528061224489796,
      "grad_norm": 0.13267722725868225,
      "learning_rate": 0.00012002540373499775,
      "loss": 0.5352,
      "step": 1775
    },
    {
      "epoch": 4.591836734693878,
      "grad_norm": 0.48903146386146545,
      "learning_rate": 0.00011799736886640227,
      "loss": 0.6186,
      "step": 1800
    },
    {
      "epoch": 4.655612244897959,
      "grad_norm": 0.14083446562290192,
      "learning_rate": 0.00011596165421192889,
      "loss": 0.534,
      "step": 1825
    },
    {
      "epoch": 4.719387755102041,
      "grad_norm": 0.49569839239120483,
      "learning_rate": 0.00011391912844592499,
      "loss": 0.6073,
      "step": 1850
    },
    {
      "epoch": 4.783163265306122,
      "grad_norm": 0.11663126200437546,
      "learning_rate": 0.00011187066314915607,
      "loss": 0.5326,
      "step": 1875
    },
    {
      "epoch": 4.846938775510204,
      "grad_norm": 0.47409895062446594,
      "learning_rate": 0.00010981713243688716,
      "loss": 0.643,
      "step": 1900
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 0.12255717068910599,
      "learning_rate": 0.00010775941258588303,
      "loss": 0.5271,
      "step": 1925
    },
    {
      "epoch": 4.974489795918368,
      "grad_norm": 0.4873335361480713,
      "learning_rate": 0.00010569838166048573,
      "loss": 0.6059,
      "step": 1950
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7151332497596741,
      "eval_runtime": 174.4481,
      "eval_samples_per_second": 4.488,
      "eval_steps_per_second": 4.488,
      "step": 1960
    },
    {
      "epoch": 5.038265306122449,
      "grad_norm": 0.3408243656158447,
      "learning_rate": 0.00010363491913792955,
      "loss": 0.3833,
      "step": 1975
    },
    {
      "epoch": 5.1020408163265305,
      "grad_norm": 0.5477519035339355,
      "learning_rate": 0.00010156990553305295,
      "loss": 0.7555,
      "step": 2000
    },
    {
      "epoch": 5.165816326530612,
      "grad_norm": 0.14079590141773224,
      "learning_rate": 9.950422202256781e-05,
      "loss": 0.3294,
      "step": 2025
    },
    {
      "epoch": 5.229591836734694,
      "grad_norm": 0.5708172917366028,
      "learning_rate": 9.743875006904625e-05,
      "loss": 0.6952,
      "step": 2050
    },
    {
      "epoch": 5.293367346938775,
      "grad_norm": 0.10973412543535233,
      "learning_rate": 9.537437104478538e-05,
      "loss": 0.3369,
      "step": 2075
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.5967990756034851,
      "learning_rate": 9.331196585571065e-05,
      "loss": 0.7095,
      "step": 2100
    },
    {
      "epoch": 5.420918367346939,
      "grad_norm": 0.5522977113723755,
      "learning_rate": 9.125241456547825e-05,
      "loss": 0.3702,
      "step": 2125
    },
    {
      "epoch": 5.48469387755102,
      "grad_norm": 0.5437604784965515,
      "learning_rate": 8.91965960199367e-05,
      "loss": 0.7415,
      "step": 2150
    },
    {
      "epoch": 5.548469387755102,
      "grad_norm": 0.12081276625394821,
      "learning_rate": 8.714538747210847e-05,
      "loss": 0.327,
      "step": 2175
    },
    {
      "epoch": 5.612244897959184,
      "grad_norm": 0.6121390461921692,
      "learning_rate": 8.509966420785086e-05,
      "loss": 0.7074,
      "step": 2200
    },
    {
      "epoch": 5.676020408163265,
      "grad_norm": 0.1267908215522766,
      "learning_rate": 8.30602991723567e-05,
      "loss": 0.3345,
      "step": 2225
    },
    {
      "epoch": 5.739795918367347,
      "grad_norm": 0.6069177389144897,
      "learning_rate": 8.102816259765353e-05,
      "loss": 0.6963,
      "step": 2250
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 0.14999713003635406,
      "learning_rate": 7.900412163126081e-05,
      "loss": 0.3347,
      "step": 2275
    },
    {
      "epoch": 5.86734693877551,
      "grad_norm": 0.5823764204978943,
      "learning_rate": 7.698903996616302e-05,
      "loss": 0.7164,
      "step": 2300
    },
    {
      "epoch": 5.9311224489795915,
      "grad_norm": 0.5484133362770081,
      "learning_rate": 7.498377747225725e-05,
      "loss": 0.4102,
      "step": 2325
    },
    {
      "epoch": 5.994897959183674,
      "grad_norm": 0.5999248027801514,
      "learning_rate": 7.298918982943185e-05,
      "loss": 0.6953,
      "step": 2350
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7258305549621582,
      "eval_runtime": 174.4445,
      "eval_samples_per_second": 4.489,
      "eval_steps_per_second": 4.489,
      "step": 2352
    },
    {
      "epoch": 6.058673469387755,
      "grad_norm": 0.5548993945121765,
      "learning_rate": 7.100612816243317e-05,
      "loss": 0.3956,
      "step": 2375
    },
    {
      "epoch": 6.122448979591836,
      "grad_norm": 0.6250448226928711,
      "learning_rate": 6.903543867767607e-05,
      "loss": 0.5919,
      "step": 2400
    },
    {
      "epoch": 6.186224489795919,
      "grad_norm": 0.6117628812789917,
      "learning_rate": 6.70779623021531e-05,
      "loss": 0.3937,
      "step": 2425
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.6250765323638916,
      "learning_rate": 6.513453432459662e-05,
      "loss": 0.5983,
      "step": 2450
    },
    {
      "epoch": 6.313775510204081,
      "grad_norm": 0.6168904900550842,
      "learning_rate": 6.320598403904654e-05,
      "loss": 0.3846,
      "step": 2475
    },
    {
      "epoch": 6.377551020408164,
      "grad_norm": 0.6357366442680359,
      "learning_rate": 6.129313439097663e-05,
      "loss": 0.5845,
      "step": 2500
    },
    {
      "epoch": 6.441326530612245,
      "grad_norm": 0.5586533546447754,
      "learning_rate": 5.939680162612943e-05,
      "loss": 0.3627,
      "step": 2525
    },
    {
      "epoch": 6.505102040816326,
      "grad_norm": 0.7397847175598145,
      "learning_rate": 5.75177949422102e-05,
      "loss": 0.6149,
      "step": 2550
    },
    {
      "epoch": 6.5688775510204085,
      "grad_norm": 0.6719878911972046,
      "learning_rate": 5.5656916143588364e-05,
      "loss": 0.4253,
      "step": 2575
    },
    {
      "epoch": 6.63265306122449,
      "grad_norm": 0.702318012714386,
      "learning_rate": 5.38149592991539e-05,
      "loss": 0.6104,
      "step": 2600
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 0.6330733895301819,
      "learning_rate": 5.199271040347451e-05,
      "loss": 0.3628,
      "step": 2625
    },
    {
      "epoch": 6.760204081632653,
      "grad_norm": 0.7147005200386047,
      "learning_rate": 5.0190947041398216e-05,
      "loss": 0.6389,
      "step": 2650
    },
    {
      "epoch": 6.823979591836735,
      "grad_norm": 0.6695539355278015,
      "learning_rate": 4.841043805624463e-05,
      "loss": 0.44,
      "step": 2675
    },
    {
      "epoch": 6.887755102040816,
      "grad_norm": 0.702112078666687,
      "learning_rate": 4.6651943221726294e-05,
      "loss": 0.586,
      "step": 2700
    },
    {
      "epoch": 6.951530612244898,
      "grad_norm": 0.638588547706604,
      "learning_rate": 4.491621291774022e-05,
      "loss": 0.3866,
      "step": 2725
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7432401180267334,
      "eval_runtime": 174.5129,
      "eval_samples_per_second": 4.487,
      "eval_steps_per_second": 4.487,
      "step": 2744
    },
    {
      "epoch": 7.01530612244898,
      "grad_norm": 0.1333962380886078,
      "learning_rate": 4.320398781016793e-05,
      "loss": 0.4673,
      "step": 2750
    },
    {
      "epoch": 7.079081632653061,
      "grad_norm": 0.6335510015487671,
      "learning_rate": 4.1515998534820657e-05,
      "loss": 0.5056,
      "step": 2775
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.1604587435722351,
      "learning_rate": 3.9852965385664344e-05,
      "loss": 0.4371,
      "step": 2800
    },
    {
      "epoch": 7.206632653061225,
      "grad_norm": 0.6566039323806763,
      "learning_rate": 3.8215598007458106e-05,
      "loss": 0.4869,
      "step": 2825
    },
    {
      "epoch": 7.270408163265306,
      "grad_norm": 0.1486763209104538,
      "learning_rate": 3.660459509293652e-05,
      "loss": 0.4257,
      "step": 2850
    },
    {
      "epoch": 7.334183673469388,
      "grad_norm": 0.6496963500976562,
      "learning_rate": 3.502064408466543e-05,
      "loss": 0.5139,
      "step": 2875
    },
    {
      "epoch": 7.3979591836734695,
      "grad_norm": 0.18598748743534088,
      "learning_rate": 3.346442088169847e-05,
      "loss": 0.4411,
      "step": 2900
    },
    {
      "epoch": 7.461734693877551,
      "grad_norm": 0.7271788716316223,
      "learning_rate": 3.193658955115932e-05,
      "loss": 0.4711,
      "step": 2925
    },
    {
      "epoch": 7.525510204081632,
      "grad_norm": 0.15797527134418488,
      "learning_rate": 3.043780204487292e-05,
      "loss": 0.4412,
      "step": 2950
    },
    {
      "epoch": 7.589285714285714,
      "grad_norm": 0.6795424222946167,
      "learning_rate": 2.8968697921166356e-05,
      "loss": 0.4953,
      "step": 2975
    },
    {
      "epoch": 7.653061224489796,
      "grad_norm": 0.17311052978038788,
      "learning_rate": 2.7529904071958467e-05,
      "loss": 0.4387,
      "step": 3000
    },
    {
      "epoch": 7.716836734693878,
      "grad_norm": 0.7357637286186218,
      "learning_rate": 2.612203445525424e-05,
      "loss": 0.489,
      "step": 3025
    },
    {
      "epoch": 7.780612244897959,
      "grad_norm": 0.15461890399456024,
      "learning_rate": 2.474568983315845e-05,
      "loss": 0.4323,
      "step": 3050
    },
    {
      "epoch": 7.844387755102041,
      "grad_norm": 0.74993497133255,
      "learning_rate": 2.340145751552011e-05,
      "loss": 0.5244,
      "step": 3075
    },
    {
      "epoch": 7.908163265306122,
      "grad_norm": 0.15872089564800262,
      "learning_rate": 2.2089911109317364e-05,
      "loss": 0.4336,
      "step": 3100
    },
    {
      "epoch": 7.971938775510204,
      "grad_norm": 0.7096872329711914,
      "learning_rate": 2.0811610273889492e-05,
      "loss": 0.555,
      "step": 3125
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7587184906005859,
      "eval_runtime": 174.3982,
      "eval_samples_per_second": 4.49,
      "eval_steps_per_second": 4.49,
      "step": 3136
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.15464112162590027,
      "learning_rate": 1.9567100482120672e-05,
      "loss": 0.3047,
      "step": 3150
    },
    {
      "epoch": 8.099489795918368,
      "grad_norm": 0.8037974834442139,
      "learning_rate": 1.8356912787677415e-05,
      "loss": 0.6238,
      "step": 3175
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.18136140704154968,
      "learning_rate": 1.7181563598398786e-05,
      "loss": 0.2909,
      "step": 3200
    },
    {
      "epoch": 8.22704081632653,
      "grad_norm": 0.7242911458015442,
      "learning_rate": 1.6041554455936392e-05,
      "loss": 0.5739,
      "step": 3225
    },
    {
      "epoch": 8.290816326530612,
      "grad_norm": 0.19893699884414673,
      "learning_rate": 1.4937371821737888e-05,
      "loss": 0.3118,
      "step": 3250
    },
    {
      "epoch": 8.354591836734693,
      "grad_norm": 0.7528952360153198,
      "learning_rate": 1.3869486869465598e-05,
      "loss": 0.609,
      "step": 3275
    },
    {
      "epoch": 8.418367346938776,
      "grad_norm": 0.1523105502128601,
      "learning_rate": 1.2838355283938574e-05,
      "loss": 0.2793,
      "step": 3300
    },
    {
      "epoch": 8.482142857142858,
      "grad_norm": 0.7315584421157837,
      "learning_rate": 1.1844417066684154e-05,
      "loss": 0.629,
      "step": 3325
    },
    {
      "epoch": 8.545918367346939,
      "grad_norm": 0.15772058069705963,
      "learning_rate": 1.0888096348181686e-05,
      "loss": 0.2968,
      "step": 3350
    },
    {
      "epoch": 8.60969387755102,
      "grad_norm": 0.738952100276947,
      "learning_rate": 9.969801206878782e-06,
      "loss": 0.5414,
      "step": 3375
    },
    {
      "epoch": 8.673469387755102,
      "grad_norm": 0.14571990072727203,
      "learning_rate": 9.08992349505734e-06,
      "loss": 0.2933,
      "step": 3400
    },
    {
      "epoch": 8.737244897959183,
      "grad_norm": 0.7181794047355652,
      "learning_rate": 8.24883867162336e-06,
      "loss": 0.5941,
      "step": 3425
    },
    {
      "epoch": 8.801020408163264,
      "grad_norm": 0.5416415929794312,
      "learning_rate": 7.4469056418922216e-06,
      "loss": 0.3252,
      "step": 3450
    },
    {
      "epoch": 8.864795918367347,
      "grad_norm": 0.7500798106193542,
      "learning_rate": 6.684466604437667e-06,
      "loss": 0.6269,
      "step": 3475
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.758876621723175,
      "learning_rate": 5.961846905069712e-06,
      "loss": 0.3542,
      "step": 3500
    },
    {
      "epoch": 8.99234693877551,
      "grad_norm": 0.8146296143531799,
      "learning_rate": 5.279354898004119e-06,
      "loss": 0.5876,
      "step": 3525
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7678524851799011,
      "eval_runtime": 174.4213,
      "eval_samples_per_second": 4.489,
      "eval_steps_per_second": 4.489,
      "step": 3528
    },
    {
      "epoch": 9.056122448979592,
      "grad_norm": 0.736723780632019,
      "learning_rate": 4.637281814282291e-06,
      "loss": 0.3455,
      "step": 3550
    },
    {
      "epoch": 9.119897959183673,
      "grad_norm": 0.8601914644241333,
      "learning_rate": 4.035901637498052e-06,
      "loss": 0.5538,
      "step": 3575
    },
    {
      "epoch": 9.183673469387756,
      "grad_norm": 0.7410115003585815,
      "learning_rate": 3.475470986884066e-06,
      "loss": 0.3629,
      "step": 3600
    },
    {
      "epoch": 9.247448979591837,
      "grad_norm": 0.7163631916046143,
      "learning_rate": 2.956229007808098e-06,
      "loss": 0.5234,
      "step": 3625
    },
    {
      "epoch": 9.311224489795919,
      "grad_norm": 0.7004392147064209,
      "learning_rate": 2.47839726972553e-06,
      "loss": 0.3339,
      "step": 3650
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.8123171925544739,
      "learning_rate": 2.0421796716319054e-06,
      "loss": 0.5249,
      "step": 3675
    },
    {
      "epoch": 9.438775510204081,
      "grad_norm": 0.785848081111908,
      "learning_rate": 1.6477623550557041e-06,
      "loss": 0.3472,
      "step": 3700
    },
    {
      "epoch": 9.502551020408163,
      "grad_norm": 0.774048924446106,
      "learning_rate": 1.2953136246285914e-06,
      "loss": 0.5316,
      "step": 3725
    },
    {
      "epoch": 9.566326530612244,
      "grad_norm": 0.7518527507781982,
      "learning_rate": 9.849838762669095e-07,
      "loss": 0.3327,
      "step": 3750
    },
    {
      "epoch": 9.630102040816327,
      "grad_norm": 0.7675513029098511,
      "learning_rate": 7.169055329952046e-07,
      "loss": 0.5583,
      "step": 3775
    },
    {
      "epoch": 9.693877551020408,
      "grad_norm": 0.8291087746620178,
      "learning_rate": 4.911929884390043e-07,
      "loss": 0.3419,
      "step": 3800
    },
    {
      "epoch": 9.75765306122449,
      "grad_norm": 0.7662336230278015,
      "learning_rate": 3.079425580111428e-07,
      "loss": 0.5542,
      "step": 3825
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.7330746650695801,
      "learning_rate": 1.6723243781228138e-07,
      "loss": 0.3353,
      "step": 3850
    },
    {
      "epoch": 9.885204081632653,
      "grad_norm": 0.7736139297485352,
      "learning_rate": 6.912267126334416e-08,
      "loss": 0.5392,
      "step": 3875
    },
    {
      "epoch": 9.948979591836736,
      "grad_norm": 0.809109628200531,
      "learning_rate": 1.3655123483891086e-08,
      "loss": 0.3808,
      "step": 3900
    }
  ],
  "logging_steps": 25,
  "max_steps": 3920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1597108190208e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
