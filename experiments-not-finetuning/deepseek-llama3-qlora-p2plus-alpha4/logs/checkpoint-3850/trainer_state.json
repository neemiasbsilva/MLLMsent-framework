{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3850,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06493506493506493,
      "grad_norm": 0.5769344568252563,
      "learning_rate": 4.3103448275862066e-05,
      "loss": 1.2597,
      "step": 25
    },
    {
      "epoch": 0.12987012987012986,
      "grad_norm": 1.1974081993103027,
      "learning_rate": 8.620689655172413e-05,
      "loss": 2.3195,
      "step": 50
    },
    {
      "epoch": 0.19480519480519481,
      "grad_norm": 0.5932166576385498,
      "learning_rate": 0.0001293103448275862,
      "loss": 0.7345,
      "step": 75
    },
    {
      "epoch": 0.2597402597402597,
      "grad_norm": 1.1181615591049194,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.1549,
      "step": 100
    },
    {
      "epoch": 0.3246753246753247,
      "grad_norm": 0.6368694305419922,
      "learning_rate": 0.0001999971331559675,
      "loss": 0.5806,
      "step": 125
    },
    {
      "epoch": 0.38961038961038963,
      "grad_norm": 0.5435322523117065,
      "learning_rate": 0.00019995908812899443,
      "loss": 0.9532,
      "step": 150
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 0.37163737416267395,
      "learning_rate": 0.0001998768212008659,
      "loss": 0.6195,
      "step": 175
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 0.5594757795333862,
      "learning_rate": 0.00019975036876647138,
      "loss": 0.931,
      "step": 200
    },
    {
      "epoch": 0.5844155844155844,
      "grad_norm": 0.3724038600921631,
      "learning_rate": 0.00019957978676836858,
      "loss": 0.5716,
      "step": 225
    },
    {
      "epoch": 0.6493506493506493,
      "grad_norm": 0.6354805827140808,
      "learning_rate": 0.00019936515067203443,
      "loss": 0.9311,
      "step": 250
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.3671325445175171,
      "learning_rate": 0.00019910655543247917,
      "loss": 0.5793,
      "step": 275
    },
    {
      "epoch": 0.7792207792207793,
      "grad_norm": 0.6289963722229004,
      "learning_rate": 0.00019880411545223825,
      "loss": 0.9492,
      "step": 300
    },
    {
      "epoch": 0.8441558441558441,
      "grad_norm": 0.33702340722084045,
      "learning_rate": 0.00019845796453076063,
      "loss": 0.5869,
      "step": 325
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.4499896466732025,
      "learning_rate": 0.0001980682558052159,
      "loss": 0.9219,
      "step": 350
    },
    {
      "epoch": 0.974025974025974,
      "grad_norm": 0.34630143642425537,
      "learning_rate": 0.00019763516168274655,
      "loss": 0.7336,
      "step": 375
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7882766723632812,
      "eval_runtime": 171.3736,
      "eval_samples_per_second": 4.487,
      "eval_steps_per_second": 4.487,
      "step": 385
    },
    {
      "epoch": 1.0389610389610389,
      "grad_norm": 0.07886042445898056,
      "learning_rate": 0.00019715887376419472,
      "loss": 0.4583,
      "step": 400
    },
    {
      "epoch": 1.103896103896104,
      "grad_norm": 0.36949148774147034,
      "learning_rate": 0.00019663960275933837,
      "loss": 0.9733,
      "step": 425
    },
    {
      "epoch": 1.1688311688311688,
      "grad_norm": 0.09940449893474579,
      "learning_rate": 0.00019607757839367292,
      "loss": 0.4397,
      "step": 450
    },
    {
      "epoch": 1.2337662337662338,
      "grad_norm": 0.36401331424713135,
      "learning_rate": 0.00019547304930678095,
      "loss": 0.9053,
      "step": 475
    },
    {
      "epoch": 1.2987012987012987,
      "grad_norm": 0.39954137802124023,
      "learning_rate": 0.00019482628294233397,
      "loss": 0.4831,
      "step": 500
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.36545518040657043,
      "learning_rate": 0.0001941375654297752,
      "loss": 1.0006,
      "step": 525
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.16488224267959595,
      "learning_rate": 0.00019340720145773617,
      "loss": 0.4693,
      "step": 550
    },
    {
      "epoch": 1.4935064935064934,
      "grad_norm": 0.38617414236068726,
      "learning_rate": 0.00019263551413924222,
      "loss": 0.9981,
      "step": 575
    },
    {
      "epoch": 1.5584415584415585,
      "grad_norm": 0.07285630702972412,
      "learning_rate": 0.00019182284486876747,
      "loss": 0.452,
      "step": 600
    },
    {
      "epoch": 1.6233766233766234,
      "grad_norm": 0.366437703371048,
      "learning_rate": 0.00019096955317120178,
      "loss": 0.9426,
      "step": 625
    },
    {
      "epoch": 1.6883116883116882,
      "grad_norm": 0.35661932826042175,
      "learning_rate": 0.00019007601654279696,
      "loss": 0.4692,
      "step": 650
    },
    {
      "epoch": 1.7532467532467533,
      "grad_norm": 0.39444127678871155,
      "learning_rate": 0.00018914263028416248,
      "loss": 0.9787,
      "step": 675
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.080935537815094,
      "learning_rate": 0.00018816980732538454,
      "loss": 0.4242,
      "step": 700
    },
    {
      "epoch": 1.883116883116883,
      "grad_norm": 0.373905211687088,
      "learning_rate": 0.00018715797804334553,
      "loss": 0.9412,
      "step": 725
    },
    {
      "epoch": 1.948051948051948,
      "grad_norm": 0.398830384016037,
      "learning_rate": 0.0001861075900713256,
      "loss": 0.6597,
      "step": 750
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7384290099143982,
      "eval_runtime": 171.3373,
      "eval_samples_per_second": 4.488,
      "eval_steps_per_second": 4.488,
      "step": 770
    },
    {
      "epoch": 2.012987012987013,
      "grad_norm": 0.1051860973238945,
      "learning_rate": 0.00018501910810096953,
      "loss": 0.7427,
      "step": 775
    },
    {
      "epoch": 2.0779220779220777,
      "grad_norm": 0.3592473864555359,
      "learning_rate": 0.0001838930136767072,
      "loss": 0.6826,
      "step": 800
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.10861556977033615,
      "learning_rate": 0.00018272980498271828,
      "loss": 0.6569,
      "step": 825
    },
    {
      "epoch": 2.207792207792208,
      "grad_norm": 0.35072195529937744,
      "learning_rate": 0.00018152999662253555,
      "loss": 0.6651,
      "step": 850
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.10967449843883514,
      "learning_rate": 0.00018029411939138443,
      "loss": 0.6694,
      "step": 875
    },
    {
      "epoch": 2.3376623376623376,
      "grad_norm": 0.3539065718650818,
      "learning_rate": 0.00017902272004135896,
      "loss": 0.6286,
      "step": 900
    },
    {
      "epoch": 2.4025974025974026,
      "grad_norm": 0.12228324264287949,
      "learning_rate": 0.00017771636103953883,
      "loss": 0.688,
      "step": 925
    },
    {
      "epoch": 2.4675324675324677,
      "grad_norm": 0.417213499546051,
      "learning_rate": 0.00017637562031915384,
      "loss": 0.648,
      "step": 950
    },
    {
      "epoch": 2.5324675324675323,
      "grad_norm": 0.07943382859230042,
      "learning_rate": 0.00017500109102390625,
      "loss": 0.6719,
      "step": 975
    },
    {
      "epoch": 2.5974025974025974,
      "grad_norm": 0.3788596987724304,
      "learning_rate": 0.00017359338124556416,
      "loss": 0.6701,
      "step": 1000
    },
    {
      "epoch": 2.6623376623376624,
      "grad_norm": 0.11624301224946976,
      "learning_rate": 0.00017215311375494142,
      "loss": 0.6687,
      "step": 1025
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.3944137394428253,
      "learning_rate": 0.00017068092572638412,
      "loss": 0.6214,
      "step": 1050
    },
    {
      "epoch": 2.792207792207792,
      "grad_norm": 0.11445010453462601,
      "learning_rate": 0.00016917746845588442,
      "loss": 0.6638,
      "step": 1075
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.3497680127620697,
      "learning_rate": 0.0001676434070729473,
      "loss": 0.6959,
      "step": 1100
    },
    {
      "epoch": 2.9220779220779223,
      "grad_norm": 0.12714022397994995,
      "learning_rate": 0.00016607942024633732,
      "loss": 0.6314,
      "step": 1125
    },
    {
      "epoch": 2.987012987012987,
      "grad_norm": 0.37471288442611694,
      "learning_rate": 0.0001644861998838354,
      "loss": 0.7511,
      "step": 1150
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7088276743888855,
      "eval_runtime": 171.2255,
      "eval_samples_per_second": 4.491,
      "eval_steps_per_second": 4.491,
      "step": 1155
    },
    {
      "epoch": 3.051948051948052,
      "grad_norm": 0.3646588921546936,
      "learning_rate": 0.00016286445082613896,
      "loss": 0.4049,
      "step": 1175
    },
    {
      "epoch": 3.116883116883117,
      "grad_norm": 0.4494737684726715,
      "learning_rate": 0.00016121489053504034,
      "loss": 0.788,
      "step": 1200
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 0.41298148036003113,
      "learning_rate": 0.00015953824877602168,
      "loss": 0.4661,
      "step": 1225
    },
    {
      "epoch": 3.2467532467532467,
      "grad_norm": 0.4403100311756134,
      "learning_rate": 0.0001578352672954067,
      "loss": 0.797,
      "step": 1250
    },
    {
      "epoch": 3.311688311688312,
      "grad_norm": 0.3931910991668701,
      "learning_rate": 0.00015610669949221205,
      "loss": 0.4465,
      "step": 1275
    },
    {
      "epoch": 3.3766233766233764,
      "grad_norm": 0.44328024983406067,
      "learning_rate": 0.0001543533100848437,
      "loss": 0.8132,
      "step": 1300
    },
    {
      "epoch": 3.4415584415584415,
      "grad_norm": 0.4226623773574829,
      "learning_rate": 0.0001525758747727854,
      "loss": 0.4825,
      "step": 1325
    },
    {
      "epoch": 3.5064935064935066,
      "grad_norm": 0.43639370799064636,
      "learning_rate": 0.00015077517989342933,
      "loss": 0.797,
      "step": 1350
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.4230533242225647,
      "learning_rate": 0.00014895202207420026,
      "loss": 0.383,
      "step": 1375
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 0.48142072558403015,
      "learning_rate": 0.00014710720788012782,
      "loss": 0.8041,
      "step": 1400
    },
    {
      "epoch": 3.7012987012987013,
      "grad_norm": 0.4228835105895996,
      "learning_rate": 0.00014524155345702194,
      "loss": 0.4408,
      "step": 1425
    },
    {
      "epoch": 3.7662337662337664,
      "grad_norm": 0.5154799222946167,
      "learning_rate": 0.00014335588417040994,
      "loss": 0.8124,
      "step": 1450
    },
    {
      "epoch": 3.8311688311688314,
      "grad_norm": 0.4265712797641754,
      "learning_rate": 0.00014145103424039495,
      "loss": 0.4358,
      "step": 1475
    },
    {
      "epoch": 3.896103896103896,
      "grad_norm": 0.4934200942516327,
      "learning_rate": 0.0001395278463725968,
      "loss": 0.8046,
      "step": 1500
    },
    {
      "epoch": 3.961038961038961,
      "grad_norm": 0.41004589200019836,
      "learning_rate": 0.00013758717138533916,
      "loss": 0.537,
      "step": 1525
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6997585296630859,
      "eval_runtime": 171.2835,
      "eval_samples_per_second": 4.49,
      "eval_steps_per_second": 4.49,
      "step": 1540
    },
    {
      "epoch": 4.025974025974026,
      "grad_norm": 0.08323661983013153,
      "learning_rate": 0.0001356298678332474,
      "loss": 0.5221,
      "step": 1550
    },
    {
      "epoch": 4.090909090909091,
      "grad_norm": 0.4908095598220825,
      "learning_rate": 0.000133656801627424,
      "loss": 0.6814,
      "step": 1575
    },
    {
      "epoch": 4.1558441558441555,
      "grad_norm": 0.12939035892486572,
      "learning_rate": 0.00013166884565236965,
      "loss": 0.4456,
      "step": 1600
    },
    {
      "epoch": 4.220779220779221,
      "grad_norm": 0.4519095718860626,
      "learning_rate": 0.00012966687937981903,
      "loss": 0.6837,
      "step": 1625
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.13248781859874725,
      "learning_rate": 0.00012765178847966242,
      "loss": 0.4604,
      "step": 1650
    },
    {
      "epoch": 4.35064935064935,
      "grad_norm": 0.4635682702064514,
      "learning_rate": 0.0001256244644281255,
      "loss": 0.7,
      "step": 1675
    },
    {
      "epoch": 4.415584415584416,
      "grad_norm": 0.1188681349158287,
      "learning_rate": 0.00012358580411338021,
      "loss": 0.4856,
      "step": 1700
    },
    {
      "epoch": 4.48051948051948,
      "grad_norm": 0.47588300704956055,
      "learning_rate": 0.00012153670943876131,
      "loss": 0.6787,
      "step": 1725
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.1191350519657135,
      "learning_rate": 0.00011947808692376452,
      "loss": 0.4472,
      "step": 1750
    },
    {
      "epoch": 4.6103896103896105,
      "grad_norm": 0.5029891729354858,
      "learning_rate": 0.0001174108473030021,
      "loss": 0.6952,
      "step": 1775
    },
    {
      "epoch": 4.675324675324675,
      "grad_norm": 0.11063455790281296,
      "learning_rate": 0.00011533590512329407,
      "loss": 0.468,
      "step": 1800
    },
    {
      "epoch": 4.740259740259741,
      "grad_norm": 0.474328875541687,
      "learning_rate": 0.00011325417833907248,
      "loss": 0.6777,
      "step": 1825
    },
    {
      "epoch": 4.805194805194805,
      "grad_norm": 0.12169301509857178,
      "learning_rate": 0.00011116658790627845,
      "loss": 0.4537,
      "step": 1850
    },
    {
      "epoch": 4.87012987012987,
      "grad_norm": 0.4853072762489319,
      "learning_rate": 0.00010907405737493135,
      "loss": 0.6968,
      "step": 1875
    },
    {
      "epoch": 4.935064935064935,
      "grad_norm": 0.11928659677505493,
      "learning_rate": 0.0001069775124805501,
      "loss": 0.4653,
      "step": 1900
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.3594743013381958,
      "learning_rate": 0.00010487788073460785,
      "loss": 0.7265,
      "step": 1925
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7062262296676636,
      "eval_runtime": 171.0915,
      "eval_samples_per_second": 4.495,
      "eval_steps_per_second": 4.495,
      "step": 1925
    },
    {
      "epoch": 5.064935064935065,
      "grad_norm": 0.47511085867881775,
      "learning_rate": 0.00010277609101420094,
      "loss": 0.4087,
      "step": 1950
    },
    {
      "epoch": 5.12987012987013,
      "grad_norm": 0.6043282151222229,
      "learning_rate": 0.00010067307315111359,
      "loss": 0.6295,
      "step": 1975
    },
    {
      "epoch": 5.194805194805195,
      "grad_norm": 0.5366548299789429,
      "learning_rate": 9.856975752046037e-05,
      "loss": 0.4513,
      "step": 2000
    },
    {
      "epoch": 5.259740259740259,
      "grad_norm": 0.582059919834137,
      "learning_rate": 9.64670746290882e-05,
      "loss": 0.6199,
      "step": 2025
    },
    {
      "epoch": 5.324675324675325,
      "grad_norm": 0.5339522361755371,
      "learning_rate": 9.43659547039202e-05,
      "loss": 0.4546,
      "step": 2050
    },
    {
      "epoch": 5.3896103896103895,
      "grad_norm": 0.5566874146461487,
      "learning_rate": 9.226732728042312e-05,
      "loss": 0.6439,
      "step": 2075
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 0.5596956014633179,
      "learning_rate": 9.017212079138104e-05,
      "loss": 0.4121,
      "step": 2100
    },
    {
      "epoch": 5.51948051948052,
      "grad_norm": 0.5695993900299072,
      "learning_rate": 8.808126215615669e-05,
      "loss": 0.6259,
      "step": 2125
    },
    {
      "epoch": 5.584415584415584,
      "grad_norm": 0.5568439364433289,
      "learning_rate": 8.599567637062202e-05,
      "loss": 0.4075,
      "step": 2150
    },
    {
      "epoch": 5.64935064935065,
      "grad_norm": 0.5613915324211121,
      "learning_rate": 8.391628609794044e-05,
      "loss": 0.6434,
      "step": 2175
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.5321427583694458,
      "learning_rate": 8.184401126038044e-05,
      "loss": 0.449,
      "step": 2200
    },
    {
      "epoch": 5.779220779220779,
      "grad_norm": 0.6584238409996033,
      "learning_rate": 7.977976863234184e-05,
      "loss": 0.64,
      "step": 2225
    },
    {
      "epoch": 5.8441558441558445,
      "grad_norm": 0.5848537683486938,
      "learning_rate": 7.772447143477506e-05,
      "loss": 0.4202,
      "step": 2250
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 0.7157720327377319,
      "learning_rate": 7.56790289311719e-05,
      "loss": 0.6396,
      "step": 2275
    },
    {
      "epoch": 5.974025974025974,
      "grad_norm": 0.5638211965560913,
      "learning_rate": 7.364434602530757e-05,
      "loss": 0.5384,
      "step": 2300
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7174513339996338,
      "eval_runtime": 170.9717,
      "eval_samples_per_second": 4.498,
      "eval_steps_per_second": 4.498,
      "step": 2310
    },
    {
      "epoch": 6.038961038961039,
      "grad_norm": 0.33984559774398804,
      "learning_rate": 7.162132286091123e-05,
      "loss": 0.3635,
      "step": 2325
    },
    {
      "epoch": 6.103896103896104,
      "grad_norm": 0.6442164778709412,
      "learning_rate": 6.961085442344221e-05,
      "loss": 0.6908,
      "step": 2350
    },
    {
      "epoch": 6.1688311688311686,
      "grad_norm": 0.12730176746845245,
      "learning_rate": 6.76138301441487e-05,
      "loss": 0.3013,
      "step": 2375
    },
    {
      "epoch": 6.233766233766234,
      "grad_norm": 0.6497397422790527,
      "learning_rate": 6.563113350658321e-05,
      "loss": 0.6765,
      "step": 2400
    },
    {
      "epoch": 6.298701298701299,
      "grad_norm": 0.14678341150283813,
      "learning_rate": 6.366364165574937e-05,
      "loss": 0.3098,
      "step": 2425
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 0.6714531779289246,
      "learning_rate": 6.171222501005325e-05,
      "loss": 0.7107,
      "step": 2450
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.21899929642677307,
      "learning_rate": 5.97777468762299e-05,
      "loss": 0.3283,
      "step": 2475
    },
    {
      "epoch": 6.4935064935064934,
      "grad_norm": 0.6973913908004761,
      "learning_rate": 5.786106306741672e-05,
      "loss": 0.6826,
      "step": 2500
    },
    {
      "epoch": 6.558441558441558,
      "grad_norm": 0.1973002701997757,
      "learning_rate": 5.5963021524541656e-05,
      "loss": 0.3108,
      "step": 2525
    },
    {
      "epoch": 6.623376623376624,
      "grad_norm": 0.6931896805763245,
      "learning_rate": 5.408446194119396e-05,
      "loss": 0.6759,
      "step": 2550
    },
    {
      "epoch": 6.688311688311688,
      "grad_norm": 0.15328872203826904,
      "learning_rate": 5.2226215392144026e-05,
      "loss": 0.2933,
      "step": 2575
    },
    {
      "epoch": 6.753246753246753,
      "grad_norm": 0.5786373615264893,
      "learning_rate": 5.038910396567571e-05,
      "loss": 0.6532,
      "step": 2600
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.11628124862909317,
      "learning_rate": 4.8573940399894434e-05,
      "loss": 0.3237,
      "step": 2625
    },
    {
      "epoch": 6.883116883116883,
      "grad_norm": 0.6388086080551147,
      "learning_rate": 4.6781527723172044e-05,
      "loss": 0.6786,
      "step": 2650
    },
    {
      "epoch": 6.948051948051948,
      "grad_norm": 0.6937752962112427,
      "learning_rate": 4.501265889888693e-05,
      "loss": 0.4184,
      "step": 2675
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7337256073951721,
      "eval_runtime": 171.0257,
      "eval_samples_per_second": 4.496,
      "eval_steps_per_second": 4.496,
      "step": 2695
    },
    {
      "epoch": 7.012987012987013,
      "grad_norm": 0.15596479177474976,
      "learning_rate": 4.326811647461692e-05,
      "loss": 0.5136,
      "step": 2700
    },
    {
      "epoch": 7.077922077922078,
      "grad_norm": 0.6129502058029175,
      "learning_rate": 4.1548672235940466e-05,
      "loss": 0.4726,
      "step": 2725
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.1523110717535019,
      "learning_rate": 3.985508686499846e-05,
      "loss": 0.4497,
      "step": 2750
    },
    {
      "epoch": 7.207792207792208,
      "grad_norm": 0.7417811751365662,
      "learning_rate": 3.8188109603968684e-05,
      "loss": 0.4962,
      "step": 2775
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.14260481297969818,
      "learning_rate": 3.65484779236008e-05,
      "loss": 0.4502,
      "step": 2800
    },
    {
      "epoch": 7.337662337662338,
      "grad_norm": 0.6408021450042725,
      "learning_rate": 3.493691719695958e-05,
      "loss": 0.5076,
      "step": 2825
    },
    {
      "epoch": 7.402597402597403,
      "grad_norm": 0.14237506687641144,
      "learning_rate": 3.335414037851957e-05,
      "loss": 0.4548,
      "step": 2850
    },
    {
      "epoch": 7.467532467532467,
      "grad_norm": 0.7171729207038879,
      "learning_rate": 3.180084768875429e-05,
      "loss": 0.4824,
      "step": 2875
    },
    {
      "epoch": 7.532467532467533,
      "grad_norm": 0.18717294931411743,
      "learning_rate": 3.0277726304358434e-05,
      "loss": 0.4475,
      "step": 2900
    },
    {
      "epoch": 7.597402597402597,
      "grad_norm": 0.6654143333435059,
      "learning_rate": 2.8785450054241148e-05,
      "loss": 0.4659,
      "step": 2925
    },
    {
      "epoch": 7.662337662337662,
      "grad_norm": 0.12408249080181122,
      "learning_rate": 2.732467912142398e-05,
      "loss": 0.4436,
      "step": 2950
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 0.7062712907791138,
      "learning_rate": 2.5896059750975822e-05,
      "loss": 0.4937,
      "step": 2975
    },
    {
      "epoch": 7.792207792207792,
      "grad_norm": 0.1608916074037552,
      "learning_rate": 2.4500223964114333e-05,
      "loss": 0.4619,
      "step": 3000
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.7236384749412537,
      "learning_rate": 2.3137789278599488e-05,
      "loss": 0.4844,
      "step": 3025
    },
    {
      "epoch": 7.922077922077922,
      "grad_norm": 0.1286492794752121,
      "learning_rate": 2.1809358435543915e-05,
      "loss": 0.4732,
      "step": 3050
    },
    {
      "epoch": 7.987012987012987,
      "grad_norm": 0.6981773376464844,
      "learning_rate": 2.051551913276014e-05,
      "loss": 0.5289,
      "step": 3075
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7487639784812927,
      "eval_runtime": 171.1149,
      "eval_samples_per_second": 4.494,
      "eval_steps_per_second": 4.494,
      "step": 3080
    },
    {
      "epoch": 8.051948051948052,
      "grad_norm": 0.7212914228439331,
      "learning_rate": 1.925684376476302e-05,
      "loss": 0.3566,
      "step": 3100
    },
    {
      "epoch": 8.116883116883116,
      "grad_norm": 0.7500373721122742,
      "learning_rate": 1.8033889169542505e-05,
      "loss": 0.5391,
      "step": 3125
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 0.7343879342079163,
      "learning_rate": 1.68471963822185e-05,
      "loss": 0.3396,
      "step": 3150
    },
    {
      "epoch": 8.246753246753247,
      "grad_norm": 0.741000235080719,
      "learning_rate": 1.569729039568678e-05,
      "loss": 0.5719,
      "step": 3175
    },
    {
      "epoch": 8.311688311688311,
      "grad_norm": 0.7320020794868469,
      "learning_rate": 1.4584679928362366e-05,
      "loss": 0.3292,
      "step": 3200
    },
    {
      "epoch": 8.376623376623376,
      "grad_norm": 0.8378432989120483,
      "learning_rate": 1.3509857199122311e-05,
      "loss": 0.5712,
      "step": 3225
    },
    {
      "epoch": 8.441558441558442,
      "grad_norm": 0.7324977517127991,
      "learning_rate": 1.2473297709548104e-05,
      "loss": 0.3328,
      "step": 3250
    },
    {
      "epoch": 8.506493506493506,
      "grad_norm": 0.7529276609420776,
      "learning_rate": 1.1475460033563846e-05,
      "loss": 0.5697,
      "step": 3275
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.6905131936073303,
      "learning_rate": 1.0516785614563018e-05,
      "loss": 0.3143,
      "step": 3300
    },
    {
      "epoch": 8.636363636363637,
      "grad_norm": 0.7517469525337219,
      "learning_rate": 9.597698570114044e-06,
      "loss": 0.5774,
      "step": 3325
    },
    {
      "epoch": 8.7012987012987,
      "grad_norm": 0.6868179440498352,
      "learning_rate": 8.718605504330612e-06,
      "loss": 0.3124,
      "step": 3350
    },
    {
      "epoch": 8.766233766233766,
      "grad_norm": 0.7487928867340088,
      "learning_rate": 7.879895327989994e-06,
      "loss": 0.5887,
      "step": 3375
    },
    {
      "epoch": 8.831168831168831,
      "grad_norm": 0.6981328129768372,
      "learning_rate": 7.081939086478972e-06,
      "loss": 0.3153,
      "step": 3400
    },
    {
      "epoch": 8.896103896103895,
      "grad_norm": 0.7475414276123047,
      "learning_rate": 6.325089795643335e-06,
      "loss": 0.5908,
      "step": 3425
    },
    {
      "epoch": 8.96103896103896,
      "grad_norm": 0.7660062909126282,
      "learning_rate": 5.609682285613604e-06,
      "loss": 0.4372,
      "step": 3450
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7591277956962585,
      "eval_runtime": 171.1549,
      "eval_samples_per_second": 4.493,
      "eval_steps_per_second": 4.493,
      "step": 3465
    },
    {
      "epoch": 9.025974025974026,
      "grad_norm": 0.14055967330932617,
      "learning_rate": 4.936033052676325e-06,
      "loss": 0.3634,
      "step": 3475
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.7677907347679138,
      "learning_rate": 4.304440119255915e-06,
      "loss": 0.5068,
      "step": 3500
    },
    {
      "epoch": 9.155844155844155,
      "grad_norm": 0.1552364081144333,
      "learning_rate": 3.7151829020697583e-06,
      "loss": 0.3388,
      "step": 3525
    },
    {
      "epoch": 9.220779220779221,
      "grad_norm": 0.8080049753189087,
      "learning_rate": 3.1685220885140367e-06,
      "loss": 0.5706,
      "step": 3550
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.15436707437038422,
      "learning_rate": 2.6646995213358006e-06,
      "loss": 0.342,
      "step": 3575
    },
    {
      "epoch": 9.35064935064935,
      "grad_norm": 0.7872737646102905,
      "learning_rate": 2.2039380916415995e-06,
      "loss": 0.536,
      "step": 3600
    },
    {
      "epoch": 9.415584415584416,
      "grad_norm": 0.167551651597023,
      "learning_rate": 1.7864416402905704e-06,
      "loss": 0.3472,
      "step": 3625
    },
    {
      "epoch": 9.480519480519481,
      "grad_norm": 0.8026964068412781,
      "learning_rate": 1.4123948677151498e-06,
      "loss": 0.5515,
      "step": 3650
    },
    {
      "epoch": 9.545454545454545,
      "grad_norm": 0.15685659646987915,
      "learning_rate": 1.081963252209639e-06,
      "loss": 0.3548,
      "step": 3675
    },
    {
      "epoch": 9.61038961038961,
      "grad_norm": 0.7306017279624939,
      "learning_rate": 7.952929767226391e-07,
      "loss": 0.5546,
      "step": 3700
    },
    {
      "epoch": 9.675324675324676,
      "grad_norm": 0.17545536160469055,
      "learning_rate": 5.525108641856181e-07,
      "loss": 0.3565,
      "step": 3725
    },
    {
      "epoch": 9.74025974025974,
      "grad_norm": 0.8317482471466064,
      "learning_rate": 3.537243214065566e-07,
      "loss": 0.5469,
      "step": 3750
    },
    {
      "epoch": 9.805194805194805,
      "grad_norm": 0.1379242092370987,
      "learning_rate": 1.9902129155311422e-07,
      "loss": 0.361,
      "step": 3775
    },
    {
      "epoch": 9.87012987012987,
      "grad_norm": 0.7840530276298523,
      "learning_rate": 8.847021524657217e-08,
      "loss": 0.5306,
      "step": 3800
    },
    {
      "epoch": 9.935064935064934,
      "grad_norm": 0.16045279800891876,
      "learning_rate": 2.212000028370964e-08,
      "loss": 0.3317,
      "step": 3825
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0902308225631714,
      "learning_rate": 0.0,
      "loss": 0.5432,
      "step": 3850
    }
  ],
  "logging_steps": 25,
  "max_steps": 3850,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.093053405301965e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
