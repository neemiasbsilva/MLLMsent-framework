{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 0.3201073110103607,
      "learning_rate": 4.4247787610619477e-05,
      "loss": 2.3572,
      "step": 25
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5113756656646729,
      "learning_rate": 8.849557522123895e-05,
      "loss": 2.105,
      "step": 50
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.32501012086868286,
      "learning_rate": 0.00013274336283185842,
      "loss": 1.6486,
      "step": 75
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.49147528409957886,
      "learning_rate": 0.0001769911504424779,
      "loss": 1.4085,
      "step": 100
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3465525507926941,
      "learning_rate": 0.00019999462792890912,
      "loss": 1.4604,
      "step": 125
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.45616263151168823,
      "learning_rate": 0.00019994893190848555,
      "loss": 1.3435,
      "step": 150
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.32112911343574524,
      "learning_rate": 0.00019985662853479525,
      "loss": 1.4153,
      "step": 175
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3446095585823059,
      "learning_rate": 0.00019971776084997842,
      "loss": 1.3105,
      "step": 200
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.29406338930130005,
      "learning_rate": 0.00019953239360965695,
      "loss": 1.3961,
      "step": 225
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.39655250310897827,
      "learning_rate": 0.0001993006132527381,
      "loss": 1.3062,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.37451171875,
      "eval_runtime": 136.3595,
      "eval_samples_per_second": 7.326,
      "eval_steps_per_second": 7.326,
      "step": 250
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2866029739379883,
      "learning_rate": 0.000199022527861107,
      "loss": 1.3666,
      "step": 275
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3401418626308441,
      "learning_rate": 0.00019869826710922675,
      "loss": 1.2731,
      "step": 300
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2972676157951355,
      "learning_rate": 0.00019832798220366978,
      "loss": 1.3633,
      "step": 325
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.37035584449768066,
      "learning_rate": 0.00019791184581260848,
      "loss": 1.2605,
      "step": 350
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.27141815423965454,
      "learning_rate": 0.00019745005198529799,
      "loss": 1.3605,
      "step": 375
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.3709790110588074,
      "learning_rate": 0.00019694281606158864,
      "loss": 1.2619,
      "step": 400
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2732740640640259,
      "learning_rate": 0.00019639037457151073,
      "loss": 1.3621,
      "step": 425
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.35163769125938416,
      "learning_rate": 0.00019579298512497758,
      "loss": 1.2528,
      "step": 450
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.25456488132476807,
      "learning_rate": 0.0001951509262916591,
      "loss": 1.3648,
      "step": 475
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.32382944226264954,
      "learning_rate": 0.0001944644974710816,
      "loss": 1.2537,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3353439569473267,
      "eval_runtime": 136.4552,
      "eval_samples_per_second": 7.321,
      "eval_steps_per_second": 7.321,
      "step": 500
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.2620318531990051,
      "learning_rate": 0.00019373401875301407,
      "loss": 1.3267,
      "step": 525
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.39805468916893005,
      "learning_rate": 0.00019295983076820687,
      "loss": 1.2234,
      "step": 550
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.2783012390136719,
      "learning_rate": 0.0001921422945295514,
      "loss": 1.3276,
      "step": 575
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.35273629426956177,
      "learning_rate": 0.00019128179126373567,
      "loss": 1.2138,
      "step": 600
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.27459952235221863,
      "learning_rate": 0.00019037872223347387,
      "loss": 1.3168,
      "step": 625
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3511786460876465,
      "learning_rate": 0.00018943350855039285,
      "loss": 1.2223,
      "step": 650
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2663143277168274,
      "learning_rate": 0.0001884465909786629,
      "loss": 1.3181,
      "step": 675
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.3448833227157593,
      "learning_rate": 0.0001874184297294641,
      "loss": 1.2116,
      "step": 700
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.2809704542160034,
      "learning_rate": 0.0001863495042463848,
      "loss": 1.3199,
      "step": 725
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.3696106970310211,
      "learning_rate": 0.0001852403129818511,
      "loss": 1.2215,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3219413757324219,
      "eval_runtime": 136.3578,
      "eval_samples_per_second": 7.326,
      "eval_steps_per_second": 7.326,
      "step": 750
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.28201085329055786,
      "learning_rate": 0.00018409137316469307,
      "loss": 1.2822,
      "step": 775
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.37180426716804504,
      "learning_rate": 0.00018290322055895453,
      "loss": 1.1784,
      "step": 800
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.28696975111961365,
      "learning_rate": 0.00018167640921406023,
      "loss": 1.2935,
      "step": 825
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.35469797253608704,
      "learning_rate": 0.0001804115112064562,
      "loss": 1.1822,
      "step": 850
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.292531281709671,
      "learning_rate": 0.00017910911637284357,
      "loss": 1.3001,
      "step": 875
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.3907485902309418,
      "learning_rate": 0.00017776983203513113,
      "loss": 1.1976,
      "step": 900
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.29986971616744995,
      "learning_rate": 0.00017639428271723384,
      "loss": 1.2825,
      "step": 925
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.38654690980911255,
      "learning_rate": 0.00017498310985385008,
      "loss": 1.1708,
      "step": 950
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.2766087055206299,
      "learning_rate": 0.00017353697149135325,
      "loss": 1.2912,
      "step": 975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.33079516887664795,
      "learning_rate": 0.00017205654198093696,
      "loss": 1.1831,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.301443099975586,
      "eval_runtime": 136.398,
      "eval_samples_per_second": 7.324,
      "eval_steps_per_second": 7.324,
      "step": 1000
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.33343765139579773,
      "learning_rate": 0.00017054251166415726,
      "loss": 1.2551,
      "step": 1025
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.38290852308273315,
      "learning_rate": 0.0001689955865510183,
      "loss": 1.1552,
      "step": 1050
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.29867008328437805,
      "learning_rate": 0.00016741648799075158,
      "loss": 1.258,
      "step": 1075
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.41545769572257996,
      "learning_rate": 0.00016580595233544248,
      "loss": 1.1422,
      "step": 1100
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.3010310232639313,
      "learning_rate": 0.00016416473059666065,
      "loss": 1.2624,
      "step": 1125
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.36280909180641174,
      "learning_rate": 0.00016249358809525456,
      "loss": 1.1476,
      "step": 1150
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.3017747402191162,
      "learning_rate": 0.00016079330410447335,
      "loss": 1.2587,
      "step": 1175
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.3873470425605774,
      "learning_rate": 0.0001590646714865828,
      "loss": 1.1467,
      "step": 1200
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.3070146143436432,
      "learning_rate": 0.00015730849632314428,
      "loss": 1.2552,
      "step": 1225
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.35799655318260193,
      "learning_rate": 0.00015552559753912953,
      "loss": 1.15,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3015106916427612,
      "eval_runtime": 136.354,
      "eval_samples_per_second": 7.327,
      "eval_steps_per_second": 7.327,
      "step": 1250
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.3414236903190613,
      "learning_rate": 0.00015371680652104643,
      "loss": 1.2166,
      "step": 1275
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.447242796421051,
      "learning_rate": 0.00015188296672925377,
      "loss": 1.1051,
      "step": 1300
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.3351670503616333,
      "learning_rate": 0.0001500249333046458,
      "loss": 1.2288,
      "step": 1325
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.3898630738258362,
      "learning_rate": 0.00014814357266989002,
      "loss": 1.1027,
      "step": 1350
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.30917611718177795,
      "learning_rate": 0.00014623976212540428,
      "loss": 1.2261,
      "step": 1375
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.38761332631111145,
      "learning_rate": 0.00014431438944026133,
      "loss": 1.123,
      "step": 1400
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.33184927701950073,
      "learning_rate": 0.00014236835243821167,
      "loss": 1.2407,
      "step": 1425
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.4007909297943115,
      "learning_rate": 0.00014040255857901798,
      "loss": 1.1271,
      "step": 1450
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.3268261253833771,
      "learning_rate": 0.00013841792453529581,
      "loss": 1.2332,
      "step": 1475
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.39487630128860474,
      "learning_rate": 0.0001364153757650588,
      "loss": 1.1257,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.299940586090088,
      "eval_runtime": 136.1744,
      "eval_samples_per_second": 7.336,
      "eval_steps_per_second": 7.336,
      "step": 1500
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.35065847635269165,
      "learning_rate": 0.00013439584608016653,
      "loss": 1.1938,
      "step": 1525
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.44130656123161316,
      "learning_rate": 0.00013236027721087723,
      "loss": 1.0873,
      "step": 1550
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.35892167687416077,
      "learning_rate": 0.00013030961836670794,
      "loss": 1.2077,
      "step": 1575
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.4061511158943176,
      "learning_rate": 0.00012824482579380716,
      "loss": 1.0802,
      "step": 1600
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.33000242710113525,
      "learning_rate": 0.00012616686232904594,
      "loss": 1.1996,
      "step": 1625
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.4543767273426056,
      "learning_rate": 0.000124076696951036,
      "loss": 1.0811,
      "step": 1650
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.34142065048217773,
      "learning_rate": 0.00012197530432828348,
      "loss": 1.2074,
      "step": 1675
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.4121169447898865,
      "learning_rate": 0.00011986366436468985,
      "loss": 1.0906,
      "step": 1700
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.3829326033592224,
      "learning_rate": 0.00011774276174261111,
      "loss": 1.2039,
      "step": 1725
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.45628949999809265,
      "learning_rate": 0.00011561358546368905,
      "loss": 1.0895,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3013876676559448,
      "eval_runtime": 136.2119,
      "eval_samples_per_second": 7.334,
      "eval_steps_per_second": 7.334,
      "step": 1750
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.35898518562316895,
      "learning_rate": 0.00011347712838766824,
      "loss": 1.1661,
      "step": 1775
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.4377007484436035,
      "learning_rate": 0.00011133438676941374,
      "loss": 1.0477,
      "step": 1800
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.35536980628967285,
      "learning_rate": 0.00010918635979434622,
      "loss": 1.1889,
      "step": 1825
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.45950308442115784,
      "learning_rate": 0.00010703404911250962,
      "loss": 1.0645,
      "step": 1850
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.3964230716228485,
      "learning_rate": 0.00010487845837149062,
      "loss": 1.1721,
      "step": 1875
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.4557737708091736,
      "learning_rate": 0.00010272059274840555,
      "loss": 1.0643,
      "step": 1900
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.3820900321006775,
      "learning_rate": 0.00010056145848117497,
      "loss": 1.1779,
      "step": 1925
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.47319188714027405,
      "learning_rate": 9.840206239930286e-05,
      "loss": 1.0458,
      "step": 1950
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.3603961169719696,
      "learning_rate": 9.624341145438053e-05,
      "loss": 1.1823,
      "step": 1975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.45667579770088196,
      "learning_rate": 9.408651225053314e-05,
      "loss": 1.072,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3039578199386597,
      "eval_runtime": 136.1165,
      "eval_samples_per_second": 7.339,
      "eval_steps_per_second": 7.339,
      "step": 2000
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.3960612118244171,
      "learning_rate": 9.193237057502864e-05,
      "loss": 1.146,
      "step": 2025
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.5091983079910278,
      "learning_rate": 8.978199092926727e-05,
      "loss": 1.0267,
      "step": 2050
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.39810219407081604,
      "learning_rate": 8.763637606037097e-05,
      "loss": 1.1629,
      "step": 2075
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.4904248118400574,
      "learning_rate": 8.549652649359053e-05,
      "loss": 1.0363,
      "step": 2100
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.38617104291915894,
      "learning_rate": 8.336344006574916e-05,
      "loss": 1.1537,
      "step": 2125
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.46864140033721924,
      "learning_rate": 8.123811145993942e-05,
      "loss": 1.0299,
      "step": 2150
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.39887920022010803,
      "learning_rate": 7.912153174169099e-05,
      "loss": 1.1601,
      "step": 2175
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.5106618404388428,
      "learning_rate": 7.70146878968251e-05,
      "loss": 1.0318,
      "step": 2200
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.3810126781463623,
      "learning_rate": 7.491856237121175e-05,
      "loss": 1.1547,
      "step": 2225
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.4940315783023834,
      "learning_rate": 7.283413261264342e-05,
      "loss": 1.0401,
      "step": 2250
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3104842901229858,
      "eval_runtime": 136.0899,
      "eval_samples_per_second": 7.341,
      "eval_steps_per_second": 7.341,
      "step": 2250
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.401429146528244,
      "learning_rate": 7.076237061504007e-05,
      "loss": 1.1203,
      "step": 2275
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.5086033344268799,
      "learning_rate": 6.870424246519682e-05,
      "loss": 1.0123,
      "step": 2300
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.41229742765426636,
      "learning_rate": 6.666070789228655e-05,
      "loss": 1.1295,
      "step": 2325
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.5111136436462402,
      "learning_rate": 6.463271982032695e-05,
      "loss": 1.0118,
      "step": 2350
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.4117705821990967,
      "learning_rate": 6.262122392382075e-05,
      "loss": 1.149,
      "step": 2375
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.5394319891929626,
      "learning_rate": 6.062715818677696e-05,
      "loss": 1.0026,
      "step": 2400
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.42075857520103455,
      "learning_rate": 5.865145246531776e-05,
      "loss": 1.1372,
      "step": 2425
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.538899838924408,
      "learning_rate": 5.669502805407591e-05,
      "loss": 1.0263,
      "step": 2450
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.41250303387641907,
      "learning_rate": 5.475879725658413e-05,
      "loss": 1.1387,
      "step": 2475
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.530975878238678,
      "learning_rate": 5.284366295985741e-05,
      "loss": 1.0112,
      "step": 2500
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3195440769195557,
      "eval_runtime": 136.1,
      "eval_samples_per_second": 7.34,
      "eval_steps_per_second": 7.34,
      "step": 2500
    },
    {
      "epoch": 10.1,
      "grad_norm": 0.4296302795410156,
      "learning_rate": 5.0950518213366314e-05,
      "loss": 1.1147,
      "step": 2525
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.5400733947753906,
      "learning_rate": 4.9080245812597434e-05,
      "loss": 0.9963,
      "step": 2550
    },
    {
      "epoch": 10.3,
      "grad_norm": 0.42917582392692566,
      "learning_rate": 4.72337178873958e-05,
      "loss": 1.1133,
      "step": 2575
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.5317812561988831,
      "learning_rate": 4.541179549528032e-05,
      "loss": 1.0054,
      "step": 2600
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.44367820024490356,
      "learning_rate": 4.361532821992258e-05,
      "loss": 1.1227,
      "step": 2625
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.5476423501968384,
      "learning_rate": 4.184515377497643e-05,
      "loss": 1.0013,
      "step": 2650
    },
    {
      "epoch": 10.7,
      "grad_norm": 0.43112391233444214,
      "learning_rate": 4.0102097613441916e-05,
      "loss": 1.1272,
      "step": 2675
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.551615834236145,
      "learning_rate": 3.838697254274708e-05,
      "loss": 0.9911,
      "step": 2700
    },
    {
      "epoch": 10.9,
      "grad_norm": 0.4236833453178406,
      "learning_rate": 3.670057834572653e-05,
      "loss": 1.1161,
      "step": 2725
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.5881577730178833,
      "learning_rate": 3.504370140767297e-05,
      "loss": 0.9835,
      "step": 2750
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3248748779296875,
      "eval_runtime": 136.111,
      "eval_samples_per_second": 7.34,
      "eval_steps_per_second": 7.34,
      "step": 2750
    },
    {
      "epoch": 11.1,
      "grad_norm": 0.4573877453804016,
      "learning_rate": 3.341711434963703e-05,
      "loss": 1.1146,
      "step": 2775
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.5468883514404297,
      "learning_rate": 3.182157566814471e-05,
      "loss": 0.9809,
      "step": 2800
    },
    {
      "epoch": 11.3,
      "grad_norm": 0.42606160044670105,
      "learning_rate": 3.0257829381501725e-05,
      "loss": 1.1094,
      "step": 2825
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.5799291729927063,
      "learning_rate": 2.872660468284919e-05,
      "loss": 0.9857,
      "step": 2850
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.447762668132782,
      "learning_rate": 2.722861560013208e-05,
      "loss": 1.0969,
      "step": 2875
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.5496521592140198,
      "learning_rate": 2.5764560663139893e-05,
      "loss": 0.9919,
      "step": 2900
    },
    {
      "epoch": 11.7,
      "grad_norm": 0.43278634548187256,
      "learning_rate": 2.4335122577774072e-05,
      "loss": 1.0998,
      "step": 2925
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.5587279796600342,
      "learning_rate": 2.2940967907694112e-05,
      "loss": 0.9783,
      "step": 2950
    },
    {
      "epoch": 11.9,
      "grad_norm": 0.45987632870674133,
      "learning_rate": 2.1582746763491245e-05,
      "loss": 1.1079,
      "step": 2975
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.6108878254890442,
      "learning_rate": 2.0261092499534285e-05,
      "loss": 0.9755,
      "step": 3000
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3274462223052979,
      "eval_runtime": 136.0961,
      "eval_samples_per_second": 7.34,
      "eval_steps_per_second": 7.34,
      "step": 3000
    },
    {
      "epoch": 12.1,
      "grad_norm": 0.44378408789634705,
      "learning_rate": 1.8976621418629047e-05,
      "loss": 1.0874,
      "step": 3025
    },
    {
      "epoch": 12.2,
      "grad_norm": 0.6102448105812073,
      "learning_rate": 1.7729932484629296e-05,
      "loss": 0.9849,
      "step": 3050
    },
    {
      "epoch": 12.3,
      "grad_norm": 0.460810124874115,
      "learning_rate": 1.6521607043132714e-05,
      "loss": 1.1045,
      "step": 3075
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.594306468963623,
      "learning_rate": 1.5352208550392743e-05,
      "loss": 0.9741,
      "step": 3100
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.4580376446247101,
      "learning_rate": 1.4222282310572465e-05,
      "loss": 1.0918,
      "step": 3125
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.610722541809082,
      "learning_rate": 1.3132355221462778e-05,
      "loss": 0.9656,
      "step": 3150
    },
    {
      "epoch": 12.7,
      "grad_norm": 0.47094491124153137,
      "learning_rate": 1.208293552878379e-05,
      "loss": 1.0955,
      "step": 3175
    },
    {
      "epoch": 12.8,
      "grad_norm": 0.5624422430992126,
      "learning_rate": 1.1074512589184105e-05,
      "loss": 0.9665,
      "step": 3200
    },
    {
      "epoch": 12.9,
      "grad_norm": 0.4509064555168152,
      "learning_rate": 1.010755664204781e-05,
      "loss": 1.1025,
      "step": 3225
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.6163169145584106,
      "learning_rate": 9.182518590216615e-06,
      "loss": 0.9723,
      "step": 3250
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3266141414642334,
      "eval_runtime": 136.1258,
      "eval_samples_per_second": 7.339,
      "eval_steps_per_second": 7.339,
      "step": 3250
    },
    {
      "epoch": 13.1,
      "grad_norm": 0.4490423798561096,
      "learning_rate": 8.299829789728498e-06,
      "loss": 1.0779,
      "step": 3275
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.6107681393623352,
      "learning_rate": 7.459901848671347e-06,
      "loss": 0.9665,
      "step": 3300
    },
    {
      "epoch": 13.3,
      "grad_norm": 0.4453173875808716,
      "learning_rate": 6.663126435245304e-06,
      "loss": 1.0924,
      "step": 3325
    },
    {
      "epoch": 13.4,
      "grad_norm": 0.6256496906280518,
      "learning_rate": 5.90987509512333e-06,
      "loss": 0.9774,
      "step": 3350
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.4634885787963867,
      "learning_rate": 5.200499078195109e-06,
      "loss": 1.098,
      "step": 3375
    },
    {
      "epoch": 13.6,
      "grad_norm": 0.6093940734863281,
      "learning_rate": 4.53532917477516e-06,
      "loss": 0.9769,
      "step": 3400
    },
    {
      "epoch": 13.7,
      "grad_norm": 0.4590093493461609,
      "learning_rate": 3.9146755613514e-06,
      "loss": 1.09,
      "step": 3425
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.5898184776306152,
      "learning_rate": 3.338827655946253e-06,
      "loss": 0.9688,
      "step": 3450
    },
    {
      "epoch": 13.9,
      "grad_norm": 0.4742305278778076,
      "learning_rate": 2.8080539831576658e-06,
      "loss": 1.0857,
      "step": 3475
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.6241714954376221,
      "learning_rate": 2.3226020489429232e-06,
      "loss": 0.9509,
      "step": 3500
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3284305334091187,
      "eval_runtime": 135.9883,
      "eval_samples_per_second": 7.346,
      "eval_steps_per_second": 7.346,
      "step": 3500
    },
    {
      "epoch": 14.1,
      "grad_norm": 0.4703163206577301,
      "learning_rate": 1.8826982252037606e-06,
      "loss": 1.0867,
      "step": 3525
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.6038919687271118,
      "learning_rate": 1.48854764422649e-06,
      "loss": 0.9626,
      "step": 3550
    },
    {
      "epoch": 14.3,
      "grad_norm": 0.47126150131225586,
      "learning_rate": 1.1403341030264192e-06,
      "loss": 1.0943,
      "step": 3575
    },
    {
      "epoch": 14.4,
      "grad_norm": 0.5925093293190002,
      "learning_rate": 8.382199776411526e-07,
      "loss": 0.9572,
      "step": 3600
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.45091697573661804,
      "learning_rate": 5.8234614741276e-07,
      "loss": 1.0758,
      "step": 3625
    },
    {
      "epoch": 14.6,
      "grad_norm": 0.6189152002334595,
      "learning_rate": 3.7283192929412626e-07,
      "loss": 0.973,
      "step": 3650
    },
    {
      "epoch": 14.7,
      "grad_norm": 0.4666203260421753,
      "learning_rate": 2.0977502221000145e-07,
      "loss": 1.0847,
      "step": 3675
    },
    {
      "epoch": 14.8,
      "grad_norm": 0.6171960234642029,
      "learning_rate": 9.325146149888886e-08,
      "loss": 0.9678,
      "step": 3700
    },
    {
      "epoch": 14.9,
      "grad_norm": 0.45360708236694336,
      "learning_rate": 2.331558345688434e-08,
      "loss": 1.0946,
      "step": 3725
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.6042065620422363,
      "learning_rate": 0.0,
      "loss": 0.9595,
      "step": 3750
    }
  ],
  "logging_steps": 25,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.696789551959245e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
