{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 2895,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12953367875647667,
      "grad_norm": 0.3996415138244629,
      "learning_rate": 5.747126436781609e-05,
      "loss": 2.3991,
      "step": 25
    },
    {
      "epoch": 0.25906735751295334,
      "grad_norm": 0.2658916711807251,
      "learning_rate": 0.00011494252873563218,
      "loss": 2.0618,
      "step": 50
    },
    {
      "epoch": 0.38860103626943004,
      "grad_norm": 0.3568193018436432,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.6279,
      "step": 75
    },
    {
      "epoch": 0.5181347150259067,
      "grad_norm": 0.49519434571266174,
      "learning_rate": 0.00019998942319271077,
      "loss": 1.4635,
      "step": 100
    },
    {
      "epoch": 0.6476683937823834,
      "grad_norm": 0.30314958095550537,
      "learning_rate": 0.00019990963977153936,
      "loss": 1.4515,
      "step": 125
    },
    {
      "epoch": 0.7772020725388601,
      "grad_norm": 0.3380996584892273,
      "learning_rate": 0.00019975169993441627,
      "loss": 1.3945,
      "step": 150
    },
    {
      "epoch": 0.9067357512953368,
      "grad_norm": 0.31653717160224915,
      "learning_rate": 0.0001995157272330992,
      "loss": 1.4058,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.419994831085205,
      "eval_runtime": 167.1532,
      "eval_samples_per_second": 4.595,
      "eval_steps_per_second": 4.595,
      "step": 193
    },
    {
      "epoch": 1.0362694300518134,
      "grad_norm": 0.30394262075424194,
      "learning_rate": 0.00019920190626219423,
      "loss": 1.3724,
      "step": 200
    },
    {
      "epoch": 1.16580310880829,
      "grad_norm": 0.3055347800254822,
      "learning_rate": 0.0001988104825147528,
      "loss": 1.3717,
      "step": 225
    },
    {
      "epoch": 1.2953367875647668,
      "grad_norm": 0.3236444890499115,
      "learning_rate": 0.00019834176219022965,
      "loss": 1.3615,
      "step": 250
    },
    {
      "epoch": 1.4248704663212435,
      "grad_norm": 0.33865058422088623,
      "learning_rate": 0.00019779611195495177,
      "loss": 1.3526,
      "step": 275
    },
    {
      "epoch": 1.5544041450777202,
      "grad_norm": 0.3468068838119507,
      "learning_rate": 0.00019717395865528602,
      "loss": 1.3695,
      "step": 300
    },
    {
      "epoch": 1.6839378238341969,
      "grad_norm": 0.2859087884426117,
      "learning_rate": 0.0001964757889837296,
      "loss": 1.3449,
      "step": 325
    },
    {
      "epoch": 1.8134715025906736,
      "grad_norm": 0.3258025646209717,
      "learning_rate": 0.00019570214909818466,
      "loss": 1.3576,
      "step": 350
    },
    {
      "epoch": 1.9430051813471503,
      "grad_norm": 0.3148680627346039,
      "learning_rate": 0.00019485364419471454,
      "loss": 1.3361,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.4017540216445923,
      "eval_runtime": 167.122,
      "eval_samples_per_second": 4.595,
      "eval_steps_per_second": 4.595,
      "step": 386
    },
    {
      "epoch": 2.0725388601036268,
      "grad_norm": 0.3263489902019501,
      "learning_rate": 0.00019393093803411686,
      "loss": 1.3496,
      "step": 400
    },
    {
      "epoch": 2.2020725388601035,
      "grad_norm": 0.31631311774253845,
      "learning_rate": 0.00019293475242268223,
      "loss": 1.3014,
      "step": 425
    },
    {
      "epoch": 2.33160621761658,
      "grad_norm": 0.3414638042449951,
      "learning_rate": 0.0001918658666475465,
      "loss": 1.3417,
      "step": 450
    },
    {
      "epoch": 2.461139896373057,
      "grad_norm": 0.3261405825614929,
      "learning_rate": 0.00019072511686707663,
      "loss": 1.298,
      "step": 475
    },
    {
      "epoch": 2.5906735751295336,
      "grad_norm": 0.31185197830200195,
      "learning_rate": 0.00018951339545676866,
      "loss": 1.3352,
      "step": 500
    },
    {
      "epoch": 2.7202072538860103,
      "grad_norm": 0.3422100245952606,
      "learning_rate": 0.0001882316503111678,
      "loss": 1.2801,
      "step": 525
    },
    {
      "epoch": 2.849740932642487,
      "grad_norm": 0.29482194781303406,
      "learning_rate": 0.00018688088410235833,
      "loss": 1.3412,
      "step": 550
    },
    {
      "epoch": 2.9792746113989637,
      "grad_norm": 0.3410293161869049,
      "learning_rate": 0.00018546215349560203,
      "loss": 1.2666,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3685234785079956,
      "eval_runtime": 167.0878,
      "eval_samples_per_second": 4.596,
      "eval_steps_per_second": 4.596,
      "step": 579
    },
    {
      "epoch": 3.1088082901554404,
      "grad_norm": 0.31517261266708374,
      "learning_rate": 0.0001839765683227398,
      "loss": 1.3286,
      "step": 600
    },
    {
      "epoch": 3.238341968911917,
      "grad_norm": 0.35931718349456787,
      "learning_rate": 0.00018242529071400214,
      "loss": 1.2297,
      "step": 625
    },
    {
      "epoch": 3.3678756476683938,
      "grad_norm": 0.29558873176574707,
      "learning_rate": 0.00018080953418890853,
      "loss": 1.3184,
      "step": 650
    },
    {
      "epoch": 3.4974093264248705,
      "grad_norm": 0.39747464656829834,
      "learning_rate": 0.0001791305627069662,
      "loss": 1.2385,
      "step": 675
    },
    {
      "epoch": 3.626943005181347,
      "grad_norm": 0.29759907722473145,
      "learning_rate": 0.0001773896896789112,
      "loss": 1.3266,
      "step": 700
    },
    {
      "epoch": 3.756476683937824,
      "grad_norm": 0.3487643897533417,
      "learning_rate": 0.00017558827693926534,
      "loss": 1.2322,
      "step": 725
    },
    {
      "epoch": 3.8860103626943006,
      "grad_norm": 0.30042657256126404,
      "learning_rate": 0.0001737277336810124,
      "loss": 1.3074,
      "step": 750
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3612760305404663,
      "eval_runtime": 167.0618,
      "eval_samples_per_second": 4.597,
      "eval_steps_per_second": 4.597,
      "step": 772
    },
    {
      "epoch": 4.015544041450777,
      "grad_norm": 0.3959800899028778,
      "learning_rate": 0.0001718095153532274,
      "loss": 1.2432,
      "step": 775
    },
    {
      "epoch": 4.1450777202072535,
      "grad_norm": 0.32020866870880127,
      "learning_rate": 0.00016983512252252085,
      "loss": 1.2672,
      "step": 800
    },
    {
      "epoch": 4.274611398963731,
      "grad_norm": 0.3819914162158966,
      "learning_rate": 0.0001678060996991891,
      "loss": 1.2198,
      "step": 825
    },
    {
      "epoch": 4.404145077720207,
      "grad_norm": 0.32862409949302673,
      "learning_rate": 0.00016572403412898855,
      "loss": 1.2641,
      "step": 850
    },
    {
      "epoch": 4.533678756476684,
      "grad_norm": 0.3241334557533264,
      "learning_rate": 0.0001635905545514795,
      "loss": 1.2272,
      "step": 875
    },
    {
      "epoch": 4.66321243523316,
      "grad_norm": 0.31440484523773193,
      "learning_rate": 0.0001614073299259101,
      "loss": 1.2565,
      "step": 900
    },
    {
      "epoch": 4.7927461139896375,
      "grad_norm": 0.34159210324287415,
      "learning_rate": 0.0001591760681256382,
      "loss": 1.2465,
      "step": 925
    },
    {
      "epoch": 4.922279792746114,
      "grad_norm": 0.31905773282051086,
      "learning_rate": 0.00015689851460211126,
      "loss": 1.253,
      "step": 950
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3573631048202515,
      "eval_runtime": 167.1042,
      "eval_samples_per_second": 4.596,
      "eval_steps_per_second": 4.596,
      "step": 965
    },
    {
      "epoch": 5.051813471502591,
      "grad_norm": 0.309501051902771,
      "learning_rate": 0.00015457645101945046,
      "loss": 1.2322,
      "step": 975
    },
    {
      "epoch": 5.181347150259067,
      "grad_norm": 0.32850882411003113,
      "learning_rate": 0.00015221169386070636,
      "loss": 1.2131,
      "step": 1000
    },
    {
      "epoch": 5.310880829015544,
      "grad_norm": 0.3248318135738373,
      "learning_rate": 0.00014980609300687683,
      "loss": 1.2265,
      "step": 1025
    },
    {
      "epoch": 5.4404145077720205,
      "grad_norm": 0.3527076840400696,
      "learning_rate": 0.00014736153028979893,
      "loss": 1.1818,
      "step": 1050
    },
    {
      "epoch": 5.569948186528498,
      "grad_norm": 0.3307351768016815,
      "learning_rate": 0.00014487991802004623,
      "loss": 1.221,
      "step": 1075
    },
    {
      "epoch": 5.699481865284974,
      "grad_norm": 0.360664039850235,
      "learning_rate": 0.00014236319749098367,
      "loss": 1.1949,
      "step": 1100
    },
    {
      "epoch": 5.829015544041451,
      "grad_norm": 0.33803069591522217,
      "learning_rate": 0.0001398133374601501,
      "loss": 1.2429,
      "step": 1125
    },
    {
      "epoch": 5.958549222797927,
      "grad_norm": 0.357864648103714,
      "learning_rate": 0.0001372323326091563,
      "loss": 1.1984,
      "step": 1150
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3537274599075317,
      "eval_runtime": 167.0806,
      "eval_samples_per_second": 4.597,
      "eval_steps_per_second": 4.597,
      "step": 1158
    },
    {
      "epoch": 6.0880829015544045,
      "grad_norm": 0.34366315603256226,
      "learning_rate": 0.00013462220198330328,
      "loss": 1.201,
      "step": 1175
    },
    {
      "epoch": 6.217616580310881,
      "grad_norm": 0.38890406489372253,
      "learning_rate": 0.00013198498741214166,
      "loss": 1.1465,
      "step": 1200
    },
    {
      "epoch": 6.347150259067358,
      "grad_norm": 0.3452860713005066,
      "learning_rate": 0.00012932275191220776,
      "loss": 1.2161,
      "step": 1225
    },
    {
      "epoch": 6.476683937823834,
      "grad_norm": 0.4378465712070465,
      "learning_rate": 0.00012663757807318521,
      "loss": 1.1311,
      "step": 1250
    },
    {
      "epoch": 6.606217616580311,
      "grad_norm": 0.3797392249107361,
      "learning_rate": 0.0001239315664287558,
      "loss": 1.2283,
      "step": 1275
    },
    {
      "epoch": 6.7357512953367875,
      "grad_norm": 0.4202462136745453,
      "learning_rate": 0.00012120683381341247,
      "loss": 1.1471,
      "step": 1300
    },
    {
      "epoch": 6.865284974093264,
      "grad_norm": 0.3639746904373169,
      "learning_rate": 0.00011846551170652127,
      "loss": 1.2252,
      "step": 1325
    },
    {
      "epoch": 6.994818652849741,
      "grad_norm": 0.4654649496078491,
      "learning_rate": 0.00011570974456492678,
      "loss": 1.1404,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3534501791000366,
      "eval_runtime": 167.2227,
      "eval_samples_per_second": 4.593,
      "eval_steps_per_second": 4.593,
      "step": 1351
    },
    {
      "epoch": 7.124352331606218,
      "grad_norm": 0.3850186765193939,
      "learning_rate": 0.00011294168814540553,
      "loss": 1.2048,
      "step": 1375
    },
    {
      "epoch": 7.253886010362694,
      "grad_norm": 0.3317146301269531,
      "learning_rate": 0.00011016350781828019,
      "loss": 1.0933,
      "step": 1400
    },
    {
      "epoch": 7.383419689119171,
      "grad_norm": 0.43394917249679565,
      "learning_rate": 0.00010737737687351284,
      "loss": 1.2156,
      "step": 1425
    },
    {
      "epoch": 7.512953367875648,
      "grad_norm": 0.4623030722141266,
      "learning_rate": 0.00010458547482060341,
      "loss": 1.1244,
      "step": 1450
    },
    {
      "epoch": 7.642487046632124,
      "grad_norm": 0.39147812128067017,
      "learning_rate": 0.00010178998568362243,
      "loss": 1.1946,
      "step": 1475
    },
    {
      "epoch": 7.772020725388601,
      "grad_norm": 0.4322128891944885,
      "learning_rate": 9.899309629271246e-05,
      "loss": 1.1345,
      "step": 1500
    },
    {
      "epoch": 7.901554404145077,
      "grad_norm": 0.4160415828227997,
      "learning_rate": 9.619699457339405e-05,
      "loss": 1.1859,
      "step": 1525
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3591694831848145,
      "eval_runtime": 167.2063,
      "eval_samples_per_second": 4.593,
      "eval_steps_per_second": 4.593,
      "step": 1544
    },
    {
      "epoch": 8.031088082901555,
      "grad_norm": 0.43381401896476746,
      "learning_rate": 9.340386783501507e-05,
      "loss": 1.1205,
      "step": 1550
    },
    {
      "epoch": 8.160621761658032,
      "grad_norm": 0.426513135433197,
      "learning_rate": 9.061590105968208e-05,
      "loss": 1.1407,
      "step": 1575
    },
    {
      "epoch": 8.290155440414507,
      "grad_norm": 0.43795281648635864,
      "learning_rate": 8.783527519301204e-05,
      "loss": 1.1188,
      "step": 1600
    },
    {
      "epoch": 8.419689119170984,
      "grad_norm": 0.4142593741416931,
      "learning_rate": 8.506416543804182e-05,
      "loss": 1.1465,
      "step": 1625
    },
    {
      "epoch": 8.549222797927461,
      "grad_norm": 0.4200710952281952,
      "learning_rate": 8.23047395536298e-05,
      "loss": 1.1203,
      "step": 1650
    },
    {
      "epoch": 8.678756476683938,
      "grad_norm": 0.4482283294200897,
      "learning_rate": 7.955915615868111e-05,
      "loss": 1.1341,
      "step": 1675
    },
    {
      "epoch": 8.808290155440414,
      "grad_norm": 0.3971813917160034,
      "learning_rate": 7.682956304352243e-05,
      "loss": 1.143,
      "step": 1700
    },
    {
      "epoch": 8.937823834196891,
      "grad_norm": 0.44688352942466736,
      "learning_rate": 7.411809548974792e-05,
      "loss": 1.1113,
      "step": 1725
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3621234893798828,
      "eval_runtime": 167.2896,
      "eval_samples_per_second": 4.591,
      "eval_steps_per_second": 4.591,
      "step": 1737
    },
    {
      "epoch": 9.067357512953368,
      "grad_norm": 0.4428401291370392,
      "learning_rate": 7.142687459985042e-05,
      "loss": 1.1465,
      "step": 1750
    },
    {
      "epoch": 9.196891191709845,
      "grad_norm": 0.4668903052806854,
      "learning_rate": 6.875800563794425e-05,
      "loss": 1.0895,
      "step": 1775
    },
    {
      "epoch": 9.32642487046632,
      "grad_norm": 0.4308678209781647,
      "learning_rate": 6.611357638287823e-05,
      "loss": 1.1286,
      "step": 1800
    },
    {
      "epoch": 9.455958549222798,
      "grad_norm": 0.43964719772338867,
      "learning_rate": 6.349565549502676e-05,
      "loss": 1.0776,
      "step": 1825
    },
    {
      "epoch": 9.585492227979275,
      "grad_norm": 0.4325917363166809,
      "learning_rate": 6.090629089803668e-05,
      "loss": 1.128,
      "step": 1850
    },
    {
      "epoch": 9.715025906735752,
      "grad_norm": 0.5049294829368591,
      "learning_rate": 5.834750817679606e-05,
      "loss": 1.0872,
      "step": 1875
    },
    {
      "epoch": 9.844559585492227,
      "grad_norm": 0.44298654794692993,
      "learning_rate": 5.582130899287775e-05,
      "loss": 1.1475,
      "step": 1900
    },
    {
      "epoch": 9.974093264248705,
      "grad_norm": 0.4819883704185486,
      "learning_rate": 5.33296695186977e-05,
      "loss": 1.0755,
      "step": 1925
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3643207550048828,
      "eval_runtime": 168.6701,
      "eval_samples_per_second": 4.553,
      "eval_steps_per_second": 4.553,
      "step": 1930
    },
    {
      "epoch": 10.103626943005182,
      "grad_norm": 0.47791948914527893,
      "learning_rate": 5.087453889161229e-05,
      "loss": 1.1402,
      "step": 1950
    },
    {
      "epoch": 10.233160621761659,
      "grad_norm": 0.5376073122024536,
      "learning_rate": 4.845783768916482e-05,
      "loss": 1.0444,
      "step": 1975
    },
    {
      "epoch": 10.362694300518134,
      "grad_norm": 0.45344001054763794,
      "learning_rate": 4.608145642667336e-05,
      "loss": 1.1341,
      "step": 2000
    },
    {
      "epoch": 10.492227979274611,
      "grad_norm": 0.5682339072227478,
      "learning_rate": 4.374725407833532e-05,
      "loss": 1.0313,
      "step": 2025
    },
    {
      "epoch": 10.621761658031089,
      "grad_norm": 0.44581952691078186,
      "learning_rate": 4.145705662300595e-05,
      "loss": 1.1504,
      "step": 2050
    },
    {
      "epoch": 10.751295336787564,
      "grad_norm": 0.37820059061050415,
      "learning_rate": 3.9212655615787804e-05,
      "loss": 1.0437,
      "step": 2075
    },
    {
      "epoch": 10.880829015544041,
      "grad_norm": 0.4791349470615387,
      "learning_rate": 3.701580678654925e-05,
      "loss": 1.1445,
      "step": 2100
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.369637131690979,
      "eval_runtime": 168.6367,
      "eval_samples_per_second": 4.554,
      "eval_steps_per_second": 4.554,
      "step": 2123
    },
    {
      "epoch": 11.010362694300518,
      "grad_norm": 0.3996042013168335,
      "learning_rate": 3.4868228666467704e-05,
      "loss": 1.048,
      "step": 2125
    },
    {
      "epoch": 11.139896373056995,
      "grad_norm": 0.47332388162612915,
      "learning_rate": 3.2771601243672825e-05,
      "loss": 1.1244,
      "step": 2150
    },
    {
      "epoch": 11.26943005181347,
      "grad_norm": 0.5089154243469238,
      "learning_rate": 3.072756464904006e-05,
      "loss": 1.045,
      "step": 2175
    },
    {
      "epoch": 11.398963730569948,
      "grad_norm": 0.48596376180648804,
      "learning_rate": 2.8737717873164094e-05,
      "loss": 1.0986,
      "step": 2200
    },
    {
      "epoch": 11.528497409326425,
      "grad_norm": 0.4402439296245575,
      "learning_rate": 2.68036175155147e-05,
      "loss": 1.051,
      "step": 2225
    },
    {
      "epoch": 11.658031088082902,
      "grad_norm": 0.4883356988430023,
      "learning_rate": 2.492677656675414e-05,
      "loss": 1.1183,
      "step": 2250
    },
    {
      "epoch": 11.787564766839377,
      "grad_norm": 0.4722880721092224,
      "learning_rate": 2.3108663225168435e-05,
      "loss": 1.0696,
      "step": 2275
    },
    {
      "epoch": 11.917098445595855,
      "grad_norm": 0.473222553730011,
      "learning_rate": 2.1350699748138326e-05,
      "loss": 1.0793,
      "step": 2300
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3705371618270874,
      "eval_runtime": 167.4027,
      "eval_samples_per_second": 4.588,
      "eval_steps_per_second": 4.588,
      "step": 2316
    },
    {
      "epoch": 12.046632124352332,
      "grad_norm": 0.4662461280822754,
      "learning_rate": 1.965426133954854e-05,
      "loss": 1.0773,
      "step": 2325
    },
    {
      "epoch": 12.176165803108809,
      "grad_norm": 0.5056465268135071,
      "learning_rate": 1.8020675074005723e-05,
      "loss": 1.077,
      "step": 2350
    },
    {
      "epoch": 12.305699481865284,
      "grad_norm": 0.5011618733406067,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 1.0693,
      "step": 2375
    },
    {
      "epoch": 12.435233160621761,
      "grad_norm": 0.5220887660980225,
      "learning_rate": 1.4947120433767047e-05,
      "loss": 1.0582,
      "step": 2400
    },
    {
      "epoch": 12.564766839378239,
      "grad_norm": 0.513176441192627,
      "learning_rate": 1.350955641179893e-05,
      "loss": 1.0726,
      "step": 2425
    },
    {
      "epoch": 12.694300518134716,
      "grad_norm": 0.5070631504058838,
      "learning_rate": 1.2139651357477788e-05,
      "loss": 1.0535,
      "step": 2450
    },
    {
      "epoch": 12.823834196891191,
      "grad_norm": 0.47929975390434265,
      "learning_rate": 1.083847690782972e-05,
      "loss": 1.0864,
      "step": 2475
    },
    {
      "epoch": 12.953367875647668,
      "grad_norm": 0.5266556739807129,
      "learning_rate": 9.607050933920459e-06,
      "loss": 1.0413,
      "step": 2500
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.372633457183838,
      "eval_runtime": 169.2408,
      "eval_samples_per_second": 4.538,
      "eval_steps_per_second": 4.538,
      "step": 2509
    },
    {
      "epoch": 13.082901554404145,
      "grad_norm": 0.476684033870697,
      "learning_rate": 8.446336744604378e-06,
      "loss": 1.0943,
      "step": 2525
    },
    {
      "epoch": 13.212435233160623,
      "grad_norm": 0.5269747972488403,
      "learning_rate": 7.357242332955916e-06,
      "loss": 1.0207,
      "step": 2550
    },
    {
      "epoch": 13.341968911917098,
      "grad_norm": 0.48960620164871216,
      "learning_rate": 6.3406196659728465e-06,
      "loss": 1.0891,
      "step": 2575
    },
    {
      "epoch": 13.471502590673575,
      "grad_norm": 0.541854739189148,
      "learning_rate": 5.397264018107295e-06,
      "loss": 1.0392,
      "step": 2600
    },
    {
      "epoch": 13.601036269430052,
      "grad_norm": 0.4773477613925934,
      "learning_rate": 4.527913349145441e-06,
      "loss": 1.1,
      "step": 2625
    },
    {
      "epoch": 13.73056994818653,
      "grad_norm": 0.541183590888977,
      "learning_rate": 3.733247726923039e-06,
      "loss": 1.033,
      "step": 2650
    },
    {
      "epoch": 13.860103626943005,
      "grad_norm": 0.47667208313941956,
      "learning_rate": 3.013888795328057e-06,
      "loss": 1.1057,
      "step": 2675
    },
    {
      "epoch": 13.989637305699482,
      "grad_norm": 0.6050524115562439,
      "learning_rate": 2.3703992880066638e-06,
      "loss": 1.0024,
      "step": 2700
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3737214803695679,
      "eval_runtime": 166.9446,
      "eval_samples_per_second": 4.6,
      "eval_steps_per_second": 4.6,
      "step": 2702
    },
    {
      "epoch": 14.119170984455959,
      "grad_norm": 0.5109598636627197,
      "learning_rate": 1.8032825881530213e-06,
      "loss": 1.1061,
      "step": 2725
    },
    {
      "epoch": 14.248704663212436,
      "grad_norm": 0.6101837158203125,
      "learning_rate": 1.3129823347271753e-06,
      "loss": 1.0038,
      "step": 2750
    },
    {
      "epoch": 14.378238341968911,
      "grad_norm": 0.48283419013023376,
      "learning_rate": 8.998820754091531e-07,
      "loss": 1.1144,
      "step": 2775
    },
    {
      "epoch": 14.507772020725389,
      "grad_norm": 0.423462450504303,
      "learning_rate": 5.643049665607691e-07,
      "loss": 1.0172,
      "step": 2800
    },
    {
      "epoch": 14.637305699481866,
      "grad_norm": 0.4990643560886383,
      "learning_rate": 3.065135204296965e-07,
      "loss": 1.1064,
      "step": 2825
    },
    {
      "epoch": 14.766839378238341,
      "grad_norm": 0.4703795313835144,
      "learning_rate": 1.2670939979384512e-07,
      "loss": 1.0175,
      "step": 2850
    },
    {
      "epoch": 14.896373056994818,
      "grad_norm": 0.49088332056999207,
      "learning_rate": 2.5033260206275277e-08,
      "loss": 1.0942,
      "step": 2875
    }
  ],
  "logging_steps": 25,
  "max_steps": 2895,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.2125625078767616e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
