{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.5146922469139099,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.1579,
      "step": 25
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4255889654159546,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.4634,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4892342984676361,
      "learning_rate": 0.0001,
      "loss": 0.7145,
      "step": 75
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9599866271018982,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.2224,
      "step": 100
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5309751033782959,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.5647,
      "step": 125
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8469762802124023,
      "learning_rate": 0.0002,
      "loss": 0.9995,
      "step": 150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.39650827646255493,
      "learning_rate": 0.00019998688836656323,
      "loss": 0.5285,
      "step": 175
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.43901002407073975,
      "learning_rate": 0.00019994755690455152,
      "loss": 0.9626,
      "step": 200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3393494188785553,
      "learning_rate": 0.0001998820159279591,
      "loss": 0.6417,
      "step": 225
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6916283369064331,
      "learning_rate": 0.00019979028262377118,
      "loss": 0.9242,
      "step": 250
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.35617953538894653,
      "learning_rate": 0.00019967238104745696,
      "loss": 0.6165,
      "step": 275
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5261372923851013,
      "learning_rate": 0.0001995283421166614,
      "loss": 0.9098,
      "step": 300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3344651162624359,
      "learning_rate": 0.00019935820360309777,
      "loss": 0.5457,
      "step": 325
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4304002821445465,
      "learning_rate": 0.00019916201012264254,
      "loss": 0.9312,
      "step": 350
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3759465217590332,
      "learning_rate": 0.00019893981312363562,
      "loss": 0.6069,
      "step": 375
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4197230339050293,
      "learning_rate": 0.00019869167087338907,
      "loss": 0.9094,
      "step": 400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3145708739757538,
      "learning_rate": 0.00019841764844290744,
      "loss": 0.5033,
      "step": 425
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5120595097541809,
      "learning_rate": 0.0001981178176898239,
      "loss": 0.9056,
      "step": 450
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.36311644315719604,
      "learning_rate": 0.00019779225723955707,
      "loss": 0.5468,
      "step": 475
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.47348952293395996,
      "learning_rate": 0.00019744105246469263,
      "loss": 0.9099,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8314544558525085,
      "eval_runtime": 219.3899,
      "eval_samples_per_second": 4.558,
      "eval_steps_per_second": 4.558,
      "step": 500
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.31214457750320435,
      "learning_rate": 0.00019706429546259593,
      "loss": 0.535,
      "step": 525
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.4773170053958893,
      "learning_rate": 0.00019666208503126112,
      "loss": 0.864,
      "step": 550
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.3476422131061554,
      "learning_rate": 0.00019623452664340306,
      "loss": 0.4972,
      "step": 575
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.41763970255851746,
      "learning_rate": 0.00019578173241879872,
      "loss": 0.8752,
      "step": 600
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.3415437936782837,
      "learning_rate": 0.0001953038210948861,
      "loss": 0.504,
      "step": 625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5581452250480652,
      "learning_rate": 0.00019480091799562704,
      "loss": 0.8854,
      "step": 650
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.3277137279510498,
      "learning_rate": 0.00019427315499864344,
      "loss": 0.5643,
      "step": 675
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.493050754070282,
      "learning_rate": 0.00019372067050063438,
      "loss": 0.8524,
      "step": 700
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.352683424949646,
      "learning_rate": 0.00019314360938108425,
      "loss": 0.5422,
      "step": 725
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.4438309669494629,
      "learning_rate": 0.00019254212296427044,
      "loss": 0.8813,
      "step": 750
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.33040696382522583,
      "learning_rate": 0.00019191636897958122,
      "loss": 0.5546,
      "step": 775
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4528060257434845,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8389,
      "step": 800
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.333514004945755,
      "learning_rate": 0.0001905927209998447,
      "loss": 0.5105,
      "step": 825
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5761985778808594,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.8618,
      "step": 850
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.33861130475997925,
      "learning_rate": 0.00018917405376582145,
      "loss": 0.4618,
      "step": 875
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5168946385383606,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.8787,
      "step": 900
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.33318832516670227,
      "learning_rate": 0.0001876618552635348,
      "loss": 0.5038,
      "step": 925
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.4725840389728546,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.8355,
      "step": 950
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.3475375175476074,
      "learning_rate": 0.00018605771158039253,
      "loss": 0.5415,
      "step": 975
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.41280028223991394,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.8573,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7508688569068909,
      "eval_runtime": 219.3124,
      "eval_samples_per_second": 4.56,
      "eval_steps_per_second": 4.56,
      "step": 1000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.35606086254119873,
      "learning_rate": 0.00018436330524160047,
      "loss": 0.5291,
      "step": 1025
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5394347906112671,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.8016,
      "step": 1050
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.3603018820285797,
      "learning_rate": 0.00018258041344542566,
      "loss": 0.4883,
      "step": 1075
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5146080255508423,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.7967,
      "step": 1100
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3663857579231262,
      "learning_rate": 0.00018071090619916093,
      "loss": 0.5524,
      "step": 1125
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.4421690106391907,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.7772,
      "step": 1150
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.3597874641418457,
      "learning_rate": 0.00017875674435774547,
      "loss": 0.5094,
      "step": 1175
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.4149385690689087,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.8233,
      "step": 1200
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3532402515411377,
      "learning_rate": 0.00017671997756709863,
      "loss": 0.4894,
      "step": 1225
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.467430055141449,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.7944,
      "step": 1250
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3544960021972656,
      "learning_rate": 0.0001746027421143246,
      "loss": 0.4761,
      "step": 1275
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.535742461681366,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.8017,
      "step": 1300
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.3831523358821869,
      "learning_rate": 0.00017240725868704218,
      "loss": 0.5323,
      "step": 1325
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.4393303692340851,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.7892,
      "step": 1350
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.3570273518562317,
      "learning_rate": 0.00017013583004418993,
      "loss": 0.4243,
      "step": 1375
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5056383609771729,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.8395,
      "step": 1400
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.3591342866420746,
      "learning_rate": 0.00016779083860075033,
      "loss": 0.4604,
      "step": 1425
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5792101621627808,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.8337,
      "step": 1450
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.32546550035476685,
      "learning_rate": 0.00016537474392892528,
      "loss": 0.4367,
      "step": 1475
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5805781483650208,
      "learning_rate": 0.000164140821963114,
      "loss": 0.7892,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.726526141166687,
      "eval_runtime": 219.3373,
      "eval_samples_per_second": 4.559,
      "eval_steps_per_second": 4.559,
      "step": 1500
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.3658123314380646,
      "learning_rate": 0.00016289008017838445,
      "loss": 0.4305,
      "step": 1525
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.5225870013237,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.7349,
      "step": 1550
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.3841620087623596,
      "learning_rate": 0.00016033945341829248,
      "loss": 0.485,
      "step": 1575
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.5186408162117004,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.7424,
      "step": 1600
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.3792310953140259,
      "learning_rate": 0.00015772553890390197,
      "loss": 0.4729,
      "step": 1625
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.4868522882461548,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.7515,
      "step": 1650
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.41478216648101807,
      "learning_rate": 0.00015505107827058036,
      "loss": 0.5162,
      "step": 1675
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.5396758913993835,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.7324,
      "step": 1700
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.39654281735420227,
      "learning_rate": 0.000152318876658213,
      "loss": 0.4744,
      "step": 1725
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.5178328156471252,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.7343,
      "step": 1750
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.40206876397132874,
      "learning_rate": 0.00014953179976899878,
      "loss": 0.4164,
      "step": 1775
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.4548936188220978,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.7552,
      "step": 1800
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.4183473289012909,
      "learning_rate": 0.00014669277086172406,
      "loss": 0.4746,
      "step": 1825
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.4770437180995941,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.7455,
      "step": 1850
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.42866846919059753,
      "learning_rate": 0.00014380476768566824,
      "loss": 0.4431,
      "step": 1875
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.5761014819145203,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.7603,
      "step": 1900
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.3940599858760834,
      "learning_rate": 0.00014087081935735564,
      "loss": 0.4321,
      "step": 1925
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.4948507249355316,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.7296,
      "step": 1950
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.43581026792526245,
      "learning_rate": 0.00013789400318343068,
      "loss": 0.4566,
      "step": 1975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.5389759540557861,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.7719,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7103967070579529,
      "eval_runtime": 219.3283,
      "eval_samples_per_second": 4.559,
      "eval_steps_per_second": 4.559,
      "step": 2000
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.4007125794887543,
      "learning_rate": 0.00013487744143298822,
      "loss": 0.4461,
      "step": 2025
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.5208436846733093,
      "learning_rate": 0.00013335524316508208,
      "loss": 0.6825,
      "step": 2050
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.45823270082473755,
      "learning_rate": 0.0001318242980627444,
      "loss": 0.4469,
      "step": 2075
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.5361164808273315,
      "learning_rate": 0.00013028500758979506,
      "loss": 0.6614,
      "step": 2100
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.42624756693840027,
      "learning_rate": 0.00012873777539848283,
      "loss": 0.4429,
      "step": 2125
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.535570502281189,
      "learning_rate": 0.0001271830072236343,
      "loss": 0.6665,
      "step": 2150
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.43771862983703613,
      "learning_rate": 0.00012562111077625722,
      "loss": 0.4509,
      "step": 2175
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.5736557841300964,
      "learning_rate": 0.00012405249563662537,
      "loss": 0.6917,
      "step": 2200
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.448431134223938,
      "learning_rate": 0.00012247757314687297,
      "loss": 0.4427,
      "step": 2225
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.5723133087158203,
      "learning_rate": 0.00012089675630312754,
      "loss": 0.701,
      "step": 2250
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.49114343523979187,
      "learning_rate": 0.00011931045964720881,
      "loss": 0.4486,
      "step": 2275
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.6237523555755615,
      "learning_rate": 0.0001177190991579223,
      "loss": 0.6871,
      "step": 2300
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.46683982014656067,
      "learning_rate": 0.00011612309214197599,
      "loss": 0.3882,
      "step": 2325
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.49172917008399963,
      "learning_rate": 0.00011452285712454904,
      "loss": 0.694,
      "step": 2350
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.4529998004436493,
      "learning_rate": 0.00011291881373954065,
      "loss": 0.4011,
      "step": 2375
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.5144772529602051,
      "learning_rate": 0.00011131138261952845,
      "loss": 0.6903,
      "step": 2400
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.47649461030960083,
      "learning_rate": 0.00010970098528546481,
      "loss": 0.4197,
      "step": 2425
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.5795661211013794,
      "learning_rate": 0.00010808804403614043,
      "loss": 0.7061,
      "step": 2450
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.5242928266525269,
      "learning_rate": 0.00010647298183744359,
      "loss": 0.4454,
      "step": 2475
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.638786792755127,
      "learning_rate": 0.00010485622221144484,
      "loss": 0.7049,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7165217995643616,
      "eval_runtime": 219.2953,
      "eval_samples_per_second": 4.56,
      "eval_steps_per_second": 4.56,
      "step": 2500
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.4946136474609375,
      "learning_rate": 0.00010323818912533561,
      "loss": 0.3901,
      "step": 2525
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.6327908635139465,
      "learning_rate": 0.00010161930688025017,
      "loss": 0.6235,
      "step": 2550
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.49079206585884094,
      "learning_rate": 0.0001,
      "loss": 0.3845,
      "step": 2575
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.5512397289276123,
      "learning_rate": 9.838069311974986e-05,
      "loss": 0.6369,
      "step": 2600
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.5789754986763,
      "learning_rate": 9.676181087466444e-05,
      "loss": 0.4206,
      "step": 2625
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.6220259070396423,
      "learning_rate": 9.514377778855521e-05,
      "loss": 0.6438,
      "step": 2650
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.5663986802101135,
      "learning_rate": 9.352701816255643e-05,
      "loss": 0.3855,
      "step": 2675
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.6653696894645691,
      "learning_rate": 9.19119559638596e-05,
      "loss": 0.6401,
      "step": 2700
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.5299130082130432,
      "learning_rate": 9.02990147145352e-05,
      "loss": 0.4372,
      "step": 2725
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.6788339018821716,
      "learning_rate": 8.868861738047158e-05,
      "loss": 0.626,
      "step": 2750
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.548416256904602,
      "learning_rate": 8.70811862604594e-05,
      "loss": 0.4378,
      "step": 2775
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.593603253364563,
      "learning_rate": 8.5477142875451e-05,
      "loss": 0.6409,
      "step": 2800
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.5249488949775696,
      "learning_rate": 8.387690785802402e-05,
      "loss": 0.3775,
      "step": 2825
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.6193860173225403,
      "learning_rate": 8.228090084207774e-05,
      "loss": 0.6251,
      "step": 2850
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.5251181125640869,
      "learning_rate": 8.068954035279121e-05,
      "loss": 0.4373,
      "step": 2875
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.5541934370994568,
      "learning_rate": 7.91032436968725e-05,
      "loss": 0.6234,
      "step": 2900
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.5523983836174011,
      "learning_rate": 7.75224268531271e-05,
      "loss": 0.3992,
      "step": 2925
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.6029078364372253,
      "learning_rate": 7.594750436337467e-05,
      "loss": 0.6496,
      "step": 2950
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.5751553773880005,
      "learning_rate": 7.437888922374276e-05,
      "loss": 0.4068,
      "step": 2975
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.6682794690132141,
      "learning_rate": 7.281699277636572e-05,
      "loss": 0.6249,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7291796803474426,
      "eval_runtime": 219.6144,
      "eval_samples_per_second": 4.553,
      "eval_steps_per_second": 4.553,
      "step": 3000
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.5827456712722778,
      "learning_rate": 7.126222460151719e-05,
      "loss": 0.3713,
      "step": 3025
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.5897841453552246,
      "learning_rate": 6.971499241020495e-05,
      "loss": 0.5926,
      "step": 3050
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.5790358781814575,
      "learning_rate": 6.817570193725564e-05,
      "loss": 0.3606,
      "step": 3075
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.6593535542488098,
      "learning_rate": 6.664475683491796e-05,
      "loss": 0.5815,
      "step": 3100
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.5579343438148499,
      "learning_rate": 6.512255856701177e-05,
      "loss": 0.3741,
      "step": 3125
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.6932533979415894,
      "learning_rate": 6.360950630365126e-05,
      "loss": 0.599,
      "step": 3150
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.6238646507263184,
      "learning_rate": 6.210599681656933e-05,
      "loss": 0.3988,
      "step": 3175
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.6892604231834412,
      "learning_rate": 6.061242437507131e-05,
      "loss": 0.5794,
      "step": 3200
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.5956364274024963,
      "learning_rate": 5.9129180642644414e-05,
      "loss": 0.3964,
      "step": 3225
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.6462383270263672,
      "learning_rate": 5.765665457425102e-05,
      "loss": 0.577,
      "step": 3250
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.5444489121437073,
      "learning_rate": 5.6195232314331766e-05,
      "loss": 0.3372,
      "step": 3275
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.6146126389503479,
      "learning_rate": 5.474529709554612e-05,
      "loss": 0.5886,
      "step": 3300
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.6468065977096558,
      "learning_rate": 5.3307229138275936e-05,
      "loss": 0.4049,
      "step": 3325
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.6818208694458008,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 0.6061,
      "step": 3350
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.5447599291801453,
      "learning_rate": 5.0468200231001286e-05,
      "loss": 0.3832,
      "step": 3375
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.8445221185684204,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 0.5859,
      "step": 3400
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.6378043293952942,
      "learning_rate": 4.768112334178699e-05,
      "loss": 0.4212,
      "step": 3425
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.6571362018585205,
      "learning_rate": 4.630798263510162e-05,
      "loss": 0.5745,
      "step": 3450
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.6576173901557922,
      "learning_rate": 4.494892172941965e-05,
      "loss": 0.4278,
      "step": 3475
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.590206503868103,
      "learning_rate": 4.360429701490934e-05,
      "loss": 0.5606,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7408096194267273,
      "eval_runtime": 219.5873,
      "eval_samples_per_second": 4.554,
      "eval_steps_per_second": 4.554,
      "step": 3500
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.598430871963501,
      "learning_rate": 4.227446109609809e-05,
      "loss": 0.3966,
      "step": 3525
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.7445058822631836,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 0.5331,
      "step": 3550
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.642731785774231,
      "learning_rate": 3.966054658170754e-05,
      "loss": 0.3679,
      "step": 3575
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.6526124477386475,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 0.5458,
      "step": 3600
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.7035693526268005,
      "learning_rate": 3.710991982161555e-05,
      "loss": 0.3847,
      "step": 3625
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.6392536163330078,
      "learning_rate": 3.585917803688603e-05,
      "loss": 0.5647,
      "step": 3650
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.6405512690544128,
      "learning_rate": 3.4625256071074773e-05,
      "loss": 0.3662,
      "step": 3675
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.5848815441131592,
      "learning_rate": 3.340847749883191e-05,
      "loss": 0.5289,
      "step": 3700
    },
    {
      "epoch": 7.45,
      "grad_norm": 0.6210563778877258,
      "learning_rate": 3.2209161399249674e-05,
      "loss": 0.3914,
      "step": 3725
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.7966432571411133,
      "learning_rate": 3.102762227218957e-05,
      "loss": 0.5474,
      "step": 3750
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.7474961876869202,
      "learning_rate": 2.9864169955810084e-05,
      "loss": 0.3816,
      "step": 3775
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.6447770595550537,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 0.5252,
      "step": 3800
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.6985270977020264,
      "learning_rate": 2.759274131295787e-05,
      "loss": 0.3443,
      "step": 3825
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.6217004656791687,
      "learning_rate": 2.6485360629279987e-05,
      "loss": 0.5604,
      "step": 3850
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.6617266535758972,
      "learning_rate": 2.5397257885675397e-05,
      "loss": 0.3417,
      "step": 3875
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.6218265891075134,
      "learning_rate": 2.432871841823047e-05,
      "loss": 0.5597,
      "step": 3900
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.6847166419029236,
      "learning_rate": 2.3280022432901383e-05,
      "loss": 0.3964,
      "step": 3925
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.7299479842185974,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 0.5662,
      "step": 3950
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.749632716178894,
      "learning_rate": 2.1243255642254578e-05,
      "loss": 0.3504,
      "step": 3975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.6279442310333252,
      "learning_rate": 2.025571894372794e-05,
      "loss": 0.5325,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7539476752281189,
      "eval_runtime": 219.7671,
      "eval_samples_per_second": 4.55,
      "eval_steps_per_second": 4.55,
      "step": 4000
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.6723182201385498,
      "learning_rate": 1.9289093800839066e-05,
      "loss": 0.3921,
      "step": 4025
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.6065791845321655,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 0.5464,
      "step": 4050
    },
    {
      "epoch": 8.15,
      "grad_norm": 0.685458779335022,
      "learning_rate": 1.741958655457436e-05,
      "loss": 0.3486,
      "step": 4075
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7020732164382935,
      "learning_rate": 1.65171946970729e-05,
      "loss": 0.5001,
      "step": 4100
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.6924450993537903,
      "learning_rate": 1.563669475839956e-05,
      "loss": 0.3392,
      "step": 4125
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.6372727155685425,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 0.5265,
      "step": 4150
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.7081796526908875,
      "learning_rate": 1.3942288419607475e-05,
      "loss": 0.3728,
      "step": 4175
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.6779430508613586,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 0.5151,
      "step": 4200
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.7258114218711853,
      "learning_rate": 1.233814473646524e-05,
      "loss": 0.3242,
      "step": 4225
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.5814458727836609,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 0.5394,
      "step": 4250
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.7001515626907349,
      "learning_rate": 1.0825946234178574e-05,
      "loss": 0.396,
      "step": 4275
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.7126095294952393,
      "learning_rate": 1.010482589146048e-05,
      "loss": 0.5313,
      "step": 4300
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.6816617250442505,
      "learning_rate": 9.407279000155312e-06,
      "loss": 0.3633,
      "step": 4325
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.7436999082565308,
      "learning_rate": 8.733488479845997e-06,
      "loss": 0.5228,
      "step": 4350
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.7273581624031067,
      "learning_rate": 8.083631020418791e-06,
      "loss": 0.3296,
      "step": 4375
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.7126848697662354,
      "learning_rate": 7.457877035729588e-06,
      "loss": 0.5086,
      "step": 4400
    },
    {
      "epoch": 8.85,
      "grad_norm": 0.6589527726173401,
      "learning_rate": 6.856390618915775e-06,
      "loss": 0.3626,
      "step": 4425
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.7218684554100037,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 0.5139,
      "step": 4450
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.7091190218925476,
      "learning_rate": 5.726845001356573e-06,
      "loss": 0.3933,
      "step": 4475
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.767061710357666,
      "learning_rate": 5.199082004372957e-06,
      "loss": 0.5099,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7640909552574158,
      "eval_runtime": 219.5752,
      "eval_samples_per_second": 4.554,
      "eval_steps_per_second": 4.554,
      "step": 4500
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.708271324634552,
      "learning_rate": 4.6961789051139124e-06,
      "loss": 0.367,
      "step": 4525
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.6839221119880676,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 0.521,
      "step": 4550
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.6941390037536621,
      "learning_rate": 3.7654733565969826e-06,
      "loss": 0.371,
      "step": 4575
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.6004732251167297,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 0.5063,
      "step": 4600
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.727256715297699,
      "learning_rate": 2.9357045374040825e-06,
      "loss": 0.4224,
      "step": 4625
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.6999037265777588,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 0.5125,
      "step": 4650
    },
    {
      "epoch": 9.35,
      "grad_norm": 0.7135998010635376,
      "learning_rate": 2.2077427604429433e-06,
      "loss": 0.3418,
      "step": 4675
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.7368047833442688,
      "learning_rate": 1.882182310176095e-06,
      "loss": 0.5168,
      "step": 4700
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.7023887038230896,
      "learning_rate": 1.5823515570925763e-06,
      "loss": 0.3392,
      "step": 4725
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.6468812227249146,
      "learning_rate": 1.30832912661093e-06,
      "loss": 0.5084,
      "step": 4750
    },
    {
      "epoch": 9.55,
      "grad_norm": 0.699370801448822,
      "learning_rate": 1.0601868763643996e-06,
      "loss": 0.3455,
      "step": 4775
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.7329353094100952,
      "learning_rate": 8.379898773574924e-07,
      "loss": 0.5157,
      "step": 4800
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.735709011554718,
      "learning_rate": 6.41796396902239e-07,
      "loss": 0.3436,
      "step": 4825
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.6764594316482544,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 0.5016,
      "step": 4850
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.7436140179634094,
      "learning_rate": 3.2761895254306287e-07,
      "loss": 0.335,
      "step": 4875
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.6569111943244934,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 0.4924,
      "step": 4900
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.6434914469718933,
      "learning_rate": 1.179840720409331e-07,
      "loss": 0.3556,
      "step": 4925
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.7425673604011536,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 0.5278,
      "step": 4950
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.7371026277542114,
      "learning_rate": 1.3111633436779791e-08,
      "loss": 0.3479,
      "step": 4975
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.6766064167022705,
      "learning_rate": 0.0,
      "loss": 0.4968,
      "step": 5000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.1200184045568e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
