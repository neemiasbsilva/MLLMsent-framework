{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1260,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 0.5613084435462952,
      "learning_rate": 0.00013157894736842108,
      "loss": 1.9193,
      "step": 25
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 0.3127917945384979,
      "learning_rate": 0.0001999524166093866,
      "loss": 1.1212,
      "step": 50
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.34615302085876465,
      "learning_rate": 0.00019954793248829695,
      "loss": 0.7891,
      "step": 75
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7090595364570618,
      "eval_runtime": 64.9197,
      "eval_samples_per_second": 5.176,
      "eval_steps_per_second": 5.176,
      "step": 84
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.2981324791908264,
      "learning_rate": 0.00019873237428991907,
      "loss": 0.6902,
      "step": 100
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 0.5292179584503174,
      "learning_rate": 0.000197509109787199,
      "loss": 0.677,
      "step": 125
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.3229602873325348,
      "learning_rate": 0.00019588319033895623,
      "loss": 0.6805,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6611424684524536,
      "eval_runtime": 65.0032,
      "eval_samples_per_second": 5.169,
      "eval_steps_per_second": 5.169,
      "step": 168
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.32531407475471497,
      "learning_rate": 0.00019386133003075967,
      "loss": 0.6427,
      "step": 175
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.344978392124176,
      "learning_rate": 0.00019145187794972565,
      "loss": 0.6223,
      "step": 200
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.34022244811058044,
      "learning_rate": 0.0001886647837077268,
      "loss": 0.6205,
      "step": 225
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 0.41721659898757935,
      "learning_rate": 0.0001855115563553803,
      "loss": 0.617,
      "step": 250
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6473675966262817,
      "eval_runtime": 64.9898,
      "eval_samples_per_second": 5.17,
      "eval_steps_per_second": 5.17,
      "step": 252
    },
    {
      "epoch": 3.2738095238095237,
      "grad_norm": 0.43231716752052307,
      "learning_rate": 0.00018200521685647663,
      "loss": 0.5921,
      "step": 275
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.313109815120697,
      "learning_rate": 0.00017816024431910115,
      "loss": 0.5893,
      "step": 300
    },
    {
      "epoch": 3.869047619047619,
      "grad_norm": 0.3341187834739685,
      "learning_rate": 0.0001739925162054823,
      "loss": 0.5864,
      "step": 325
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6362082958221436,
      "eval_runtime": 64.9441,
      "eval_samples_per_second": 5.174,
      "eval_steps_per_second": 5.174,
      "step": 336
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.3580670952796936,
      "learning_rate": 0.00016951924276746425,
      "loss": 0.5572,
      "step": 350
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.4178529679775238,
      "learning_rate": 0.00016475889597834695,
      "loss": 0.5387,
      "step": 375
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.41559094190597534,
      "learning_rate": 0.0001597311332545629,
      "loss": 0.5611,
      "step": 400
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.629348635673523,
      "eval_runtime": 65.0685,
      "eval_samples_per_second": 5.164,
      "eval_steps_per_second": 5.164,
      "step": 420
    },
    {
      "epoch": 5.059523809523809,
      "grad_norm": 0.3497772812843323,
      "learning_rate": 0.00015445671628217466,
      "loss": 0.5433,
      "step": 425
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.34394702315330505,
      "learning_rate": 0.0001489574252833924,
      "loss": 0.5118,
      "step": 450
    },
    {
      "epoch": 5.654761904761905,
      "grad_norm": 0.4112398326396942,
      "learning_rate": 0.00014325596907713937,
      "loss": 0.5213,
      "step": 475
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.4646213948726654,
      "learning_rate": 0.00013737589130506246,
      "loss": 0.5048,
      "step": 500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6272941827774048,
      "eval_runtime": 65.029,
      "eval_samples_per_second": 5.167,
      "eval_steps_per_second": 5.167,
      "step": 504
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.44648119807243347,
      "learning_rate": 0.00013134147321021829,
      "loss": 0.4879,
      "step": 525
    },
    {
      "epoch": 6.5476190476190474,
      "grad_norm": 0.4266452491283417,
      "learning_rate": 0.0001251776333699023,
      "loss": 0.4971,
      "step": 550
    },
    {
      "epoch": 6.845238095238095,
      "grad_norm": 0.4140859544277191,
      "learning_rate": 0.00011890982479666412,
      "loss": 0.4966,
      "step": 575
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.6355177760124207,
      "eval_runtime": 65.0726,
      "eval_samples_per_second": 5.163,
      "eval_steps_per_second": 5.163,
      "step": 588
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.4588679373264313,
      "learning_rate": 0.00011256392983242143,
      "loss": 0.4745,
      "step": 600
    },
    {
      "epoch": 7.440476190476191,
      "grad_norm": 0.5061962604522705,
      "learning_rate": 0.00010616615326969767,
      "loss": 0.4515,
      "step": 625
    },
    {
      "epoch": 7.738095238095238,
      "grad_norm": 0.5079668760299683,
      "learning_rate": 9.97429141413294e-05,
      "loss": 0.4639,
      "step": 650
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.642111599445343,
      "eval_runtime": 65.0788,
      "eval_samples_per_second": 5.163,
      "eval_steps_per_second": 5.163,
      "step": 672
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.46021074056625366,
      "learning_rate": 9.332073662548784e-05,
      "loss": 0.4632,
      "step": 675
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.49607187509536743,
      "learning_rate": 8.692614051651242e-05,
      "loss": 0.4336,
      "step": 700
    },
    {
      "epoch": 8.630952380952381,
      "grad_norm": 0.5344851613044739,
      "learning_rate": 8.058553171384699e-05,
      "loss": 0.4459,
      "step": 725
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.535882830619812,
      "learning_rate": 7.43250931812945e-05,
      "loss": 0.4292,
      "step": 750
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6525146961212158,
      "eval_runtime": 64.4932,
      "eval_samples_per_second": 5.21,
      "eval_steps_per_second": 5.21,
      "step": 756
    },
    {
      "epoch": 9.226190476190476,
      "grad_norm": 0.6318897008895874,
      "learning_rate": 6.817067682686413e-05,
      "loss": 0.4152,
      "step": 775
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.5557976365089417,
      "learning_rate": 6.214769674968282e-05,
      "loss": 0.4309,
      "step": 800
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.5640823841094971,
      "learning_rate": 5.6281024294798864e-05,
      "loss": 0.4107,
      "step": 825
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6643068194389343,
      "eval_runtime": 64.4766,
      "eval_samples_per_second": 5.211,
      "eval_steps_per_second": 5.211,
      "step": 840
    },
    {
      "epoch": 10.119047619047619,
      "grad_norm": 0.49034589529037476,
      "learning_rate": 5.059488534923831e-05,
      "loss": 0.407,
      "step": 850
    },
    {
      "epoch": 10.416666666666666,
      "grad_norm": 0.537940502166748,
      "learning_rate": 4.51127603034217e-05,
      "loss": 0.3903,
      "step": 875
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.6114990711212158,
      "learning_rate": 3.985728709104041e-05,
      "loss": 0.3939,
      "step": 900
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.6820164918899536,
      "eval_runtime": 64.9975,
      "eval_samples_per_second": 5.169,
      "eval_steps_per_second": 5.169,
      "step": 924
    },
    {
      "epoch": 11.011904761904763,
      "grad_norm": 0.4922976493835449,
      "learning_rate": 3.4850167707781256e-05,
      "loss": 0.4054,
      "step": 925
    },
    {
      "epoch": 11.30952380952381,
      "grad_norm": 0.5369774699211121,
      "learning_rate": 3.011207859492131e-05,
      "loss": 0.3982,
      "step": 950
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.5889591574668884,
      "learning_rate": 2.5662585257855775e-05,
      "loss": 0.3732,
      "step": 975
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 0.5848217010498047,
      "learning_rate": 2.1520061472133902e-05,
      "loss": 0.3839,
      "step": 1000
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.6875573992729187,
      "eval_runtime": 64.4883,
      "eval_samples_per_second": 5.21,
      "eval_steps_per_second": 5.21,
      "step": 1008
    },
    {
      "epoch": 12.202380952380953,
      "grad_norm": 0.5362151861190796,
      "learning_rate": 1.7701613410634365e-05,
      "loss": 0.3726,
      "step": 1025
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.6208698749542236,
      "learning_rate": 1.4223009005189792e-05,
      "loss": 0.3789,
      "step": 1050
    },
    {
      "epoch": 12.797619047619047,
      "grad_norm": 0.5546208024024963,
      "learning_rate": 1.1098612834355204e-05,
      "loss": 0.3784,
      "step": 1075
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.6963872909545898,
      "eval_runtime": 64.9758,
      "eval_samples_per_second": 5.171,
      "eval_steps_per_second": 5.171,
      "step": 1092
    },
    {
      "epoch": 13.095238095238095,
      "grad_norm": 0.5239973068237305,
      "learning_rate": 8.34132680619546e-06,
      "loss": 0.3706,
      "step": 1100
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.55042964220047,
      "learning_rate": 5.962536881036507e-06,
      "loss": 0.3725,
      "step": 1125
    },
    {
      "epoch": 13.69047619047619,
      "grad_norm": 0.6636233925819397,
      "learning_rate": 3.97206605418432e-06,
      "loss": 0.3622,
      "step": 1150
    },
    {
      "epoch": 13.988095238095237,
      "grad_norm": 0.5867546796798706,
      "learning_rate": 2.3781337927645585e-06,
      "loss": 0.3682,
      "step": 1175
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.6998223662376404,
      "eval_runtime": 64.9371,
      "eval_samples_per_second": 5.174,
      "eval_steps_per_second": 5.174,
      "step": 1176
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.5730695128440857,
      "learning_rate": 1.1873220941853502e-06,
      "loss": 0.3731,
      "step": 1200
    },
    {
      "epoch": 14.583333333333334,
      "grad_norm": 0.5683758854866028,
      "learning_rate": 4.045483063813471e-07,
      "loss": 0.3692,
      "step": 1225
    },
    {
      "epoch": 14.880952380952381,
      "grad_norm": 0.6170101165771484,
      "learning_rate": 3.304482207533433e-08,
      "loss": 0.3608,
      "step": 1250
    }
  ],
  "logging_steps": 25,
  "max_steps": 1260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1187029629833216e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
