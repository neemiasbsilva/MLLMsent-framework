{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2980,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08389261744966443,
      "grad_norm": 0.5060010552406311,
      "learning_rate": 5.555555555555556e-05,
      "loss": 1.2397,
      "step": 25
    },
    {
      "epoch": 0.16778523489932887,
      "grad_norm": 1.0653796195983887,
      "learning_rate": 0.00011111111111111112,
      "loss": 2.1255,
      "step": 50
    },
    {
      "epoch": 0.2516778523489933,
      "grad_norm": 0.7197878360748291,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.7165,
      "step": 75
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 1.0589877367019653,
      "learning_rate": 0.00019999409160138693,
      "loss": 1.0768,
      "step": 100
    },
    {
      "epoch": 0.41946308724832215,
      "grad_norm": 0.4424453675746918,
      "learning_rate": 0.0001999276301349302,
      "loss": 0.6965,
      "step": 125
    },
    {
      "epoch": 0.5033557046979866,
      "grad_norm": 0.921116828918457,
      "learning_rate": 0.00019978737094995526,
      "loss": 0.9544,
      "step": 150
    },
    {
      "epoch": 0.587248322147651,
      "grad_norm": 0.40762120485305786,
      "learning_rate": 0.00019957341762950344,
      "loss": 0.6422,
      "step": 175
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 0.5316795110702515,
      "learning_rate": 0.0001992859281805935,
      "loss": 0.9404,
      "step": 200
    },
    {
      "epoch": 0.7550335570469798,
      "grad_norm": 0.33454033732414246,
      "learning_rate": 0.00019892511491753124,
      "loss": 0.547,
      "step": 225
    },
    {
      "epoch": 0.8389261744966443,
      "grad_norm": 0.6773989200592041,
      "learning_rate": 0.0001984912443051131,
      "loss": 0.9187,
      "step": 250
    },
    {
      "epoch": 0.9228187919463087,
      "grad_norm": 0.34705764055252075,
      "learning_rate": 0.00019798463676183888,
      "loss": 0.6016,
      "step": 275
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8467361330986023,
      "eval_runtime": 131.6311,
      "eval_samples_per_second": 4.528,
      "eval_steps_per_second": 4.528,
      "step": 298
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 0.11799819022417068,
      "learning_rate": 0.00019740566642327867,
      "loss": 0.8679,
      "step": 300
    },
    {
      "epoch": 1.0906040268456376,
      "grad_norm": 0.38823968172073364,
      "learning_rate": 0.00019675476086576972,
      "loss": 0.6642,
      "step": 325
    },
    {
      "epoch": 1.174496644295302,
      "grad_norm": 0.11011878401041031,
      "learning_rate": 0.00019603240079064604,
      "loss": 0.8148,
      "step": 350
    },
    {
      "epoch": 1.2583892617449663,
      "grad_norm": 0.3808888792991638,
      "learning_rate": 0.00019523911966923507,
      "loss": 0.6021,
      "step": 375
    },
    {
      "epoch": 1.342281879194631,
      "grad_norm": 0.13099998235702515,
      "learning_rate": 0.00019437550334888278,
      "loss": 0.8243,
      "step": 400
    },
    {
      "epoch": 1.4261744966442953,
      "grad_norm": 0.38727644085884094,
      "learning_rate": 0.00019344218962029857,
      "loss": 0.6722,
      "step": 425
    },
    {
      "epoch": 1.5100671140939599,
      "grad_norm": 0.15750008821487427,
      "learning_rate": 0.00019243986774653956,
      "loss": 0.7974,
      "step": 450
    },
    {
      "epoch": 1.5939597315436242,
      "grad_norm": 0.33963143825531006,
      "learning_rate": 0.00019136927795398157,
      "loss": 0.5744,
      "step": 475
    },
    {
      "epoch": 1.6778523489932886,
      "grad_norm": 0.12496045976877213,
      "learning_rate": 0.00019023121088565352,
      "loss": 0.7982,
      "step": 500
    },
    {
      "epoch": 1.761744966442953,
      "grad_norm": 0.34576675295829773,
      "learning_rate": 0.0001890265070173382,
      "loss": 0.6485,
      "step": 525
    },
    {
      "epoch": 1.8456375838926173,
      "grad_norm": 0.1380535066127777,
      "learning_rate": 0.00018775605603687127,
      "loss": 0.8123,
      "step": 550
    },
    {
      "epoch": 1.929530201342282,
      "grad_norm": 0.33253714442253113,
      "learning_rate": 0.00018642079618709628,
      "loss": 0.622,
      "step": 575
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7745444178581238,
      "eval_runtime": 131.5952,
      "eval_samples_per_second": 4.529,
      "eval_steps_per_second": 4.529,
      "step": 596
    },
    {
      "epoch": 2.0134228187919465,
      "grad_norm": 0.09340786933898926,
      "learning_rate": 0.00018502171357296144,
      "loss": 0.7648,
      "step": 600
    },
    {
      "epoch": 2.097315436241611,
      "grad_norm": 0.36664676666259766,
      "learning_rate": 0.00018355984143326968,
      "loss": 0.7033,
      "step": 625
    },
    {
      "epoch": 2.1812080536912752,
      "grad_norm": 0.12357814610004425,
      "learning_rate": 0.0001820362593776198,
      "loss": 0.6971,
      "step": 650
    },
    {
      "epoch": 2.2651006711409396,
      "grad_norm": 0.3556303083896637,
      "learning_rate": 0.0001804520925891021,
      "loss": 0.6349,
      "step": 675
    },
    {
      "epoch": 2.348993288590604,
      "grad_norm": 0.11858145147562027,
      "learning_rate": 0.00017880851099333762,
      "loss": 0.7025,
      "step": 700
    },
    {
      "epoch": 2.4328859060402683,
      "grad_norm": 0.36737295985221863,
      "learning_rate": 0.0001771067283944744,
      "loss": 0.602,
      "step": 725
    },
    {
      "epoch": 2.5167785234899327,
      "grad_norm": 0.12702029943466187,
      "learning_rate": 0.00017534800157877918,
      "loss": 0.6997,
      "step": 750
    },
    {
      "epoch": 2.600671140939597,
      "grad_norm": 0.37213265895843506,
      "learning_rate": 0.0001735336293864857,
      "loss": 0.6481,
      "step": 775
    },
    {
      "epoch": 2.684563758389262,
      "grad_norm": 0.12704312801361084,
      "learning_rate": 0.00017166495175258652,
      "loss": 0.703,
      "step": 800
    },
    {
      "epoch": 2.7684563758389262,
      "grad_norm": 0.41460004448890686,
      "learning_rate": 0.00016974334871727517,
      "loss": 0.6395,
      "step": 825
    },
    {
      "epoch": 2.8523489932885906,
      "grad_norm": 0.09962985664606094,
      "learning_rate": 0.00016777023940677034,
      "loss": 0.7173,
      "step": 850
    },
    {
      "epoch": 2.936241610738255,
      "grad_norm": 0.37553688883781433,
      "learning_rate": 0.0001657470809852749,
      "loss": 0.6819,
      "step": 875
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.742431104183197,
      "eval_runtime": 131.6105,
      "eval_samples_per_second": 4.529,
      "eval_steps_per_second": 4.529,
      "step": 894
    },
    {
      "epoch": 3.0201342281879193,
      "grad_norm": 0.10687118768692017,
      "learning_rate": 0.00016367536757884286,
      "loss": 0.6597,
      "step": 900
    },
    {
      "epoch": 3.1040268456375837,
      "grad_norm": 0.37731996178627014,
      "learning_rate": 0.00016155662917195017,
      "loss": 0.6529,
      "step": 925
    },
    {
      "epoch": 3.1879194630872485,
      "grad_norm": 0.1552221029996872,
      "learning_rate": 0.0001593924304775831,
      "loss": 0.6085,
      "step": 950
    },
    {
      "epoch": 3.271812080536913,
      "grad_norm": 0.4278571903705597,
      "learning_rate": 0.00015718436978167977,
      "loss": 0.7178,
      "step": 975
    },
    {
      "epoch": 3.3557046979865772,
      "grad_norm": 0.08605527132749557,
      "learning_rate": 0.00015493407776277698,
      "loss": 0.6085,
      "step": 1000
    },
    {
      "epoch": 3.4395973154362416,
      "grad_norm": 0.4203477203845978,
      "learning_rate": 0.0001526432162877356,
      "loss": 0.6492,
      "step": 1025
    },
    {
      "epoch": 3.523489932885906,
      "grad_norm": 0.11248090118169785,
      "learning_rate": 0.00015031347718443211,
      "loss": 0.6071,
      "step": 1050
    },
    {
      "epoch": 3.6073825503355703,
      "grad_norm": 0.48982611298561096,
      "learning_rate": 0.00014794658099232425,
      "loss": 0.6731,
      "step": 1075
    },
    {
      "epoch": 3.6912751677852347,
      "grad_norm": 0.10710129886865616,
      "learning_rate": 0.0001455442756918126,
      "loss": 0.6072,
      "step": 1100
    },
    {
      "epoch": 3.7751677852348995,
      "grad_norm": 0.43763262033462524,
      "learning_rate": 0.00014310833541333656,
      "loss": 0.644,
      "step": 1125
    },
    {
      "epoch": 3.859060402684564,
      "grad_norm": 0.10549430549144745,
      "learning_rate": 0.00014064055912715845,
      "loss": 0.5981,
      "step": 1150
    },
    {
      "epoch": 3.942953020134228,
      "grad_norm": 0.41093194484710693,
      "learning_rate": 0.00013814276931480308,
      "loss": 0.6156,
      "step": 1175
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7388205528259277,
      "eval_runtime": 131.6496,
      "eval_samples_per_second": 4.527,
      "eval_steps_per_second": 4.527,
      "step": 1192
    },
    {
      "epoch": 4.026845637583893,
      "grad_norm": 0.11565026640892029,
      "learning_rate": 0.0001356168106231337,
      "loss": 0.5509,
      "step": 1200
    },
    {
      "epoch": 4.110738255033557,
      "grad_norm": 0.4759006202220917,
      "learning_rate": 0.00013306454850205913,
      "loss": 0.7152,
      "step": 1225
    },
    {
      "epoch": 4.194630872483222,
      "grad_norm": 0.1306021809577942,
      "learning_rate": 0.00013048786782687705,
      "loss": 0.5148,
      "step": 1250
    },
    {
      "epoch": 4.278523489932886,
      "grad_norm": 0.45842042565345764,
      "learning_rate": 0.00012788867150627161,
      "loss": 0.6392,
      "step": 1275
    },
    {
      "epoch": 4.3624161073825505,
      "grad_norm": 0.12341410666704178,
      "learning_rate": 0.00012526887907699348,
      "loss": 0.4957,
      "step": 1300
    },
    {
      "epoch": 4.446308724832215,
      "grad_norm": 0.5047346949577332,
      "learning_rate": 0.00012263042528625926,
      "loss": 0.6464,
      "step": 1325
    },
    {
      "epoch": 4.530201342281879,
      "grad_norm": 0.11529866605997086,
      "learning_rate": 0.00011997525866291841,
      "loss": 0.5041,
      "step": 1350
    },
    {
      "epoch": 4.614093959731544,
      "grad_norm": 0.5024940967559814,
      "learning_rate": 0.00011730534007844185,
      "loss": 0.6446,
      "step": 1375
    },
    {
      "epoch": 4.697986577181208,
      "grad_norm": 0.12856276333332062,
      "learning_rate": 0.00011462264129879554,
      "loss": 0.529,
      "step": 1400
    },
    {
      "epoch": 4.781879194630872,
      "grad_norm": 0.5248509049415588,
      "learning_rate": 0.00011192914352826849,
      "loss": 0.658,
      "step": 1425
    },
    {
      "epoch": 4.865771812080537,
      "grad_norm": 0.12311744689941406,
      "learning_rate": 0.00010922683594633021,
      "loss": 0.5019,
      "step": 1450
    },
    {
      "epoch": 4.949664429530201,
      "grad_norm": 0.4908876419067383,
      "learning_rate": 0.00010651771423859844,
      "loss": 0.6934,
      "step": 1475
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.731848418712616,
      "eval_runtime": 131.5672,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 4.53,
      "step": 1490
    },
    {
      "epoch": 5.033557046979865,
      "grad_norm": 0.1239461824297905,
      "learning_rate": 0.0001038037791230023,
      "loss": 0.4699,
      "step": 1500
    },
    {
      "epoch": 5.117449664429531,
      "grad_norm": 0.5566223859786987,
      "learning_rate": 0.00010108703487222855,
      "loss": 0.6861,
      "step": 1525
    },
    {
      "epoch": 5.201342281879195,
      "grad_norm": 0.11737260222434998,
      "learning_rate": 9.836948783354309e-05,
      "loss": 0.4179,
      "step": 1550
    },
    {
      "epoch": 5.285234899328859,
      "grad_norm": 0.5283644199371338,
      "learning_rate": 9.565314494707995e-05,
      "loss": 0.6943,
      "step": 1575
    },
    {
      "epoch": 5.369127516778524,
      "grad_norm": 0.13272322714328766,
      "learning_rate": 9.294001226369282e-05,
      "loss": 0.4296,
      "step": 1600
    },
    {
      "epoch": 5.453020134228188,
      "grad_norm": 0.5499820709228516,
      "learning_rate": 9.023209346346293e-05,
      "loss": 0.6822,
      "step": 1625
    },
    {
      "epoch": 5.5369127516778525,
      "grad_norm": 0.13729028403759003,
      "learning_rate": 8.753138837595817e-05,
      "loss": 0.4305,
      "step": 1650
    },
    {
      "epoch": 5.620805369127517,
      "grad_norm": 0.5564575791358948,
      "learning_rate": 8.483989150333556e-05,
      "loss": 0.6619,
      "step": 1675
    },
    {
      "epoch": 5.704697986577181,
      "grad_norm": 0.14394253492355347,
      "learning_rate": 8.215959054737817e-05,
      "loss": 0.4387,
      "step": 1700
    },
    {
      "epoch": 5.7885906040268456,
      "grad_norm": 0.5585713386535645,
      "learning_rate": 7.949246494155421e-05,
      "loss": 0.6415,
      "step": 1725
    },
    {
      "epoch": 5.87248322147651,
      "grad_norm": 0.1530735194683075,
      "learning_rate": 7.684048438918248e-05,
      "loss": 0.4307,
      "step": 1750
    },
    {
      "epoch": 5.956375838926174,
      "grad_norm": 0.5513046979904175,
      "learning_rate": 7.420560740878334e-05,
      "loss": 0.6185,
      "step": 1775
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.735049843788147,
      "eval_runtime": 131.6181,
      "eval_samples_per_second": 4.528,
      "eval_steps_per_second": 4.528,
      "step": 1788
    },
    {
      "epoch": 6.040268456375839,
      "grad_norm": 0.11901117861270905,
      "learning_rate": 7.158977988769023e-05,
      "loss": 0.3941,
      "step": 1800
    },
    {
      "epoch": 6.124161073825503,
      "grad_norm": 0.5874331593513489,
      "learning_rate": 6.899493364498883e-05,
      "loss": 0.6696,
      "step": 1825
    },
    {
      "epoch": 6.208053691275167,
      "grad_norm": 0.13798587024211884,
      "learning_rate": 6.642298500484658e-05,
      "loss": 0.3646,
      "step": 1850
    },
    {
      "epoch": 6.291946308724833,
      "grad_norm": 0.6564117074012756,
      "learning_rate": 6.387583338128471e-05,
      "loss": 0.6505,
      "step": 1875
    },
    {
      "epoch": 6.375838926174497,
      "grad_norm": 0.13562044501304626,
      "learning_rate": 6.135535987543899e-05,
      "loss": 0.3724,
      "step": 1900
    },
    {
      "epoch": 6.459731543624161,
      "grad_norm": 0.6461546421051025,
      "learning_rate": 5.886342588634458e-05,
      "loss": 0.6863,
      "step": 1925
    },
    {
      "epoch": 6.543624161073826,
      "grad_norm": 0.13988792896270752,
      "learning_rate": 5.64018717362711e-05,
      "loss": 0.3568,
      "step": 1950
    },
    {
      "epoch": 6.62751677852349,
      "grad_norm": 0.6449170708656311,
      "learning_rate": 5.397251531162332e-05,
      "loss": 0.638,
      "step": 1975
    },
    {
      "epoch": 6.7114093959731544,
      "grad_norm": 0.1658291518688202,
      "learning_rate": 5.1577150720410935e-05,
      "loss": 0.3491,
      "step": 2000
    },
    {
      "epoch": 6.795302013422819,
      "grad_norm": 0.6743526458740234,
      "learning_rate": 4.921754696727869e-05,
      "loss": 0.6477,
      "step": 2025
    },
    {
      "epoch": 6.879194630872483,
      "grad_norm": 0.12273870408535004,
      "learning_rate": 4.6895446647076005e-05,
      "loss": 0.3542,
      "step": 2050
    },
    {
      "epoch": 6.9630872483221475,
      "grad_norm": 0.680073618888855,
      "learning_rate": 4.461256465793032e-05,
      "loss": 0.6568,
      "step": 2075
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7483145594596863,
      "eval_runtime": 131.6323,
      "eval_samples_per_second": 4.528,
      "eval_steps_per_second": 4.528,
      "step": 2086
    },
    {
      "epoch": 7.046979865771812,
      "grad_norm": 0.1530442237854004,
      "learning_rate": 4.237058693477499e-05,
      "loss": 0.3396,
      "step": 2100
    },
    {
      "epoch": 7.130872483221476,
      "grad_norm": 0.632149875164032,
      "learning_rate": 4.017116920426651e-05,
      "loss": 0.6603,
      "step": 2125
    },
    {
      "epoch": 7.214765100671141,
      "grad_norm": 0.14563870429992676,
      "learning_rate": 3.801593576201118e-05,
      "loss": 0.3176,
      "step": 2150
    },
    {
      "epoch": 7.298657718120805,
      "grad_norm": 0.6579564809799194,
      "learning_rate": 3.590647827300405e-05,
      "loss": 0.6389,
      "step": 2175
    },
    {
      "epoch": 7.382550335570469,
      "grad_norm": 0.15241335332393646,
      "learning_rate": 3.384435459616536e-05,
      "loss": 0.3142,
      "step": 2200
    },
    {
      "epoch": 7.466442953020135,
      "grad_norm": 0.7474321126937866,
      "learning_rate": 3.1831087633844145e-05,
      "loss": 0.6331,
      "step": 2225
    },
    {
      "epoch": 7.550335570469799,
      "grad_norm": 0.16106471419334412,
      "learning_rate": 2.9868164207136616e-05,
      "loss": 0.311,
      "step": 2250
    },
    {
      "epoch": 7.634228187919463,
      "grad_norm": 0.7261984944343567,
      "learning_rate": 2.795703395785184e-05,
      "loss": 0.6574,
      "step": 2275
    },
    {
      "epoch": 7.718120805369128,
      "grad_norm": 0.2715460956096649,
      "learning_rate": 2.6099108277934103e-05,
      "loss": 0.3126,
      "step": 2300
    },
    {
      "epoch": 7.802013422818792,
      "grad_norm": 0.751805305480957,
      "learning_rate": 2.42957592671337e-05,
      "loss": 0.6575,
      "step": 2325
    },
    {
      "epoch": 7.885906040268456,
      "grad_norm": 0.1469549685716629,
      "learning_rate": 2.2548318719695182e-05,
      "loss": 0.3137,
      "step": 2350
    },
    {
      "epoch": 7.969798657718121,
      "grad_norm": 0.704738438129425,
      "learning_rate": 2.085807714081195e-05,
      "loss": 0.6444,
      "step": 2375
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7616012096405029,
      "eval_runtime": 131.6219,
      "eval_samples_per_second": 4.528,
      "eval_steps_per_second": 4.528,
      "step": 2384
    },
    {
      "epoch": 8.053691275167786,
      "grad_norm": 0.683387279510498,
      "learning_rate": 1.9226282793572924e-05,
      "loss": 0.3217,
      "step": 2400
    },
    {
      "epoch": 8.13758389261745,
      "grad_norm": 0.7352825999259949,
      "learning_rate": 1.7654140777105953e-05,
      "loss": 0.6149,
      "step": 2425
    },
    {
      "epoch": 8.221476510067115,
      "grad_norm": 0.1232871487736702,
      "learning_rate": 1.6142812136597853e-05,
      "loss": 0.2684,
      "step": 2450
    },
    {
      "epoch": 8.305369127516778,
      "grad_norm": 0.7289324998855591,
      "learning_rate": 1.4693413005849143e-05,
      "loss": 0.5624,
      "step": 2475
    },
    {
      "epoch": 8.389261744966444,
      "grad_norm": 0.21771275997161865,
      "learning_rate": 1.3307013782996235e-05,
      "loss": 0.2867,
      "step": 2500
    },
    {
      "epoch": 8.473154362416107,
      "grad_norm": 0.719497561454773,
      "learning_rate": 1.1984638340009934e-05,
      "loss": 0.6432,
      "step": 2525
    },
    {
      "epoch": 8.557046979865772,
      "grad_norm": 0.755591869354248,
      "learning_rate": 1.0727263266554011e-05,
      "loss": 0.3392,
      "step": 2550
    },
    {
      "epoch": 8.640939597315436,
      "grad_norm": 0.7974687218666077,
      "learning_rate": 9.535817148762461e-06,
      "loss": 0.628,
      "step": 2575
    },
    {
      "epoch": 8.724832214765101,
      "grad_norm": 0.6558040976524353,
      "learning_rate": 8.411179883467667e-06,
      "loss": 0.3261,
      "step": 2600
    },
    {
      "epoch": 8.808724832214764,
      "grad_norm": 0.7941562533378601,
      "learning_rate": 7.354182028386591e-06,
      "loss": 0.6236,
      "step": 2625
    },
    {
      "epoch": 8.89261744966443,
      "grad_norm": 0.6339905261993408,
      "learning_rate": 6.365604188743979e-06,
      "loss": 0.344,
      "step": 2650
    },
    {
      "epoch": 8.976510067114093,
      "grad_norm": 0.8175039291381836,
      "learning_rate": 5.446176440786488e-06,
      "loss": 0.6076,
      "step": 2675
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7682881355285645,
      "eval_runtime": 131.6215,
      "eval_samples_per_second": 4.528,
      "eval_steps_per_second": 4.528,
      "step": 2682
    },
    {
      "epoch": 9.060402684563758,
      "grad_norm": 0.6994063258171082,
      "learning_rate": 4.596577792612755e-06,
      "loss": 0.3395,
      "step": 2700
    },
    {
      "epoch": 9.144295302013424,
      "grad_norm": 0.7481642365455627,
      "learning_rate": 3.817435682718096e-06,
      "loss": 0.5844,
      "step": 2725
    },
    {
      "epoch": 9.228187919463087,
      "grad_norm": 0.6647382378578186,
      "learning_rate": 3.1093255166238176e-06,
      "loss": 0.3049,
      "step": 2750
    },
    {
      "epoch": 9.312080536912752,
      "grad_norm": 0.7654926180839539,
      "learning_rate": 2.4727702419335864e-06,
      "loss": 0.6,
      "step": 2775
    },
    {
      "epoch": 9.395973154362416,
      "grad_norm": 0.742375373840332,
      "learning_rate": 1.908239962130476e-06,
      "loss": 0.308,
      "step": 2800
    },
    {
      "epoch": 9.479865771812081,
      "grad_norm": 0.7522438168525696,
      "learning_rate": 1.4161515894001165e-06,
      "loss": 0.6002,
      "step": 2825
    },
    {
      "epoch": 9.563758389261745,
      "grad_norm": 0.6726034283638,
      "learning_rate": 9.968685367361618e-07,
      "loss": 0.3196,
      "step": 2850
    },
    {
      "epoch": 9.64765100671141,
      "grad_norm": 0.7364824414253235,
      "learning_rate": 6.507004495555969e-07,
      "loss": 0.5771,
      "step": 2875
    },
    {
      "epoch": 9.731543624161073,
      "grad_norm": 0.6934212446212769,
      "learning_rate": 3.779029770219378e-07,
      "loss": 0.3028,
      "step": 2900
    },
    {
      "epoch": 9.815436241610739,
      "grad_norm": 0.7517547607421875,
      "learning_rate": 1.786775832454013e-07,
      "loss": 0.6059,
      "step": 2925
    },
    {
      "epoch": 9.899328859060402,
      "grad_norm": 0.708906352519989,
      "learning_rate": 5.317139849928543e-08,
      "loss": 0.3459,
      "step": 2950
    },
    {
      "epoch": 9.983221476510067,
      "grad_norm": 0.7786555886268616,
      "learning_rate": 1.4771105625421834e-09,
      "loss": 0.5776,
      "step": 2975
    }
  ],
  "logging_steps": 25,
  "max_steps": 2980,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3737684753293312e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
