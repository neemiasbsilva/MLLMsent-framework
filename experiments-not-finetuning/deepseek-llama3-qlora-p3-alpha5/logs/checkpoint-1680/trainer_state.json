{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1680,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1488095238095238,
      "grad_norm": 0.5661634802818298,
      "learning_rate": 9.80392156862745e-05,
      "loss": 1.4436,
      "step": 25
    },
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 0.1530442088842392,
      "learning_rate": 0.000196078431372549,
      "loss": 1.3914,
      "step": 50
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.7296481132507324,
      "learning_rate": 0.00019989290417745542,
      "loss": 1.0847,
      "step": 75
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 0.44406259059906006,
      "learning_rate": 0.00019955383393934674,
      "loss": 0.6548,
      "step": 100
    },
    {
      "epoch": 0.7440476190476191,
      "grad_norm": 0.4372686445713043,
      "learning_rate": 0.00019898339135298508,
      "loss": 1.0232,
      "step": 125
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.35944679379463196,
      "learning_rate": 0.00019818290217987587,
      "loss": 0.6457,
      "step": 150
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8571695685386658,
      "eval_runtime": 113.6712,
      "eval_samples_per_second": 2.956,
      "eval_steps_per_second": 2.956,
      "step": 168
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.1377636045217514,
      "learning_rate": 0.00019715422683113938,
      "loss": 0.716,
      "step": 175
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.41501811146736145,
      "learning_rate": 0.00019589975604374286,
      "loss": 0.8335,
      "step": 200
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.5264672636985779,
      "learning_rate": 0.00019442240532420584,
      "loss": 0.5295,
      "step": 225
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 0.3750944137573242,
      "learning_rate": 0.00019272560817269247,
      "loss": 0.9605,
      "step": 250
    },
    {
      "epoch": 1.6369047619047619,
      "grad_norm": 0.3859926462173462,
      "learning_rate": 0.00019081330810323852,
      "loss": 0.654,
      "step": 275
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.1312640756368637,
      "learning_rate": 0.00018868994947865883,
      "loss": 0.7183,
      "step": 300
    },
    {
      "epoch": 1.9345238095238095,
      "grad_norm": 0.4247559905052185,
      "learning_rate": 0.0001863604671814357,
      "loss": 0.819,
      "step": 325
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7949240803718567,
      "eval_runtime": 110.379,
      "eval_samples_per_second": 3.044,
      "eval_steps_per_second": 3.044,
      "step": 336
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.07045280933380127,
      "learning_rate": 0.00018383027514459402,
      "loss": 0.4734,
      "step": 350
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.3855273127555847,
      "learning_rate": 0.00018110525376921862,
      "loss": 0.8932,
      "step": 375
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.42419523000717163,
      "learning_rate": 0.00017819173625785643,
      "loss": 0.6475,
      "step": 400
    },
    {
      "epoch": 2.5297619047619047,
      "grad_norm": 0.10506783425807953,
      "learning_rate": 0.00017509649389556607,
      "loss": 0.6927,
      "step": 425
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.4357561767101288,
      "learning_rate": 0.00017182672031282296,
      "loss": 0.763,
      "step": 450
    },
    {
      "epoch": 2.8273809523809526,
      "grad_norm": 0.1405135691165924,
      "learning_rate": 0.0001683900147668547,
      "loss": 0.4925,
      "step": 475
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 0.45411840081214905,
      "learning_rate": 0.00016479436448026195,
      "loss": 0.926,
      "step": 500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7685701251029968,
      "eval_runtime": 120.7739,
      "eval_samples_per_second": 2.782,
      "eval_steps_per_second": 2.782,
      "step": 504
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.3769031763076782,
      "learning_rate": 0.00016104812607797202,
      "loss": 0.5567,
      "step": 525
    },
    {
      "epoch": 3.2738095238095237,
      "grad_norm": 0.12311413139104843,
      "learning_rate": 0.00015716000616566698,
      "loss": 0.6807,
      "step": 550
    },
    {
      "epoch": 3.4226190476190474,
      "grad_norm": 0.4547887146472931,
      "learning_rate": 0.00015313904109482432,
      "loss": 0.6851,
      "step": 575
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.11422424018383026,
      "learning_rate": 0.00014899457596139729,
      "loss": 0.4799,
      "step": 600
    },
    {
      "epoch": 3.7202380952380953,
      "grad_norm": 0.4879702031612396,
      "learning_rate": 0.00014473624288694498,
      "loss": 0.8265,
      "step": 625
    },
    {
      "epoch": 3.869047619047619,
      "grad_norm": 0.4140746593475342,
      "learning_rate": 0.00014037393863268783,
      "loss": 0.559,
      "step": 650
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7575430274009705,
      "eval_runtime": 100.7436,
      "eval_samples_per_second": 3.335,
      "eval_steps_per_second": 3.335,
      "step": 672
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.12707100808620453,
      "learning_rate": 0.0001359178015985163,
      "loss": 0.6931,
      "step": 675
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.4673181176185608,
      "learning_rate": 0.00013137818826040854,
      "loss": 0.625,
      "step": 700
    },
    {
      "epoch": 4.315476190476191,
      "grad_norm": 0.1122424304485321,
      "learning_rate": 0.00012676564910101947,
      "loss": 0.4551,
      "step": 725
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.5223516821861267,
      "learning_rate": 0.00012209090408937971,
      "loss": 0.7393,
      "step": 750
    },
    {
      "epoch": 4.613095238095238,
      "grad_norm": 0.49048948287963867,
      "learning_rate": 0.00011736481776669306,
      "loss": 0.5384,
      "step": 775
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.11192809045314789,
      "learning_rate": 0.0001125983739961344,
      "loss": 0.69,
      "step": 800
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 0.5125061869621277,
      "learning_rate": 0.0001078026504353325,
      "loss": 0.5573,
      "step": 825
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7503566741943359,
      "eval_runtime": 102.9626,
      "eval_samples_per_second": 3.263,
      "eval_steps_per_second": 3.263,
      "step": 840
    },
    {
      "epoch": 5.059523809523809,
      "grad_norm": 0.1194843053817749,
      "learning_rate": 0.00010298879279086568,
      "loss": 0.4847,
      "step": 850
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 0.548609733581543,
      "learning_rate": 9.816798891460546e-05,
      "loss": 0.6997,
      "step": 875
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.6305694580078125,
      "learning_rate": 9.335144280211066e-05,
      "loss": 0.462,
      "step": 900
    },
    {
      "epoch": 5.505952380952381,
      "grad_norm": 0.14275698363780975,
      "learning_rate": 8.855034855350194e-05,
      "loss": 0.644,
      "step": 925
    },
    {
      "epoch": 5.654761904761905,
      "grad_norm": 0.5925068855285645,
      "learning_rate": 8.377586435733446e-05,
      "loss": 0.534,
      "step": 950
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 0.15507791936397552,
      "learning_rate": 7.903908655793224e-05,
      "loss": 0.4703,
      "step": 975
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.5798906683921814,
      "learning_rate": 7.43510238664542e-05,
      "loss": 0.6711,
      "step": 1000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7521133422851562,
      "eval_runtime": 99.9021,
      "eval_samples_per_second": 3.363,
      "eval_steps_per_second": 3.363,
      "step": 1008
    },
    {
      "epoch": 6.101190476190476,
      "grad_norm": 0.5644449591636658,
      "learning_rate": 6.97225717756278e-05,
      "loss": 0.4269,
      "step": 1025
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.7925593852996826,
      "learning_rate": 6.516448723761315e-05,
      "loss": 0.6314,
      "step": 1050
    },
    {
      "epoch": 6.398809523809524,
      "grad_norm": 0.615488588809967,
      "learning_rate": 6.068736366384764e-05,
      "loss": 0.4731,
      "step": 1075
    },
    {
      "epoch": 6.5476190476190474,
      "grad_norm": 0.16251830756664276,
      "learning_rate": 5.630160630497493e-05,
      "loss": 0.4548,
      "step": 1100
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 0.6555115580558777,
      "learning_rate": 5.2017408068077064e-05,
      "loss": 0.6349,
      "step": 1125
    },
    {
      "epoch": 6.845238095238095,
      "grad_norm": 0.6460558772087097,
      "learning_rate": 4.7844725827412054e-05,
      "loss": 0.3741,
      "step": 1150
    },
    {
      "epoch": 6.994047619047619,
      "grad_norm": 0.6525358557701111,
      "learning_rate": 4.379325728371473e-05,
      "loss": 0.6547,
      "step": 1175
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7654324769973755,
      "eval_runtime": 100.5306,
      "eval_samples_per_second": 3.342,
      "eval_steps_per_second": 3.342,
      "step": 1176
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.6030939221382141,
      "learning_rate": 3.987241842583983e-05,
      "loss": 0.4383,
      "step": 1200
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 0.18021661043167114,
      "learning_rate": 3.6091321647130484e-05,
      "loss": 0.4407,
      "step": 1225
    },
    {
      "epoch": 7.440476190476191,
      "grad_norm": 0.7316427230834961,
      "learning_rate": 3.24587545673703e-05,
      "loss": 0.5705,
      "step": 1250
    },
    {
      "epoch": 7.589285714285714,
      "grad_norm": 0.7503220438957214,
      "learning_rate": 2.8983159609539635e-05,
      "loss": 0.4032,
      "step": 1275
    },
    {
      "epoch": 7.738095238095238,
      "grad_norm": 0.8210831880569458,
      "learning_rate": 2.567261437884112e-05,
      "loss": 0.6212,
      "step": 1300
    },
    {
      "epoch": 7.886904761904762,
      "grad_norm": 0.6844701170921326,
      "learning_rate": 2.253481288959558e-05,
      "loss": 0.4222,
      "step": 1325
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7788258790969849,
      "eval_runtime": 111.4124,
      "eval_samples_per_second": 3.016,
      "eval_steps_per_second": 3.016,
      "step": 1344
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.1545504331588745,
      "learning_rate": 1.9577047683638873e-05,
      "loss": 0.4664,
      "step": 1350
    },
    {
      "epoch": 8.18452380952381,
      "grad_norm": 0.7014166116714478,
      "learning_rate": 1.680619288177775e-05,
      "loss": 0.5183,
      "step": 1375
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.7309668064117432,
      "learning_rate": 1.422868820769554e-05,
      "loss": 0.3651,
      "step": 1400
    },
    {
      "epoch": 8.482142857142858,
      "grad_norm": 0.7466016411781311,
      "learning_rate": 1.1850524021436337e-05,
      "loss": 0.6221,
      "step": 1425
    },
    {
      "epoch": 8.630952380952381,
      "grad_norm": 0.6977907419204712,
      "learning_rate": 9.677227397252708e-06,
      "loss": 0.449,
      "step": 1450
    },
    {
      "epoch": 8.779761904761905,
      "grad_norm": 0.17224477231502533,
      "learning_rate": 7.713849278172047e-06,
      "loss": 0.4503,
      "step": 1475
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.7443668246269226,
      "learning_rate": 5.964952737136353e-06,
      "loss": 0.5007,
      "step": 1500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7852787971496582,
      "eval_runtime": 102.2911,
      "eval_samples_per_second": 3.285,
      "eval_steps_per_second": 3.285,
      "step": 1512
    },
    {
      "epoch": 9.077380952380953,
      "grad_norm": 0.6902071237564087,
      "learning_rate": 4.434602371997243e-06,
      "loss": 0.3531,
      "step": 1525
    },
    {
      "epoch": 9.226190476190476,
      "grad_norm": 0.7468720078468323,
      "learning_rate": 3.1263548590133917e-06,
      "loss": 0.6097,
      "step": 1550
    },
    {
      "epoch": 9.375,
      "grad_norm": 0.805109977722168,
      "learning_rate": 2.043250686804865e-06,
      "loss": 0.4038,
      "step": 1575
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.15370893478393555,
      "learning_rate": 1.187807089975379e-06,
      "loss": 0.4745,
      "step": 1600
    },
    {
      "epoch": 9.672619047619047,
      "grad_norm": 0.7432318329811096,
      "learning_rate": 5.620121988255567e-07,
      "loss": 0.4575,
      "step": 1625
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.18240128457546234,
      "learning_rate": 1.6732041875354709e-07,
      "loss": 0.3498,
      "step": 1650
    },
    {
      "epoch": 9.970238095238095,
      "grad_norm": 0.7661082744598389,
      "learning_rate": 4.649050082006223e-09,
      "loss": 0.6315,
      "step": 1675
    }
  ],
  "logging_steps": 25,
  "max_steps": 1680,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.357977554239488e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
