{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1905,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 0.6579386591911316,
      "learning_rate": 8.620689655172413e-05,
      "loss": 1.9425,
      "step": 25
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.4334971606731415,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.2916,
      "step": 50
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.6653896570205688,
      "learning_rate": 0.00019995819737621894,
      "loss": 0.8424,
      "step": 75
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.263857901096344,
      "learning_rate": 0.00019974493560924895,
      "loss": 0.7196,
      "step": 100
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.6368663311004639,
      "learning_rate": 0.00019935134242983634,
      "loss": 0.6717,
      "step": 125
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7188021540641785,
      "eval_runtime": 96.843,
      "eval_samples_per_second": 5.215,
      "eval_steps_per_second": 5.215,
      "step": 127
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.2759952247142792,
      "learning_rate": 0.00019877812942512617,
      "loss": 0.6705,
      "step": 150
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.3146016597747803,
      "learning_rate": 0.00019802633292152584,
      "loss": 0.6589,
      "step": 175
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.2773732841014862,
      "learning_rate": 0.0001970973121111039,
      "loss": 0.636,
      "step": 200
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.3411291241645813,
      "learning_rate": 0.00019599274659427228,
      "loss": 0.6281,
      "step": 225
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.28538277745246887,
      "learning_rate": 0.0001947146333431937,
      "loss": 0.6319,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.662423312664032,
      "eval_runtime": 96.8784,
      "eval_samples_per_second": 5.213,
      "eval_steps_per_second": 5.213,
      "step": 254
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.2923901677131653,
      "learning_rate": 0.00019326528309140478,
      "loss": 0.6121,
      "step": 275
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.3091510236263275,
      "learning_rate": 0.00019164731615618226,
      "loss": 0.6012,
      "step": 300
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.2756000757217407,
      "learning_rate": 0.00018986365770120412,
      "loss": 0.5932,
      "step": 325
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4331623613834381,
      "learning_rate": 0.00018791753244807184,
      "loss": 0.5956,
      "step": 350
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.3006986379623413,
      "learning_rate": 0.00018581245884625406,
      "loss": 0.588,
      "step": 375
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6482251286506653,
      "eval_runtime": 96.8521,
      "eval_samples_per_second": 5.214,
      "eval_steps_per_second": 5.214,
      "step": 381
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.3390169143676758,
      "learning_rate": 0.00018355224271199188,
      "loss": 0.5784,
      "step": 400
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.3002783954143524,
      "learning_rate": 0.00018114097034766674,
      "loss": 0.5546,
      "step": 425
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.315341979265213,
      "learning_rate": 0.00017858300115407015,
      "loss": 0.5681,
      "step": 450
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.4377937912940979,
      "learning_rate": 0.0001758829597489318,
      "loss": 0.5503,
      "step": 475
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.32135245203971863,
      "learning_rate": 0.00017304572760595528,
      "loss": 0.5843,
      "step": 500
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6389435529708862,
      "eval_runtime": 96.8627,
      "eval_samples_per_second": 5.214,
      "eval_steps_per_second": 5.214,
      "step": 508
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.31600818037986755,
      "learning_rate": 0.00017007643422947726,
      "loss": 0.549,
      "step": 525
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.30304476618766785,
      "learning_rate": 0.00016698044788070592,
      "loss": 0.5255,
      "step": 550
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.36446261405944824,
      "learning_rate": 0.0001637633658723044,
      "loss": 0.5276,
      "step": 575
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.37649038434028625,
      "learning_rate": 0.00016043100444886673,
      "loss": 0.52,
      "step": 600
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.3399697542190552,
      "learning_rate": 0.00015698938827158089,
      "loss": 0.5509,
      "step": 625
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.63670814037323,
      "eval_runtime": 96.8256,
      "eval_samples_per_second": 5.216,
      "eval_steps_per_second": 5.216,
      "step": 635
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.33053234219551086,
      "learning_rate": 0.00015344473952609005,
      "loss": 0.5198,
      "step": 650
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.32802698016166687,
      "learning_rate": 0.00014980346667324484,
      "loss": 0.501,
      "step": 675
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.4410662353038788,
      "learning_rate": 0.00014607215286308316,
      "loss": 0.5046,
      "step": 700
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.41660797595977783,
      "learning_rate": 0.00014225754403298556,
      "loss": 0.5015,
      "step": 725
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.3641241490840912,
      "learning_rate": 0.00013836653671152322,
      "loss": 0.5084,
      "step": 750
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6465543508529663,
      "eval_runtime": 96.8418,
      "eval_samples_per_second": 5.215,
      "eval_steps_per_second": 5.215,
      "step": 762
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.3218317925930023,
      "learning_rate": 0.00013440616555004768,
      "loss": 0.4966,
      "step": 775
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.3806193172931671,
      "learning_rate": 0.00013038359060456572,
      "loss": 0.4733,
      "step": 800
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.4206567406654358,
      "learning_rate": 0.0001263060843908912,
      "loss": 0.4658,
      "step": 825
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.3840791881084442,
      "learning_rate": 0.00012218101873647842,
      "loss": 0.4725,
      "step": 850
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.359910786151886,
      "learning_rate": 0.00011801585145270741,
      "loss": 0.4871,
      "step": 875
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.6507448554039001,
      "eval_runtime": 96.8795,
      "eval_samples_per_second": 5.213,
      "eval_steps_per_second": 5.213,
      "step": 889
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.3433929681777954,
      "learning_rate": 0.00011381811285171633,
      "loss": 0.4645,
      "step": 900
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.4641563892364502,
      "learning_rate": 0.00010959539213215832,
      "loss": 0.4512,
      "step": 925
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.45923569798469543,
      "learning_rate": 0.00010535532365849566,
      "loss": 0.4372,
      "step": 950
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.3799726366996765,
      "learning_rate": 0.00010110557315863762,
      "loss": 0.4631,
      "step": 975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.3738490045070648,
      "learning_rate": 9.685382386487555e-05,
      "loss": 0.4562,
      "step": 1000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.6622627377510071,
      "eval_runtime": 96.8786,
      "eval_samples_per_second": 5.213,
      "eval_steps_per_second": 5.213,
      "step": 1016
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.405355840921402,
      "learning_rate": 9.260776262317117e-05,
      "loss": 0.4486,
      "step": 1025
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.5153847336769104,
      "learning_rate": 8.837506599591198e-05,
      "loss": 0.4116,
      "step": 1050
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.4358943998813629,
      "learning_rate": 8.416338638325815e-05,
      "loss": 0.4287,
      "step": 1075
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.4106992781162262,
      "learning_rate": 7.998033818817327e-05,
      "loss": 0.4337,
      "step": 1100
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.4088974893093109,
      "learning_rate": 7.583348405015099e-05,
      "loss": 0.4349,
      "step": 1125
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6731417775154114,
      "eval_runtime": 96.6768,
      "eval_samples_per_second": 5.224,
      "eval_steps_per_second": 5.224,
      "step": 1143
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.4167095422744751,
      "learning_rate": 7.173032117252643e-05,
      "loss": 0.4212,
      "step": 1150
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.4406921863555908,
      "learning_rate": 6.767826776809085e-05,
      "loss": 0.3903,
      "step": 1175
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.4682062268257141,
      "learning_rate": 6.368464964751575e-05,
      "loss": 0.4099,
      "step": 1200
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.4971548020839691,
      "learning_rate": 5.9756686974832985e-05,
      "loss": 0.4169,
      "step": 1225
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.47828078269958496,
      "learning_rate": 5.590148121391594e-05,
      "loss": 0.4106,
      "step": 1250
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6773478984832764,
      "eval_runtime": 98.0597,
      "eval_samples_per_second": 5.15,
      "eval_steps_per_second": 5.15,
      "step": 1270
    },
    {
      "epoch": 10.039370078740157,
      "grad_norm": 0.45495593547821045,
      "learning_rate": 5.212600228956207e-05,
      "loss": 0.4004,
      "step": 1275
    },
    {
      "epoch": 10.236220472440944,
      "grad_norm": 0.539749026298523,
      "learning_rate": 4.843707598638806e-05,
      "loss": 0.3729,
      "step": 1300
    },
    {
      "epoch": 10.433070866141732,
      "grad_norm": 0.48973679542541504,
      "learning_rate": 4.484137160831988e-05,
      "loss": 0.3948,
      "step": 1325
    },
    {
      "epoch": 10.62992125984252,
      "grad_norm": 0.462095707654953,
      "learning_rate": 4.134538992098798e-05,
      "loss": 0.402,
      "step": 1350
    },
    {
      "epoch": 10.826771653543307,
      "grad_norm": 0.5219160318374634,
      "learning_rate": 3.7955451398827434e-05,
      "loss": 0.3959,
      "step": 1375
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.6889196038246155,
      "eval_runtime": 97.5714,
      "eval_samples_per_second": 5.176,
      "eval_steps_per_second": 5.176,
      "step": 1397
    },
    {
      "epoch": 11.023622047244094,
      "grad_norm": 0.48345664143562317,
      "learning_rate": 3.467768479813116e-05,
      "loss": 0.3836,
      "step": 1400
    },
    {
      "epoch": 11.220472440944881,
      "grad_norm": 0.549223780632019,
      "learning_rate": 3.151801607671495e-05,
      "loss": 0.3738,
      "step": 1425
    },
    {
      "epoch": 11.417322834645669,
      "grad_norm": 0.4872271418571472,
      "learning_rate": 2.8482157680227307e-05,
      "loss": 0.3886,
      "step": 1450
    },
    {
      "epoch": 11.614173228346457,
      "grad_norm": 0.49041467905044556,
      "learning_rate": 2.5575598214473317e-05,
      "loss": 0.376,
      "step": 1475
    },
    {
      "epoch": 11.811023622047244,
      "grad_norm": 0.470233678817749,
      "learning_rate": 2.2803592522424322e-05,
      "loss": 0.3713,
      "step": 1500
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.7055838704109192,
      "eval_runtime": 97.0586,
      "eval_samples_per_second": 5.203,
      "eval_steps_per_second": 5.203,
      "step": 1524
    },
    {
      "epoch": 12.007874015748031,
      "grad_norm": 0.4732268750667572,
      "learning_rate": 2.017115218385318e-05,
      "loss": 0.3565,
      "step": 1525
    },
    {
      "epoch": 12.204724409448819,
      "grad_norm": 0.519868791103363,
      "learning_rate": 1.7683036454771463e-05,
      "loss": 0.3566,
      "step": 1550
    },
    {
      "epoch": 12.401574803149606,
      "grad_norm": 0.4835878312587738,
      "learning_rate": 1.534374366304926e-05,
      "loss": 0.3718,
      "step": 1575
    },
    {
      "epoch": 12.598425196850394,
      "grad_norm": 0.495669424533844,
      "learning_rate": 1.3157503075773359e-05,
      "loss": 0.3711,
      "step": 1600
    },
    {
      "epoch": 12.795275590551181,
      "grad_norm": 0.5447211265563965,
      "learning_rate": 1.112826725304752e-05,
      "loss": 0.3708,
      "step": 1625
    },
    {
      "epoch": 12.992125984251969,
      "grad_norm": 0.5101225972175598,
      "learning_rate": 9.25970490205832e-06,
      "loss": 0.3541,
      "step": 1650
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.7092612981796265,
      "eval_runtime": 97.0362,
      "eval_samples_per_second": 5.204,
      "eval_steps_per_second": 5.204,
      "step": 1651
    },
    {
      "epoch": 13.188976377952756,
      "grad_norm": 0.51437908411026,
      "learning_rate": 7.555194244325792e-06,
      "loss": 0.3638,
      "step": 1675
    },
    {
      "epoch": 13.385826771653543,
      "grad_norm": 0.533776581287384,
      "learning_rate": 6.0178169081306575e-06,
      "loss": 0.3691,
      "step": 1700
    },
    {
      "epoch": 13.582677165354331,
      "grad_norm": 0.5164313316345215,
      "learning_rate": 4.650352357159982e-06,
      "loss": 0.3647,
      "step": 1725
    },
    {
      "epoch": 13.779527559055119,
      "grad_norm": 0.513092577457428,
      "learning_rate": 3.455272865443859e-06,
      "loss": 0.3548,
      "step": 1750
    },
    {
      "epoch": 13.976377952755906,
      "grad_norm": 0.6535671353340149,
      "learning_rate": 2.4347390476682108e-06,
      "loss": 0.3456,
      "step": 1775
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.7138345837593079,
      "eval_runtime": 96.3459,
      "eval_samples_per_second": 5.242,
      "eval_steps_per_second": 5.242,
      "step": 1778
    },
    {
      "epoch": 14.173228346456693,
      "grad_norm": 0.4779422879219055,
      "learning_rate": 1.5905959529443625e-06,
      "loss": 0.3657,
      "step": 1800
    },
    {
      "epoch": 14.37007874015748,
      "grad_norm": 0.5074725151062012,
      "learning_rate": 9.243697290977071e-07,
      "loss": 0.3685,
      "step": 1825
    },
    {
      "epoch": 14.566929133858268,
      "grad_norm": 0.5041585564613342,
      "learning_rate": 4.372648635061705e-07,
      "loss": 0.3552,
      "step": 1850
    },
    {
      "epoch": 14.763779527559056,
      "grad_norm": 0.5110155940055847,
      "learning_rate": 1.3016200547674163e-07,
      "loss": 0.3491,
      "step": 1875
    },
    {
      "epoch": 14.960629921259843,
      "grad_norm": 0.5531809329986572,
      "learning_rate": 3.616374097148434e-09,
      "loss": 0.3444,
      "step": 1900
    }
  ],
  "logging_steps": 25,
  "max_steps": 1905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6499218869633024e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
