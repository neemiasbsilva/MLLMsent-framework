{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1790,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13966480446927373,
      "grad_norm": 0.34796175360679626,
      "learning_rate": 9.25925925925926e-05,
      "loss": 2.3881,
      "step": 25
    },
    {
      "epoch": 0.27932960893854747,
      "grad_norm": 0.3171992599964142,
      "learning_rate": 0.0001851851851851852,
      "loss": 1.8831,
      "step": 50
    },
    {
      "epoch": 0.41899441340782123,
      "grad_norm": 0.4269532263278961,
      "learning_rate": 0.00019992779676965885,
      "loss": 1.5384,
      "step": 75
    },
    {
      "epoch": 0.5586592178770949,
      "grad_norm": 0.3014849126338959,
      "learning_rate": 0.00019965371381818598,
      "loss": 1.4643,
      "step": 100
    },
    {
      "epoch": 0.6983240223463687,
      "grad_norm": 0.3118075728416443,
      "learning_rate": 0.00019917569212703367,
      "loss": 1.4107,
      "step": 125
    },
    {
      "epoch": 0.8379888268156425,
      "grad_norm": 0.2753751873970032,
      "learning_rate": 0.00019849470995518992,
      "loss": 1.4266,
      "step": 150
    },
    {
      "epoch": 0.9776536312849162,
      "grad_norm": 0.3382556438446045,
      "learning_rate": 0.00019761216091500043,
      "loss": 1.3711,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4188414812088013,
      "eval_runtime": 156.0487,
      "eval_samples_per_second": 4.569,
      "eval_steps_per_second": 4.569,
      "step": 179
    },
    {
      "epoch": 1.1173184357541899,
      "grad_norm": 0.29831406474113464,
      "learning_rate": 0.000196529851120177,
      "loss": 1.4126,
      "step": 200
    },
    {
      "epoch": 1.2569832402234637,
      "grad_norm": 0.5754556655883789,
      "learning_rate": 0.00019524999548963274,
      "loss": 1.3358,
      "step": 225
    },
    {
      "epoch": 1.3966480446927374,
      "grad_norm": 0.27845150232315063,
      "learning_rate": 0.00019377521321470805,
      "loss": 1.3979,
      "step": 250
    },
    {
      "epoch": 1.536312849162011,
      "grad_norm": 0.3022603392601013,
      "learning_rate": 0.00019210852239906332,
      "loss": 1.3487,
      "step": 275
    },
    {
      "epoch": 1.675977653631285,
      "grad_norm": 0.3094637095928192,
      "learning_rate": 0.0001902533338822082,
      "loss": 1.3382,
      "step": 300
    },
    {
      "epoch": 1.8156424581005588,
      "grad_norm": 0.2965008616447449,
      "learning_rate": 0.00018821344425930714,
      "loss": 1.3805,
      "step": 325
    },
    {
      "epoch": 1.9553072625698324,
      "grad_norm": 0.32482102513313293,
      "learning_rate": 0.00018599302811154572,
      "loss": 1.3399,
      "step": 350
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.390161156654358,
      "eval_runtime": 156.0875,
      "eval_samples_per_second": 4.568,
      "eval_steps_per_second": 4.568,
      "step": 358
    },
    {
      "epoch": 2.094972067039106,
      "grad_norm": 0.2897658348083496,
      "learning_rate": 0.0001835966294629586,
      "loss": 1.3541,
      "step": 375
    },
    {
      "epoch": 2.2346368715083798,
      "grad_norm": 0.40861836075782776,
      "learning_rate": 0.00018102915248120237,
      "loss": 1.2797,
      "step": 400
    },
    {
      "epoch": 2.3743016759776534,
      "grad_norm": 0.32049843668937683,
      "learning_rate": 0.00017829585144130356,
      "loss": 1.3523,
      "step": 425
    },
    {
      "epoch": 2.5139664804469275,
      "grad_norm": 0.44677436351776123,
      "learning_rate": 0.00017540231997292114,
      "loss": 1.2905,
      "step": 450
    },
    {
      "epoch": 2.653631284916201,
      "grad_norm": 0.289065957069397,
      "learning_rate": 0.00017235447961312861,
      "loss": 1.3411,
      "step": 475
    },
    {
      "epoch": 2.793296089385475,
      "grad_norm": 0.31087177991867065,
      "learning_rate": 0.00016915856768814197,
      "loss": 1.3185,
      "step": 500
    },
    {
      "epoch": 2.9329608938547485,
      "grad_norm": 0.340794175863266,
      "learning_rate": 0.00016582112454879348,
      "loss": 1.3024,
      "step": 525
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3679800033569336,
      "eval_runtime": 155.9244,
      "eval_samples_per_second": 4.573,
      "eval_steps_per_second": 4.573,
      "step": 537
    },
    {
      "epoch": 3.0726256983240225,
      "grad_norm": 0.3292146623134613,
      "learning_rate": 0.00016234898018587337,
      "loss": 1.3154,
      "step": 550
    },
    {
      "epoch": 3.212290502793296,
      "grad_norm": 0.34596186876296997,
      "learning_rate": 0.00015874924025273087,
      "loss": 1.2633,
      "step": 575
    },
    {
      "epoch": 3.35195530726257,
      "grad_norm": 0.3532339334487915,
      "learning_rate": 0.00015502927152373914,
      "loss": 1.3085,
      "step": 600
    },
    {
      "epoch": 3.4916201117318435,
      "grad_norm": 0.3985021114349365,
      "learning_rate": 0.00015119668681838245,
      "loss": 1.251,
      "step": 625
    },
    {
      "epoch": 3.631284916201117,
      "grad_norm": 0.32749396562576294,
      "learning_rate": 0.00014725932942181872,
      "loss": 1.3304,
      "step": 650
    },
    {
      "epoch": 3.770949720670391,
      "grad_norm": 0.36744531989097595,
      "learning_rate": 0.0001432252570338,
      "loss": 1.2549,
      "step": 675
    },
    {
      "epoch": 3.910614525139665,
      "grad_norm": 0.3123771548271179,
      "learning_rate": 0.00013910272527879898,
      "loss": 1.2912,
      "step": 700
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.358672857284546,
      "eval_runtime": 155.9698,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 716
    },
    {
      "epoch": 4.050279329608939,
      "grad_norm": 0.31066644191741943,
      "learning_rate": 0.0001349001708110876,
      "loss": 1.2668,
      "step": 725
    },
    {
      "epoch": 4.189944134078212,
      "grad_norm": 0.3530004322528839,
      "learning_rate": 0.00013062619404934317,
      "loss": 1.2395,
      "step": 750
    },
    {
      "epoch": 4.329608938547486,
      "grad_norm": 0.3267197012901306,
      "learning_rate": 0.0001262895415761145,
      "loss": 1.28,
      "step": 775
    },
    {
      "epoch": 4.4692737430167595,
      "grad_norm": 0.3636114299297333,
      "learning_rate": 0.00012189908823816774,
      "loss": 1.2203,
      "step": 800
    },
    {
      "epoch": 4.608938547486034,
      "grad_norm": 0.35866037011146545,
      "learning_rate": 0.00011746381898434289,
      "loss": 1.2852,
      "step": 825
    },
    {
      "epoch": 4.748603351955307,
      "grad_norm": 0.34847453236579895,
      "learning_rate": 0.00011299281047808877,
      "loss": 1.2074,
      "step": 850
    },
    {
      "epoch": 4.888268156424581,
      "grad_norm": 0.3554092347621918,
      "learning_rate": 0.00010849521252230716,
      "loss": 1.2901,
      "step": 875
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3503772020339966,
      "eval_runtime": 155.9331,
      "eval_samples_per_second": 4.572,
      "eval_steps_per_second": 4.572,
      "step": 895
    },
    {
      "epoch": 5.027932960893855,
      "grad_norm": 0.3764011561870575,
      "learning_rate": 0.00010398022933451837,
      "loss": 1.2291,
      "step": 900
    },
    {
      "epoch": 5.167597765363128,
      "grad_norm": 0.3389812707901001,
      "learning_rate": 9.94571007106689e-05,
      "loss": 1.2378,
      "step": 925
    },
    {
      "epoch": 5.307262569832402,
      "grad_norm": 0.3316890597343445,
      "learning_rate": 9.493508311612874e-05,
      "loss": 1.2271,
      "step": 950
    },
    {
      "epoch": 5.446927374301676,
      "grad_norm": 0.39073529839515686,
      "learning_rate": 9.042343074257538e-05,
      "loss": 1.2108,
      "step": 975
    },
    {
      "epoch": 5.58659217877095,
      "grad_norm": 0.34205755591392517,
      "learning_rate": 8.593137656953037e-05,
      "loss": 1.2476,
      "step": 1000
    },
    {
      "epoch": 5.726256983240224,
      "grad_norm": 0.39229798316955566,
      "learning_rate": 8.146811346930653e-05,
      "loss": 1.1877,
      "step": 1025
    },
    {
      "epoch": 5.865921787709497,
      "grad_norm": 0.37334367632865906,
      "learning_rate": 7.704277539403304e-05,
      "loss": 1.2648,
      "step": 1050
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.351945400238037,
      "eval_runtime": 155.9704,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 1074
    },
    {
      "epoch": 6.005586592178771,
      "grad_norm": 0.3094055652618408,
      "learning_rate": 7.266441868325962e-05,
      "loss": 1.1695,
      "step": 1075
    },
    {
      "epoch": 6.145251396648045,
      "grad_norm": 0.3893008530139923,
      "learning_rate": 6.834200353039258e-05,
      "loss": 1.2369,
      "step": 1100
    },
    {
      "epoch": 6.284916201117318,
      "grad_norm": 0.3721792697906494,
      "learning_rate": 6.40843756458913e-05,
      "loss": 1.1909,
      "step": 1125
    },
    {
      "epoch": 6.424581005586592,
      "grad_norm": 0.39170509576797485,
      "learning_rate": 5.9900248154751616e-05,
      "loss": 1.2085,
      "step": 1150
    },
    {
      "epoch": 6.564245810055866,
      "grad_norm": 0.375925749540329,
      "learning_rate": 5.579818376532131e-05,
      "loss": 1.2107,
      "step": 1175
    },
    {
      "epoch": 6.70391061452514,
      "grad_norm": 0.43660488724708557,
      "learning_rate": 5.1786577245939784e-05,
      "loss": 1.1796,
      "step": 1200
    },
    {
      "epoch": 6.843575418994414,
      "grad_norm": 0.371307373046875,
      "learning_rate": 4.787363824526244e-05,
      "loss": 1.2296,
      "step": 1225
    },
    {
      "epoch": 6.983240223463687,
      "grad_norm": 0.4862358272075653,
      "learning_rate": 4.406737449142769e-05,
      "loss": 1.1644,
      "step": 1250
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.349269986152649,
      "eval_runtime": 155.9695,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 1253
    },
    {
      "epoch": 7.122905027932961,
      "grad_norm": 0.37935760617256165,
      "learning_rate": 4.037557540444914e-05,
      "loss": 1.237,
      "step": 1275
    },
    {
      "epoch": 7.262569832402234,
      "grad_norm": 0.3928642272949219,
      "learning_rate": 3.680579615536961e-05,
      "loss": 1.1514,
      "step": 1300
    },
    {
      "epoch": 7.402234636871508,
      "grad_norm": 0.41034215688705444,
      "learning_rate": 3.336534220479961e-05,
      "loss": 1.218,
      "step": 1325
    },
    {
      "epoch": 7.5418994413407825,
      "grad_norm": 0.4245491623878479,
      "learning_rate": 3.0061254352481804e-05,
      "loss": 1.1704,
      "step": 1350
    },
    {
      "epoch": 7.681564245810056,
      "grad_norm": 0.41672471165657043,
      "learning_rate": 2.690029432847694e-05,
      "loss": 1.1886,
      "step": 1375
    },
    {
      "epoch": 7.82122905027933,
      "grad_norm": 0.3854255974292755,
      "learning_rate": 2.388893095545881e-05,
      "loss": 1.2017,
      "step": 1400
    },
    {
      "epoch": 7.960893854748603,
      "grad_norm": 0.44552767276763916,
      "learning_rate": 2.103332691043641e-05,
      "loss": 1.1539,
      "step": 1425
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3490140438079834,
      "eval_runtime": 155.9734,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 1432
    },
    {
      "epoch": 8.100558659217878,
      "grad_norm": 0.39813318848609924,
      "learning_rate": 1.8339326112995425e-05,
      "loss": 1.2131,
      "step": 1450
    },
    {
      "epoch": 8.240223463687151,
      "grad_norm": 0.49659931659698486,
      "learning_rate": 1.5812441765868292e-05,
      "loss": 1.1262,
      "step": 1475
    },
    {
      "epoch": 8.379888268156424,
      "grad_norm": 0.39401376247406006,
      "learning_rate": 1.3457845072308084e-05,
      "loss": 1.2252,
      "step": 1500
    },
    {
      "epoch": 8.519553072625698,
      "grad_norm": 0.4036400020122528,
      "learning_rate": 1.1280354653354929e-05,
      "loss": 1.1629,
      "step": 1525
    },
    {
      "epoch": 8.659217877094973,
      "grad_norm": 0.40371233224868774,
      "learning_rate": 9.284426686653303e-06,
      "loss": 1.1766,
      "step": 1550
    },
    {
      "epoch": 8.798882681564246,
      "grad_norm": 0.38581064343452454,
      "learning_rate": 7.474145787000087e-06,
      "loss": 1.1716,
      "step": 1575
    },
    {
      "epoch": 8.938547486033519,
      "grad_norm": 0.4431854486465454,
      "learning_rate": 5.853216647286197e-06,
      "loss": 1.1714,
      "step": 1600
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3454310894012451,
      "eval_runtime": 155.999,
      "eval_samples_per_second": 4.571,
      "eval_steps_per_second": 4.571,
      "step": 1611
    },
    {
      "epoch": 9.078212290502794,
      "grad_norm": 0.4023244082927704,
      "learning_rate": 4.424956456938878e-06,
      "loss": 1.1933,
      "step": 1625
    },
    {
      "epoch": 9.217877094972067,
      "grad_norm": 0.44425132870674133,
      "learning_rate": 3.1922881133795825e-06,
      "loss": 1.1441,
      "step": 1650
    },
    {
      "epoch": 9.35754189944134,
      "grad_norm": 0.41887927055358887,
      "learning_rate": 2.15773424039013e-06,
      "loss": 1.1902,
      "step": 1675
    },
    {
      "epoch": 9.497206703910614,
      "grad_norm": 0.3207147419452667,
      "learning_rate": 1.323412025628712e-06,
      "loss": 1.1303,
      "step": 1700
    },
    {
      "epoch": 9.636871508379889,
      "grad_norm": 0.39927828311920166,
      "learning_rate": 6.910288878602456e-07,
      "loss": 1.1979,
      "step": 1725
    },
    {
      "epoch": 9.776536312849162,
      "grad_norm": 0.3824376165866852,
      "learning_rate": 2.6187898276813784e-07,
      "loss": 1.1533,
      "step": 1750
    },
    {
      "epoch": 9.916201117318435,
      "grad_norm": 0.4008912742137909,
      "learning_rate": 3.6840554498274174e-08,
      "loss": 1.1818,
      "step": 1775
    }
  ],
  "logging_steps": 25,
  "max_steps": 1790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.626237681532928e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
