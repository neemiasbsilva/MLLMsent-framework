{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 4510,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05543237250554324,
      "grad_norm": 0.5827599167823792,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.1633,
      "step": 25
    },
    {
      "epoch": 0.11086474501108648,
      "grad_norm": 1.5965096950531006,
      "learning_rate": 7.352941176470589e-05,
      "loss": 2.4399,
      "step": 50
    },
    {
      "epoch": 0.1662971175166297,
      "grad_norm": 0.44587740302085876,
      "learning_rate": 0.00011029411764705884,
      "loss": 0.7481,
      "step": 75
    },
    {
      "epoch": 0.22172949002217296,
      "grad_norm": 1.440824031829834,
      "learning_rate": 0.00014705882352941178,
      "loss": 1.2001,
      "step": 100
    },
    {
      "epoch": 0.2771618625277162,
      "grad_norm": 0.5123746991157532,
      "learning_rate": 0.0001838235294117647,
      "loss": 0.5885,
      "step": 125
    },
    {
      "epoch": 0.3325942350332594,
      "grad_norm": 0.5157217979431152,
      "learning_rate": 0.00019999494449430045,
      "loss": 0.9968,
      "step": 150
    },
    {
      "epoch": 0.38802660753880264,
      "grad_norm": 0.5191218256950378,
      "learning_rate": 0.0001999607704786645,
      "loss": 0.6575,
      "step": 175
    },
    {
      "epoch": 0.4434589800443459,
      "grad_norm": 0.7443811893463135,
      "learning_rate": 0.0001998943679601577,
      "loss": 0.9263,
      "step": 200
    },
    {
      "epoch": 0.49889135254988914,
      "grad_norm": 0.4308376908302307,
      "learning_rate": 0.0001997957583477163,
      "loss": 0.5904,
      "step": 225
    },
    {
      "epoch": 0.5543237250554324,
      "grad_norm": 0.5825148224830627,
      "learning_rate": 0.0001996649734342143,
      "loss": 0.9511,
      "step": 250
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 0.337929368019104,
      "learning_rate": 0.00019950205538621292,
      "loss": 0.6163,
      "step": 275
    },
    {
      "epoch": 0.6651884700665188,
      "grad_norm": 0.4524264931678772,
      "learning_rate": 0.00019930705673036606,
      "loss": 0.9274,
      "step": 300
    },
    {
      "epoch": 0.720620842572062,
      "grad_norm": 0.3440055549144745,
      "learning_rate": 0.00019908004033648453,
      "loss": 0.5828,
      "step": 325
    },
    {
      "epoch": 0.7760532150776053,
      "grad_norm": 0.4695134460926056,
      "learning_rate": 0.00019882107939726655,
      "loss": 0.893,
      "step": 350
    },
    {
      "epoch": 0.8314855875831486,
      "grad_norm": 0.34794825315475464,
      "learning_rate": 0.0001985302574046993,
      "loss": 0.5229,
      "step": 375
    },
    {
      "epoch": 0.8869179600886918,
      "grad_norm": 0.5179392695426941,
      "learning_rate": 0.00019820766812314036,
      "loss": 0.9146,
      "step": 400
    },
    {
      "epoch": 0.9423503325942351,
      "grad_norm": 0.3208063542842865,
      "learning_rate": 0.00019785341555908685,
      "loss": 0.6288,
      "step": 425
    },
    {
      "epoch": 0.9977827050997783,
      "grad_norm": 0.4633059799671173,
      "learning_rate": 0.00019746761392764253,
      "loss": 0.891,
      "step": 450
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8192335963249207,
      "eval_runtime": 201.7503,
      "eval_samples_per_second": 4.471,
      "eval_steps_per_second": 4.471,
      "step": 451
    },
    {
      "epoch": 1.0532150776053215,
      "grad_norm": 0.2820279002189636,
      "learning_rate": 0.0001970503876156937,
      "loss": 0.5381,
      "step": 475
    },
    {
      "epoch": 1.1086474501108647,
      "grad_norm": 0.3662140369415283,
      "learning_rate": 0.00019660187114180528,
      "loss": 0.8884,
      "step": 500
    },
    {
      "epoch": 1.164079822616408,
      "grad_norm": 0.340005487203598,
      "learning_rate": 0.00019612220911285048,
      "loss": 0.5484,
      "step": 525
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 0.41919657588005066,
      "learning_rate": 0.00019561155617738797,
      "loss": 0.8657,
      "step": 550
    },
    {
      "epoch": 1.2749445676274944,
      "grad_norm": 0.34385544061660767,
      "learning_rate": 0.00019507007697580137,
      "loss": 0.5208,
      "step": 575
    },
    {
      "epoch": 1.3303769401330376,
      "grad_norm": 0.46962034702301025,
      "learning_rate": 0.00019449794608721724,
      "loss": 0.8758,
      "step": 600
    },
    {
      "epoch": 1.3858093126385809,
      "grad_norm": 0.3364810645580292,
      "learning_rate": 0.00019389534797321884,
      "loss": 0.5309,
      "step": 625
    },
    {
      "epoch": 1.441241685144124,
      "grad_norm": 0.40298327803611755,
      "learning_rate": 0.00019326247691837356,
      "loss": 0.8899,
      "step": 650
    },
    {
      "epoch": 1.4966740576496673,
      "grad_norm": 0.35509106516838074,
      "learning_rate": 0.00019259953696759328,
      "loss": 0.5551,
      "step": 675
    },
    {
      "epoch": 1.5521064301552108,
      "grad_norm": 0.39025768637657166,
      "learning_rate": 0.00019190674186034807,
      "loss": 0.8713,
      "step": 700
    },
    {
      "epoch": 1.6075388026607538,
      "grad_norm": 0.33668917417526245,
      "learning_rate": 0.00019118431496175403,
      "loss": 0.5666,
      "step": 725
    },
    {
      "epoch": 1.6629711751662972,
      "grad_norm": 0.40431874990463257,
      "learning_rate": 0.00019043248919055778,
      "loss": 0.8693,
      "step": 750
    },
    {
      "epoch": 1.7184035476718402,
      "grad_norm": 0.3116013705730438,
      "learning_rate": 0.00018965150694404094,
      "loss": 0.5198,
      "step": 775
    },
    {
      "epoch": 1.7738359201773837,
      "grad_norm": 0.4817332625389099,
      "learning_rate": 0.00018884162001986821,
      "loss": 0.8958,
      "step": 800
    },
    {
      "epoch": 1.8292682926829267,
      "grad_norm": 0.3324614465236664,
      "learning_rate": 0.0001880030895349051,
      "loss": 0.4832,
      "step": 825
    },
    {
      "epoch": 1.8847006651884701,
      "grad_norm": 0.3568907678127289,
      "learning_rate": 0.0001871361858410308,
      "loss": 0.8799,
      "step": 850
    },
    {
      "epoch": 1.9401330376940134,
      "grad_norm": 0.34377321600914,
      "learning_rate": 0.00018624118843797355,
      "loss": 0.5282,
      "step": 875
    },
    {
      "epoch": 1.9955654101995566,
      "grad_norm": 0.4168078303337097,
      "learning_rate": 0.00018531838588319683,
      "loss": 0.844,
      "step": 900
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7456644177436829,
      "eval_runtime": 201.8857,
      "eval_samples_per_second": 4.468,
      "eval_steps_per_second": 4.468,
      "step": 902
    },
    {
      "epoch": 2.0509977827050996,
      "grad_norm": 0.3348439931869507,
      "learning_rate": 0.000184368075698865,
      "loss": 0.4189,
      "step": 925
    },
    {
      "epoch": 2.106430155210643,
      "grad_norm": 0.3915422260761261,
      "learning_rate": 0.00018339056427591884,
      "loss": 0.8526,
      "step": 950
    },
    {
      "epoch": 2.1618625277161865,
      "grad_norm": 0.35011500120162964,
      "learning_rate": 0.0001823861667752914,
      "loss": 0.5129,
      "step": 975
    },
    {
      "epoch": 2.2172949002217295,
      "grad_norm": 0.47656819224357605,
      "learning_rate": 0.00018135520702629675,
      "loss": 0.8351,
      "step": 1000
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.3872259557247162,
      "learning_rate": 0.0001802980174222235,
      "loss": 0.4173,
      "step": 1025
    },
    {
      "epoch": 2.328159645232816,
      "grad_norm": 0.429798424243927,
      "learning_rate": 0.0001792149388131674,
      "loss": 0.8467,
      "step": 1050
    },
    {
      "epoch": 2.3835920177383594,
      "grad_norm": 0.36333218216896057,
      "learning_rate": 0.00017810632039613736,
      "loss": 0.5062,
      "step": 1075
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 0.39587894082069397,
      "learning_rate": 0.00017697251960247036,
      "loss": 0.8417,
      "step": 1100
    },
    {
      "epoch": 2.494456762749446,
      "grad_norm": 0.34537285566329956,
      "learning_rate": 0.00017581390198259138,
      "loss": 0.5113,
      "step": 1125
    },
    {
      "epoch": 2.549889135254989,
      "grad_norm": 0.39580264687538147,
      "learning_rate": 0.00017463084108815586,
      "loss": 0.8213,
      "step": 1150
    },
    {
      "epoch": 2.6053215077605323,
      "grad_norm": 0.35877522826194763,
      "learning_rate": 0.00017342371835161227,
      "loss": 0.5,
      "step": 1175
    },
    {
      "epoch": 2.6607538802660753,
      "grad_norm": 0.4485836327075958,
      "learning_rate": 0.00017219292296322385,
      "loss": 0.8137,
      "step": 1200
    },
    {
      "epoch": 2.7161862527716187,
      "grad_norm": 0.3670256435871124,
      "learning_rate": 0.0001709388517455893,
      "loss": 0.518,
      "step": 1225
    },
    {
      "epoch": 2.7716186252771617,
      "grad_norm": 0.44367989897727966,
      "learning_rate": 0.00016966190902570257,
      "loss": 0.8294,
      "step": 1250
    },
    {
      "epoch": 2.827050997782705,
      "grad_norm": 0.34531858563423157,
      "learning_rate": 0.0001683625065045931,
      "loss": 0.4742,
      "step": 1275
    },
    {
      "epoch": 2.882483370288248,
      "grad_norm": 0.4778357744216919,
      "learning_rate": 0.00016704106312458877,
      "loss": 0.8099,
      "step": 1300
    },
    {
      "epoch": 2.9379157427937916,
      "grad_norm": 0.34649989008903503,
      "learning_rate": 0.00016569800493424413,
      "loss": 0.503,
      "step": 1325
    },
    {
      "epoch": 2.9933481152993346,
      "grad_norm": 0.41174691915512085,
      "learning_rate": 0.00016433376495097717,
      "loss": 0.8251,
      "step": 1350
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7189134359359741,
      "eval_runtime": 201.6935,
      "eval_samples_per_second": 4.472,
      "eval_steps_per_second": 4.472,
      "step": 1353
    },
    {
      "epoch": 3.048780487804878,
      "grad_norm": 0.37301334738731384,
      "learning_rate": 0.00016294878302145987,
      "loss": 0.4206,
      "step": 1375
    },
    {
      "epoch": 3.104212860310421,
      "grad_norm": 0.44874465465545654,
      "learning_rate": 0.00016154350567980635,
      "loss": 0.797,
      "step": 1400
    },
    {
      "epoch": 3.1596452328159645,
      "grad_norm": 0.35571157932281494,
      "learning_rate": 0.00016011838600360508,
      "loss": 0.5032,
      "step": 1425
    },
    {
      "epoch": 3.2150776053215075,
      "grad_norm": 0.4639626145362854,
      "learning_rate": 0.0001586738834678418,
      "loss": 0.7869,
      "step": 1450
    },
    {
      "epoch": 3.270509977827051,
      "grad_norm": 0.41029196977615356,
      "learning_rate": 0.000157210463796759,
      "loss": 0.419,
      "step": 1475
    },
    {
      "epoch": 3.3259423503325944,
      "grad_norm": 0.41079917550086975,
      "learning_rate": 0.00015572859881370148,
      "loss": 0.7959,
      "step": 1500
    },
    {
      "epoch": 3.3813747228381374,
      "grad_norm": 0.3923162817955017,
      "learning_rate": 0.0001542287662889948,
      "loss": 0.4944,
      "step": 1525
    },
    {
      "epoch": 3.436807095343681,
      "grad_norm": 0.44573846459388733,
      "learning_rate": 0.00015271144978590685,
      "loss": 0.7621,
      "step": 1550
    },
    {
      "epoch": 3.492239467849224,
      "grad_norm": 0.4482535123825073,
      "learning_rate": 0.00015117713850474135,
      "loss": 0.3979,
      "step": 1575
    },
    {
      "epoch": 3.5476718403547673,
      "grad_norm": 0.4590136706829071,
      "learning_rate": 0.00014962632712511395,
      "loss": 0.7877,
      "step": 1600
    },
    {
      "epoch": 3.6031042128603104,
      "grad_norm": 0.4385741353034973,
      "learning_rate": 0.00014805951564646213,
      "loss": 0.4363,
      "step": 1625
    },
    {
      "epoch": 3.658536585365854,
      "grad_norm": 0.432655930519104,
      "learning_rate": 0.0001464772092268393,
      "loss": 0.7854,
      "step": 1650
    },
    {
      "epoch": 3.713968957871397,
      "grad_norm": 0.38979220390319824,
      "learning_rate": 0.00014487991802004623,
      "loss": 0.4687,
      "step": 1675
    },
    {
      "epoch": 3.7694013303769403,
      "grad_norm": 0.4842939078807831,
      "learning_rate": 0.00014326815701115156,
      "loss": 0.7662,
      "step": 1700
    },
    {
      "epoch": 3.8248337028824833,
      "grad_norm": 0.41992053389549255,
      "learning_rate": 0.0001416424458504546,
      "loss": 0.4227,
      "step": 1725
    },
    {
      "epoch": 3.8802660753880267,
      "grad_norm": 0.4602978825569153,
      "learning_rate": 0.00014000330868594427,
      "loss": 0.785,
      "step": 1750
    },
    {
      "epoch": 3.9356984478935697,
      "grad_norm": 0.39994585514068604,
      "learning_rate": 0.00013835127399430748,
      "loss": 0.44,
      "step": 1775
    },
    {
      "epoch": 3.991130820399113,
      "grad_norm": 0.4799070954322815,
      "learning_rate": 0.00013668687441054252,
      "loss": 0.7706,
      "step": 1800
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7100293040275574,
      "eval_runtime": 201.6106,
      "eval_samples_per_second": 4.474,
      "eval_steps_per_second": 4.474,
      "step": 1804
    },
    {
      "epoch": 4.046563192904657,
      "grad_norm": 0.429360568523407,
      "learning_rate": 0.00013501064655623094,
      "loss": 0.4823,
      "step": 1825
    },
    {
      "epoch": 4.101995565410199,
      "grad_norm": 0.5432500243186951,
      "learning_rate": 0.00013332313086652516,
      "loss": 0.739,
      "step": 1850
    },
    {
      "epoch": 4.157427937915743,
      "grad_norm": 0.4626924991607666,
      "learning_rate": 0.0001316248714159054,
      "loss": 0.3912,
      "step": 1875
    },
    {
      "epoch": 4.212860310421286,
      "grad_norm": 0.4703323245048523,
      "learning_rate": 0.00012991641574276418,
      "loss": 0.7195,
      "step": 1900
    },
    {
      "epoch": 4.2682926829268295,
      "grad_norm": 0.49186253547668457,
      "learning_rate": 0.0001281983146728735,
      "loss": 0.4492,
      "step": 1925
    },
    {
      "epoch": 4.323725055432373,
      "grad_norm": 0.4802667200565338,
      "learning_rate": 0.00012647112214179222,
      "loss": 0.7494,
      "step": 1950
    },
    {
      "epoch": 4.3791574279379155,
      "grad_norm": 0.4318423271179199,
      "learning_rate": 0.000124735395016271,
      "loss": 0.4565,
      "step": 1975
    },
    {
      "epoch": 4.434589800443459,
      "grad_norm": 0.5199180841445923,
      "learning_rate": 0.00012299169291471197,
      "loss": 0.7062,
      "step": 2000
    },
    {
      "epoch": 4.490022172949002,
      "grad_norm": 0.4654035270214081,
      "learning_rate": 0.0001212405780267412,
      "loss": 0.3989,
      "step": 2025
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.5650349259376526,
      "learning_rate": 0.00011948261493195256,
      "loss": 0.7262,
      "step": 2050
    },
    {
      "epoch": 4.600886917960088,
      "grad_norm": 0.43893668055534363,
      "learning_rate": 0.00011771837041788059,
      "loss": 0.3074,
      "step": 2075
    },
    {
      "epoch": 4.656319290465632,
      "grad_norm": 0.5082677602767944,
      "learning_rate": 0.00011594841329726158,
      "loss": 0.7419,
      "step": 2100
    },
    {
      "epoch": 4.711751662971175,
      "grad_norm": 0.48323485255241394,
      "learning_rate": 0.00011417331422464205,
      "loss": 0.4071,
      "step": 2125
    },
    {
      "epoch": 4.767184035476719,
      "grad_norm": 0.5436197519302368,
      "learning_rate": 0.000112393645512393,
      "loss": 0.7499,
      "step": 2150
    },
    {
      "epoch": 4.822616407982261,
      "grad_norm": 0.4240136742591858,
      "learning_rate": 0.00011060998094618982,
      "loss": 0.3779,
      "step": 2175
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 0.5178422331809998,
      "learning_rate": 0.0001088228956000172,
      "loss": 0.7383,
      "step": 2200
    },
    {
      "epoch": 4.933481152993348,
      "grad_norm": 0.48213550448417664,
      "learning_rate": 0.00010703296565075867,
      "loss": 0.3986,
      "step": 2225
    },
    {
      "epoch": 4.988913525498892,
      "grad_norm": 0.49277037382125854,
      "learning_rate": 0.00010524076819243051,
      "loss": 0.7432,
      "step": 2250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7077682018280029,
      "eval_runtime": 201.5998,
      "eval_samples_per_second": 4.474,
      "eval_steps_per_second": 4.474,
      "step": 2255
    },
    {
      "epoch": 5.044345898004434,
      "grad_norm": 0.5020537972450256,
      "learning_rate": 0.00010344688105012005,
      "loss": 0.3845,
      "step": 2275
    },
    {
      "epoch": 5.099778270509978,
      "grad_norm": 0.5626206398010254,
      "learning_rate": 0.00010165188259368823,
      "loss": 0.6883,
      "step": 2300
    },
    {
      "epoch": 5.155210643015521,
      "grad_norm": 0.5236793756484985,
      "learning_rate": 9.985635155129632e-05,
      "loss": 0.3787,
      "step": 2325
    },
    {
      "epoch": 5.210643015521065,
      "grad_norm": 0.6192787885665894,
      "learning_rate": 9.806086682281758e-05,
      "loss": 0.6716,
      "step": 2350
    },
    {
      "epoch": 5.266075388026607,
      "grad_norm": 0.5166110992431641,
      "learning_rate": 9.626600729319302e-05,
      "loss": 0.3722,
      "step": 2375
    },
    {
      "epoch": 5.321507760532151,
      "grad_norm": 0.5925762057304382,
      "learning_rate": 9.447235164579237e-05,
      "loss": 0.6981,
      "step": 2400
    },
    {
      "epoch": 5.376940133037694,
      "grad_norm": 0.569911003112793,
      "learning_rate": 9.268047817583998e-05,
      "loss": 0.3355,
      "step": 2425
    },
    {
      "epoch": 5.4323725055432375,
      "grad_norm": 0.6434093713760376,
      "learning_rate": 9.089096460396552e-05,
      "loss": 0.7197,
      "step": 2450
    },
    {
      "epoch": 5.487804878048781,
      "grad_norm": 0.5525026917457581,
      "learning_rate": 8.910438788994043e-05,
      "loss": 0.3976,
      "step": 2475
    },
    {
      "epoch": 5.5432372505543235,
      "grad_norm": 0.6241782307624817,
      "learning_rate": 8.732132404665947e-05,
      "loss": 0.687,
      "step": 2500
    },
    {
      "epoch": 5.598669623059867,
      "grad_norm": 0.6069068908691406,
      "learning_rate": 8.554234795442724e-05,
      "loss": 0.3682,
      "step": 2525
    },
    {
      "epoch": 5.65410199556541,
      "grad_norm": 0.5962932705879211,
      "learning_rate": 8.376803317561048e-05,
      "loss": 0.6686,
      "step": 2550
    },
    {
      "epoch": 5.709534368070954,
      "grad_norm": 0.5697328448295593,
      "learning_rate": 8.199895176971488e-05,
      "loss": 0.3704,
      "step": 2575
    },
    {
      "epoch": 5.764966740576496,
      "grad_norm": 0.5867636203765869,
      "learning_rate": 8.023567410894639e-05,
      "loss": 0.6799,
      "step": 2600
    },
    {
      "epoch": 5.82039911308204,
      "grad_norm": 0.5787259936332703,
      "learning_rate": 7.847876869431674e-05,
      "loss": 0.3608,
      "step": 2625
    },
    {
      "epoch": 5.875831485587583,
      "grad_norm": 0.5654253363609314,
      "learning_rate": 7.672880197235222e-05,
      "loss": 0.6988,
      "step": 2650
    },
    {
      "epoch": 5.931263858093127,
      "grad_norm": 0.5252237915992737,
      "learning_rate": 7.498633815246465e-05,
      "loss": 0.3904,
      "step": 2675
    },
    {
      "epoch": 5.986696230598669,
      "grad_norm": 0.6404609084129333,
      "learning_rate": 7.3251939025044e-05,
      "loss": 0.6897,
      "step": 2700
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7190431952476501,
      "eval_runtime": 201.5509,
      "eval_samples_per_second": 4.475,
      "eval_steps_per_second": 4.475,
      "step": 2706
    },
    {
      "epoch": 6.042128603104213,
      "grad_norm": 0.4767967760562897,
      "learning_rate": 7.152616378033042e-05,
      "loss": 0.3243,
      "step": 2725
    },
    {
      "epoch": 6.097560975609756,
      "grad_norm": 0.6012323498725891,
      "learning_rate": 6.980956882812515e-05,
      "loss": 0.6508,
      "step": 2750
    },
    {
      "epoch": 6.1529933481153,
      "grad_norm": 0.5758029818534851,
      "learning_rate": 6.810270761839741e-05,
      "loss": 0.3813,
      "step": 2775
    },
    {
      "epoch": 6.208425720620842,
      "grad_norm": 0.6564934849739075,
      "learning_rate": 6.640613046284581e-05,
      "loss": 0.6354,
      "step": 2800
    },
    {
      "epoch": 6.263858093126386,
      "grad_norm": 0.6054109334945679,
      "learning_rate": 6.472038435747151e-05,
      "loss": 0.3645,
      "step": 2825
    },
    {
      "epoch": 6.319290465631929,
      "grad_norm": 0.5613057613372803,
      "learning_rate": 6.304601280622055e-05,
      "loss": 0.6469,
      "step": 2850
    },
    {
      "epoch": 6.3747228381374725,
      "grad_norm": 0.5855637192726135,
      "learning_rate": 6.138355564575169e-05,
      "loss": 0.3076,
      "step": 2875
    },
    {
      "epoch": 6.430155210643015,
      "grad_norm": 0.6641600131988525,
      "learning_rate": 5.9733548871387e-05,
      "loss": 0.6578,
      "step": 2900
    },
    {
      "epoch": 6.4855875831485585,
      "grad_norm": 0.565161406993866,
      "learning_rate": 5.8096524464300826e-05,
      "loss": 0.3058,
      "step": 2925
    },
    {
      "epoch": 6.541019955654102,
      "grad_norm": 0.6582233905792236,
      "learning_rate": 5.647301022000284e-05,
      "loss": 0.6715,
      "step": 2950
    },
    {
      "epoch": 6.596452328159645,
      "grad_norm": 0.663375973701477,
      "learning_rate": 5.4863529578170744e-05,
      "loss": 0.3041,
      "step": 2975
    },
    {
      "epoch": 6.651884700665189,
      "grad_norm": 0.6639496684074402,
      "learning_rate": 5.326860145388731e-05,
      "loss": 0.65,
      "step": 3000
    },
    {
      "epoch": 6.7073170731707314,
      "grad_norm": 0.6776130199432373,
      "learning_rate": 5.168874007033615e-05,
      "loss": 0.4286,
      "step": 3025
    },
    {
      "epoch": 6.762749445676275,
      "grad_norm": 0.7183144688606262,
      "learning_rate": 5.012445479301027e-05,
      "loss": 0.6278,
      "step": 3050
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.6278499364852905,
      "learning_rate": 4.8576249965486776e-05,
      "loss": 0.3569,
      "step": 3075
    },
    {
      "epoch": 6.873614190687362,
      "grad_norm": 0.709586501121521,
      "learning_rate": 4.704462474682055e-05,
      "loss": 0.6395,
      "step": 3100
    },
    {
      "epoch": 6.929046563192904,
      "grad_norm": 0.6010147929191589,
      "learning_rate": 4.553007295060999e-05,
      "loss": 0.3115,
      "step": 3125
    },
    {
      "epoch": 6.984478935698448,
      "grad_norm": 0.6153159737586975,
      "learning_rate": 4.403308288578544e-05,
      "loss": 0.6731,
      "step": 3150
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7307661175727844,
      "eval_runtime": 201.4387,
      "eval_samples_per_second": 4.478,
      "eval_steps_per_second": 4.478,
      "step": 3157
    },
    {
      "epoch": 7.039911308203991,
      "grad_norm": 0.5728288292884827,
      "learning_rate": 4.255413719917294e-05,
      "loss": 0.2886,
      "step": 3175
    },
    {
      "epoch": 7.095343680709535,
      "grad_norm": 0.7261060476303101,
      "learning_rate": 4.109371271988335e-05,
      "loss": 0.626,
      "step": 3200
    },
    {
      "epoch": 7.150776053215077,
      "grad_norm": 0.6813069581985474,
      "learning_rate": 3.9652280305577095e-05,
      "loss": 0.3211,
      "step": 3225
    },
    {
      "epoch": 7.206208425720621,
      "grad_norm": 0.7338211536407471,
      "learning_rate": 3.8230304690654304e-05,
      "loss": 0.5884,
      "step": 3250
    },
    {
      "epoch": 7.261640798226164,
      "grad_norm": 0.5873029232025146,
      "learning_rate": 3.682824433641902e-05,
      "loss": 0.3355,
      "step": 3275
    },
    {
      "epoch": 7.317073170731708,
      "grad_norm": 0.6646270751953125,
      "learning_rate": 3.5446551283266025e-05,
      "loss": 0.6354,
      "step": 3300
    },
    {
      "epoch": 7.37250554323725,
      "grad_norm": 0.6813551783561707,
      "learning_rate": 3.408567100493787e-05,
      "loss": 0.3297,
      "step": 3325
    },
    {
      "epoch": 7.427937915742794,
      "grad_norm": 0.7147699594497681,
      "learning_rate": 3.2746042264898905e-05,
      "loss": 0.6363,
      "step": 3350
    },
    {
      "epoch": 7.483370288248337,
      "grad_norm": 0.5962313413619995,
      "learning_rate": 3.142809697487298e-05,
      "loss": 0.2879,
      "step": 3375
    },
    {
      "epoch": 7.5388026607538805,
      "grad_norm": 0.6761707067489624,
      "learning_rate": 3.0132260055590088e-05,
      "loss": 0.6601,
      "step": 3400
    },
    {
      "epoch": 7.594235033259423,
      "grad_norm": 0.615646481513977,
      "learning_rate": 2.8858949299787074e-05,
      "loss": 0.2984,
      "step": 3425
    },
    {
      "epoch": 7.6496674057649665,
      "grad_norm": 0.7072033882141113,
      "learning_rate": 2.760857523750637e-05,
      "loss": 0.6187,
      "step": 3450
    },
    {
      "epoch": 7.70509977827051,
      "grad_norm": 0.6822680234909058,
      "learning_rate": 2.6381541003736486e-05,
      "loss": 0.338,
      "step": 3475
    },
    {
      "epoch": 7.760532150776053,
      "grad_norm": 0.7027259469032288,
      "learning_rate": 2.5178242208436554e-05,
      "loss": 0.59,
      "step": 3500
    },
    {
      "epoch": 7.815964523281597,
      "grad_norm": 0.69112628698349,
      "learning_rate": 2.399906680898719e-05,
      "loss": 0.3213,
      "step": 3525
    },
    {
      "epoch": 7.871396895787139,
      "grad_norm": 0.7987419366836548,
      "learning_rate": 2.284439498510854e-05,
      "loss": 0.64,
      "step": 3550
    },
    {
      "epoch": 7.926829268292683,
      "grad_norm": 0.6775063276290894,
      "learning_rate": 2.1714599016285975e-05,
      "loss": 0.3077,
      "step": 3575
    },
    {
      "epoch": 7.982261640798226,
      "grad_norm": 0.7573849558830261,
      "learning_rate": 2.0610043161742888e-05,
      "loss": 0.6143,
      "step": 3600
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7451159954071045,
      "eval_runtime": 201.6701,
      "eval_samples_per_second": 4.473,
      "eval_steps_per_second": 4.473,
      "step": 3608
    },
    {
      "epoch": 8.037694013303769,
      "grad_norm": 0.15174917876720428,
      "learning_rate": 1.9531083542999317e-05,
      "loss": 0.2486,
      "step": 3625
    },
    {
      "epoch": 8.093126385809313,
      "grad_norm": 0.6827335953712463,
      "learning_rate": 1.8478068029054386e-05,
      "loss": 0.6237,
      "step": 3650
    },
    {
      "epoch": 8.148558758314856,
      "grad_norm": 0.5762749314308167,
      "learning_rate": 1.7451336124229066e-05,
      "loss": 0.2668,
      "step": 3675
    },
    {
      "epoch": 8.203991130820398,
      "grad_norm": 0.7124771475791931,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 0.6025,
      "step": 3700
    },
    {
      "epoch": 8.259423503325943,
      "grad_norm": 0.6303750872612,
      "learning_rate": 1.5478038681803254e-05,
      "loss": 0.3251,
      "step": 3725
    },
    {
      "epoch": 8.314855875831485,
      "grad_norm": 0.748266339302063,
      "learning_rate": 1.4532109358009272e-05,
      "loss": 0.5929,
      "step": 3750
    },
    {
      "epoch": 8.37028824833703,
      "grad_norm": 0.6549056172370911,
      "learning_rate": 1.3613735865825305e-05,
      "loss": 0.2908,
      "step": 3775
    },
    {
      "epoch": 8.425720620842572,
      "grad_norm": 0.7593897581100464,
      "learning_rate": 1.2723214299434982e-05,
      "loss": 0.6145,
      "step": 3800
    },
    {
      "epoch": 8.481152993348115,
      "grad_norm": 0.698993980884552,
      "learning_rate": 1.1860831773240499e-05,
      "loss": 0.3142,
      "step": 3825
    },
    {
      "epoch": 8.536585365853659,
      "grad_norm": 0.8042502999305725,
      "learning_rate": 1.1026866329293628e-05,
      "loss": 0.5989,
      "step": 3850
    },
    {
      "epoch": 8.592017738359202,
      "grad_norm": 0.6640542149543762,
      "learning_rate": 1.0221586847651777e-05,
      "loss": 0.2898,
      "step": 3875
    },
    {
      "epoch": 8.647450110864746,
      "grad_norm": 0.7648062109947205,
      "learning_rate": 9.445252959687944e-06,
      "loss": 0.6061,
      "step": 3900
    },
    {
      "epoch": 8.702882483370288,
      "grad_norm": 0.33489152789115906,
      "learning_rate": 8.698114964382598e-06,
      "loss": 0.2638,
      "step": 3925
    },
    {
      "epoch": 8.758314855875831,
      "grad_norm": 0.659283459186554,
      "learning_rate": 7.980413747624383e-06,
      "loss": 0.6182,
      "step": 3950
    },
    {
      "epoch": 8.813747228381375,
      "grad_norm": 0.6753647923469543,
      "learning_rate": 7.292380704545743e-06,
      "loss": 0.3266,
      "step": 3975
    },
    {
      "epoch": 8.869179600886918,
      "grad_norm": 0.728053867816925,
      "learning_rate": 6.6342376649184855e-06,
      "loss": 0.5972,
      "step": 4000
    },
    {
      "epoch": 8.92461197339246,
      "grad_norm": 0.6681531667709351,
      "learning_rate": 6.006196821633281e-06,
      "loss": 0.2927,
      "step": 4025
    },
    {
      "epoch": 8.980044345898005,
      "grad_norm": 0.767750084400177,
      "learning_rate": 5.408460662286241e-06,
      "loss": 0.6257,
      "step": 4050
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7541519999504089,
      "eval_runtime": 201.4803,
      "eval_samples_per_second": 4.477,
      "eval_steps_per_second": 4.477,
      "step": 4059
    },
    {
      "epoch": 9.035476718403547,
      "grad_norm": 0.4974063038825989,
      "learning_rate": 4.841221903894633e-06,
      "loss": 0.2914,
      "step": 4075
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.765975832939148,
      "learning_rate": 4.304663430762601e-06,
      "loss": 0.6035,
      "step": 4100
    },
    {
      "epoch": 9.146341463414634,
      "grad_norm": 0.3908078670501709,
      "learning_rate": 3.7989582355172582e-06,
      "loss": 0.2714,
      "step": 4125
    },
    {
      "epoch": 9.201773835920177,
      "grad_norm": 0.7495348453521729,
      "learning_rate": 3.3242693633337983e-06,
      "loss": 0.6182,
      "step": 4150
    },
    {
      "epoch": 9.257206208425721,
      "grad_norm": 0.651566207408905,
      "learning_rate": 2.880749859367915e-06,
      "loss": 0.3149,
      "step": 4175
    },
    {
      "epoch": 9.312638580931264,
      "grad_norm": 0.6947478652000427,
      "learning_rate": 2.4685427194122368e-06,
      "loss": 0.5983,
      "step": 4200
    },
    {
      "epoch": 9.368070953436806,
      "grad_norm": 0.16083066165447235,
      "learning_rate": 2.0877808437928637e-06,
      "loss": 0.2656,
      "step": 4225
    },
    {
      "epoch": 9.42350332594235,
      "grad_norm": 0.8119639158248901,
      "learning_rate": 1.7385869945207523e-06,
      "loss": 0.5936,
      "step": 4250
    },
    {
      "epoch": 9.478935698447893,
      "grad_norm": 0.7133737802505493,
      "learning_rate": 1.4210737557118548e-06,
      "loss": 0.3014,
      "step": 4275
    },
    {
      "epoch": 9.534368070953438,
      "grad_norm": 0.809643566608429,
      "learning_rate": 1.1353434972886878e-06,
      "loss": 0.5785,
      "step": 4300
    },
    {
      "epoch": 9.58980044345898,
      "grad_norm": 0.4903694689273834,
      "learning_rate": 8.814883419750786e-07,
      "loss": 0.2809,
      "step": 4325
    },
    {
      "epoch": 9.645232815964523,
      "grad_norm": 0.751874566078186,
      "learning_rate": 6.595901355947898e-07,
      "loss": 0.6111,
      "step": 4350
    },
    {
      "epoch": 9.700665188470067,
      "grad_norm": 0.15335696935653687,
      "learning_rate": 4.6972042068341714e-07,
      "loss": 0.2581,
      "step": 4375
    },
    {
      "epoch": 9.75609756097561,
      "grad_norm": 0.8402917385101318,
      "learning_rate": 3.1194041342230695e-07,
      "loss": 0.571,
      "step": 4400
    },
    {
      "epoch": 9.811529933481154,
      "grad_norm": 0.7359615564346313,
      "learning_rate": 1.8630098390172156e-07,
      "loss": 0.3234,
      "step": 4425
    },
    {
      "epoch": 9.866962305986696,
      "grad_norm": 0.7099043130874634,
      "learning_rate": 9.284263971972573e-08,
      "loss": 0.6002,
      "step": 4450
    },
    {
      "epoch": 9.922394678492239,
      "grad_norm": 0.2115962952375412,
      "learning_rate": 3.159551292214458e-08,
      "loss": 0.264,
      "step": 4475
    },
    {
      "epoch": 9.977827050997783,
      "grad_norm": 0.8159729838371277,
      "learning_rate": 2.5793502875459673e-09,
      "loss": 0.6218,
      "step": 4500
    }
  ],
  "logging_steps": 25,
  "max_steps": 4510,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.625051402071245e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
