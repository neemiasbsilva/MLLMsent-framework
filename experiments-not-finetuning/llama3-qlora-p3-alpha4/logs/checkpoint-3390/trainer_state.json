{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 3390,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11061946902654868,
      "grad_norm": 0.4286394715309143,
      "learning_rate": 4.901960784313725e-05,
      "loss": 1.7786,
      "step": 25
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 0.7672241926193237,
      "learning_rate": 9.80392156862745e-05,
      "loss": 1.4981,
      "step": 50
    },
    {
      "epoch": 0.33185840707964603,
      "grad_norm": 0.2412973791360855,
      "learning_rate": 0.00014705882352941178,
      "loss": 0.8649,
      "step": 75
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 0.43582287430763245,
      "learning_rate": 0.000196078431372549,
      "loss": 0.6739,
      "step": 100
    },
    {
      "epoch": 0.5530973451327433,
      "grad_norm": 0.27119091153144836,
      "learning_rate": 0.0001999758540483965,
      "loss": 0.6814,
      "step": 125
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 0.34708264470100403,
      "learning_rate": 0.00019989484922416502,
      "loss": 0.5766,
      "step": 150
    },
    {
      "epoch": 0.7743362831858407,
      "grad_norm": 0.23173072934150696,
      "learning_rate": 0.00019975684915942164,
      "loss": 0.6466,
      "step": 175
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 0.35658788681030273,
      "learning_rate": 0.00019956193259042696,
      "loss": 0.5518,
      "step": 200
    },
    {
      "epoch": 0.995575221238938,
      "grad_norm": 0.23510119318962097,
      "learning_rate": 0.00019931021072728657,
      "loss": 0.6144,
      "step": 225
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5998819470405579,
      "eval_runtime": 100.7351,
      "eval_samples_per_second": 8.944,
      "eval_steps_per_second": 8.944,
      "step": 226
    },
    {
      "epoch": 1.1061946902654867,
      "grad_norm": 0.23753584921360016,
      "learning_rate": 0.00019900182719049983,
      "loss": 0.6128,
      "step": 250
    },
    {
      "epoch": 1.2168141592920354,
      "grad_norm": 0.28155332803726196,
      "learning_rate": 0.0001986369579290169,
      "loss": 0.5341,
      "step": 275
    },
    {
      "epoch": 1.3274336283185841,
      "grad_norm": 0.24539586901664734,
      "learning_rate": 0.00019821581111985071,
      "loss": 0.6158,
      "step": 300
    },
    {
      "epoch": 1.4380530973451329,
      "grad_norm": 0.29425638914108276,
      "learning_rate": 0.0001977386270493009,
      "loss": 0.5329,
      "step": 325
    },
    {
      "epoch": 1.5486725663716814,
      "grad_norm": 0.23750588297843933,
      "learning_rate": 0.00019720567797585817,
      "loss": 0.6081,
      "step": 350
    },
    {
      "epoch": 1.6592920353982301,
      "grad_norm": 0.2528585195541382,
      "learning_rate": 0.00019661726797486626,
      "loss": 0.5189,
      "step": 375
    },
    {
      "epoch": 1.7699115044247788,
      "grad_norm": 0.29970428347587585,
      "learning_rate": 0.00019597373276503125,
      "loss": 0.5961,
      "step": 400
    },
    {
      "epoch": 1.8805309734513274,
      "grad_norm": 0.2499559074640274,
      "learning_rate": 0.00019527543951687642,
      "loss": 0.5098,
      "step": 425
    },
    {
      "epoch": 1.991150442477876,
      "grad_norm": 0.28334885835647583,
      "learning_rate": 0.00019452278664325228,
      "loss": 0.5561,
      "step": 450
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.5591893196105957,
      "eval_runtime": 100.8143,
      "eval_samples_per_second": 8.937,
      "eval_steps_per_second": 8.937,
      "step": 452
    },
    {
      "epoch": 2.101769911504425,
      "grad_norm": 0.22625792026519775,
      "learning_rate": 0.00019371620357202103,
      "loss": 0.5589,
      "step": 475
    },
    {
      "epoch": 2.2123893805309733,
      "grad_norm": 0.28288891911506653,
      "learning_rate": 0.00019285615050104572,
      "loss": 0.5001,
      "step": 500
    },
    {
      "epoch": 2.3230088495575223,
      "grad_norm": 0.24257655441761017,
      "learning_rate": 0.00019194311813562308,
      "loss": 0.5717,
      "step": 525
    },
    {
      "epoch": 2.433628318584071,
      "grad_norm": 0.285286545753479,
      "learning_rate": 0.00019097762740851061,
      "loss": 0.4914,
      "step": 550
    },
    {
      "epoch": 2.5442477876106193,
      "grad_norm": 0.2508293092250824,
      "learning_rate": 0.00018996022918270705,
      "loss": 0.5696,
      "step": 575
    },
    {
      "epoch": 2.6548672566371683,
      "grad_norm": 0.2810937762260437,
      "learning_rate": 0.00018889150393715628,
      "loss": 0.4814,
      "step": 600
    },
    {
      "epoch": 2.765486725663717,
      "grad_norm": 0.272745817899704,
      "learning_rate": 0.00018777206143555362,
      "loss": 0.5537,
      "step": 625
    },
    {
      "epoch": 2.8761061946902657,
      "grad_norm": 0.25682738423347473,
      "learning_rate": 0.00018660254037844388,
      "loss": 0.4897,
      "step": 650
    },
    {
      "epoch": 2.9867256637168142,
      "grad_norm": 0.24152661859989166,
      "learning_rate": 0.0001853836080388091,
      "loss": 0.539,
      "step": 675
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5416412949562073,
      "eval_runtime": 100.8783,
      "eval_samples_per_second": 8.932,
      "eval_steps_per_second": 8.932,
      "step": 678
    },
    {
      "epoch": 3.0973451327433628,
      "grad_norm": 0.24405917525291443,
      "learning_rate": 0.00018411595988135444,
      "loss": 0.533,
      "step": 700
    },
    {
      "epoch": 3.2079646017699117,
      "grad_norm": 0.28724655508995056,
      "learning_rate": 0.00018280031916570927,
      "loss": 0.4697,
      "step": 725
    },
    {
      "epoch": 3.3185840707964602,
      "grad_norm": 0.2521563768386841,
      "learning_rate": 0.00018143743653376942,
      "loss": 0.5337,
      "step": 750
    },
    {
      "epoch": 3.4292035398230087,
      "grad_norm": 0.29311084747314453,
      "learning_rate": 0.00018002808958141704,
      "loss": 0.4788,
      "step": 775
    },
    {
      "epoch": 3.5398230088495577,
      "grad_norm": 0.2506992518901825,
      "learning_rate": 0.00017857308241486116,
      "loss": 0.5363,
      "step": 800
    },
    {
      "epoch": 3.650442477876106,
      "grad_norm": 0.27112850546836853,
      "learning_rate": 0.00017707324519185318,
      "loss": 0.4553,
      "step": 825
    },
    {
      "epoch": 3.7610619469026547,
      "grad_norm": 0.24103038012981415,
      "learning_rate": 0.00017552943364803825,
      "loss": 0.5302,
      "step": 850
    },
    {
      "epoch": 3.8716814159292037,
      "grad_norm": 0.25809532403945923,
      "learning_rate": 0.00017394252860871342,
      "loss": 0.4607,
      "step": 875
    },
    {
      "epoch": 3.982300884955752,
      "grad_norm": 0.2758254110813141,
      "learning_rate": 0.00017231343548627083,
      "loss": 0.5106,
      "step": 900
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.53369140625,
      "eval_runtime": 100.8227,
      "eval_samples_per_second": 8.936,
      "eval_steps_per_second": 8.936,
      "step": 904
    },
    {
      "epoch": 4.092920353982301,
      "grad_norm": 0.24930866062641144,
      "learning_rate": 0.00017064308376361218,
      "loss": 0.5027,
      "step": 925
    },
    {
      "epoch": 4.20353982300885,
      "grad_norm": 0.29249459505081177,
      "learning_rate": 0.0001689324264638304,
      "loss": 0.4441,
      "step": 950
    },
    {
      "epoch": 4.314159292035399,
      "grad_norm": 0.25262683629989624,
      "learning_rate": 0.00016718243960645986,
      "loss": 0.4942,
      "step": 975
    },
    {
      "epoch": 4.424778761061947,
      "grad_norm": 0.2835721969604492,
      "learning_rate": 0.00016539412165060647,
      "loss": 0.4388,
      "step": 1000
    },
    {
      "epoch": 4.535398230088496,
      "grad_norm": 0.2696506977081299,
      "learning_rate": 0.00016356849292527406,
      "loss": 0.509,
      "step": 1025
    },
    {
      "epoch": 4.646017699115045,
      "grad_norm": 0.2626618444919586,
      "learning_rate": 0.00016170659504721364,
      "loss": 0.4542,
      "step": 1050
    },
    {
      "epoch": 4.756637168141593,
      "grad_norm": 0.2505477964878082,
      "learning_rate": 0.00015980949032662627,
      "loss": 0.507,
      "step": 1075
    },
    {
      "epoch": 4.867256637168142,
      "grad_norm": 0.3040466010570526,
      "learning_rate": 0.00015787826116105962,
      "loss": 0.4423,
      "step": 1100
    },
    {
      "epoch": 4.977876106194691,
      "grad_norm": 0.2743842601776123,
      "learning_rate": 0.00015591400941784356,
      "loss": 0.4835,
      "step": 1125
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.5287348628044128,
      "eval_runtime": 100.7877,
      "eval_samples_per_second": 8.94,
      "eval_steps_per_second": 8.94,
      "step": 1130
    },
    {
      "epoch": 5.088495575221239,
      "grad_norm": 0.26004356145858765,
      "learning_rate": 0.00015391785580541698,
      "loss": 0.4796,
      "step": 1150
    },
    {
      "epoch": 5.199115044247788,
      "grad_norm": 0.3061041235923767,
      "learning_rate": 0.00015189093923390504,
      "loss": 0.4275,
      "step": 1175
    },
    {
      "epoch": 5.3097345132743365,
      "grad_norm": 0.26496604084968567,
      "learning_rate": 0.0001498344161653115,
      "loss": 0.4788,
      "step": 1200
    },
    {
      "epoch": 5.420353982300885,
      "grad_norm": 0.3042261004447937,
      "learning_rate": 0.00014774945995369636,
      "loss": 0.4226,
      "step": 1225
    },
    {
      "epoch": 5.530973451327434,
      "grad_norm": 0.27325430512428284,
      "learning_rate": 0.00014563726017571607,
      "loss": 0.4756,
      "step": 1250
    },
    {
      "epoch": 5.6415929203539825,
      "grad_norm": 0.28130677342414856,
      "learning_rate": 0.00014349902195190777,
      "loss": 0.4315,
      "step": 1275
    },
    {
      "epoch": 5.752212389380531,
      "grad_norm": 0.2800779342651367,
      "learning_rate": 0.00014133596525910496,
      "loss": 0.4823,
      "step": 1300
    },
    {
      "epoch": 5.8628318584070795,
      "grad_norm": 0.2896520793437958,
      "learning_rate": 0.00013914932423437682,
      "loss": 0.4231,
      "step": 1325
    },
    {
      "epoch": 5.9734513274336285,
      "grad_norm": 0.30866098403930664,
      "learning_rate": 0.0001369403464708884,
      "loss": 0.46,
      "step": 1350
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.5287816524505615,
      "eval_runtime": 100.7932,
      "eval_samples_per_second": 8.939,
      "eval_steps_per_second": 8.939,
      "step": 1356
    },
    {
      "epoch": 6.084070796460177,
      "grad_norm": 0.29198014736175537,
      "learning_rate": 0.00013471029230608346,
      "loss": 0.447,
      "step": 1375
    },
    {
      "epoch": 6.1946902654867255,
      "grad_norm": 0.29595664143562317,
      "learning_rate": 0.00013246043410259598,
      "loss": 0.4039,
      "step": 1400
    },
    {
      "epoch": 6.3053097345132745,
      "grad_norm": 0.2870156466960907,
      "learning_rate": 0.00013019205552230057,
      "loss": 0.4447,
      "step": 1425
    },
    {
      "epoch": 6.415929203539823,
      "grad_norm": 0.33607208728790283,
      "learning_rate": 0.00012790645079391641,
      "loss": 0.4067,
      "step": 1450
    },
    {
      "epoch": 6.5265486725663715,
      "grad_norm": 0.30902066826820374,
      "learning_rate": 0.00012560492397458174,
      "loss": 0.4557,
      "step": 1475
    },
    {
      "epoch": 6.6371681415929205,
      "grad_norm": 0.3252398371696472,
      "learning_rate": 0.0001232887882058212,
      "loss": 0.4072,
      "step": 1500
    },
    {
      "epoch": 6.747787610619469,
      "grad_norm": 0.2763496935367584,
      "learning_rate": 0.00012095936496432983,
      "loss": 0.4478,
      "step": 1525
    },
    {
      "epoch": 6.8584070796460175,
      "grad_norm": 0.3472089171409607,
      "learning_rate": 0.00011861798330800125,
      "loss": 0.4071,
      "step": 1550
    },
    {
      "epoch": 6.969026548672566,
      "grad_norm": 0.2941206693649292,
      "learning_rate": 0.00011626597911763084,
      "loss": 0.4396,
      "step": 1575
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.5291515588760376,
      "eval_runtime": 100.7892,
      "eval_samples_per_second": 8.939,
      "eval_steps_per_second": 8.939,
      "step": 1582
    },
    {
      "epoch": 7.079646017699115,
      "grad_norm": 0.31002888083457947,
      "learning_rate": 0.00011390469433472569,
      "loss": 0.4325,
      "step": 1600
    },
    {
      "epoch": 7.1902654867256635,
      "grad_norm": 0.3137054443359375,
      "learning_rate": 0.00011153547619585667,
      "loss": 0.3814,
      "step": 1625
    },
    {
      "epoch": 7.300884955752212,
      "grad_norm": 0.3008445203304291,
      "learning_rate": 0.0001091596764639895,
      "loss": 0.4227,
      "step": 1650
    },
    {
      "epoch": 7.411504424778761,
      "grad_norm": 0.3275059461593628,
      "learning_rate": 0.00010677865065723332,
      "loss": 0.389,
      "step": 1675
    },
    {
      "epoch": 7.522123893805309,
      "grad_norm": 0.3120991587638855,
      "learning_rate": 0.0001043937572754464,
      "loss": 0.4291,
      "step": 1700
    },
    {
      "epoch": 7.632743362831858,
      "grad_norm": 0.3233225345611572,
      "learning_rate": 0.00010200635702514114,
      "loss": 0.3814,
      "step": 1725
    },
    {
      "epoch": 7.743362831858407,
      "grad_norm": 0.3171504735946655,
      "learning_rate": 9.96178120431296e-05,
      "loss": 0.4232,
      "step": 1750
    },
    {
      "epoch": 7.853982300884955,
      "grad_norm": 0.3434993624687195,
      "learning_rate": 9.722948511935324e-05,
      "loss": 0.391,
      "step": 1775
    },
    {
      "epoch": 7.964601769911504,
      "grad_norm": 0.32587096095085144,
      "learning_rate": 9.484273891933982e-05,
      "loss": 0.4122,
      "step": 1800
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.5344123244285583,
      "eval_runtime": 100.8401,
      "eval_samples_per_second": 8.935,
      "eval_steps_per_second": 8.935,
      "step": 1808
    },
    {
      "epoch": 8.075221238938052,
      "grad_norm": 0.31103405356407166,
      "learning_rate": 9.245893520673146e-05,
      "loss": 0.408,
      "step": 1825
    },
    {
      "epoch": 8.185840707964601,
      "grad_norm": 0.3410656154155731,
      "learning_rate": 9.007943406632724e-05,
      "loss": 0.3623,
      "step": 1850
    },
    {
      "epoch": 8.29646017699115,
      "grad_norm": 0.3295835852622986,
      "learning_rate": 8.770559312808356e-05,
      "loss": 0.4049,
      "step": 1875
    },
    {
      "epoch": 8.4070796460177,
      "grad_norm": 0.3649381399154663,
      "learning_rate": 8.533876679251516e-05,
      "loss": 0.3671,
      "step": 1900
    },
    {
      "epoch": 8.517699115044248,
      "grad_norm": 0.3350451588630676,
      "learning_rate": 8.29803054579388e-05,
      "loss": 0.4144,
      "step": 1925
    },
    {
      "epoch": 8.628318584070797,
      "grad_norm": 0.3669640123844147,
      "learning_rate": 8.063155475000037e-05,
      "loss": 0.3689,
      "step": 1950
    },
    {
      "epoch": 8.738938053097344,
      "grad_norm": 0.3371461033821106,
      "learning_rate": 7.829385475392483e-05,
      "loss": 0.3975,
      "step": 1975
    },
    {
      "epoch": 8.849557522123893,
      "grad_norm": 0.34434086084365845,
      "learning_rate": 7.596853924992766e-05,
      "loss": 0.3708,
      "step": 2000
    },
    {
      "epoch": 8.960176991150442,
      "grad_norm": 0.34380432963371277,
      "learning_rate": 7.365693495222332e-05,
      "loss": 0.3914,
      "step": 2025
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.5398711562156677,
      "eval_runtime": 100.8386,
      "eval_samples_per_second": 8.935,
      "eval_steps_per_second": 8.935,
      "step": 2034
    },
    {
      "epoch": 9.070796460176991,
      "grad_norm": 0.3475494384765625,
      "learning_rate": 7.136036075206535e-05,
      "loss": 0.3947,
      "step": 2050
    },
    {
      "epoch": 9.18141592920354,
      "grad_norm": 0.3557201623916626,
      "learning_rate": 6.908012696524989e-05,
      "loss": 0.3517,
      "step": 2075
    },
    {
      "epoch": 9.29203539823009,
      "grad_norm": 0.3657282292842865,
      "learning_rate": 6.681753458451189e-05,
      "loss": 0.3833,
      "step": 2100
    },
    {
      "epoch": 9.402654867256636,
      "grad_norm": 0.3872736096382141,
      "learning_rate": 6.457387453724077e-05,
      "loss": 0.3534,
      "step": 2125
    },
    {
      "epoch": 9.513274336283185,
      "grad_norm": 0.3527542054653168,
      "learning_rate": 6.235042694893862e-05,
      "loss": 0.378,
      "step": 2150
    },
    {
      "epoch": 9.623893805309734,
      "grad_norm": 0.37472835183143616,
      "learning_rate": 6.0148460412841676e-05,
      "loss": 0.3515,
      "step": 2175
    },
    {
      "epoch": 9.734513274336283,
      "grad_norm": 0.4102691411972046,
      "learning_rate": 5.79692312661215e-05,
      "loss": 0.3844,
      "step": 2200
    },
    {
      "epoch": 9.845132743362832,
      "grad_norm": 0.40859711170196533,
      "learning_rate": 5.5813982873078684e-05,
      "loss": 0.3596,
      "step": 2225
    },
    {
      "epoch": 9.955752212389381,
      "grad_norm": 0.4059158265590668,
      "learning_rate": 5.368394491573876e-05,
      "loss": 0.3725,
      "step": 2250
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.5534287691116333,
      "eval_runtime": 100.755,
      "eval_samples_per_second": 8.942,
      "eval_steps_per_second": 8.942,
      "step": 2260
    },
    {
      "epoch": 10.06637168141593,
      "grad_norm": 0.37510019540786743,
      "learning_rate": 5.1580332692253904e-05,
      "loss": 0.3713,
      "step": 2275
    },
    {
      "epoch": 10.176991150442477,
      "grad_norm": 0.38833725452423096,
      "learning_rate": 4.9504346423511905e-05,
      "loss": 0.3363,
      "step": 2300
    },
    {
      "epoch": 10.287610619469026,
      "grad_norm": 0.3748089373111725,
      "learning_rate": 4.7457170568347285e-05,
      "loss": 0.3635,
      "step": 2325
    },
    {
      "epoch": 10.398230088495575,
      "grad_norm": 0.4396815598011017,
      "learning_rate": 4.543997314774553e-05,
      "loss": 0.3355,
      "step": 2350
    },
    {
      "epoch": 10.508849557522124,
      "grad_norm": 0.42753440141677856,
      "learning_rate": 4.3453905078425996e-05,
      "loss": 0.3605,
      "step": 2375
    },
    {
      "epoch": 10.619469026548673,
      "grad_norm": 0.39708298444747925,
      "learning_rate": 4.1500099516183555e-05,
      "loss": 0.348,
      "step": 2400
    },
    {
      "epoch": 10.730088495575222,
      "grad_norm": 0.427189439535141,
      "learning_rate": 3.957967120936412e-05,
      "loss": 0.3728,
      "step": 2425
    },
    {
      "epoch": 10.84070796460177,
      "grad_norm": 0.38821226358413696,
      "learning_rate": 3.7693715862842216e-05,
      "loss": 0.3485,
      "step": 2450
    },
    {
      "epoch": 10.951327433628318,
      "grad_norm": 0.41196367144584656,
      "learning_rate": 3.5843309512863976e-05,
      "loss": 0.3544,
      "step": 2475
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.5672622919082642,
      "eval_runtime": 100.6694,
      "eval_samples_per_second": 8.95,
      "eval_steps_per_second": 8.95,
      "step": 2486
    },
    {
      "epoch": 11.061946902654867,
      "grad_norm": 0.3832469880580902,
      "learning_rate": 3.402950791311221e-05,
      "loss": 0.3489,
      "step": 2500
    },
    {
      "epoch": 11.172566371681416,
      "grad_norm": 0.3984867036342621,
      "learning_rate": 3.225334593234361e-05,
      "loss": 0.3306,
      "step": 2525
    },
    {
      "epoch": 11.283185840707965,
      "grad_norm": 0.4143589437007904,
      "learning_rate": 3.0515836963942056e-05,
      "loss": 0.3557,
      "step": 2550
    },
    {
      "epoch": 11.393805309734514,
      "grad_norm": 0.39860132336616516,
      "learning_rate": 2.8817972347724488e-05,
      "loss": 0.3309,
      "step": 2575
    },
    {
      "epoch": 11.504424778761061,
      "grad_norm": 0.4638304114341736,
      "learning_rate": 2.7160720804329755e-05,
      "loss": 0.3456,
      "step": 2600
    },
    {
      "epoch": 11.61504424778761,
      "grad_norm": 0.4304561913013458,
      "learning_rate": 2.554502788251274e-05,
      "loss": 0.3305,
      "step": 2625
    },
    {
      "epoch": 11.725663716814159,
      "grad_norm": 0.4626414477825165,
      "learning_rate": 2.397181541965935e-05,
      "loss": 0.3584,
      "step": 2650
    },
    {
      "epoch": 11.836283185840708,
      "grad_norm": 0.4161568582057953,
      "learning_rate": 2.244198101582996e-05,
      "loss": 0.3362,
      "step": 2675
    },
    {
      "epoch": 11.946902654867257,
      "grad_norm": 0.40903398394584656,
      "learning_rate": 2.0956397521631664e-05,
      "loss": 0.3411,
      "step": 2700
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.5792876482009888,
      "eval_runtime": 100.7139,
      "eval_samples_per_second": 8.946,
      "eval_steps_per_second": 8.946,
      "step": 2712
    },
    {
      "epoch": 12.057522123893806,
      "grad_norm": 0.4435678720474243,
      "learning_rate": 1.9515912540211268e-05,
      "loss": 0.3383,
      "step": 2725
    },
    {
      "epoch": 12.168141592920353,
      "grad_norm": 0.4338216483592987,
      "learning_rate": 1.8121347943653332e-05,
      "loss": 0.3266,
      "step": 2750
    },
    {
      "epoch": 12.278761061946902,
      "grad_norm": 0.4310266971588135,
      "learning_rate": 1.6773499404059156e-05,
      "loss": 0.3367,
      "step": 2775
    },
    {
      "epoch": 12.389380530973451,
      "grad_norm": 0.41623446345329285,
      "learning_rate": 1.5473135939574168e-05,
      "loss": 0.328,
      "step": 2800
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.4151266813278198,
      "learning_rate": 1.422099947562282e-05,
      "loss": 0.3398,
      "step": 2825
    },
    {
      "epoch": 12.610619469026549,
      "grad_norm": 0.4082329273223877,
      "learning_rate": 1.3017804421601298e-05,
      "loss": 0.3228,
      "step": 2850
    },
    {
      "epoch": 12.721238938053098,
      "grad_norm": 0.42403826117515564,
      "learning_rate": 1.1864237263269561e-05,
      "loss": 0.3422,
      "step": 2875
    },
    {
      "epoch": 12.831858407079647,
      "grad_norm": 0.4071546494960785,
      "learning_rate": 1.076095617107531e-05,
      "loss": 0.3195,
      "step": 2900
    },
    {
      "epoch": 12.942477876106194,
      "grad_norm": 0.4414883553981781,
      "learning_rate": 9.70859062463324e-06,
      "loss": 0.3384,
      "step": 2925
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.5872632265090942,
      "eval_runtime": 100.7565,
      "eval_samples_per_second": 8.942,
      "eval_steps_per_second": 8.942,
      "step": 2938
    },
    {
      "epoch": 13.053097345132743,
      "grad_norm": 0.43752145767211914,
      "learning_rate": 8.70774105357407e-06,
      "loss": 0.3441,
      "step": 2950
    },
    {
      "epoch": 13.163716814159292,
      "grad_norm": 0.4207010269165039,
      "learning_rate": 7.758978494967895e-06,
      "loss": 0.3258,
      "step": 2975
    },
    {
      "epoch": 13.274336283185841,
      "grad_norm": 0.44824767112731934,
      "learning_rate": 6.862844267517643e-06,
      "loss": 0.3293,
      "step": 3000
    },
    {
      "epoch": 13.38495575221239,
      "grad_norm": 0.43038254976272583,
      "learning_rate": 6.019849662708554e-06,
      "loss": 0.3173,
      "step": 3025
    },
    {
      "epoch": 13.495575221238939,
      "grad_norm": 0.42701318860054016,
      "learning_rate": 5.230475653089506e-06,
      "loss": 0.3347,
      "step": 3050
    },
    {
      "epoch": 13.606194690265486,
      "grad_norm": 0.4470768868923187,
      "learning_rate": 4.495172617853038e-06,
      "loss": 0.3219,
      "step": 3075
    },
    {
      "epoch": 13.716814159292035,
      "grad_norm": 0.42368918657302856,
      "learning_rate": 3.814360085870439e-06,
      "loss": 0.3339,
      "step": 3100
    },
    {
      "epoch": 13.827433628318584,
      "grad_norm": 0.421823650598526,
      "learning_rate": 3.188426496328556e-06,
      "loss": 0.3161,
      "step": 3125
    },
    {
      "epoch": 13.938053097345133,
      "grad_norm": 0.47320160269737244,
      "learning_rate": 2.6177289771049274e-06,
      "loss": 0.3257,
      "step": 3150
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.5913888216018677,
      "eval_runtime": 100.7596,
      "eval_samples_per_second": 8.942,
      "eval_steps_per_second": 8.942,
      "step": 3164
    },
    {
      "epoch": 14.048672566371682,
      "grad_norm": 0.4411224126815796,
      "learning_rate": 2.102593141007636e-06,
      "loss": 0.3407,
      "step": 3175
    },
    {
      "epoch": 14.15929203539823,
      "grad_norm": 0.40050816535949707,
      "learning_rate": 1.6433128999961301e-06,
      "loss": 0.3118,
      "step": 3200
    },
    {
      "epoch": 14.269911504424778,
      "grad_norm": 0.451877623796463,
      "learning_rate": 1.2401502974890732e-06,
      "loss": 0.3221,
      "step": 3225
    },
    {
      "epoch": 14.380530973451327,
      "grad_norm": 0.4447615146636963,
      "learning_rate": 8.933353588548965e-07,
      "loss": 0.3282,
      "step": 3250
    },
    {
      "epoch": 14.491150442477876,
      "grad_norm": 0.42871588468551636,
      "learning_rate": 6.030659601702237e-07,
      "loss": 0.3306,
      "step": 3275
    },
    {
      "epoch": 14.601769911504425,
      "grad_norm": 0.45040327310562134,
      "learning_rate": 3.6950771532126006e-07,
      "loss": 0.32,
      "step": 3300
    },
    {
      "epoch": 14.712389380530974,
      "grad_norm": 0.4384720027446747,
      "learning_rate": 1.9279388151237644e-07,
      "loss": 0.3339,
      "step": 3325
    },
    {
      "epoch": 14.823008849557523,
      "grad_norm": 0.42601776123046875,
      "learning_rate": 7.302528323589464e-08,
      "loss": 0.3175,
      "step": 3350
    },
    {
      "epoch": 14.93362831858407,
      "grad_norm": 0.43793341517448425,
      "learning_rate": 1.027025474648058e-08,
      "loss": 0.3209,
      "step": 3375
    }
  ],
  "logging_steps": 25,
  "max_steps": 3390,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2459303128989696e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
