{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.4883147180080414,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.1571,
      "step": 25
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.397971510887146,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.4663,
      "step": 50
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5046388506889343,
      "learning_rate": 0.0001,
      "loss": 0.7173,
      "step": 75
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8103380799293518,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.2188,
      "step": 100
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5510199666023254,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.5655,
      "step": 125
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8048515319824219,
      "learning_rate": 0.0002,
      "loss": 0.9967,
      "step": 150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.38599881529808044,
      "learning_rate": 0.00019998688836656323,
      "loss": 0.5293,
      "step": 175
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5064254999160767,
      "learning_rate": 0.00019994755690455152,
      "loss": 0.9578,
      "step": 200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.35229018330574036,
      "learning_rate": 0.0001998820159279591,
      "loss": 0.6417,
      "step": 225
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.650837242603302,
      "learning_rate": 0.00019979028262377118,
      "loss": 0.9188,
      "step": 250
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.3517161011695862,
      "learning_rate": 0.00019967238104745696,
      "loss": 0.6167,
      "step": 275
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5354323983192444,
      "learning_rate": 0.0001995283421166614,
      "loss": 0.9085,
      "step": 300
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.32893770933151245,
      "learning_rate": 0.00019935820360309777,
      "loss": 0.5476,
      "step": 325
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4193626940250397,
      "learning_rate": 0.00019916201012264254,
      "loss": 0.9276,
      "step": 350
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.39131343364715576,
      "learning_rate": 0.00019893981312363562,
      "loss": 0.6077,
      "step": 375
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.42684677243232727,
      "learning_rate": 0.00019869167087338907,
      "loss": 0.9049,
      "step": 400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3177747130393982,
      "learning_rate": 0.00019841764844290744,
      "loss": 0.5032,
      "step": 425
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.502062976360321,
      "learning_rate": 0.0001981178176898239,
      "loss": 0.9014,
      "step": 450
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3625639081001282,
      "learning_rate": 0.00019779225723955707,
      "loss": 0.5468,
      "step": 475
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4558628797531128,
      "learning_rate": 0.00019744105246469263,
      "loss": 0.9071,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8360317945480347,
      "eval_runtime": 218.6411,
      "eval_samples_per_second": 4.574,
      "eval_steps_per_second": 4.574,
      "step": 500
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.3177274763584137,
      "learning_rate": 0.00019706429546259593,
      "loss": 0.5359,
      "step": 525
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.498818576335907,
      "learning_rate": 0.00019666208503126112,
      "loss": 0.8609,
      "step": 550
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.3455190658569336,
      "learning_rate": 0.00019623452664340306,
      "loss": 0.4966,
      "step": 575
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.41168656945228577,
      "learning_rate": 0.00019578173241879872,
      "loss": 0.8723,
      "step": 600
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.3455474376678467,
      "learning_rate": 0.0001953038210948861,
      "loss": 0.5046,
      "step": 625
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.566112756729126,
      "learning_rate": 0.00019480091799562704,
      "loss": 0.882,
      "step": 650
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.32338249683380127,
      "learning_rate": 0.00019427315499864344,
      "loss": 0.5648,
      "step": 675
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5035897493362427,
      "learning_rate": 0.00019372067050063438,
      "loss": 0.8496,
      "step": 700
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.347220778465271,
      "learning_rate": 0.00019314360938108425,
      "loss": 0.5422,
      "step": 725
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.4411548376083374,
      "learning_rate": 0.00019254212296427044,
      "loss": 0.8801,
      "step": 750
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.3250371813774109,
      "learning_rate": 0.00019191636897958122,
      "loss": 0.5559,
      "step": 775
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4426506757736206,
      "learning_rate": 0.00019126651152015403,
      "loss": 0.8372,
      "step": 800
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.32307693362236023,
      "learning_rate": 0.0001905927209998447,
      "loss": 0.5127,
      "step": 825
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.4492076337337494,
      "learning_rate": 0.00018989517410853955,
      "loss": 0.862,
      "step": 850
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.3357814848423004,
      "learning_rate": 0.00018917405376582145,
      "loss": 0.4653,
      "step": 875
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6447809338569641,
      "learning_rate": 0.00018842954907300236,
      "loss": 0.8771,
      "step": 900
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.3210543990135193,
      "learning_rate": 0.0001876618552635348,
      "loss": 0.5044,
      "step": 925
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.45989349484443665,
      "learning_rate": 0.00018687117365181512,
      "loss": 0.8362,
      "step": 950
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.34306731820106506,
      "learning_rate": 0.00018605771158039253,
      "loss": 0.5427,
      "step": 975
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.40070247650146484,
      "learning_rate": 0.00018522168236559695,
      "loss": 0.8568,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7492143511772156,
      "eval_runtime": 218.5956,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 1000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.34060582518577576,
      "learning_rate": 0.00018436330524160047,
      "loss": 0.5294,
      "step": 1025
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5275000333786011,
      "learning_rate": 0.00018348280530292713,
      "loss": 0.8008,
      "step": 1050
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.3433125615119934,
      "learning_rate": 0.00018258041344542566,
      "loss": 0.4898,
      "step": 1075
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5046310424804688,
      "learning_rate": 0.0001816563663057211,
      "loss": 0.7956,
      "step": 1100
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3542502224445343,
      "learning_rate": 0.00018071090619916093,
      "loss": 0.5536,
      "step": 1125
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.43223679065704346,
      "learning_rate": 0.00017974428105627208,
      "loss": 0.7775,
      "step": 1150
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.35769227147102356,
      "learning_rate": 0.00017875674435774547,
      "loss": 0.5109,
      "step": 1175
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.404085248708725,
      "learning_rate": 0.00017774855506796496,
      "loss": 0.8255,
      "step": 1200
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.34122636914253235,
      "learning_rate": 0.00017671997756709863,
      "loss": 0.4899,
      "step": 1225
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.44982942938804626,
      "learning_rate": 0.00017567128158176953,
      "loss": 0.7931,
      "step": 1250
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.34922248125076294,
      "learning_rate": 0.0001746027421143246,
      "loss": 0.4757,
      "step": 1275
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.552498996257782,
      "learning_rate": 0.00017351463937072004,
      "loss": 0.8007,
      "step": 1300
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.3762407898902893,
      "learning_rate": 0.00017240725868704218,
      "loss": 0.5328,
      "step": 1325
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.4407366216182709,
      "learning_rate": 0.00017128089045468294,
      "loss": 0.7882,
      "step": 1350
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.36023178696632385,
      "learning_rate": 0.00017013583004418993,
      "loss": 0.4233,
      "step": 1375
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.4940161406993866,
      "learning_rate": 0.00016897237772781044,
      "loss": 0.8395,
      "step": 1400
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.3451070487499237,
      "learning_rate": 0.00016779083860075033,
      "loss": 0.4613,
      "step": 1425
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.48804718255996704,
      "learning_rate": 0.00016659152250116812,
      "loss": 0.8324,
      "step": 1450
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3133487403392792,
      "learning_rate": 0.00016537474392892528,
      "loss": 0.4364,
      "step": 1475
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5972755551338196,
      "learning_rate": 0.000164140821963114,
      "loss": 0.788,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7261662483215332,
      "eval_runtime": 218.5467,
      "eval_samples_per_second": 4.576,
      "eval_steps_per_second": 4.576,
      "step": 1500
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.35417720675468445,
      "learning_rate": 0.00016289008017838445,
      "loss": 0.4311,
      "step": 1525
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.5235798954963684,
      "learning_rate": 0.00016162284656009274,
      "loss": 0.7335,
      "step": 1550
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.3771834969520569,
      "learning_rate": 0.00016033945341829248,
      "loss": 0.4864,
      "step": 1575
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.527886152267456,
      "learning_rate": 0.00015904023730059228,
      "loss": 0.7416,
      "step": 1600
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.3707130253314972,
      "learning_rate": 0.00015772553890390197,
      "loss": 0.473,
      "step": 1625
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.4490775465965271,
      "learning_rate": 0.00015639570298509064,
      "loss": 0.7505,
      "step": 1650
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.4111699163913727,
      "learning_rate": 0.00015505107827058036,
      "loss": 0.5168,
      "step": 1675
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.5550400018692017,
      "learning_rate": 0.0001536920173648984,
      "loss": 0.7292,
      "step": 1700
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.3870089054107666,
      "learning_rate": 0.000152318876658213,
      "loss": 0.4744,
      "step": 1725
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.49697041511535645,
      "learning_rate": 0.00015093201623287631,
      "loss": 0.7326,
      "step": 1750
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.3878072202205658,
      "learning_rate": 0.00014953179976899878,
      "loss": 0.4162,
      "step": 1775
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.44354259967803955,
      "learning_rate": 0.00014811859444908052,
      "loss": 0.7533,
      "step": 1800
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.4053493142127991,
      "learning_rate": 0.00014669277086172406,
      "loss": 0.4747,
      "step": 1825
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.4707287847995758,
      "learning_rate": 0.00014525470290445392,
      "loss": 0.7446,
      "step": 1850
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.4248770773410797,
      "learning_rate": 0.00014380476768566824,
      "loss": 0.4429,
      "step": 1875
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.5186546444892883,
      "learning_rate": 0.00014234334542574906,
      "loss": 0.7604,
      "step": 1900
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.391743928194046,
      "learning_rate": 0.00014087081935735564,
      "loss": 0.4328,
      "step": 1925
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.4917706847190857,
      "learning_rate": 0.00013938757562492873,
      "loss": 0.7285,
      "step": 1950
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.4341624677181244,
      "learning_rate": 0.00013789400318343068,
      "loss": 0.4581,
      "step": 1975
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.5214529037475586,
      "learning_rate": 0.00013639049369634876,
      "loss": 0.7713,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7102497816085815,
      "eval_runtime": 218.5929,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 2000
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.39864885807037354,
      "learning_rate": 0.00013487744143298822,
      "loss": 0.4456,
      "step": 2025
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.5492661595344543,
      "learning_rate": 0.00013335524316508208,
      "loss": 0.6815,
      "step": 2050
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.4459651708602905,
      "learning_rate": 0.0001318242980627444,
      "loss": 0.4463,
      "step": 2075
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.5372052192687988,
      "learning_rate": 0.00013028500758979506,
      "loss": 0.6601,
      "step": 2100
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.41802895069122314,
      "learning_rate": 0.00012873777539848283,
      "loss": 0.4429,
      "step": 2125
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.5380886793136597,
      "learning_rate": 0.0001271830072236343,
      "loss": 0.6662,
      "step": 2150
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.42595264315605164,
      "learning_rate": 0.00012562111077625722,
      "loss": 0.4515,
      "step": 2175
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.5522435903549194,
      "learning_rate": 0.00012405249563662537,
      "loss": 0.691,
      "step": 2200
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.4401111602783203,
      "learning_rate": 0.00012247757314687297,
      "loss": 0.4434,
      "step": 2225
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.552882730960846,
      "learning_rate": 0.00012089675630312754,
      "loss": 0.6974,
      "step": 2250
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.4957764446735382,
      "learning_rate": 0.00011931045964720881,
      "loss": 0.4496,
      "step": 2275
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.614093005657196,
      "learning_rate": 0.0001177190991579223,
      "loss": 0.6839,
      "step": 2300
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.4580642282962799,
      "learning_rate": 0.00011612309214197599,
      "loss": 0.3887,
      "step": 2325
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.4938104450702667,
      "learning_rate": 0.00011452285712454904,
      "loss": 0.6926,
      "step": 2350
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.45218929648399353,
      "learning_rate": 0.00011291881373954065,
      "loss": 0.3998,
      "step": 2375
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.4967931807041168,
      "learning_rate": 0.00011131138261952845,
      "loss": 0.689,
      "step": 2400
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.47067397832870483,
      "learning_rate": 0.00010970098528546481,
      "loss": 0.4203,
      "step": 2425
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.5793052911758423,
      "learning_rate": 0.00010808804403614043,
      "loss": 0.7045,
      "step": 2450
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.5125204920768738,
      "learning_rate": 0.00010647298183744359,
      "loss": 0.446,
      "step": 2475
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.6072902679443359,
      "learning_rate": 0.00010485622221144484,
      "loss": 0.7045,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7172776460647583,
      "eval_runtime": 218.5817,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 2500
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.4900226891040802,
      "learning_rate": 0.00010323818912533561,
      "loss": 0.391,
      "step": 2525
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.6470639705657959,
      "learning_rate": 0.00010161930688025017,
      "loss": 0.6238,
      "step": 2550
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.49048036336898804,
      "learning_rate": 0.0001,
      "loss": 0.3846,
      "step": 2575
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.5439808964729309,
      "learning_rate": 9.838069311974986e-05,
      "loss": 0.6362,
      "step": 2600
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.5729826092720032,
      "learning_rate": 9.676181087466444e-05,
      "loss": 0.4214,
      "step": 2625
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.619086503982544,
      "learning_rate": 9.514377778855521e-05,
      "loss": 0.643,
      "step": 2650
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.5543289184570312,
      "learning_rate": 9.352701816255643e-05,
      "loss": 0.3862,
      "step": 2675
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.636737585067749,
      "learning_rate": 9.19119559638596e-05,
      "loss": 0.6403,
      "step": 2700
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.52287358045578,
      "learning_rate": 9.02990147145352e-05,
      "loss": 0.4392,
      "step": 2725
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.6512364745140076,
      "learning_rate": 8.868861738047158e-05,
      "loss": 0.6213,
      "step": 2750
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.5595900416374207,
      "learning_rate": 8.70811862604594e-05,
      "loss": 0.436,
      "step": 2775
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.5991116762161255,
      "learning_rate": 8.5477142875451e-05,
      "loss": 0.6402,
      "step": 2800
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.5178930759429932,
      "learning_rate": 8.387690785802402e-05,
      "loss": 0.3778,
      "step": 2825
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.6239563822746277,
      "learning_rate": 8.228090084207774e-05,
      "loss": 0.6232,
      "step": 2850
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.5271592736244202,
      "learning_rate": 8.068954035279121e-05,
      "loss": 0.4387,
      "step": 2875
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.5712928175926208,
      "learning_rate": 7.91032436968725e-05,
      "loss": 0.6222,
      "step": 2900
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.5604329109191895,
      "learning_rate": 7.75224268531271e-05,
      "loss": 0.3995,
      "step": 2925
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.559648871421814,
      "learning_rate": 7.594750436337467e-05,
      "loss": 0.6482,
      "step": 2950
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.575752854347229,
      "learning_rate": 7.437888922374276e-05,
      "loss": 0.4071,
      "step": 2975
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.7309179306030273,
      "learning_rate": 7.281699277636572e-05,
      "loss": 0.6232,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7307729125022888,
      "eval_runtime": 218.5169,
      "eval_samples_per_second": 4.576,
      "eval_steps_per_second": 4.576,
      "step": 3000
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.5787127614021301,
      "learning_rate": 7.126222460151719e-05,
      "loss": 0.3708,
      "step": 3025
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.623243510723114,
      "learning_rate": 6.971499241020495e-05,
      "loss": 0.5882,
      "step": 3050
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.5920851826667786,
      "learning_rate": 6.817570193725564e-05,
      "loss": 0.362,
      "step": 3075
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.654502272605896,
      "learning_rate": 6.664475683491796e-05,
      "loss": 0.58,
      "step": 3100
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.5616466999053955,
      "learning_rate": 6.512255856701177e-05,
      "loss": 0.3767,
      "step": 3125
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.6414095759391785,
      "learning_rate": 6.360950630365126e-05,
      "loss": 0.5991,
      "step": 3150
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.6276426911354065,
      "learning_rate": 6.210599681656933e-05,
      "loss": 0.3988,
      "step": 3175
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.6794831156730652,
      "learning_rate": 6.061242437507131e-05,
      "loss": 0.5779,
      "step": 3200
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.5963647365570068,
      "learning_rate": 5.9129180642644414e-05,
      "loss": 0.3981,
      "step": 3225
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.6468406915664673,
      "learning_rate": 5.765665457425102e-05,
      "loss": 0.5767,
      "step": 3250
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.544664204120636,
      "learning_rate": 5.6195232314331766e-05,
      "loss": 0.3391,
      "step": 3275
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.6043624877929688,
      "learning_rate": 5.474529709554612e-05,
      "loss": 0.5888,
      "step": 3300
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.6582447290420532,
      "learning_rate": 5.3307229138275936e-05,
      "loss": 0.4033,
      "step": 3325
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.706730842590332,
      "learning_rate": 5.1881405550919493e-05,
      "loss": 0.6027,
      "step": 3350
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.5518860816955566,
      "learning_rate": 5.0468200231001286e-05,
      "loss": 0.3838,
      "step": 3375
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.8287966847419739,
      "learning_rate": 4.9067983767123736e-05,
      "loss": 0.5814,
      "step": 3400
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.6333245038986206,
      "learning_rate": 4.768112334178699e-05,
      "loss": 0.4218,
      "step": 3425
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.7130221128463745,
      "learning_rate": 4.630798263510162e-05,
      "loss": 0.5743,
      "step": 3450
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.6440684199333191,
      "learning_rate": 4.494892172941965e-05,
      "loss": 0.4273,
      "step": 3475
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.6007062792778015,
      "learning_rate": 4.360429701490934e-05,
      "loss": 0.5611,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.740486204624176,
      "eval_runtime": 218.5681,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 3500
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.5755683183670044,
      "learning_rate": 4.227446109609809e-05,
      "loss": 0.3963,
      "step": 3525
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.7188610434532166,
      "learning_rate": 4.0959762699407766e-05,
      "loss": 0.5277,
      "step": 3550
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.6625348329544067,
      "learning_rate": 3.966054658170754e-05,
      "loss": 0.3684,
      "step": 3575
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.6679999232292175,
      "learning_rate": 3.8377153439907266e-05,
      "loss": 0.5462,
      "step": 3600
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.6889784336090088,
      "learning_rate": 3.710991982161555e-05,
      "loss": 0.3858,
      "step": 3625
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.6439942121505737,
      "learning_rate": 3.585917803688603e-05,
      "loss": 0.5631,
      "step": 3650
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.6537156701087952,
      "learning_rate": 3.4625256071074773e-05,
      "loss": 0.3664,
      "step": 3675
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.6209041476249695,
      "learning_rate": 3.340847749883191e-05,
      "loss": 0.5272,
      "step": 3700
    },
    {
      "epoch": 7.45,
      "grad_norm": 0.615443229675293,
      "learning_rate": 3.2209161399249674e-05,
      "loss": 0.3942,
      "step": 3725
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.7517237663269043,
      "learning_rate": 3.102762227218957e-05,
      "loss": 0.5472,
      "step": 3750
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.7356301546096802,
      "learning_rate": 2.9864169955810084e-05,
      "loss": 0.3799,
      "step": 3775
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.6264599561691284,
      "learning_rate": 2.8719109545317103e-05,
      "loss": 0.5226,
      "step": 3800
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.6741682291030884,
      "learning_rate": 2.759274131295787e-05,
      "loss": 0.3451,
      "step": 3825
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.6461891531944275,
      "learning_rate": 2.6485360629279987e-05,
      "loss": 0.561,
      "step": 3850
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.6604924201965332,
      "learning_rate": 2.5397257885675397e-05,
      "loss": 0.3432,
      "step": 3875
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.6104917526245117,
      "learning_rate": 2.432871841823047e-05,
      "loss": 0.5614,
      "step": 3900
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.694582462310791,
      "learning_rate": 2.3280022432901383e-05,
      "loss": 0.3978,
      "step": 3925
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.7138830423355103,
      "learning_rate": 2.2251444932035094e-05,
      "loss": 0.5626,
      "step": 3950
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.7337437868118286,
      "learning_rate": 2.1243255642254578e-05,
      "loss": 0.3485,
      "step": 3975
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.6352806687355042,
      "learning_rate": 2.025571894372794e-05,
      "loss": 0.5347,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7550863027572632,
      "eval_runtime": 218.5727,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 4000
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.6886122226715088,
      "learning_rate": 1.9289093800839066e-05,
      "loss": 0.3927,
      "step": 4025
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.6338043212890625,
      "learning_rate": 1.8343633694278895e-05,
      "loss": 0.5435,
      "step": 4050
    },
    {
      "epoch": 8.15,
      "grad_norm": 0.6872689723968506,
      "learning_rate": 1.741958655457436e-05,
      "loss": 0.3496,
      "step": 4075
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.6859167218208313,
      "learning_rate": 1.65171946970729e-05,
      "loss": 0.5018,
      "step": 4100
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.7115866541862488,
      "learning_rate": 1.563669475839956e-05,
      "loss": 0.3396,
      "step": 4125
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.6064643263816833,
      "learning_rate": 1.4778317634403083e-05,
      "loss": 0.5274,
      "step": 4150
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.7077499628067017,
      "learning_rate": 1.3942288419607475e-05,
      "loss": 0.3729,
      "step": 4175
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.6522040367126465,
      "learning_rate": 1.3128826348184887e-05,
      "loss": 0.5145,
      "step": 4200
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.7407277822494507,
      "learning_rate": 1.233814473646524e-05,
      "loss": 0.3234,
      "step": 4225
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.6264805793762207,
      "learning_rate": 1.1570450926997655e-05,
      "loss": 0.538,
      "step": 4250
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.7068399786949158,
      "learning_rate": 1.0825946234178574e-05,
      "loss": 0.3949,
      "step": 4275
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.7018409371376038,
      "learning_rate": 1.010482589146048e-05,
      "loss": 0.5311,
      "step": 4300
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.70475172996521,
      "learning_rate": 9.407279000155312e-06,
      "loss": 0.3654,
      "step": 4325
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.7449743151664734,
      "learning_rate": 8.733488479845997e-06,
      "loss": 0.525,
      "step": 4350
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.7277312278747559,
      "learning_rate": 8.083631020418791e-06,
      "loss": 0.3287,
      "step": 4375
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.7029580473899841,
      "learning_rate": 7.457877035729588e-06,
      "loss": 0.5057,
      "step": 4400
    },
    {
      "epoch": 8.85,
      "grad_norm": 0.6682687997817993,
      "learning_rate": 6.856390618915775e-06,
      "loss": 0.3615,
      "step": 4425
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.7545983791351318,
      "learning_rate": 6.2793294993656494e-06,
      "loss": 0.5117,
      "step": 4450
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.712037205696106,
      "learning_rate": 5.726845001356573e-06,
      "loss": 0.3951,
      "step": 4475
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.7424407005310059,
      "learning_rate": 5.199082004372957e-06,
      "loss": 0.5051,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7654117345809937,
      "eval_runtime": 218.852,
      "eval_samples_per_second": 4.569,
      "eval_steps_per_second": 4.569,
      "step": 4500
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.7173388600349426,
      "learning_rate": 4.6961789051139124e-06,
      "loss": 0.3673,
      "step": 4525
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.6088714003562927,
      "learning_rate": 4.2182675812012965e-06,
      "loss": 0.5203,
      "step": 4550
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.7020381689071655,
      "learning_rate": 3.7654733565969826e-06,
      "loss": 0.3725,
      "step": 4575
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.66562819480896,
      "learning_rate": 3.3379149687388867e-06,
      "loss": 0.5053,
      "step": 4600
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.7392590641975403,
      "learning_rate": 2.9357045374040825e-06,
      "loss": 0.4228,
      "step": 4625
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.7097228765487671,
      "learning_rate": 2.5589475353073988e-06,
      "loss": 0.5084,
      "step": 4650
    },
    {
      "epoch": 9.35,
      "grad_norm": 0.7191447019577026,
      "learning_rate": 2.2077427604429433e-06,
      "loss": 0.3412,
      "step": 4675
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.7158499360084534,
      "learning_rate": 1.882182310176095e-06,
      "loss": 0.5149,
      "step": 4700
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.6957696676254272,
      "learning_rate": 1.5823515570925763e-06,
      "loss": 0.3401,
      "step": 4725
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.7181519865989685,
      "learning_rate": 1.30832912661093e-06,
      "loss": 0.5067,
      "step": 4750
    },
    {
      "epoch": 9.55,
      "grad_norm": 0.7021570205688477,
      "learning_rate": 1.0601868763643996e-06,
      "loss": 0.3448,
      "step": 4775
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.6896758079528809,
      "learning_rate": 8.379898773574924e-07,
      "loss": 0.5126,
      "step": 4800
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.7350299954414368,
      "learning_rate": 6.41796396902239e-07,
      "loss": 0.3449,
      "step": 4825
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.6799773573875427,
      "learning_rate": 4.7165788333860536e-07,
      "loss": 0.4978,
      "step": 4850
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.7546692490577698,
      "learning_rate": 3.2761895254306287e-07,
      "loss": 0.3351,
      "step": 4875
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.6453920602798462,
      "learning_rate": 2.0971737622883515e-07,
      "loss": 0.4951,
      "step": 4900
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.6451714038848877,
      "learning_rate": 1.179840720409331e-07,
      "loss": 0.3565,
      "step": 4925
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.7048543095588684,
      "learning_rate": 5.2443095448506674e-08,
      "loss": 0.526,
      "step": 4950
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.7188707590103149,
      "learning_rate": 1.3111633436779791e-08,
      "loss": 0.3481,
      "step": 4975
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.6650217771530151,
      "learning_rate": 0.0,
      "loss": 0.498,
      "step": 5000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.1200184045568e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
