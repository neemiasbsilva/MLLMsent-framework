{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0984251968503937,
      "grad_norm": 0.524985671043396,
      "learning_rate": 6.493506493506494e-05,
      "loss": 1.1823,
      "step": 25
    },
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 0.9865207076072693,
      "learning_rate": 0.00012987012987012987,
      "loss": 1.9305,
      "step": 50
    },
    {
      "epoch": 0.2952755905511811,
      "grad_norm": 0.5422508716583252,
      "learning_rate": 0.0001948051948051948,
      "loss": 0.7192,
      "step": 75
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.8466345071792603,
      "learning_rate": 0.0001999569705841918,
      "loss": 1.0527,
      "step": 100
    },
    {
      "epoch": 0.4921259842519685,
      "grad_norm": 0.4605882465839386,
      "learning_rate": 0.00019981263531593422,
      "loss": 0.6105,
      "step": 125
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.6673232316970825,
      "learning_rate": 0.0001995668155607342,
      "loss": 0.9623,
      "step": 150
    },
    {
      "epoch": 0.6889763779527559,
      "grad_norm": 0.3623445928096771,
      "learning_rate": 0.0001992197612558032,
      "loss": 0.5801,
      "step": 175
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.6242563128471375,
      "learning_rate": 0.00019877182526857086,
      "loss": 0.9474,
      "step": 200
    },
    {
      "epoch": 0.8858267716535433,
      "grad_norm": 0.3613653779029846,
      "learning_rate": 0.0001982234630379073,
      "loss": 0.6024,
      "step": 225
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.5344192385673523,
      "learning_rate": 0.00019757523211105555,
      "loss": 0.925,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8215617537498474,
      "eval_runtime": 113.475,
      "eval_samples_per_second": 4.468,
      "eval_steps_per_second": 4.468,
      "step": 254
    },
    {
      "epoch": 1.0826771653543308,
      "grad_norm": 0.32678931951522827,
      "learning_rate": 0.00019682779157674537,
      "loss": 0.5092,
      "step": 275
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.4615655541419983,
      "learning_rate": 0.00019598190139506508,
      "loss": 0.9007,
      "step": 300
    },
    {
      "epoch": 1.279527559055118,
      "grad_norm": 0.3656233847141266,
      "learning_rate": 0.00019503842162477204,
      "loss": 0.5352,
      "step": 325
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.3996892273426056,
      "learning_rate": 0.00019399831154882796,
      "loss": 0.9168,
      "step": 350
    },
    {
      "epoch": 1.4763779527559056,
      "grad_norm": 0.35791486501693726,
      "learning_rate": 0.00019286262869904828,
      "loss": 0.4927,
      "step": 375
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.4208301305770874,
      "learning_rate": 0.00019163252778085646,
      "loss": 0.9371,
      "step": 400
    },
    {
      "epoch": 1.673228346456693,
      "grad_norm": 0.33060750365257263,
      "learning_rate": 0.00019030925949923777,
      "loss": 0.5449,
      "step": 425
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.4339338541030884,
      "learning_rate": 0.00018889416928708465,
      "loss": 0.9292,
      "step": 450
    },
    {
      "epoch": 1.8700787401574803,
      "grad_norm": 0.38779065012931824,
      "learning_rate": 0.00018738869593722842,
      "loss": 0.4795,
      "step": 475
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.38832953572273254,
      "learning_rate": 0.0001857943701395464,
      "loss": 0.9429,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8121553063392639,
      "eval_runtime": 113.4893,
      "eval_samples_per_second": 4.467,
      "eval_steps_per_second": 4.467,
      "step": 508
    },
    {
      "epoch": 2.0669291338582676,
      "grad_norm": 0.39397260546684265,
      "learning_rate": 0.00018411281292463345,
      "loss": 0.3891,
      "step": 525
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.40759652853012085,
      "learning_rate": 0.00018234573401561914,
      "loss": 0.9247,
      "step": 550
    },
    {
      "epoch": 2.263779527559055,
      "grad_norm": 0.5058108568191528,
      "learning_rate": 0.00018049493008980686,
      "loss": 0.4111,
      "step": 575
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.438763827085495,
      "learning_rate": 0.00017856228295190252,
      "loss": 0.9325,
      "step": 600
    },
    {
      "epoch": 2.4606299212598426,
      "grad_norm": 0.5013923048973083,
      "learning_rate": 0.0001765497576206896,
      "loss": 0.4121,
      "step": 625
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.3951208293437958,
      "learning_rate": 0.0001744594003310967,
      "loss": 0.9307,
      "step": 650
    },
    {
      "epoch": 2.65748031496063,
      "grad_norm": 0.47534745931625366,
      "learning_rate": 0.00017229333645368833,
      "loss": 0.4825,
      "step": 675
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4318195879459381,
      "learning_rate": 0.00017005376833369442,
      "loss": 0.9082,
      "step": 700
    },
    {
      "epoch": 2.8543307086614176,
      "grad_norm": 0.47339630126953125,
      "learning_rate": 0.0001677429730517763,
      "loss": 0.4103,
      "step": 725
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.4435698091983795,
      "learning_rate": 0.00016536330010880502,
      "loss": 0.9264,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.738786518573761,
      "eval_runtime": 113.4729,
      "eval_samples_per_second": 4.468,
      "eval_steps_per_second": 4.468,
      "step": 762
    },
    {
      "epoch": 3.0511811023622046,
      "grad_norm": 0.07720838487148285,
      "learning_rate": 0.00016291716903700656,
      "loss": 0.4704,
      "step": 775
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.458097368478775,
      "learning_rate": 0.0001604070669399027,
      "loss": 0.8309,
      "step": 800
    },
    {
      "epoch": 3.248031496062992,
      "grad_norm": 0.07655702531337738,
      "learning_rate": 0.00015783554596354883,
      "loss": 0.4453,
      "step": 825
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.44891393184661865,
      "learning_rate": 0.00015520522070163964,
      "loss": 0.8392,
      "step": 850
    },
    {
      "epoch": 3.4448818897637796,
      "grad_norm": 0.11791045218706131,
      "learning_rate": 0.00015251876553712128,
      "loss": 0.4385,
      "step": 875
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.4519127309322357,
      "learning_rate": 0.00014977891192301265,
      "loss": 0.8183,
      "step": 900
    },
    {
      "epoch": 3.6417322834645667,
      "grad_norm": 0.10247290879487991,
      "learning_rate": 0.00014698844560520106,
      "loss": 0.4354,
      "step": 925
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.44786885380744934,
      "learning_rate": 0.00014415020379003512,
      "loss": 0.8165,
      "step": 950
    },
    {
      "epoch": 3.838582677165354,
      "grad_norm": 0.12562084197998047,
      "learning_rate": 0.0001412670722595956,
      "loss": 0.4253,
      "step": 975
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.43851926922798157,
      "learning_rate": 0.0001383419824375768,
      "loss": 0.8518,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.729901134967804,
      "eval_runtime": 113.4159,
      "eval_samples_per_second": 4.47,
      "eval_steps_per_second": 4.47,
      "step": 1016
    },
    {
      "epoch": 4.035433070866142,
      "grad_norm": 0.09102071076631546,
      "learning_rate": 0.0001353779084087618,
      "loss": 0.5028,
      "step": 1025
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.4506132900714874,
      "learning_rate": 0.0001323778638951219,
      "loss": 0.6665,
      "step": 1050
    },
    {
      "epoch": 4.232283464566929,
      "grad_norm": 0.13867847621440887,
      "learning_rate": 0.0001293448991916154,
      "loss": 0.4801,
      "step": 1075
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.4608456492424011,
      "learning_rate": 0.00012628209806480023,
      "loss": 0.6963,
      "step": 1100
    },
    {
      "epoch": 4.429133858267717,
      "grad_norm": 0.1393735557794571,
      "learning_rate": 0.0001231925746174148,
      "loss": 0.5007,
      "step": 1125
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.4828193783760071,
      "learning_rate": 0.00012007947012211418,
      "loss": 0.7296,
      "step": 1150
    },
    {
      "epoch": 4.625984251968504,
      "grad_norm": 0.11062245815992355,
      "learning_rate": 0.00011694594982758164,
      "loss": 0.4855,
      "step": 1175
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.5290626287460327,
      "learning_rate": 0.00011379519974026224,
      "loss": 0.7076,
      "step": 1200
    },
    {
      "epoch": 4.822834645669292,
      "grad_norm": 0.13354668021202087,
      "learning_rate": 0.00011063042338499112,
      "loss": 0.4965,
      "step": 1225
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.4753052890300751,
      "learning_rate": 0.00010745483854780996,
      "loss": 0.6754,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7261006832122803,
      "eval_runtime": 113.4313,
      "eval_samples_per_second": 4.47,
      "eval_steps_per_second": 4.47,
      "step": 1270
    },
    {
      "epoch": 5.019685039370079,
      "grad_norm": 0.09355027228593826,
      "learning_rate": 0.0001042716740042833,
      "loss": 0.5519,
      "step": 1275
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.5439605116844177,
      "learning_rate": 0.0001010841662366414,
      "loss": 0.5993,
      "step": 1300
    },
    {
      "epoch": 5.216535433070866,
      "grad_norm": 0.18478554487228394,
      "learning_rate": 9.789555614308721e-05,
      "loss": 0.5332,
      "step": 1325
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.5297941565513611,
      "learning_rate": 9.470908574261332e-05,
      "loss": 0.5447,
      "step": 1350
    },
    {
      "epoch": 5.413385826771654,
      "grad_norm": 0.179717555642128,
      "learning_rate": 9.15279948786798e-05,
      "loss": 0.535,
      "step": 1375
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.5527756810188293,
      "learning_rate": 8.83555179251033e-05,
      "loss": 0.5713,
      "step": 1400
    },
    {
      "epoch": 5.610236220472441,
      "grad_norm": 0.13202086091041565,
      "learning_rate": 8.519488049750807e-05,
      "loss": 0.5486,
      "step": 1425
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.5510562062263489,
      "learning_rate": 8.204929617368147e-05,
      "loss": 0.5596,
      "step": 1450
    },
    {
      "epoch": 5.807086614173229,
      "grad_norm": 0.138108029961586,
      "learning_rate": 7.892196322616913e-05,
      "loss": 0.5248,
      "step": 1475
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.5577210783958435,
      "learning_rate": 7.581606137043167e-05,
      "loss": 0.5374,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7264041900634766,
      "eval_runtime": 113.4402,
      "eval_samples_per_second": 4.469,
      "eval_steps_per_second": 4.469,
      "step": 1524
    },
    {
      "epoch": 6.003937007874016,
      "grad_norm": 0.11406661570072174,
      "learning_rate": 7.273474853186922e-05,
      "loss": 0.5985,
      "step": 1525
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.5394797921180725,
      "learning_rate": 6.968115763500127e-05,
      "loss": 0.4656,
      "step": 1550
    },
    {
      "epoch": 6.200787401574803,
      "grad_norm": 0.14683672785758972,
      "learning_rate": 6.66583934180658e-05,
      "loss": 0.5844,
      "step": 1575
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.598819375038147,
      "learning_rate": 6.366952927627702e-05,
      "loss": 0.4901,
      "step": 1600
    },
    {
      "epoch": 6.397637795275591,
      "grad_norm": 0.15793316066265106,
      "learning_rate": 6.071760413695131e-05,
      "loss": 0.5654,
      "step": 1625
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.6797133684158325,
      "learning_rate": 5.7805619369677785e-05,
      "loss": 0.4255,
      "step": 1650
    },
    {
      "epoch": 6.594488188976378,
      "grad_norm": 0.14501968026161194,
      "learning_rate": 5.4936535734676474e-05,
      "loss": 0.5687,
      "step": 1675
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.6404864192008972,
      "learning_rate": 5.211327037244533e-05,
      "loss": 0.434,
      "step": 1700
    },
    {
      "epoch": 6.791338582677166,
      "grad_norm": 0.16606885194778442,
      "learning_rate": 4.933869383775809e-05,
      "loss": 0.5934,
      "step": 1725
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.615697979927063,
      "learning_rate": 4.661562718102807e-05,
      "loss": 0.4126,
      "step": 1750
    },
    {
      "epoch": 6.988188976377953,
      "grad_norm": 0.13098295032978058,
      "learning_rate": 4.3946839080005234e-05,
      "loss": 0.5897,
      "step": 1775
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7371729016304016,
      "eval_runtime": 113.4048,
      "eval_samples_per_second": 4.471,
      "eval_steps_per_second": 4.471,
      "step": 1778
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.6309309005737305,
      "learning_rate": 4.133504302472355e-05,
      "loss": 0.3778,
      "step": 1800
    },
    {
      "epoch": 7.18503937007874,
      "grad_norm": 0.6949825882911682,
      "learning_rate": 3.878289455856014e-05,
      "loss": 0.5677,
      "step": 1825
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.680632472038269,
      "learning_rate": 3.629298857821186e-05,
      "loss": 0.361,
      "step": 1850
    },
    {
      "epoch": 7.381889763779528,
      "grad_norm": 0.6693277359008789,
      "learning_rate": 3.3867856695334464e-05,
      "loss": 0.5837,
      "step": 1875
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.714507520198822,
      "learning_rate": 3.150996466252648e-05,
      "loss": 0.3831,
      "step": 1900
    },
    {
      "epoch": 7.578740157480315,
      "grad_norm": 0.6689651012420654,
      "learning_rate": 2.9221709866275726e-05,
      "loss": 0.5935,
      "step": 1925
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.705001950263977,
      "learning_rate": 2.7005418889416667e-05,
      "loss": 0.3964,
      "step": 1950
    },
    {
      "epoch": 7.775590551181102,
      "grad_norm": 0.7263421416282654,
      "learning_rate": 2.486334514557761e-05,
      "loss": 0.6084,
      "step": 1975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.7622035145759583,
      "learning_rate": 2.2797666588022748e-05,
      "loss": 0.3594,
      "step": 2000
    },
    {
      "epoch": 7.97244094488189,
      "grad_norm": 0.7488787770271301,
      "learning_rate": 2.0810483495218135e-05,
      "loss": 0.6089,
      "step": 2025
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7445728182792664,
      "eval_runtime": 113.5493,
      "eval_samples_per_second": 4.465,
      "eval_steps_per_second": 4.465,
      "step": 2032
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.6609115600585938,
      "learning_rate": 1.8903816335374046e-05,
      "loss": 0.2961,
      "step": 2050
    },
    {
      "epoch": 8.169291338582678,
      "grad_norm": 0.72383713722229,
      "learning_rate": 1.7079603712133907e-05,
      "loss": 0.6277,
      "step": 2075
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.7468353509902954,
      "learning_rate": 1.5339700393499355e-05,
      "loss": 0.3269,
      "step": 2100
    },
    {
      "epoch": 8.366141732283465,
      "grad_norm": 0.7849278450012207,
      "learning_rate": 1.3685875425995065e-05,
      "loss": 0.6071,
      "step": 2125
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.6997049450874329,
      "learning_rate": 1.2119810335990788e-05,
      "loss": 0.3578,
      "step": 2150
    },
    {
      "epoch": 8.562992125984252,
      "grad_norm": 0.7607104778289795,
      "learning_rate": 1.0643097420009628e-05,
      "loss": 0.6031,
      "step": 2175
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.7609604597091675,
      "learning_rate": 9.257238125760781e-06,
      "loss": 0.3078,
      "step": 2200
    },
    {
      "epoch": 8.759842519685039,
      "grad_norm": 0.7212551236152649,
      "learning_rate": 7.963641525542564e-06,
      "loss": 0.6185,
      "step": 2225
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.7266631722450256,
      "learning_rate": 6.763622883568521e-06,
      "loss": 0.3021,
      "step": 2250
    },
    {
      "epoch": 8.956692913385826,
      "grad_norm": 0.6980621218681335,
      "learning_rate": 5.658402318672418e-06,
      "loss": 0.6115,
      "step": 2275
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7551618814468384,
      "eval_runtime": 113.4024,
      "eval_samples_per_second": 4.471,
      "eval_steps_per_second": 4.471,
      "step": 2286
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.20245657861232758,
      "learning_rate": 4.649103563752743e-06,
      "loss": 0.2924,
      "step": 2300
    },
    {
      "epoch": 9.153543307086615,
      "grad_norm": 0.7525610327720642,
      "learning_rate": 3.7367528232172597e-06,
      "loss": 0.6034,
      "step": 2325
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.15874320268630981,
      "learning_rate": 2.9222777295899063e-06,
      "loss": 0.2884,
      "step": 2350
    },
    {
      "epoch": 9.350393700787402,
      "grad_norm": 0.7867267727851868,
      "learning_rate": 2.206506400340369e-06,
      "loss": 0.6469,
      "step": 2375
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.15247121453285217,
      "learning_rate": 1.59016659589587e-06,
      "loss": 0.2987,
      "step": 2400
    },
    {
      "epoch": 9.547244094488189,
      "grad_norm": 0.7351521849632263,
      "learning_rate": 1.073884979690709e-06,
      "loss": 0.619,
      "step": 2425
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.170371413230896,
      "learning_rate": 6.581864810063732e-07,
      "loss": 0.2849,
      "step": 2450
    },
    {
      "epoch": 9.744094488188976,
      "grad_norm": 0.7167494297027588,
      "learning_rate": 3.4349376124969134e-07,
      "loss": 0.6483,
      "step": 2475
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.18569299578666687,
      "learning_rate": 1.3012678421191472e-07,
      "loss": 0.2951,
      "step": 2500
    },
    {
      "epoch": 9.940944881889763,
      "grad_norm": 0.8163719773292542,
      "learning_rate": 1.8302490745503166e-08,
      "loss": 0.5862,
      "step": 2525
    }
  ],
  "logging_steps": 25,
  "max_steps": 2540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0419479762997248e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
