{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 2895,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.12953367875647667,
      "grad_norm": 0.47575002908706665,
      "learning_rate": 5.747126436781609e-05,
      "loss": 1.8786,
      "step": 25
    },
    {
      "epoch": 0.25906735751295334,
      "grad_norm": 0.3626662492752075,
      "learning_rate": 0.00011494252873563218,
      "loss": 1.5422,
      "step": 50
    },
    {
      "epoch": 0.38860103626943004,
      "grad_norm": 0.39562222361564636,
      "learning_rate": 0.00017241379310344826,
      "loss": 0.9064,
      "step": 75
    },
    {
      "epoch": 0.5181347150259067,
      "grad_norm": 0.7720252275466919,
      "learning_rate": 0.00019998942319271077,
      "loss": 0.7647,
      "step": 100
    },
    {
      "epoch": 0.6476683937823834,
      "grad_norm": 0.29617393016815186,
      "learning_rate": 0.00019990963977153936,
      "loss": 0.7125,
      "step": 125
    },
    {
      "epoch": 0.7772020725388601,
      "grad_norm": 0.4344136118888855,
      "learning_rate": 0.00019975169993441627,
      "loss": 0.6893,
      "step": 150
    },
    {
      "epoch": 0.9067357512953368,
      "grad_norm": 0.28627243638038635,
      "learning_rate": 0.0001995157272330992,
      "loss": 0.6704,
      "step": 175
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7176869511604309,
      "eval_runtime": 148.1103,
      "eval_samples_per_second": 5.192,
      "eval_steps_per_second": 5.192,
      "step": 193
    },
    {
      "epoch": 1.0362694300518134,
      "grad_norm": 0.30116671323776245,
      "learning_rate": 0.00019920190626219423,
      "loss": 0.6551,
      "step": 200
    },
    {
      "epoch": 1.16580310880829,
      "grad_norm": 0.2771284580230713,
      "learning_rate": 0.0001988104825147528,
      "loss": 0.6501,
      "step": 225
    },
    {
      "epoch": 1.2953367875647668,
      "grad_norm": 0.2561744451522827,
      "learning_rate": 0.00019834176219022965,
      "loss": 0.6362,
      "step": 250
    },
    {
      "epoch": 1.4248704663212435,
      "grad_norm": 0.2741793990135193,
      "learning_rate": 0.00019779611195495177,
      "loss": 0.6279,
      "step": 275
    },
    {
      "epoch": 1.5544041450777202,
      "grad_norm": 0.2374938428401947,
      "learning_rate": 0.00019717395865528602,
      "loss": 0.6398,
      "step": 300
    },
    {
      "epoch": 1.6839378238341969,
      "grad_norm": 0.28610342741012573,
      "learning_rate": 0.0001964757889837296,
      "loss": 0.6099,
      "step": 325
    },
    {
      "epoch": 1.8134715025906736,
      "grad_norm": 0.28658708930015564,
      "learning_rate": 0.00019570214909818466,
      "loss": 0.6368,
      "step": 350
    },
    {
      "epoch": 1.9430051813471503,
      "grad_norm": 0.2628714144229889,
      "learning_rate": 0.00019485364419471454,
      "loss": 0.6103,
      "step": 375
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.664602518081665,
      "eval_runtime": 148.2412,
      "eval_samples_per_second": 5.187,
      "eval_steps_per_second": 5.187,
      "step": 386
    },
    {
      "epoch": 2.0725388601036268,
      "grad_norm": 0.2984038293361664,
      "learning_rate": 0.00019393093803411686,
      "loss": 0.6165,
      "step": 400
    },
    {
      "epoch": 2.2020725388601035,
      "grad_norm": 0.28801971673965454,
      "learning_rate": 0.00019293475242268223,
      "loss": 0.5695,
      "step": 425
    },
    {
      "epoch": 2.33160621761658,
      "grad_norm": 0.28850293159484863,
      "learning_rate": 0.0001918658666475465,
      "loss": 0.6042,
      "step": 450
    },
    {
      "epoch": 2.461139896373057,
      "grad_norm": 0.27677932381629944,
      "learning_rate": 0.00019072511686707663,
      "loss": 0.5526,
      "step": 475
    },
    {
      "epoch": 2.5906735751295336,
      "grad_norm": 0.2878665626049042,
      "learning_rate": 0.00018951339545676866,
      "loss": 0.6265,
      "step": 500
    },
    {
      "epoch": 2.7202072538860103,
      "grad_norm": 0.3099275827407837,
      "learning_rate": 0.0001882316503111678,
      "loss": 0.5619,
      "step": 525
    },
    {
      "epoch": 2.849740932642487,
      "grad_norm": 0.2974199950695038,
      "learning_rate": 0.00018688088410235833,
      "loss": 0.6182,
      "step": 550
    },
    {
      "epoch": 2.9792746113989637,
      "grad_norm": 0.32090824842453003,
      "learning_rate": 0.00018546215349560203,
      "loss": 0.5655,
      "step": 575
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6436254382133484,
      "eval_runtime": 147.7043,
      "eval_samples_per_second": 5.206,
      "eval_steps_per_second": 5.206,
      "step": 579
    },
    {
      "epoch": 3.1088082901554404,
      "grad_norm": 0.31077149510383606,
      "learning_rate": 0.0001839765683227398,
      "loss": 0.5948,
      "step": 600
    },
    {
      "epoch": 3.238341968911917,
      "grad_norm": 0.3116118311882019,
      "learning_rate": 0.00018242529071400214,
      "loss": 0.5275,
      "step": 625
    },
    {
      "epoch": 3.3678756476683938,
      "grad_norm": 0.306938499212265,
      "learning_rate": 0.00018080953418890853,
      "loss": 0.5821,
      "step": 650
    },
    {
      "epoch": 3.4974093264248705,
      "grad_norm": 0.3922148644924164,
      "learning_rate": 0.0001791305627069662,
      "loss": 0.5217,
      "step": 675
    },
    {
      "epoch": 3.626943005181347,
      "grad_norm": 0.2834595739841461,
      "learning_rate": 0.0001773896896789112,
      "loss": 0.5862,
      "step": 700
    },
    {
      "epoch": 3.756476683937824,
      "grad_norm": 0.43304821848869324,
      "learning_rate": 0.00017558827693926534,
      "loss": 0.5389,
      "step": 725
    },
    {
      "epoch": 3.8860103626943006,
      "grad_norm": 0.3097042441368103,
      "learning_rate": 0.0001737277336810124,
      "loss": 0.5864,
      "step": 750
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.626248300075531,
      "eval_runtime": 147.7729,
      "eval_samples_per_second": 5.204,
      "eval_steps_per_second": 5.204,
      "step": 772
    },
    {
      "epoch": 4.015544041450777,
      "grad_norm": 0.35964006185531616,
      "learning_rate": 0.0001718095153532274,
      "loss": 0.5309,
      "step": 775
    },
    {
      "epoch": 4.1450777202072535,
      "grad_norm": 0.33849701285362244,
      "learning_rate": 0.00016983512252252085,
      "loss": 0.5344,
      "step": 800
    },
    {
      "epoch": 4.274611398963731,
      "grad_norm": 0.3457067012786865,
      "learning_rate": 0.0001678060996991891,
      "loss": 0.5188,
      "step": 825
    },
    {
      "epoch": 4.404145077720207,
      "grad_norm": 0.3100905418395996,
      "learning_rate": 0.00016572403412898855,
      "loss": 0.5295,
      "step": 850
    },
    {
      "epoch": 4.533678756476684,
      "grad_norm": 0.304583340883255,
      "learning_rate": 0.0001635905545514795,
      "loss": 0.5282,
      "step": 875
    },
    {
      "epoch": 4.66321243523316,
      "grad_norm": 0.2808663547039032,
      "learning_rate": 0.0001614073299259101,
      "loss": 0.5324,
      "step": 900
    },
    {
      "epoch": 4.7927461139896375,
      "grad_norm": 0.27176326513290405,
      "learning_rate": 0.0001591760681256382,
      "loss": 0.5339,
      "step": 925
    },
    {
      "epoch": 4.922279792746114,
      "grad_norm": 0.3172021508216858,
      "learning_rate": 0.00015689851460211126,
      "loss": 0.5304,
      "step": 950
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6172037124633789,
      "eval_runtime": 149.234,
      "eval_samples_per_second": 5.153,
      "eval_steps_per_second": 5.153,
      "step": 965
    },
    {
      "epoch": 5.051813471502591,
      "grad_norm": 0.2755216956138611,
      "learning_rate": 0.00015457645101945046,
      "loss": 0.5176,
      "step": 975
    },
    {
      "epoch": 5.181347150259067,
      "grad_norm": 0.3580726683139801,
      "learning_rate": 0.00015221169386070636,
      "loss": 0.4819,
      "step": 1000
    },
    {
      "epoch": 5.310880829015544,
      "grad_norm": 0.26382988691329956,
      "learning_rate": 0.00014980609300687683,
      "loss": 0.5085,
      "step": 1025
    },
    {
      "epoch": 5.4404145077720205,
      "grad_norm": 0.3366776704788208,
      "learning_rate": 0.00014736153028979893,
      "loss": 0.4843,
      "step": 1050
    },
    {
      "epoch": 5.569948186528498,
      "grad_norm": 0.2824583649635315,
      "learning_rate": 0.00014487991802004623,
      "loss": 0.5198,
      "step": 1075
    },
    {
      "epoch": 5.699481865284974,
      "grad_norm": 0.3229568600654602,
      "learning_rate": 0.00014236319749098367,
      "loss": 0.4893,
      "step": 1100
    },
    {
      "epoch": 5.829015544041451,
      "grad_norm": 0.2902766466140747,
      "learning_rate": 0.0001398133374601501,
      "loss": 0.5189,
      "step": 1125
    },
    {
      "epoch": 5.958549222797927,
      "grad_norm": 0.37515705823898315,
      "learning_rate": 0.0001372323326091563,
      "loss": 0.4826,
      "step": 1150
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6199478507041931,
      "eval_runtime": 148.4001,
      "eval_samples_per_second": 5.182,
      "eval_steps_per_second": 5.182,
      "step": 1158
    },
    {
      "epoch": 6.0880829015544045,
      "grad_norm": 0.29334157705307007,
      "learning_rate": 0.00013462220198330328,
      "loss": 0.5217,
      "step": 1175
    },
    {
      "epoch": 6.217616580310881,
      "grad_norm": 0.3587939739227295,
      "learning_rate": 0.00013198498741214166,
      "loss": 0.4443,
      "step": 1200
    },
    {
      "epoch": 6.347150259067358,
      "grad_norm": 0.3157407343387604,
      "learning_rate": 0.00012932275191220776,
      "loss": 0.4905,
      "step": 1225
    },
    {
      "epoch": 6.476683937823834,
      "grad_norm": 0.4205420911312103,
      "learning_rate": 0.00012663757807318521,
      "loss": 0.4459,
      "step": 1250
    },
    {
      "epoch": 6.606217616580311,
      "grad_norm": 0.3237156867980957,
      "learning_rate": 0.0001239315664287558,
      "loss": 0.5129,
      "step": 1275
    },
    {
      "epoch": 6.7357512953367875,
      "grad_norm": 0.3968808054924011,
      "learning_rate": 0.00012120683381341247,
      "loss": 0.4516,
      "step": 1300
    },
    {
      "epoch": 6.865284974093264,
      "grad_norm": 0.31704652309417725,
      "learning_rate": 0.00011846551170652127,
      "loss": 0.4983,
      "step": 1325
    },
    {
      "epoch": 6.994818652849741,
      "grad_norm": 0.4564906656742096,
      "learning_rate": 0.00011570974456492678,
      "loss": 0.4497,
      "step": 1350
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.617435872554779,
      "eval_runtime": 147.9037,
      "eval_samples_per_second": 5.199,
      "eval_steps_per_second": 5.199,
      "step": 1351
    },
    {
      "epoch": 7.124352331606218,
      "grad_norm": 0.3469628393650055,
      "learning_rate": 0.00011294168814540553,
      "loss": 0.4709,
      "step": 1375
    },
    {
      "epoch": 7.253886010362694,
      "grad_norm": 0.3799530565738678,
      "learning_rate": 0.00011016350781828019,
      "loss": 0.4127,
      "step": 1400
    },
    {
      "epoch": 7.383419689119171,
      "grad_norm": 0.37229061126708984,
      "learning_rate": 0.00010737737687351284,
      "loss": 0.4716,
      "step": 1425
    },
    {
      "epoch": 7.512953367875648,
      "grad_norm": 0.47433385252952576,
      "learning_rate": 0.00010458547482060341,
      "loss": 0.435,
      "step": 1450
    },
    {
      "epoch": 7.642487046632124,
      "grad_norm": 0.36780059337615967,
      "learning_rate": 0.00010178998568362243,
      "loss": 0.466,
      "step": 1475
    },
    {
      "epoch": 7.772020725388601,
      "grad_norm": 0.40811479091644287,
      "learning_rate": 9.899309629271246e-05,
      "loss": 0.4434,
      "step": 1500
    },
    {
      "epoch": 7.901554404145077,
      "grad_norm": 0.3312036097049713,
      "learning_rate": 9.619699457339405e-05,
      "loss": 0.4695,
      "step": 1525
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.6271383762359619,
      "eval_runtime": 147.9764,
      "eval_samples_per_second": 5.197,
      "eval_steps_per_second": 5.197,
      "step": 1544
    },
    {
      "epoch": 8.031088082901555,
      "grad_norm": 0.3682107925415039,
      "learning_rate": 9.340386783501507e-05,
      "loss": 0.4655,
      "step": 1550
    },
    {
      "epoch": 8.160621761658032,
      "grad_norm": 0.39643922448158264,
      "learning_rate": 9.061590105968208e-05,
      "loss": 0.4234,
      "step": 1575
    },
    {
      "epoch": 8.290155440414507,
      "grad_norm": 0.4110065996646881,
      "learning_rate": 8.783527519301204e-05,
      "loss": 0.4334,
      "step": 1600
    },
    {
      "epoch": 8.419689119170984,
      "grad_norm": 0.414842814207077,
      "learning_rate": 8.506416543804182e-05,
      "loss": 0.4204,
      "step": 1625
    },
    {
      "epoch": 8.549222797927461,
      "grad_norm": 0.4210236966609955,
      "learning_rate": 8.23047395536298e-05,
      "loss": 0.4396,
      "step": 1650
    },
    {
      "epoch": 8.678756476683938,
      "grad_norm": 0.39927294850349426,
      "learning_rate": 7.955915615868111e-05,
      "loss": 0.421,
      "step": 1675
    },
    {
      "epoch": 8.808290155440414,
      "grad_norm": 0.4014557898044586,
      "learning_rate": 7.682956304352243e-05,
      "loss": 0.4358,
      "step": 1700
    },
    {
      "epoch": 8.937823834196891,
      "grad_norm": 0.4151593744754791,
      "learning_rate": 7.411809548974792e-05,
      "loss": 0.421,
      "step": 1725
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6414166688919067,
      "eval_runtime": 148.1933,
      "eval_samples_per_second": 5.189,
      "eval_steps_per_second": 5.189,
      "step": 1737
    },
    {
      "epoch": 9.067357512953368,
      "grad_norm": 0.38805437088012695,
      "learning_rate": 7.142687459985042e-05,
      "loss": 0.4247,
      "step": 1750
    },
    {
      "epoch": 9.196891191709845,
      "grad_norm": 0.40986549854278564,
      "learning_rate": 6.875800563794425e-05,
      "loss": 0.3904,
      "step": 1775
    },
    {
      "epoch": 9.32642487046632,
      "grad_norm": 0.4169498682022095,
      "learning_rate": 6.611357638287823e-05,
      "loss": 0.4213,
      "step": 1800
    },
    {
      "epoch": 9.455958549222798,
      "grad_norm": 0.43397319316864014,
      "learning_rate": 6.349565549502676e-05,
      "loss": 0.3943,
      "step": 1825
    },
    {
      "epoch": 9.585492227979275,
      "grad_norm": 0.41376927495002747,
      "learning_rate": 6.090629089803668e-05,
      "loss": 0.4337,
      "step": 1850
    },
    {
      "epoch": 9.715025906735752,
      "grad_norm": 0.46226975321769714,
      "learning_rate": 5.834750817679606e-05,
      "loss": 0.3838,
      "step": 1875
    },
    {
      "epoch": 9.844559585492227,
      "grad_norm": 0.41313913464546204,
      "learning_rate": 5.582130899287775e-05,
      "loss": 0.4312,
      "step": 1900
    },
    {
      "epoch": 9.974093264248705,
      "grad_norm": 0.49682819843292236,
      "learning_rate": 5.33296695186977e-05,
      "loss": 0.3835,
      "step": 1925
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6538968682289124,
      "eval_runtime": 148.1107,
      "eval_samples_per_second": 5.192,
      "eval_steps_per_second": 5.192,
      "step": 1930
    },
    {
      "epoch": 10.103626943005182,
      "grad_norm": 0.420999139547348,
      "learning_rate": 5.087453889161229e-05,
      "loss": 0.4209,
      "step": 1950
    },
    {
      "epoch": 10.233160621761659,
      "grad_norm": 0.44133618474006653,
      "learning_rate": 4.845783768916482e-05,
      "loss": 0.3633,
      "step": 1975
    },
    {
      "epoch": 10.362694300518134,
      "grad_norm": 0.4146338701248169,
      "learning_rate": 4.608145642667336e-05,
      "loss": 0.4254,
      "step": 2000
    },
    {
      "epoch": 10.492227979274611,
      "grad_norm": 0.46334806084632874,
      "learning_rate": 4.374725407833532e-05,
      "loss": 0.3687,
      "step": 2025
    },
    {
      "epoch": 10.621761658031089,
      "grad_norm": 0.43539902567863464,
      "learning_rate": 4.145705662300595e-05,
      "loss": 0.4181,
      "step": 2050
    },
    {
      "epoch": 10.751295336787564,
      "grad_norm": 0.3673839569091797,
      "learning_rate": 3.9212655615787804e-05,
      "loss": 0.3601,
      "step": 2075
    },
    {
      "epoch": 10.880829015544041,
      "grad_norm": 0.45795968174934387,
      "learning_rate": 3.701580678654925e-05,
      "loss": 0.4145,
      "step": 2100
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.6579700708389282,
      "eval_runtime": 147.8981,
      "eval_samples_per_second": 5.2,
      "eval_steps_per_second": 5.2,
      "step": 2123
    },
    {
      "epoch": 11.010362694300518,
      "grad_norm": 0.4589911699295044,
      "learning_rate": 3.4868228666467704e-05,
      "loss": 0.3782,
      "step": 2125
    },
    {
      "epoch": 11.139896373056995,
      "grad_norm": 0.4477919340133667,
      "learning_rate": 3.2771601243672825e-05,
      "loss": 0.3811,
      "step": 2150
    },
    {
      "epoch": 11.26943005181347,
      "grad_norm": 0.4809691905975342,
      "learning_rate": 3.072756464904006e-05,
      "loss": 0.3756,
      "step": 2175
    },
    {
      "epoch": 11.398963730569948,
      "grad_norm": 0.44053202867507935,
      "learning_rate": 2.8737717873164094e-05,
      "loss": 0.3858,
      "step": 2200
    },
    {
      "epoch": 11.528497409326425,
      "grad_norm": 0.467122346162796,
      "learning_rate": 2.68036175155147e-05,
      "loss": 0.3726,
      "step": 2225
    },
    {
      "epoch": 11.658031088082902,
      "grad_norm": 0.4791370630264282,
      "learning_rate": 2.492677656675414e-05,
      "loss": 0.3858,
      "step": 2250
    },
    {
      "epoch": 11.787564766839377,
      "grad_norm": 0.4714454710483551,
      "learning_rate": 2.3108663225168435e-05,
      "loss": 0.3842,
      "step": 2275
    },
    {
      "epoch": 11.917098445595855,
      "grad_norm": 0.45890840888023376,
      "learning_rate": 2.1350699748138326e-05,
      "loss": 0.3722,
      "step": 2300
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.6634961366653442,
      "eval_runtime": 154.3617,
      "eval_samples_per_second": 4.982,
      "eval_steps_per_second": 4.982,
      "step": 2316
    },
    {
      "epoch": 12.046632124352332,
      "grad_norm": 0.4432671368122101,
      "learning_rate": 1.965426133954854e-05,
      "loss": 0.3862,
      "step": 2325
    },
    {
      "epoch": 12.176165803108809,
      "grad_norm": 0.455422967672348,
      "learning_rate": 1.8020675074005723e-05,
      "loss": 0.3628,
      "step": 2350
    },
    {
      "epoch": 12.305699481865284,
      "grad_norm": 0.47231367230415344,
      "learning_rate": 1.6451218858706374e-05,
      "loss": 0.3785,
      "step": 2375
    },
    {
      "epoch": 12.435233160621761,
      "grad_norm": 0.4374043643474579,
      "learning_rate": 1.4947120433767047e-05,
      "loss": 0.3554,
      "step": 2400
    },
    {
      "epoch": 12.564766839378239,
      "grad_norm": 0.4621674120426178,
      "learning_rate": 1.350955641179893e-05,
      "loss": 0.3749,
      "step": 2425
    },
    {
      "epoch": 12.694300518134716,
      "grad_norm": 0.46616777777671814,
      "learning_rate": 1.2139651357477788e-05,
      "loss": 0.3508,
      "step": 2450
    },
    {
      "epoch": 12.823834196891191,
      "grad_norm": 0.4944767355918884,
      "learning_rate": 1.083847690782972e-05,
      "loss": 0.3953,
      "step": 2475
    },
    {
      "epoch": 12.953367875647668,
      "grad_norm": 0.47193339467048645,
      "learning_rate": 9.607050933920459e-06,
      "loss": 0.3517,
      "step": 2500
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.6687940359115601,
      "eval_runtime": 148.001,
      "eval_samples_per_second": 5.196,
      "eval_steps_per_second": 5.196,
      "step": 2509
    },
    {
      "epoch": 13.082901554404145,
      "grad_norm": 0.45401132106781006,
      "learning_rate": 8.446336744604378e-06,
      "loss": 0.3722,
      "step": 2525
    },
    {
      "epoch": 13.212435233160623,
      "grad_norm": 0.4674447178840637,
      "learning_rate": 7.357242332955916e-06,
      "loss": 0.3482,
      "step": 2550
    },
    {
      "epoch": 13.341968911917098,
      "grad_norm": 0.506443977355957,
      "learning_rate": 6.3406196659728465e-06,
      "loss": 0.3804,
      "step": 2575
    },
    {
      "epoch": 13.471502590673575,
      "grad_norm": 0.497322678565979,
      "learning_rate": 5.397264018107295e-06,
      "loss": 0.3353,
      "step": 2600
    },
    {
      "epoch": 13.601036269430052,
      "grad_norm": 0.5060560703277588,
      "learning_rate": 4.527913349145441e-06,
      "loss": 0.387,
      "step": 2625
    },
    {
      "epoch": 13.73056994818653,
      "grad_norm": 0.5467789173126221,
      "learning_rate": 3.733247726923039e-06,
      "loss": 0.3367,
      "step": 2650
    },
    {
      "epoch": 13.860103626943005,
      "grad_norm": 0.4839702546596527,
      "learning_rate": 3.013888795328057e-06,
      "loss": 0.3892,
      "step": 2675
    },
    {
      "epoch": 13.989637305699482,
      "grad_norm": 0.5471124053001404,
      "learning_rate": 2.3703992880066638e-06,
      "loss": 0.3449,
      "step": 2700
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.6729004383087158,
      "eval_runtime": 147.9157,
      "eval_samples_per_second": 5.199,
      "eval_steps_per_second": 5.199,
      "step": 2702
    },
    {
      "epoch": 14.119170984455959,
      "grad_norm": 0.5118899941444397,
      "learning_rate": 1.8032825881530213e-06,
      "loss": 0.3746,
      "step": 2725
    },
    {
      "epoch": 14.248704663212436,
      "grad_norm": 0.5852957963943481,
      "learning_rate": 1.3129823347271753e-06,
      "loss": 0.3406,
      "step": 2750
    },
    {
      "epoch": 14.378238341968911,
      "grad_norm": 0.4527933895587921,
      "learning_rate": 8.998820754091531e-07,
      "loss": 0.3817,
      "step": 2775
    },
    {
      "epoch": 14.507772020725389,
      "grad_norm": 0.4878605008125305,
      "learning_rate": 5.643049665607691e-07,
      "loss": 0.347,
      "step": 2800
    },
    {
      "epoch": 14.637305699481866,
      "grad_norm": 0.4865879416465759,
      "learning_rate": 3.065135204296965e-07,
      "loss": 0.371,
      "step": 2825
    },
    {
      "epoch": 14.766839378238341,
      "grad_norm": 0.5028488039970398,
      "learning_rate": 1.2670939979384512e-07,
      "loss": 0.3511,
      "step": 2850
    },
    {
      "epoch": 14.896373056994818,
      "grad_norm": 0.46494436264038086,
      "learning_rate": 2.5033260206275277e-08,
      "loss": 0.3687,
      "step": 2875
    }
  ],
  "logging_steps": 25,
  "max_steps": 2895,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.476411653654528e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
