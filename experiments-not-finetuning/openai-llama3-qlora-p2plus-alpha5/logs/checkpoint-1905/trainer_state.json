{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1905,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 0.38603177666664124,
      "learning_rate": 8.620689655172413e-05,
      "loss": 2.3759,
      "step": 25
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.3529539108276367,
      "learning_rate": 0.00017241379310344826,
      "loss": 1.894,
      "step": 50
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.30116939544677734,
      "learning_rate": 0.00019995819737621894,
      "loss": 1.5348,
      "step": 75
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 0.27587729692459106,
      "learning_rate": 0.00019974493560924895,
      "loss": 1.4391,
      "step": 100
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.386388897895813,
      "learning_rate": 0.00019935134242983634,
      "loss": 1.3948,
      "step": 125
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4089380502700806,
      "eval_runtime": 109.124,
      "eval_samples_per_second": 4.619,
      "eval_steps_per_second": 4.619,
      "step": 127
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.3226035237312317,
      "learning_rate": 0.00019877812942512617,
      "loss": 1.3888,
      "step": 150
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.32778000831604004,
      "learning_rate": 0.00019802633292152584,
      "loss": 1.379,
      "step": 175
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.3397336006164551,
      "learning_rate": 0.0001970973121111039,
      "loss": 1.3485,
      "step": 200
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.3733472526073456,
      "learning_rate": 0.00019599274659427228,
      "loss": 1.3551,
      "step": 225
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.3606921434402466,
      "learning_rate": 0.0001947146333431937,
      "loss": 1.331,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.3747279644012451,
      "eval_runtime": 109.1735,
      "eval_samples_per_second": 4.617,
      "eval_steps_per_second": 4.617,
      "step": 254
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.2988848090171814,
      "learning_rate": 0.00019326528309140478,
      "loss": 1.3409,
      "step": 275
    },
    {
      "epoch": 2.362204724409449,
      "grad_norm": 0.33031752705574036,
      "learning_rate": 0.00019164731615618226,
      "loss": 1.331,
      "step": 300
    },
    {
      "epoch": 2.559055118110236,
      "grad_norm": 0.3245493471622467,
      "learning_rate": 0.00018986365770120412,
      "loss": 1.3074,
      "step": 325
    },
    {
      "epoch": 2.7559055118110236,
      "grad_norm": 0.4678167700767517,
      "learning_rate": 0.00018791753244807184,
      "loss": 1.3059,
      "step": 350
    },
    {
      "epoch": 2.952755905511811,
      "grad_norm": 0.3282783627510071,
      "learning_rate": 0.00018581245884625406,
      "loss": 1.3008,
      "step": 375
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.356464147567749,
      "eval_runtime": 109.2557,
      "eval_samples_per_second": 4.613,
      "eval_steps_per_second": 4.613,
      "step": 381
    },
    {
      "epoch": 3.1496062992125986,
      "grad_norm": 0.36695390939712524,
      "learning_rate": 0.00018355224271199188,
      "loss": 1.3124,
      "step": 400
    },
    {
      "epoch": 3.3464566929133857,
      "grad_norm": 0.3822838366031647,
      "learning_rate": 0.00018114097034766674,
      "loss": 1.2808,
      "step": 425
    },
    {
      "epoch": 3.543307086614173,
      "grad_norm": 0.31401509046554565,
      "learning_rate": 0.00017858300115407015,
      "loss": 1.281,
      "step": 450
    },
    {
      "epoch": 3.7401574803149606,
      "grad_norm": 0.29952865839004517,
      "learning_rate": 0.0001758829597489318,
      "loss": 1.2581,
      "step": 475
    },
    {
      "epoch": 3.937007874015748,
      "grad_norm": 0.37979164719581604,
      "learning_rate": 0.00017304572760595528,
      "loss": 1.2771,
      "step": 500
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.348704218864441,
      "eval_runtime": 109.3176,
      "eval_samples_per_second": 4.61,
      "eval_steps_per_second": 4.61,
      "step": 508
    },
    {
      "epoch": 4.133858267716535,
      "grad_norm": 0.40780550241470337,
      "learning_rate": 0.00017007643422947726,
      "loss": 1.2729,
      "step": 525
    },
    {
      "epoch": 4.330708661417323,
      "grad_norm": 0.33063989877700806,
      "learning_rate": 0.00016698044788070592,
      "loss": 1.2378,
      "step": 550
    },
    {
      "epoch": 4.52755905511811,
      "grad_norm": 0.4419792592525482,
      "learning_rate": 0.0001637633658723044,
      "loss": 1.2516,
      "step": 575
    },
    {
      "epoch": 4.724409448818898,
      "grad_norm": 0.42518293857574463,
      "learning_rate": 0.00016043100444886673,
      "loss": 1.2312,
      "step": 600
    },
    {
      "epoch": 4.921259842519685,
      "grad_norm": 0.3729265630245209,
      "learning_rate": 0.00015698938827158089,
      "loss": 1.2584,
      "step": 625
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.3457038402557373,
      "eval_runtime": 108.3243,
      "eval_samples_per_second": 4.653,
      "eval_steps_per_second": 4.653,
      "step": 635
    },
    {
      "epoch": 5.118110236220472,
      "grad_norm": 0.35440343618392944,
      "learning_rate": 0.00015344473952609005,
      "loss": 1.2362,
      "step": 650
    },
    {
      "epoch": 5.31496062992126,
      "grad_norm": 0.34677577018737793,
      "learning_rate": 0.00014980346667324484,
      "loss": 1.2092,
      "step": 675
    },
    {
      "epoch": 5.511811023622047,
      "grad_norm": 0.471497118473053,
      "learning_rate": 0.00014607215286308316,
      "loss": 1.1976,
      "step": 700
    },
    {
      "epoch": 5.708661417322834,
      "grad_norm": 0.4087774455547333,
      "learning_rate": 0.00014225754403298556,
      "loss": 1.2141,
      "step": 725
    },
    {
      "epoch": 5.905511811023622,
      "grad_norm": 0.40991494059562683,
      "learning_rate": 0.00013836653671152322,
      "loss": 1.2362,
      "step": 750
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3472098112106323,
      "eval_runtime": 109.1388,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 762
    },
    {
      "epoch": 6.102362204724409,
      "grad_norm": 0.35219329595565796,
      "learning_rate": 0.00013440616555004768,
      "loss": 1.2101,
      "step": 775
    },
    {
      "epoch": 6.299212598425197,
      "grad_norm": 0.36927810311317444,
      "learning_rate": 0.00013038359060456572,
      "loss": 1.1766,
      "step": 800
    },
    {
      "epoch": 6.496062992125984,
      "grad_norm": 0.344516783952713,
      "learning_rate": 0.0001263060843908912,
      "loss": 1.1584,
      "step": 825
    },
    {
      "epoch": 6.692913385826771,
      "grad_norm": 0.44102948904037476,
      "learning_rate": 0.00012218101873647842,
      "loss": 1.1961,
      "step": 850
    },
    {
      "epoch": 6.889763779527559,
      "grad_norm": 0.43443551659584045,
      "learning_rate": 0.00011801585145270741,
      "loss": 1.2052,
      "step": 875
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.3406087160110474,
      "eval_runtime": 109.148,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 889
    },
    {
      "epoch": 7.086614173228346,
      "grad_norm": 0.3969421088695526,
      "learning_rate": 0.00011381811285171633,
      "loss": 1.1731,
      "step": 900
    },
    {
      "epoch": 7.283464566929134,
      "grad_norm": 0.42686161398887634,
      "learning_rate": 0.00010959539213215832,
      "loss": 1.1452,
      "step": 925
    },
    {
      "epoch": 7.480314960629921,
      "grad_norm": 0.5223325490951538,
      "learning_rate": 0.00010535532365849566,
      "loss": 1.1394,
      "step": 950
    },
    {
      "epoch": 7.677165354330708,
      "grad_norm": 0.47308650612831116,
      "learning_rate": 0.00010110557315863762,
      "loss": 1.1844,
      "step": 975
    },
    {
      "epoch": 7.874015748031496,
      "grad_norm": 0.41156482696533203,
      "learning_rate": 9.685382386487555e-05,
      "loss": 1.1823,
      "step": 1000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.3513624668121338,
      "eval_runtime": 109.1143,
      "eval_samples_per_second": 4.619,
      "eval_steps_per_second": 4.619,
      "step": 1016
    },
    {
      "epoch": 8.070866141732283,
      "grad_norm": 0.3830866813659668,
      "learning_rate": 9.260776262317117e-05,
      "loss": 1.1328,
      "step": 1025
    },
    {
      "epoch": 8.26771653543307,
      "grad_norm": 0.48258769512176514,
      "learning_rate": 8.837506599591198e-05,
      "loss": 1.1134,
      "step": 1050
    },
    {
      "epoch": 8.464566929133857,
      "grad_norm": 0.5119547247886658,
      "learning_rate": 8.416338638325815e-05,
      "loss": 1.134,
      "step": 1075
    },
    {
      "epoch": 8.661417322834646,
      "grad_norm": 0.4679983854293823,
      "learning_rate": 7.998033818817327e-05,
      "loss": 1.1434,
      "step": 1100
    },
    {
      "epoch": 8.858267716535433,
      "grad_norm": 0.4541342556476593,
      "learning_rate": 7.583348405015099e-05,
      "loss": 1.1458,
      "step": 1125
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.3600410223007202,
      "eval_runtime": 109.2086,
      "eval_samples_per_second": 4.615,
      "eval_steps_per_second": 4.615,
      "step": 1143
    },
    {
      "epoch": 9.05511811023622,
      "grad_norm": 0.4152553975582123,
      "learning_rate": 7.173032117252643e-05,
      "loss": 1.1184,
      "step": 1150
    },
    {
      "epoch": 9.251968503937007,
      "grad_norm": 0.407947301864624,
      "learning_rate": 6.767826776809085e-05,
      "loss": 1.0869,
      "step": 1175
    },
    {
      "epoch": 9.448818897637794,
      "grad_norm": 0.530610978603363,
      "learning_rate": 6.368464964751575e-05,
      "loss": 1.1248,
      "step": 1200
    },
    {
      "epoch": 9.645669291338583,
      "grad_norm": 0.49058032035827637,
      "learning_rate": 5.9756686974832985e-05,
      "loss": 1.1172,
      "step": 1225
    },
    {
      "epoch": 9.84251968503937,
      "grad_norm": 0.5017526745796204,
      "learning_rate": 5.590148121391594e-05,
      "loss": 1.1245,
      "step": 1250
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.372198224067688,
      "eval_runtime": 110.1574,
      "eval_samples_per_second": 4.575,
      "eval_steps_per_second": 4.575,
      "step": 1270
    },
    {
      "epoch": 10.039370078740157,
      "grad_norm": 0.48262345790863037,
      "learning_rate": 5.212600228956207e-05,
      "loss": 1.0875,
      "step": 1275
    },
    {
      "epoch": 10.236220472440944,
      "grad_norm": 0.6069486737251282,
      "learning_rate": 4.843707598638806e-05,
      "loss": 1.0652,
      "step": 1300
    },
    {
      "epoch": 10.433070866141732,
      "grad_norm": 0.5270913243293762,
      "learning_rate": 4.484137160831988e-05,
      "loss": 1.1117,
      "step": 1325
    },
    {
      "epoch": 10.62992125984252,
      "grad_norm": 0.48516637086868286,
      "learning_rate": 4.134538992098798e-05,
      "loss": 1.1028,
      "step": 1350
    },
    {
      "epoch": 10.826771653543307,
      "grad_norm": 0.5164074897766113,
      "learning_rate": 3.7955451398827434e-05,
      "loss": 1.0912,
      "step": 1375
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.3721227645874023,
      "eval_runtime": 109.1521,
      "eval_samples_per_second": 4.617,
      "eval_steps_per_second": 4.617,
      "step": 1397
    },
    {
      "epoch": 11.023622047244094,
      "grad_norm": 0.49936607480049133,
      "learning_rate": 3.467768479813116e-05,
      "loss": 1.0825,
      "step": 1400
    },
    {
      "epoch": 11.220472440944881,
      "grad_norm": 0.5462387800216675,
      "learning_rate": 3.151801607671495e-05,
      "loss": 1.0641,
      "step": 1425
    },
    {
      "epoch": 11.417322834645669,
      "grad_norm": 0.5413402318954468,
      "learning_rate": 2.8482157680227307e-05,
      "loss": 1.0978,
      "step": 1450
    },
    {
      "epoch": 11.614173228346457,
      "grad_norm": 0.5372833609580994,
      "learning_rate": 2.5575598214473317e-05,
      "loss": 1.0934,
      "step": 1475
    },
    {
      "epoch": 11.811023622047244,
      "grad_norm": 0.5079541206359863,
      "learning_rate": 2.2803592522424322e-05,
      "loss": 1.0757,
      "step": 1500
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.3769429922103882,
      "eval_runtime": 109.1475,
      "eval_samples_per_second": 4.618,
      "eval_steps_per_second": 4.618,
      "step": 1524
    },
    {
      "epoch": 12.007874015748031,
      "grad_norm": 0.4172382950782776,
      "learning_rate": 2.017115218385318e-05,
      "loss": 1.0414,
      "step": 1525
    },
    {
      "epoch": 12.204724409448819,
      "grad_norm": 0.5837513208389282,
      "learning_rate": 1.7683036454771463e-05,
      "loss": 1.0788,
      "step": 1550
    },
    {
      "epoch": 12.401574803149606,
      "grad_norm": 0.536068320274353,
      "learning_rate": 1.534374366304926e-05,
      "loss": 1.074,
      "step": 1575
    },
    {
      "epoch": 12.598425196850394,
      "grad_norm": 0.5267623662948608,
      "learning_rate": 1.3157503075773359e-05,
      "loss": 1.0749,
      "step": 1600
    },
    {
      "epoch": 12.795275590551181,
      "grad_norm": 0.5096085071563721,
      "learning_rate": 1.112826725304752e-05,
      "loss": 1.0659,
      "step": 1625
    },
    {
      "epoch": 12.992125984251969,
      "grad_norm": 0.545080840587616,
      "learning_rate": 9.25970490205832e-06,
      "loss": 1.0404,
      "step": 1650
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.3762263059616089,
      "eval_runtime": 109.1115,
      "eval_samples_per_second": 4.619,
      "eval_steps_per_second": 4.619,
      "step": 1651
    },
    {
      "epoch": 13.188976377952756,
      "grad_norm": 0.5715623497962952,
      "learning_rate": 7.555194244325792e-06,
      "loss": 1.0916,
      "step": 1675
    },
    {
      "epoch": 13.385826771653543,
      "grad_norm": 0.5192654132843018,
      "learning_rate": 6.0178169081306575e-06,
      "loss": 1.0628,
      "step": 1700
    },
    {
      "epoch": 13.582677165354331,
      "grad_norm": 0.5554351210594177,
      "learning_rate": 4.650352357159982e-06,
      "loss": 1.0583,
      "step": 1725
    },
    {
      "epoch": 13.779527559055119,
      "grad_norm": 0.49488332867622375,
      "learning_rate": 3.455272865443859e-06,
      "loss": 1.0488,
      "step": 1750
    },
    {
      "epoch": 13.976377952755906,
      "grad_norm": 0.6636049747467041,
      "learning_rate": 2.4347390476682108e-06,
      "loss": 1.0394,
      "step": 1775
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.3790998458862305,
      "eval_runtime": 109.201,
      "eval_samples_per_second": 4.615,
      "eval_steps_per_second": 4.615,
      "step": 1778
    },
    {
      "epoch": 14.173228346456693,
      "grad_norm": 0.5523813962936401,
      "learning_rate": 1.5905959529443625e-06,
      "loss": 1.0946,
      "step": 1800
    },
    {
      "epoch": 14.37007874015748,
      "grad_norm": 0.522930383682251,
      "learning_rate": 9.243697290977071e-07,
      "loss": 1.0646,
      "step": 1825
    },
    {
      "epoch": 14.566929133858268,
      "grad_norm": 0.5058735609054565,
      "learning_rate": 4.372648635061705e-07,
      "loss": 1.0615,
      "step": 1850
    },
    {
      "epoch": 14.763779527559056,
      "grad_norm": 0.5018670558929443,
      "learning_rate": 1.3016200547674163e-07,
      "loss": 1.045,
      "step": 1875
    },
    {
      "epoch": 14.960629921259843,
      "grad_norm": 0.5647022724151611,
      "learning_rate": 3.616374097148434e-09,
      "loss": 1.0375,
      "step": 1900
    }
  ],
  "logging_steps": 25,
  "max_steps": 1905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.790018901499904e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
