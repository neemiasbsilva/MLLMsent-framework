{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1260,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 0.3866257965564728,
      "learning_rate": 0.00013157894736842108,
      "loss": 1.8831,
      "step": 25
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 0.264177143573761,
      "learning_rate": 0.0001999524166093866,
      "loss": 1.0483,
      "step": 50
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.38655027747154236,
      "learning_rate": 0.00019954793248829695,
      "loss": 0.7541,
      "step": 75
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.689446210861206,
      "eval_runtime": 36.3107,
      "eval_samples_per_second": 9.226,
      "eval_steps_per_second": 9.226,
      "step": 84
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.27037057280540466,
      "learning_rate": 0.00019873237428991907,
      "loss": 0.6621,
      "step": 100
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 0.2777184247970581,
      "learning_rate": 0.000197509109787199,
      "loss": 0.6326,
      "step": 125
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.39316326379776,
      "learning_rate": 0.00019588319033895623,
      "loss": 0.6352,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6228572130203247,
      "eval_runtime": 36.3152,
      "eval_samples_per_second": 9.225,
      "eval_steps_per_second": 9.225,
      "step": 168
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 0.2744430899620056,
      "learning_rate": 0.00019386133003075967,
      "loss": 0.6226,
      "step": 175
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.27007970213890076,
      "learning_rate": 0.00019145187794972565,
      "loss": 0.5893,
      "step": 200
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.29582005739212036,
      "learning_rate": 0.0001886647837077268,
      "loss": 0.5869,
      "step": 225
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 0.3205775022506714,
      "learning_rate": 0.0001855115563553803,
      "loss": 0.5745,
      "step": 250
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6025882363319397,
      "eval_runtime": 36.3369,
      "eval_samples_per_second": 9.219,
      "eval_steps_per_second": 9.219,
      "step": 252
    },
    {
      "epoch": 3.2738095238095237,
      "grad_norm": 0.4355872571468353,
      "learning_rate": 0.00018200521685647663,
      "loss": 0.5492,
      "step": 275
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.32988297939300537,
      "learning_rate": 0.00017816024431910115,
      "loss": 0.56,
      "step": 300
    },
    {
      "epoch": 3.869047619047619,
      "grad_norm": 0.26785361766815186,
      "learning_rate": 0.0001739925162054823,
      "loss": 0.5487,
      "step": 325
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5937713384628296,
      "eval_runtime": 36.3291,
      "eval_samples_per_second": 9.221,
      "eval_steps_per_second": 9.221,
      "step": 336
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.3267258405685425,
      "learning_rate": 0.00016951924276746425,
      "loss": 0.5241,
      "step": 350
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.33408477902412415,
      "learning_rate": 0.00016475889597834695,
      "loss": 0.5139,
      "step": 375
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.35815781354904175,
      "learning_rate": 0.0001597311332545629,
      "loss": 0.5176,
      "step": 400
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.5914257168769836,
      "eval_runtime": 36.3374,
      "eval_samples_per_second": 9.219,
      "eval_steps_per_second": 9.219,
      "step": 420
    },
    {
      "epoch": 5.059523809523809,
      "grad_norm": 0.3175934851169586,
      "learning_rate": 0.00015445671628217466,
      "loss": 0.5254,
      "step": 425
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.3114653527736664,
      "learning_rate": 0.0001489574252833924,
      "loss": 0.4989,
      "step": 450
    },
    {
      "epoch": 5.654761904761905,
      "grad_norm": 0.35368359088897705,
      "learning_rate": 0.00014325596907713937,
      "loss": 0.4758,
      "step": 475
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.36813923716545105,
      "learning_rate": 0.00013737589130506246,
      "loss": 0.4825,
      "step": 500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.5938660502433777,
      "eval_runtime": 36.3311,
      "eval_samples_per_second": 9.221,
      "eval_steps_per_second": 9.221,
      "step": 504
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.5515438914299011,
      "learning_rate": 0.00013134147321021829,
      "loss": 0.4616,
      "step": 525
    },
    {
      "epoch": 6.5476190476190474,
      "grad_norm": 0.386706680059433,
      "learning_rate": 0.0001251776333699023,
      "loss": 0.4757,
      "step": 550
    },
    {
      "epoch": 6.845238095238095,
      "grad_norm": 0.40311312675476074,
      "learning_rate": 0.00011890982479666412,
      "loss": 0.4607,
      "step": 575
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.5961884260177612,
      "eval_runtime": 36.3462,
      "eval_samples_per_second": 9.217,
      "eval_steps_per_second": 9.217,
      "step": 588
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.3792864978313446,
      "learning_rate": 0.00011256392983242143,
      "loss": 0.4469,
      "step": 600
    },
    {
      "epoch": 7.440476190476191,
      "grad_norm": 0.38600584864616394,
      "learning_rate": 0.00010616615326969767,
      "loss": 0.4289,
      "step": 625
    },
    {
      "epoch": 7.738095238095238,
      "grad_norm": 0.45319435000419617,
      "learning_rate": 9.97429141413294e-05,
      "loss": 0.4317,
      "step": 650
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.604984700679779,
      "eval_runtime": 36.3539,
      "eval_samples_per_second": 9.215,
      "eval_steps_per_second": 9.215,
      "step": 672
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.43846699595451355,
      "learning_rate": 9.332073662548784e-05,
      "loss": 0.4396,
      "step": 675
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.4694174528121948,
      "learning_rate": 8.692614051651242e-05,
      "loss": 0.4116,
      "step": 700
    },
    {
      "epoch": 8.630952380952381,
      "grad_norm": 0.43596184253692627,
      "learning_rate": 8.058553171384699e-05,
      "loss": 0.4137,
      "step": 725
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.4590170085430145,
      "learning_rate": 7.43250931812945e-05,
      "loss": 0.4112,
      "step": 750
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.616240918636322,
      "eval_runtime": 36.3375,
      "eval_samples_per_second": 9.219,
      "eval_steps_per_second": 9.219,
      "step": 756
    },
    {
      "epoch": 9.226190476190476,
      "grad_norm": 0.5044163465499878,
      "learning_rate": 6.817067682686413e-05,
      "loss": 0.3815,
      "step": 775
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.5317159295082092,
      "learning_rate": 6.214769674968282e-05,
      "loss": 0.3959,
      "step": 800
    },
    {
      "epoch": 9.821428571428571,
      "grad_norm": 0.5203182101249695,
      "learning_rate": 5.6281024294798864e-05,
      "loss": 0.3985,
      "step": 825
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.6299980282783508,
      "eval_runtime": 36.4424,
      "eval_samples_per_second": 9.193,
      "eval_steps_per_second": 9.193,
      "step": 840
    },
    {
      "epoch": 10.119047619047619,
      "grad_norm": 0.46058642864227295,
      "learning_rate": 5.059488534923831e-05,
      "loss": 0.384,
      "step": 850
    },
    {
      "epoch": 10.416666666666666,
      "grad_norm": 0.5205210447311401,
      "learning_rate": 4.51127603034217e-05,
      "loss": 0.3677,
      "step": 875
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.46595677733421326,
      "learning_rate": 3.985728709104041e-05,
      "loss": 0.3681,
      "step": 900
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.6422709822654724,
      "eval_runtime": 36.4355,
      "eval_samples_per_second": 9.194,
      "eval_steps_per_second": 9.194,
      "step": 924
    },
    {
      "epoch": 11.011904761904763,
      "grad_norm": 0.4911142885684967,
      "learning_rate": 3.4850167707781256e-05,
      "loss": 0.377,
      "step": 925
    },
    {
      "epoch": 11.30952380952381,
      "grad_norm": 0.5118074417114258,
      "learning_rate": 3.011207859492131e-05,
      "loss": 0.3607,
      "step": 950
    },
    {
      "epoch": 11.607142857142858,
      "grad_norm": 0.5361130833625793,
      "learning_rate": 2.5662585257855775e-05,
      "loss": 0.3629,
      "step": 975
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 0.5312142968177795,
      "learning_rate": 2.1520061472133902e-05,
      "loss": 0.359,
      "step": 1000
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.6518315076828003,
      "eval_runtime": 36.4217,
      "eval_samples_per_second": 9.198,
      "eval_steps_per_second": 9.198,
      "step": 1008
    },
    {
      "epoch": 12.202380952380953,
      "grad_norm": 0.5472728610038757,
      "learning_rate": 1.7701613410634365e-05,
      "loss": 0.3514,
      "step": 1025
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.644987165927887,
      "learning_rate": 1.4223009005189792e-05,
      "loss": 0.3481,
      "step": 1050
    },
    {
      "epoch": 12.797619047619047,
      "grad_norm": 0.5463434457778931,
      "learning_rate": 1.1098612834355204e-05,
      "loss": 0.3594,
      "step": 1075
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.6645570397377014,
      "eval_runtime": 36.4275,
      "eval_samples_per_second": 9.196,
      "eval_steps_per_second": 9.196,
      "step": 1092
    },
    {
      "epoch": 13.095238095238095,
      "grad_norm": 0.4974524676799774,
      "learning_rate": 8.34132680619546e-06,
      "loss": 0.347,
      "step": 1100
    },
    {
      "epoch": 13.392857142857142,
      "grad_norm": 0.5680662989616394,
      "learning_rate": 5.962536881036507e-06,
      "loss": 0.345,
      "step": 1125
    },
    {
      "epoch": 13.69047619047619,
      "grad_norm": 0.5354349613189697,
      "learning_rate": 3.97206605418432e-06,
      "loss": 0.3445,
      "step": 1150
    },
    {
      "epoch": 13.988095238095237,
      "grad_norm": 0.5790510773658752,
      "learning_rate": 2.3781337927645585e-06,
      "loss": 0.337,
      "step": 1175
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.6683546304702759,
      "eval_runtime": 36.4462,
      "eval_samples_per_second": 9.192,
      "eval_steps_per_second": 9.192,
      "step": 1176
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.537237823009491,
      "learning_rate": 1.1873220941853502e-06,
      "loss": 0.3537,
      "step": 1200
    },
    {
      "epoch": 14.583333333333334,
      "grad_norm": 0.5138508677482605,
      "learning_rate": 4.045483063813471e-07,
      "loss": 0.3402,
      "step": 1225
    },
    {
      "epoch": 14.880952380952381,
      "grad_norm": 0.4943326711654663,
      "learning_rate": 3.304482207533433e-08,
      "loss": 0.3443,
      "step": 1250
    }
  ],
  "logging_steps": 25,
  "max_steps": 1260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1723101180329984e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
