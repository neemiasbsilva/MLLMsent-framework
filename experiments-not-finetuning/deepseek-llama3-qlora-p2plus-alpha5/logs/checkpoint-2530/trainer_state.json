{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2530,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09881422924901186,
      "grad_norm": 0.5384306907653809,
      "learning_rate": 6.578947368421054e-05,
      "loss": 1.317,
      "step": 25
    },
    {
      "epoch": 0.1976284584980237,
      "grad_norm": 1.0885577201843262,
      "learning_rate": 0.00013157894736842108,
      "loss": 1.9644,
      "step": 50
    },
    {
      "epoch": 0.2964426877470356,
      "grad_norm": 0.5368013381958008,
      "learning_rate": 0.00019736842105263157,
      "loss": 0.678,
      "step": 75
    },
    {
      "epoch": 0.3952569169960474,
      "grad_norm": 0.9468609690666199,
      "learning_rate": 0.00019995280359149149,
      "loss": 1.0727,
      "step": 100
    },
    {
      "epoch": 0.49407114624505927,
      "grad_norm": 0.4081272482872009,
      "learning_rate": 0.00019980331539108542,
      "loss": 0.6912,
      "step": 125
    },
    {
      "epoch": 0.5928853754940712,
      "grad_norm": 0.5217648148536682,
      "learning_rate": 0.00019955160656305604,
      "loss": 0.9328,
      "step": 150
    },
    {
      "epoch": 0.691699604743083,
      "grad_norm": 0.3866328001022339,
      "learning_rate": 0.00019919793491281069,
      "loss": 0.6071,
      "step": 175
    },
    {
      "epoch": 0.7905138339920948,
      "grad_norm": 0.5244994163513184,
      "learning_rate": 0.00019874266267819602,
      "loss": 0.9185,
      "step": 200
    },
    {
      "epoch": 0.8893280632411067,
      "grad_norm": 0.31008851528167725,
      "learning_rate": 0.00019818625615848664,
      "loss": 0.5577,
      "step": 225
    },
    {
      "epoch": 0.9881422924901185,
      "grad_norm": 0.562192440032959,
      "learning_rate": 0.00019752928523679143,
      "loss": 0.9122,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8430441617965698,
      "eval_runtime": 155.5178,
      "eval_samples_per_second": 3.247,
      "eval_steps_per_second": 3.247,
      "step": 253
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.34390541911125183,
      "learning_rate": 0.0001967724227963677,
      "loss": 0.5248,
      "step": 275
    },
    {
      "epoch": 1.1857707509881423,
      "grad_norm": 0.389151394367218,
      "learning_rate": 0.00019591644403143995,
      "loss": 0.9041,
      "step": 300
    },
    {
      "epoch": 1.2845849802371543,
      "grad_norm": 0.3720656633377075,
      "learning_rate": 0.00019496222565323015,
      "loss": 0.6069,
      "step": 325
    },
    {
      "epoch": 1.383399209486166,
      "grad_norm": 0.3967197835445404,
      "learning_rate": 0.00019391074499201154,
      "loss": 0.904,
      "step": 350
    },
    {
      "epoch": 1.4822134387351777,
      "grad_norm": 0.3293100595474243,
      "learning_rate": 0.000192763078996107,
      "loss": 0.5515,
      "step": 375
    },
    {
      "epoch": 1.5810276679841897,
      "grad_norm": 0.44084230065345764,
      "learning_rate": 0.00019152040312885604,
      "loss": 0.8921,
      "step": 400
    },
    {
      "epoch": 1.6798418972332017,
      "grad_norm": 0.3652501404285431,
      "learning_rate": 0.00019018399016468084,
      "loss": 0.5121,
      "step": 425
    },
    {
      "epoch": 1.7786561264822134,
      "grad_norm": 0.44430646300315857,
      "learning_rate": 0.00018875520888548438,
      "loss": 0.9158,
      "step": 450
    },
    {
      "epoch": 1.8774703557312253,
      "grad_norm": 0.3810444176197052,
      "learning_rate": 0.00018723552267871555,
      "loss": 0.4713,
      "step": 475
    },
    {
      "epoch": 1.9762845849802373,
      "grad_norm": 0.39230045676231384,
      "learning_rate": 0.0001856264880385372,
      "loss": 0.8939,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7757900357246399,
      "eval_runtime": 139.0332,
      "eval_samples_per_second": 3.632,
      "eval_steps_per_second": 3.632,
      "step": 506
    },
    {
      "epoch": 2.075098814229249,
      "grad_norm": 0.3941648006439209,
      "learning_rate": 0.0001839297529716327,
      "loss": 0.4523,
      "step": 525
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.3930986821651459,
      "learning_rate": 0.0001821470553092832,
      "loss": 0.8729,
      "step": 550
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 0.43796730041503906,
      "learning_rate": 0.00018028022092744482,
      "loss": 0.5009,
      "step": 575
    },
    {
      "epoch": 2.3715415019762847,
      "grad_norm": 0.4100843071937561,
      "learning_rate": 0.00017833116187664848,
      "loss": 0.888,
      "step": 600
    },
    {
      "epoch": 2.4703557312252964,
      "grad_norm": 0.41596513986587524,
      "learning_rate": 0.00017630187442363798,
      "loss": 0.455,
      "step": 625
    },
    {
      "epoch": 2.5691699604743086,
      "grad_norm": 0.45146337151527405,
      "learning_rate": 0.00017419443700675247,
      "loss": 0.8886,
      "step": 650
    },
    {
      "epoch": 2.6679841897233203,
      "grad_norm": 0.41658633947372437,
      "learning_rate": 0.0001720110081071465,
      "loss": 0.4658,
      "step": 675
    },
    {
      "epoch": 2.766798418972332,
      "grad_norm": 0.4442055821418762,
      "learning_rate": 0.00016975382403802878,
      "loss": 0.8588,
      "step": 700
    },
    {
      "epoch": 2.8656126482213438,
      "grad_norm": 0.40711790323257446,
      "learning_rate": 0.00016742519665418395,
      "loss": 0.4395,
      "step": 725
    },
    {
      "epoch": 2.9644268774703555,
      "grad_norm": 0.47062253952026367,
      "learning_rate": 0.00016502751098412282,
      "loss": 0.8973,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.7415651679039001,
      "eval_runtime": 112.6355,
      "eval_samples_per_second": 4.483,
      "eval_steps_per_second": 4.483,
      "step": 759
    },
    {
      "epoch": 3.0632411067193677,
      "grad_norm": 0.1545722782611847,
      "learning_rate": 0.0001625632227872865,
      "loss": 0.3782,
      "step": 775
    },
    {
      "epoch": 3.1620553359683794,
      "grad_norm": 0.5248509645462036,
      "learning_rate": 0.00016003485603880699,
      "loss": 0.8727,
      "step": 800
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 0.5685561895370483,
      "learning_rate": 0.00015744500034439902,
      "loss": 0.4276,
      "step": 825
    },
    {
      "epoch": 3.3596837944664033,
      "grad_norm": 0.46746739745140076,
      "learning_rate": 0.00015479630828803235,
      "loss": 0.8488,
      "step": 850
    },
    {
      "epoch": 3.458498023715415,
      "grad_norm": 0.5300218462944031,
      "learning_rate": 0.00015209149271510017,
      "loss": 0.4046,
      "step": 875
    },
    {
      "epoch": 3.5573122529644268,
      "grad_norm": 0.4986155331134796,
      "learning_rate": 0.00014933332395386653,
      "loss": 0.8632,
      "step": 900
    },
    {
      "epoch": 3.6561264822134385,
      "grad_norm": 0.5569835305213928,
      "learning_rate": 0.00014652462697803848,
      "loss": 0.4498,
      "step": 925
    },
    {
      "epoch": 3.7549407114624507,
      "grad_norm": 0.4924500584602356,
      "learning_rate": 0.00014366827851336963,
      "loss": 0.8475,
      "step": 950
    },
    {
      "epoch": 3.8537549407114624,
      "grad_norm": 0.09579239785671234,
      "learning_rate": 0.00014076720409125762,
      "loss": 0.3662,
      "step": 975
    },
    {
      "epoch": 3.9525691699604746,
      "grad_norm": 0.4528491795063019,
      "learning_rate": 0.0001378243750523543,
      "loss": 0.8534,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.7388968467712402,
      "eval_runtime": 112.6223,
      "eval_samples_per_second": 4.484,
      "eval_steps_per_second": 4.484,
      "step": 1012
    },
    {
      "epoch": 4.051383399209486,
      "grad_norm": 0.08514401316642761,
      "learning_rate": 0.00013484280550325693,
      "loss": 0.4051,
      "step": 1025
    },
    {
      "epoch": 4.150197628458498,
      "grad_norm": 0.47712597250938416,
      "learning_rate": 0.00013182554922939747,
      "loss": 0.7741,
      "step": 1050
    },
    {
      "epoch": 4.24901185770751,
      "grad_norm": 0.13017669320106506,
      "learning_rate": 0.00012877569656729243,
      "loss": 0.4052,
      "step": 1075
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.49725478887557983,
      "learning_rate": 0.0001256963712393558,
      "loss": 0.7824,
      "step": 1100
    },
    {
      "epoch": 4.446640316205533,
      "grad_norm": 0.10208587348461151,
      "learning_rate": 0.00012259072715451778,
      "loss": 0.3968,
      "step": 1125
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.4932892620563507,
      "learning_rate": 0.00011946194517792584,
      "loss": 0.8113,
      "step": 1150
    },
    {
      "epoch": 4.644268774703558,
      "grad_norm": 0.14989782869815826,
      "learning_rate": 0.0001163132298730365,
      "loss": 0.3982,
      "step": 1175
    },
    {
      "epoch": 4.743083003952569,
      "grad_norm": 0.4943813383579254,
      "learning_rate": 0.000113147806219435,
      "loss": 0.7514,
      "step": 1200
    },
    {
      "epoch": 4.841897233201581,
      "grad_norm": 0.11795687675476074,
      "learning_rate": 0.00010996891630974415,
      "loss": 0.4077,
      "step": 1225
    },
    {
      "epoch": 4.940711462450593,
      "grad_norm": 0.5226763486862183,
      "learning_rate": 0.00010677981602900589,
      "loss": 0.7693,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.7283225059509277,
      "eval_runtime": 112.5833,
      "eval_samples_per_second": 4.486,
      "eval_steps_per_second": 4.486,
      "step": 1265
    },
    {
      "epoch": 5.0395256916996045,
      "grad_norm": 0.11780278384685516,
      "learning_rate": 0.0001035837717199361,
      "loss": 0.4484,
      "step": 1275
    },
    {
      "epoch": 5.138339920948616,
      "grad_norm": 0.5315989255905151,
      "learning_rate": 0.00010038405683746867,
      "loss": 0.6299,
      "step": 1300
    },
    {
      "epoch": 5.237154150197629,
      "grad_norm": 0.14201563596725464,
      "learning_rate": 9.718394859601498e-05,
      "loss": 0.4248,
      "step": 1325
    },
    {
      "epoch": 5.335968379446641,
      "grad_norm": 0.537826657295227,
      "learning_rate": 9.398672461287281e-05,
      "loss": 0.6716,
      "step": 1350
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 0.13030710816383362,
      "learning_rate": 9.07956595512227e-05,
      "loss": 0.4235,
      "step": 1375
    },
    {
      "epoch": 5.533596837944664,
      "grad_norm": 0.5972973704338074,
      "learning_rate": 8.761402176615002e-05,
      "loss": 0.6562,
      "step": 1400
    },
    {
      "epoch": 5.632411067193676,
      "grad_norm": 0.12330380082130432,
      "learning_rate": 8.444506995712768e-05,
      "loss": 0.4225,
      "step": 1425
    },
    {
      "epoch": 5.7312252964426875,
      "grad_norm": 0.5795795321464539,
      "learning_rate": 8.129204983038847e-05,
      "loss": 0.6524,
      "step": 1450
    },
    {
      "epoch": 5.830039525691699,
      "grad_norm": 0.11781461536884308,
      "learning_rate": 7.815819077460559e-05,
      "loss": 0.4323,
      "step": 1475
    },
    {
      "epoch": 5.928853754940711,
      "grad_norm": 0.616549551486969,
      "learning_rate": 7.504670255328547e-05,
      "loss": 0.7087,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.7324657440185547,
      "eval_runtime": 112.6584,
      "eval_samples_per_second": 4.483,
      "eval_steps_per_second": 4.483,
      "step": 1518
    },
    {
      "epoch": 6.027667984189724,
      "grad_norm": 0.15221476554870605,
      "learning_rate": 7.196077201726148e-05,
      "loss": 0.4844,
      "step": 1525
    },
    {
      "epoch": 6.126482213438735,
      "grad_norm": 0.5654322504997253,
      "learning_rate": 6.890355984065508e-05,
      "loss": 0.5382,
      "step": 1550
    },
    {
      "epoch": 6.225296442687747,
      "grad_norm": 0.12494218349456787,
      "learning_rate": 6.587819728364784e-05,
      "loss": 0.4477,
      "step": 1575
    },
    {
      "epoch": 6.324110671936759,
      "grad_norm": 0.6276782155036926,
      "learning_rate": 6.288778298537967e-05,
      "loss": 0.592,
      "step": 1600
    },
    {
      "epoch": 6.4229249011857705,
      "grad_norm": 0.15098583698272705,
      "learning_rate": 5.9935379790258326e-05,
      "loss": 0.4475,
      "step": 1625
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 0.6410635709762573,
      "learning_rate": 5.70240116109306e-05,
      "loss": 0.5418,
      "step": 1650
    },
    {
      "epoch": 6.620553359683795,
      "grad_norm": 0.15103837847709656,
      "learning_rate": 5.4156660331128225e-05,
      "loss": 0.46,
      "step": 1675
    },
    {
      "epoch": 6.719367588932807,
      "grad_norm": 0.5737171173095703,
      "learning_rate": 5.133626275156055e-05,
      "loss": 0.606,
      "step": 1700
    },
    {
      "epoch": 6.818181818181818,
      "grad_norm": 0.16306038200855255,
      "learning_rate": 4.8565707581982386e-05,
      "loss": 0.4457,
      "step": 1725
    },
    {
      "epoch": 6.91699604743083,
      "grad_norm": 0.6602018475532532,
      "learning_rate": 4.5847832482517386e-05,
      "loss": 0.5657,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.7382900714874268,
      "eval_runtime": 112.6663,
      "eval_samples_per_second": 4.482,
      "eval_steps_per_second": 4.482,
      "step": 1771
    },
    {
      "epoch": 7.015810276679842,
      "grad_norm": 0.13607648015022278,
      "learning_rate": 4.318542115726779e-05,
      "loss": 0.5029,
      "step": 1775
    },
    {
      "epoch": 7.1146245059288535,
      "grad_norm": 0.6699594855308533,
      "learning_rate": 4.05812005031868e-05,
      "loss": 0.4937,
      "step": 1800
    },
    {
      "epoch": 7.213438735177865,
      "grad_norm": 0.15613383054733276,
      "learning_rate": 3.803783781713411e-05,
      "loss": 0.4807,
      "step": 1825
    },
    {
      "epoch": 7.312252964426877,
      "grad_norm": 0.6709794402122498,
      "learning_rate": 3.55579380639751e-05,
      "loss": 0.4737,
      "step": 1850
    },
    {
      "epoch": 7.41106719367589,
      "grad_norm": 0.18715649843215942,
      "learning_rate": 3.314404120852175e-05,
      "loss": 0.4528,
      "step": 1875
    },
    {
      "epoch": 7.509881422924901,
      "grad_norm": 0.6696286201477051,
      "learning_rate": 3.079861961404789e-05,
      "loss": 0.4905,
      "step": 1900
    },
    {
      "epoch": 7.608695652173913,
      "grad_norm": 0.17294536530971527,
      "learning_rate": 2.852407551004349e-05,
      "loss": 0.4826,
      "step": 1925
    },
    {
      "epoch": 7.707509881422925,
      "grad_norm": 0.7374448776245117,
      "learning_rate": 2.6322738531801317e-05,
      "loss": 0.5387,
      "step": 1950
    },
    {
      "epoch": 7.8063241106719365,
      "grad_norm": 0.16244623064994812,
      "learning_rate": 2.419686333435606e-05,
      "loss": 0.4854,
      "step": 1975
    },
    {
      "epoch": 7.905138339920948,
      "grad_norm": 0.7205216288566589,
      "learning_rate": 2.214862728321987e-05,
      "loss": 0.4571,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.7479594349861145,
      "eval_runtime": 112.6833,
      "eval_samples_per_second": 4.482,
      "eval_steps_per_second": 4.482,
      "step": 2024
    },
    {
      "epoch": 8.003952569169961,
      "grad_norm": 0.15796904265880585,
      "learning_rate": 2.0180128224279417e-05,
      "loss": 0.5196,
      "step": 2025
    },
    {
      "epoch": 8.102766798418973,
      "grad_norm": 0.6774937510490417,
      "learning_rate": 1.829338233513853e-05,
      "loss": 0.4306,
      "step": 2050
    },
    {
      "epoch": 8.201581027667984,
      "grad_norm": 0.178569495677948,
      "learning_rate": 1.6490322060107298e-05,
      "loss": 0.5018,
      "step": 2075
    },
    {
      "epoch": 8.300395256916996,
      "grad_norm": 0.7450153231620789,
      "learning_rate": 1.4772794130952417e-05,
      "loss": 0.3934,
      "step": 2100
    },
    {
      "epoch": 8.399209486166008,
      "grad_norm": 0.1785896271467209,
      "learning_rate": 1.3142557675436262e-05,
      "loss": 0.5293,
      "step": 2125
    },
    {
      "epoch": 8.49802371541502,
      "grad_norm": 0.7049186825752258,
      "learning_rate": 1.1601282415581628e-05,
      "loss": 0.4832,
      "step": 2150
    },
    {
      "epoch": 8.596837944664031,
      "grad_norm": 0.17291150987148285,
      "learning_rate": 1.015054695750779e-05,
      "loss": 0.4993,
      "step": 2175
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 0.745305597782135,
      "learning_rate": 8.791837174589402e-06,
      "loss": 0.3924,
      "step": 2200
    },
    {
      "epoch": 8.794466403162055,
      "grad_norm": 0.16736571490764618,
      "learning_rate": 7.5265446855940615e-06,
      "loss": 0.5131,
      "step": 2225
    },
    {
      "epoch": 8.893280632411066,
      "grad_norm": 0.7242476344108582,
      "learning_rate": 6.355965429357514e-06,
      "loss": 0.4092,
      "step": 2250
    },
    {
      "epoch": 8.992094861660078,
      "grad_norm": 0.14629177749156952,
      "learning_rate": 5.2812983374562195e-06,
      "loss": 0.5121,
      "step": 2275
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.7566449046134949,
      "eval_runtime": 112.6199,
      "eval_samples_per_second": 4.484,
      "eval_steps_per_second": 4.484,
      "step": 2277
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 0.7231831550598145,
      "learning_rate": 4.303644106236704e-06,
      "loss": 0.3765,
      "step": 2300
    },
    {
      "epoch": 9.189723320158103,
      "grad_norm": 0.7439365983009338,
      "learning_rate": 3.4240040694594413e-06,
      "loss": 0.5495,
      "step": 2325
    },
    {
      "epoch": 9.288537549407115,
      "grad_norm": 0.7354709506034851,
      "learning_rate": 2.6432791727121984e-06,
      "loss": 0.3937,
      "step": 2350
    },
    {
      "epoch": 9.387351778656127,
      "grad_norm": 0.8178128600120544,
      "learning_rate": 1.9622690506426956e-06,
      "loss": 0.5353,
      "step": 2375
    },
    {
      "epoch": 9.486166007905139,
      "grad_norm": 0.6938849687576294,
      "learning_rate": 1.3816712079563033e-06,
      "loss": 0.369,
      "step": 2400
    },
    {
      "epoch": 9.58498023715415,
      "grad_norm": 0.7877365946769714,
      "learning_rate": 9.020803050172055e-07,
      "loss": 0.5494,
      "step": 2425
    },
    {
      "epoch": 9.683794466403162,
      "grad_norm": 0.7027530670166016,
      "learning_rate": 5.239875487848877e-07,
      "loss": 0.3579,
      "step": 2450
    },
    {
      "epoch": 9.782608695652174,
      "grad_norm": 0.673551619052887,
      "learning_rate": 2.477801897097898e-07,
      "loss": 0.5339,
      "step": 2475
    },
    {
      "epoch": 9.881422924901186,
      "grad_norm": 0.7134718298912048,
      "learning_rate": 7.374112510339926e-08,
      "loss": 0.3874,
      "step": 2500
    },
    {
      "epoch": 9.980237154150197,
      "grad_norm": 0.8281238675117493,
      "learning_rate": 2.048609388860534e-09,
      "loss": 0.5284,
      "step": 2525
    }
  ],
  "logging_steps": 25,
  "max_steps": 2530,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0198528945700864e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
