{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 1125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.45296382904052734,
      "learning_rate": 0.00014705882352941178,
      "loss": 1.9275,
      "step": 25
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.34311649203300476,
      "learning_rate": 0.0001998938833847273,
      "loss": 1.0964,
      "step": 50
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7381740212440491,
      "learning_rate": 0.00019930388106030166,
      "loss": 0.7811,
      "step": 75
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7273053526878357,
      "eval_runtime": 57.164,
      "eval_samples_per_second": 5.178,
      "eval_steps_per_second": 5.178,
      "step": 75
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.40564021468162537,
      "learning_rate": 0.00019819946930907332,
      "loss": 0.711,
      "step": 100
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.34689584374427795,
      "learning_rate": 0.00019658636915432788,
      "loss": 0.6907,
      "step": 125
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6932888627052307,
      "learning_rate": 0.0001944729367037736,
      "loss": 0.6703,
      "step": 150
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6927469372749329,
      "eval_runtime": 57.0921,
      "eval_samples_per_second": 5.185,
      "eval_steps_per_second": 5.185,
      "step": 150
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.30488401651382446,
      "learning_rate": 0.00019187011986361374,
      "loss": 0.6616,
      "step": 175
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.3085743188858032,
      "learning_rate": 0.00018879140162670347,
      "loss": 0.6324,
      "step": 200
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8671808242797852,
      "learning_rate": 0.00018525273022856607,
      "loss": 0.6204,
      "step": 225
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6576153635978699,
      "eval_runtime": 57.1485,
      "eval_samples_per_second": 5.179,
      "eval_steps_per_second": 5.179,
      "step": 225
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.32410311698913574,
      "learning_rate": 0.00018127243653307248,
      "loss": 0.6211,
      "step": 250
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.36400166153907776,
      "learning_rate": 0.0001768711390757374,
      "loss": 0.591,
      "step": 275
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.7245193123817444,
      "learning_rate": 0.00017207163725652445,
      "loss": 0.5741,
      "step": 300
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6478197574615479,
      "eval_runtime": 56.3687,
      "eval_samples_per_second": 5.251,
      "eval_steps_per_second": 5.251,
      "step": 300
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.3451178967952728,
      "learning_rate": 0.00016689879323543566,
      "loss": 0.5682,
      "step": 325
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.36144208908081055,
      "learning_rate": 0.00016137940314268695,
      "loss": 0.5654,
      "step": 350
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9598718881607056,
      "learning_rate": 0.00015554205827061855,
      "loss": 0.5473,
      "step": 375
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.6416982412338257,
      "eval_runtime": 56.336,
      "eval_samples_per_second": 5.254,
      "eval_steps_per_second": 5.254,
      "step": 375
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.38140869140625,
      "learning_rate": 0.00014941699696638887,
      "loss": 0.5394,
      "step": 400
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 0.43683552742004395,
      "learning_rate": 0.00014303594799267065,
      "loss": 0.5206,
      "step": 425
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.022750973701477,
      "learning_rate": 0.00013643196616776432,
      "loss": 0.5282,
      "step": 450
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.6467284560203552,
      "eval_runtime": 56.3569,
      "eval_samples_per_second": 5.252,
      "eval_steps_per_second": 5.252,
      "step": 450
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 0.43853339552879333,
      "learning_rate": 0.00012963926113653863,
      "loss": 0.5013,
      "step": 475
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.428408145904541,
      "learning_rate": 0.00012269302015919172,
      "loss": 0.4892,
      "step": 500
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.9203357696533203,
      "learning_rate": 0.00011562922583581375,
      "loss": 0.5055,
      "step": 525
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.6488177180290222,
      "eval_runtime": 56.3975,
      "eval_samples_per_second": 5.248,
      "eval_steps_per_second": 5.248,
      "step": 525
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 0.45289480686187744,
      "learning_rate": 0.00010848446971096606,
      "loss": 0.4781,
      "step": 550
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 0.5142726898193359,
      "learning_rate": 0.00010129576272383445,
      "loss": 0.4728,
      "step": 575
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.2280527353286743,
      "learning_rate": 9.410034348585298e-05,
      "loss": 0.4608,
      "step": 600
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.661028265953064,
      "eval_runtime": 56.3649,
      "eval_samples_per_second": 5.251,
      "eval_steps_per_second": 5.251,
      "step": 600
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.5136454701423645,
      "learning_rate": 8.69354853789509e-05,
      "loss": 0.451,
      "step": 625
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.5120888948440552,
      "learning_rate": 7.983830347368276e-05,
      "loss": 0.449,
      "step": 650
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.551186442375183,
      "learning_rate": 7.284556226743598e-05,
      "loss": 0.4404,
      "step": 675
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.6784054636955261,
      "eval_runtime": 56.3641,
      "eval_samples_per_second": 5.252,
      "eval_steps_per_second": 5.252,
      "step": 675
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 0.5138509273529053,
      "learning_rate": 6.599348523866155e-05,
      "loss": 0.4351,
      "step": 700
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 0.5829799771308899,
      "learning_rate": 5.931756720366621e-05,
      "loss": 0.4163,
      "step": 725
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.4744210243225098,
      "learning_rate": 5.285239044798695e-05,
      "loss": 0.4181,
      "step": 750
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.689656138420105,
      "eval_runtime": 56.347,
      "eval_samples_per_second": 5.253,
      "eval_steps_per_second": 5.253,
      "step": 750
    },
    {
      "epoch": 10.333333333333334,
      "grad_norm": 0.5893763899803162,
      "learning_rate": 4.6631445584815926e-05,
      "loss": 0.4071,
      "step": 775
    },
    {
      "epoch": 10.666666666666666,
      "grad_norm": 0.5502368211746216,
      "learning_rate": 4.068695806845624e-05,
      "loss": 0.4079,
      "step": 800
    },
    {
      "epoch": 11.0,
      "grad_norm": 1.3344361782073975,
      "learning_rate": 3.504972126149639e-05,
      "loss": 0.4,
      "step": 825
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.7022833228111267,
      "eval_runtime": 56.365,
      "eval_samples_per_second": 5.251,
      "eval_steps_per_second": 5.251,
      "step": 825
    },
    {
      "epoch": 11.333333333333334,
      "grad_norm": 0.6031194925308228,
      "learning_rate": 2.9748936920440286e-05,
      "loss": 0.3994,
      "step": 850
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 0.5963559150695801,
      "learning_rate": 2.481206392610278e-05,
      "loss": 0.387,
      "step": 875
    },
    {
      "epoch": 12.0,
      "grad_norm": 1.5445952415466309,
      "learning_rate": 2.0264676042370025e-05,
      "loss": 0.3874,
      "step": 900
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.7144067883491516,
      "eval_runtime": 56.3548,
      "eval_samples_per_second": 5.252,
      "eval_steps_per_second": 5.252,
      "step": 900
    },
    {
      "epoch": 12.333333333333334,
      "grad_norm": 0.6491050720214844,
      "learning_rate": 1.6130329440156432e-05,
      "loss": 0.3893,
      "step": 925
    },
    {
      "epoch": 12.666666666666666,
      "grad_norm": 0.63559490442276,
      "learning_rate": 1.2430440672804545e-05,
      "loss": 0.3789,
      "step": 950
    },
    {
      "epoch": 13.0,
      "grad_norm": 1.6980228424072266,
      "learning_rate": 9.18417573503404e-06,
      "loss": 0.3748,
      "step": 975
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.7175934314727783,
      "eval_runtime": 56.3462,
      "eval_samples_per_second": 5.253,
      "eval_steps_per_second": 5.253,
      "step": 975
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.6088464856147766,
      "learning_rate": 6.408350780131778e-06,
      "loss": 0.3852,
      "step": 1000
    },
    {
      "epoch": 13.666666666666666,
      "grad_norm": 0.6545222997665405,
      "learning_rate": 4.117345009682916e-06,
      "loss": 0.3736,
      "step": 1025
    },
    {
      "epoch": 14.0,
      "grad_norm": 1.6075036525726318,
      "learning_rate": 2.3230261870879956e-06,
      "loss": 0.3656,
      "step": 1050
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.7242428660392761,
      "eval_runtime": 56.3441,
      "eval_samples_per_second": 5.253,
      "eval_steps_per_second": 5.253,
      "step": 1050
    },
    {
      "epoch": 14.333333333333334,
      "grad_norm": 0.6161300539970398,
      "learning_rate": 1.0346891607172614e-06,
      "loss": 0.3834,
      "step": 1075
    },
    {
      "epoch": 14.666666666666666,
      "grad_norm": 0.6624378561973572,
      "learning_rate": 2.5900771516188527e-07,
      "loss": 0.3683,
      "step": 1100
    },
    {
      "epoch": 15.0,
      "grad_norm": 1.5853996276855469,
      "learning_rate": 0.0,
      "loss": 0.3629,
      "step": 1125
    }
  ],
  "logging_steps": 25,
  "max_steps": 1125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.935429119279104e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
