{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/neemias/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/neemias/PerceptSent-LLM-approach/data/prompts.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha5_p3.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha3_p2neg.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha4_p5.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha4_p3.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha3_p2plus.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha5_p5.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha3_p5.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha5_p2plus.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha5_p2neg.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha4_p2plus.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha3_p3.csv', '/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/percept_dataset_alpha4_p2neg.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p3.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p2neg.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p5.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p3.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p2plus.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p5.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p5.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p2plus.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p2neg.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p2plus.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p3.csv', '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p2neg.csv']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "data_path_open_source = \"/home/neemias/PerceptSent-LLM-approach/data/\"\n",
    "data_path_open_ai = \"/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/\"\n",
    "data_path_deep_seek = \"/home/neemias/PerceptSent-LLM-approach/data/deepseek/\"\n",
    "\n",
    "data_paths = []\n",
    "\n",
    "for data_path in [data_path_open_source, data_path_open_ai, data_path_deep_seek]:\n",
    "    data_paths.extend([os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.csv')])\n",
    "\n",
    "# The del data_paths[6] line was removed as it was arbitrary.\n",
    "\n",
    "print(data_paths)  # Print the list of CSV file paths\n",
    "print(len(data_paths)) # Print the number of CSV files found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb301c9b0034066b4b8535b3efaaebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/neemias/PerceptSent-LLM-approach/data/prompts.csv because it has fewer than 5 samples (1).\n"
     ]
    }
   ],
   "source": [
    "for data_path in tqdm(data_paths):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df_metrics = pd.DataFrame([])\n",
    "    if len(df) < 5:  # n_splits = 5\n",
    "        print(f\"Skipping {data_path} because it has fewer than 5 samples ({len(df)}).\")\n",
    "        continue  # Move to the next file\n",
    "    \n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(df)):\n",
    "        train_df = pd.DataFrame({\"text\": df[\"text\"].iloc[train_idx].to_list(), \n",
    "                                        \"sentiment\": df[\"sentiment\"].iloc[train_idx].to_list()})\n",
    "        val_df = pd.DataFrame({\"text\": df[\"text\"].iloc[val_idx].to_list(), \n",
    "                                    \"sentiment\": df[\"sentiment\"].iloc[val_idx].to_list()})\n",
    "        \n",
    "        model = SentimentIntensityAnalyzer()\n",
    "\n",
    "        text = val_df[\"text\"].to_list()\n",
    "        target = val_df[\"sentiment\"].to_list()\n",
    "\n",
    "        sentiments = np.unique(target)\n",
    "\n",
    "        if (len(sentiments) == 3):\n",
    "            sent_dic = {\n",
    "                \"neg\": 1,\n",
    "                \"neu\": 0,\n",
    "                \"pos\": 2,\n",
    "            }\n",
    "        elif (len(sentiments) == 2):\n",
    "            if (data_path.split('/')[-1].split('.')[0].split('_')[-1] == \"p2plus\"):\n",
    "                sent_dic = {\n",
    "                    \"neg\": 1, \"neu\": 0, \"pos\": 0,\n",
    "                }\n",
    "            else:\n",
    "                sent_dic = {\n",
    "                    \"neg\": 0, \"neu\": 0, \"pos\": 1,\n",
    "                }\n",
    "\n",
    "        pred = []\n",
    "        for t in text:\n",
    "            result = model.polarity_scores(t)\n",
    "            del result[\"compound\"]\n",
    "            # print(f\"Result: {result}\") # For debug\n",
    "            max_key = max(result, key=result.get)\n",
    "            max_value = result[max_key]\n",
    "            pred.append(sent_dic[max_key])\n",
    "\n",
    "        accuracy_val = accuracy_score(target, pred)\n",
    "        f1_val = f1_score(target, pred, average=\"weighted\")    \n",
    "        df_metrics = pd.concat([df_metrics, pd.DataFrame({\"accuracy\": [accuracy_val], \"f1_score\": [f1_val]\n",
    "                                                            })], axis=0)\n",
    "    # Determine the flag based on the data path\n",
    "    if \"openai\" in data_path:\n",
    "        flag = \"openai\"\n",
    "    elif \"deepseek\" in data_path:\n",
    "        flag = \"deepseek\"\n",
    "    elif \"percept\" in data_path or \"open_source\" in data_path: # Handles both \"percept\" and \"open_source\"\n",
    "        flag = \"percept\"  # Or \"opensource\" if you prefer\n",
    "    else:\n",
    "        flag = \"unknown\" # Handle cases where the path doesn't match known flags\n",
    "        \n",
    "    # display(df_metrics.head())\n",
    "    if (len(sentiments) <= 3):\n",
    "        df_metrics.to_csv(f\"/home/neemias/PerceptSent-LLM-approach/experiments/vader-experiment/{flag}-{data_path.split('/')[-1]}\",\n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha5_p2neg\n",
      "Max F1-score: 0.5189435259561487\n",
      "Average F1-score: 0.49074234954804813\n",
      "Confidence interval 95%: (0.45191682301330005, 0.5295678760827962)\n",
      "Inteval: 0.03882552653474808 - Interval: 0.03882552653474808\n",
      "Inteval: 0.03882552653474808 - Interval: 0.03882552653474802\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha5_p2plus\n",
      "Max F1-score: 0.6474433981859724\n",
      "Average F1-score: 0.6282014212922771\n",
      "Confidence interval 95%: (0.6074191385525002, 0.648983704032054)\n",
      "Inteval: 0.02078228273977689 - Interval: 0.02078228273977689\n",
      "Inteval: 0.02078228273977689 - Interval: 0.02078228273977689\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha4_p2plus\n",
      "Max F1-score: 0.59909004841813\n",
      "Average F1-score: 0.5657914816935575\n",
      "Confidence interval 95%: (0.5332214163067354, 0.5983615470803797)\n",
      "Inteval: 0.03257006538682217 - Interval: 0.03257006538682217\n",
      "Inteval: 0.03257006538682217 - Interval: 0.03257006538682217\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha3_p2plus\n",
      "Max F1-score: 0.5260939193257074\n",
      "Average F1-score: 0.5153812454261695\n",
      "Confidence interval 95%: (0.49622455546629474, 0.5345379353860442)\n",
      "Inteval: 0.01915668995987474 - Interval: 0.01915668995987474\n",
      "Inteval: 0.01915668995987474 - Interval: 0.01915668995987474\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha4_p2neg\n",
      "Max F1-score: 0.4997339293316303\n",
      "Average F1-score: 0.4802209984198651\n",
      "Confidence interval 95%: (0.4644905262398328, 0.4959514705998974)\n",
      "Inteval: 0.015730472180032318 - Interval: 0.015730472180032318\n",
      "Inteval: 0.015730472180032318 - Interval: 0.015730472180032318\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha3_p3\n",
      "Max F1-score: 0.0658548115262876\n",
      "Average F1-score: 0.052744411740211904\n",
      "Confidence interval 95%: (0.04331431193142994, 0.062174511548993866)\n",
      "Inteval: 0.009430099808781962 - Interval: 0.009430099808781962\n",
      "Inteval: 0.009430099808781955 - Interval: 0.009430099808781955\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p2plus\n",
      "Max F1-score: 0.59909004841813\n",
      "Average F1-score: 0.5657914816935575\n",
      "Confidence interval 95%: (0.5332214163067354, 0.5983615470803797)\n",
      "Inteval: 0.03257006538682217 - Interval: 0.03257006538682217\n",
      "Inteval: 0.03257006538682217 - Interval: 0.03257006538682217\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha5_p2plus\n",
      "Max F1-score: 0.6589446589446589\n",
      "Average F1-score: 0.6228177535258477\n",
      "Confidence interval 95%: (0.5874874132094263, 0.658148093842269)\n",
      "Inteval: 0.03533034031642135 - Interval: 0.03533034031642135\n",
      "Inteval: 0.03533034031642135 - Interval: 0.03533034031642135\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p2neg\n",
      "Max F1-score: 0.4997339293316303\n",
      "Average F1-score: 0.4802209984198651\n",
      "Confidence interval 95%: (0.4644905262398328, 0.4959514705998974)\n",
      "Inteval: 0.015730472180032318 - Interval: 0.015730472180032318\n",
      "Inteval: 0.015730472180032318 - Interval: 0.015730472180032318\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha3_p3\n",
      "Max F1-score: 0.0702551841341144\n",
      "Average F1-score: 0.05823760070808424\n",
      "Confidence interval 95%: (0.04509528350560452, 0.07137991791056396)\n",
      "Inteval: 0.013142317202479714 - Interval: 0.013142317202479721\n",
      "Inteval: 0.013142317202479714 - Interval: 0.013142317202479714\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p2plus\n",
      "Max F1-score: 0.6474433981859724\n",
      "Average F1-score: 0.6282014212922771\n",
      "Confidence interval 95%: (0.6074191385525002, 0.648983704032054)\n",
      "Inteval: 0.02078228273977689 - Interval: 0.02078228273977689\n",
      "Inteval: 0.02078228273977689 - Interval: 0.02078228273977689\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha4_p2neg\n",
      "Max F1-score: 0.5051767410595316\n",
      "Average F1-score: 0.4786502868690177\n",
      "Confidence interval 95%: (0.45375188376775866, 0.5035486899702768)\n",
      "Inteval: 0.02489840310125907 - Interval: 0.02489840310125907\n",
      "Inteval: 0.02489840310125907 - Interval: 0.024898403101259015\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p2neg\n",
      "Max F1-score: 0.4855481579414725\n",
      "Average F1-score: 0.45795868157580805\n",
      "Confidence interval 95%: (0.4351406416642076, 0.4807767214874085)\n",
      "Inteval: 0.022818039911600474 - Interval: 0.022818039911600474\n",
      "Inteval: 0.022818039911600474 - Interval: 0.02281803991160053\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha5_p3\n",
      "Max F1-score: 0.0066880684858212\n",
      "Average F1-score: 0.0040374161400681206\n",
      "Confidence interval 95%: (0.0015483597879331328, 0.006526472492203108)\n",
      "Inteval: 0.0024890563521349877 - Interval: 0.0024890563521349877\n",
      "Inteval: 0.0024890563521349877 - Interval: 0.0024890563521349886\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha5_p2neg\n",
      "Max F1-score: 0.5528255528255529\n",
      "Average F1-score: 0.4881062493364805\n",
      "Confidence interval 95%: (0.43768514003310877, 0.5385273586398522)\n",
      "Inteval: 0.050421109303371736 - Interval: 0.050421109303371736\n",
      "Inteval: 0.050421109303371736 - Interval: 0.050421109303371736\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha4_p3\n",
      "Max F1-score: 0.0234432234432234\n",
      "Average F1-score: 0.019474994266995622\n",
      "Confidence interval 95%: (0.016012158422690524, 0.02293783011130072)\n",
      "Inteval: 0.003462835844305099 - Interval: 0.003462835844305099\n",
      "Inteval: 0.003462835844305099 - Interval: 0.003462835844305099\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha3_p2neg\n",
      "Max F1-score: 0.4832562999385372\n",
      "Average F1-score: 0.455850522711995\n",
      "Confidence interval 95%: (0.43269065540015084, 0.47901039002383916)\n",
      "Inteval: 0.023159867311844162 - Interval: 0.023159867311844162\n",
      "Inteval: 0.023159867311844162 - Interval: 0.023159867311844107\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha3_p2neg\n",
      "Max F1-score: 0.4855481579414725\n",
      "Average F1-score: 0.45795868157580805\n",
      "Confidence interval 95%: (0.4351406416642076, 0.4807767214874085)\n",
      "Inteval: 0.022818039911600474 - Interval: 0.022818039911600474\n",
      "Inteval: 0.022818039911600474 - Interval: 0.02281803991160053\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p3\n",
      "Max F1-score: 0.0278558886348516\n",
      "Average F1-score: 0.015677346053148862\n",
      "Confidence interval 95%: (0.004915089573228596, 0.02643960253306913)\n",
      "Inteval: 0.010762256479920266 - Interval: 0.010762256479920268\n",
      "Inteval: 0.010762256479920265 - Interval: 0.010762256479920265\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p2plus\n",
      "Max F1-score: 0.5281541054735542\n",
      "Average F1-score: 0.518089918578405\n",
      "Confidence interval 95%: (0.5096367944003456, 0.5265430427564645)\n",
      "Inteval: 0.008453124178059435 - Interval: 0.008453124178059435\n",
      "Inteval: 0.008453124178059435 - Interval: 0.008453124178059435\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p3\n",
      "Max F1-score: 0.0356289296485585\n",
      "Average F1-score: 0.026138213771428997\n",
      "Confidence interval 95%: (0.01754818736039191, 0.034728240182466084)\n",
      "Inteval: 0.008590026411037087 - Interval: 0.008590026411037087\n",
      "Inteval: 0.008590026411037087 - Interval: 0.008590026411037087\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p2neg\n",
      "Max F1-score: 0.5189435259561487\n",
      "Average F1-score: 0.49074234954804813\n",
      "Confidence interval 95%: (0.45191682301330005, 0.5295678760827962)\n",
      "Inteval: 0.03882552653474808 - Interval: 0.03882552653474808\n",
      "Inteval: 0.03882552653474808 - Interval: 0.03882552653474802\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha4_p3\n",
      "Max F1-score: 0.0356289296485585\n",
      "Average F1-score: 0.026138213771428997\n",
      "Confidence interval 95%: (0.01754818736039191, 0.034728240182466084)\n",
      "Inteval: 0.008590026411037087 - Interval: 0.008590026411037087\n",
      "Inteval: 0.008590026411037087 - Interval: 0.008590026411037087\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha5_p3\n",
      "Max F1-score: 0.0278558886348516\n",
      "Average F1-score: 0.015677346053148862\n",
      "Confidence interval 95%: (0.004915089573228596, 0.02643960253306913)\n",
      "Inteval: 0.010762256479920266 - Interval: 0.010762256479920268\n",
      "Inteval: 0.010762256479920265 - Interval: 0.010762256479920265\n",
      "\n",
      "\n",
      "Problem: openai-percept_dataset_alpha4_p2plus\n",
      "Max F1-score: 0.5822689871403107\n",
      "Average F1-score: 0.562121498464542\n",
      "Confidence interval 95%: (0.5458636982968283, 0.5783792986322556)\n",
      "Inteval: 0.01625780016771361 - Interval: 0.01625780016771361\n",
      "Inteval: 0.01625780016771361 - Interval: 0.01625780016771361\n",
      "\n",
      "\n",
      "Problem: deepseek-percept_dataset_alpha3_p2plus\n",
      "Max F1-score: 0.5281541054735542\n",
      "Average F1-score: 0.518089918578405\n",
      "Confidence interval 95%: (0.5096367944003456, 0.5265430427564645)\n",
      "Inteval: 0.008453124178059435 - Interval: 0.008453124178059435\n",
      "Inteval: 0.008453124178059435 - Interval: 0.008453124178059435\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p3\n",
      "Max F1-score: 0.0702551841341144\n",
      "Average F1-score: 0.05823760070808424\n",
      "Confidence interval 95%: (0.04509528350560452, 0.07137991791056396)\n",
      "Inteval: 0.013142317202479714 - Interval: 0.013142317202479721\n",
      "Inteval: 0.013142317202479714 - Interval: 0.013142317202479714\n"
     ]
    }
   ],
   "source": [
    "csv_files = [os.path.join(\"/home/neemias/PerceptSent-LLM-approach/experiments/vader-experiment\", f) \n",
    "             for f in os.listdir(\"/home/neemias/PerceptSent-LLM-approach/experiments/vader-experiment\") if f.endswith(\".csv\")]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df_metrics = pd.read_csv(csv_file)\n",
    "    f1_scores = df_metrics[\"f1_score\"].to_list()\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "\n",
    "    # define the confidence level\n",
    "    confidence_level = 0.95\n",
    "    degrees_freedon = len(f1_scores)-1\n",
    "\n",
    "    confidence_interval = stats.t.interval(\n",
    "        confidence_level, \n",
    "        degrees_freedon, \n",
    "        loc=mean_f1, \n",
    "        scale=stats.sem(f1_scores)\n",
    "    )\n",
    "\n",
    "    print(f\"\\n\\nProblem: {csv_file.split('/')[-1].split('.')[0]}\")\n",
    "    print(f\"Max F1-score: {max(f1_scores)}\")\n",
    "    print(f\"Average F1-score: {mean_f1}\")\n",
    "    print(f\"Confidence interval 95%: {confidence_interval}\")\n",
    "    print(f\"Inteval: {abs(confidence_interval[0]-mean_f1)} - Interval: {abs(confidence_interval[1]-mean_f1)}\")\n",
    "    confidence_interval = stats.t.interval(\n",
    "        confidence_level, \n",
    "        degrees_freedon, \n",
    "        loc=max(f1_scores), \n",
    "        scale=stats.sem(f1_scores)\n",
    "    )\n",
    "\n",
    "    print(f\"Inteval: {abs(confidence_interval[0]-max(f1_scores))} - Interval: {abs(confidence_interval[1]-max(f1_scores))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
