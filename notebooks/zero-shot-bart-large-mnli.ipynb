{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero shot learning - BART-LARGE MNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neemias/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/neemias/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "model = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\", device=\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_open_source = \"/home/neemias/PerceptSent-LLM-approach/data/\"\n",
    "# data_path_open_ai = \"/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/\"\n",
    "data_path_open_ai = \"/home/neemias/PerceptSent-LLM-approach/data/deepseek/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p2neg.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p5.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p3.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p2plus.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p5.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p2plus.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p2neg.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p2plus.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p3.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p2neg.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths = [os.path.join(data_path_open_source, f) \n",
    "              for f in os.listdir(data_path_open_source) if f.endswith('.csv')] + [os.path.join(data_path_open_ai, f)\n",
    "                                                              for f in os.listdir(data_path_open_ai) if f.endswith('.csv')]\n",
    "del data_paths[6]\n",
    "data_paths[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea871c75de94ed4bb09cba58b845633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p2neg.csv\n",
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p5.csv\n",
      "1484\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p3.csv\n",
      "2978\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p2plus.csv\n",
      "5000\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p5.csv\n",
      "3566\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p2plus.csv\n",
      "2525\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha5_p2neg.csv\n",
      "2532\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p2plus.csv\n",
      "3843\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha3_p3.csv\n",
      "4506\n",
      "/home/neemias/PerceptSent-LLM-approach/data/deepseek/percept_dataset_alpha4_p2neg.csv\n",
      "3913\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for data_path in tqdm(data_paths[-10:]):\n",
    "    print(data_path)\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(len(df))\n",
    "    df_metrics = pd.DataFrame([])\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(df)):\n",
    "        train_df = pd.DataFrame({\"text\": df[\"text\"].iloc[train_idx].to_list(), \n",
    "                                        \"sentiment\": df[\"sentiment\"].iloc[train_idx].to_list()})\n",
    "        val_df = pd.DataFrame({\"text\": df[\"text\"].iloc[val_idx].to_list(), \n",
    "                                    \"sentiment\": df[\"sentiment\"].iloc[val_idx].to_list()})\n",
    "        \n",
    "\n",
    "        text = val_df[\"text\"].to_list()\n",
    "        target = val_df[\"sentiment\"].to_list()\n",
    "\n",
    "        sentiments = np.unique(target)\n",
    "\n",
    "        if (len(sentiments) == 3):\n",
    "            sent_dic = {\n",
    "                \"Negative\": 1,\n",
    "                \"Neutral\": 0,\n",
    "                \"Positive\": 2,\n",
    "            }\n",
    "            sents = [\"Positive\", \"Neutral\", \"Negative\"]\n",
    "        elif (len(sentiments) == 2):\n",
    "            # # P2+\n",
    "\n",
    "            if (data_path.split('/')[-1].split('.')[0].split('_')[-1] == \"p2plus\"):\n",
    "                sent_dic = {\n",
    "                    \"Negative\": 1, \"Positive\": 0,\n",
    "                }\n",
    "            else:\n",
    "                sent_dic = {\n",
    "                    \"Negative\": 0, \"Positive\": 1,\n",
    "                }\n",
    "            sents = [\"Negative\", \"Positive\"]\n",
    "        else:\n",
    "            sent_dic = {\n",
    "                \"Positive\": 4,\n",
    "                \"SlightlyPositive\": 3,\n",
    "                \"Neutral\": 2,\n",
    "                \"SlightlyNegative\": 1,\n",
    "                \"Negative\": 0\n",
    "            }\n",
    "            sents = [\"Positive\", \"SlightlyPositive\", \"Neutral\", \"SlightlyNegative\", \"Negative\"]\n",
    "\n",
    "        pred = []\n",
    "        for t in text:\n",
    "            result = model(t, sents)\n",
    "            pred.append(sent_dic[result[\"labels\"][0]])\n",
    "        accuracy_val = accuracy_score(target, pred)\n",
    "        f1_val = f1_score(target, pred, average=\"weighted\")    \n",
    "        df_metrics = pd.concat([df_metrics, pd.DataFrame({\"accuracy\": [accuracy_val], \"f1_score\": [f1_val]\n",
    "                                                            })], axis=0)\n",
    "    # display(df_metrics.head())\n",
    "    if (len(data_path.split('/')[-2].split('-')) > 2):\n",
    "        flag = \"openai\"\n",
    "    else:\n",
    "        flag = \"opensource\"\n",
    "    df_metrics.to_csv(f\"/home/neemias/PerceptSent-LLM-approach/experiments/zero-shot-bart/{flag}-{data_path.split('/')[-1]}\",\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p2neg\n",
      "Max F1-score: 0.762038161606818\n",
      "Average F1-score: 0.7450589861120556\n",
      "Confidence interval 95%: (0.7274977706638637, 0.7626202015602475)\n",
      "Inteval: 0.01756121544819189 - Interval: 0.01756121544819189\n",
      "Inteval: 0.01756121544819189 - Interval: 0.01756121544819189\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p2plus\n",
      "Max F1-score: 0.6267001532055154\n",
      "Average F1-score: 0.6015667564579\n",
      "Confidence interval 95%: (0.5773556448002242, 0.6257778681155759)\n",
      "Inteval: 0.024211111657675866 - Interval: 0.024211111657675866\n",
      "Inteval: 0.024211111657675866 - Interval: 0.024211111657675866\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p3\n",
      "Max F1-score: 0.3759660751994322\n",
      "Average F1-score: 0.3696117002085493\n",
      "Confidence interval 95%: (0.3633939531845113, 0.37582944723258727)\n",
      "Inteval: 0.0062177470240379895 - Interval: 0.0062177470240379895\n",
      "Inteval: 0.0062177470240379895 - Interval: 0.0062177470240379895\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha3_p5\n",
      "Max F1-score: 0.3162576758265124\n",
      "Average F1-score: 0.29739168062038773\n",
      "Confidence interval 95%: (0.283908817978974, 0.3108745432618015)\n",
      "Inteval: 0.01348286264141374 - Interval: 0.01348286264141374\n",
      "Inteval: 0.01348286264141374 - Interval: 0.01348286264141374\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p2neg\n",
      "Max F1-score: 0.8247137959611099\n",
      "Average F1-score: 0.8015439023483427\n",
      "Confidence interval 95%: (0.7708004856553968, 0.8322873190412886)\n",
      "Inteval: 0.03074341669294589 - Interval: 0.03074341669294589\n",
      "Inteval: 0.03074341669294589 - Interval: 0.03074341669294589\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p2plus\n",
      "Max F1-score: 0.6512288904082629\n",
      "Average F1-score: 0.6359068480050647\n",
      "Confidence interval 95%: (0.6193595079534798, 0.6524541880566496)\n",
      "Inteval: 0.01654734005158487 - Interval: 0.01654734005158487\n",
      "Inteval: 0.01654734005158487 - Interval: 0.01654734005158487\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p3\n",
      "Max F1-score: 0.4349504069891518\n",
      "Average F1-score: 0.42798343413647977\n",
      "Confidence interval 95%: (0.4171089663904301, 0.43885790188252943)\n",
      "Inteval: 0.010874467746049665 - Interval: 0.010874467746049665\n",
      "Inteval: 0.010874467746049665 - Interval: 0.010874467746049665\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha4_p5\n",
      "Max F1-score: 0.4186645359249792\n",
      "Average F1-score: 0.40804564870675913\n",
      "Confidence interval 95%: (0.38767765932307235, 0.4284136380904459)\n",
      "Inteval: 0.02036798938368678 - Interval: 0.02036798938368678\n",
      "Inteval: 0.02036798938368678 - Interval: 0.02036798938368678\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p2neg\n",
      "Max F1-score: 0.8942302458899041\n",
      "Average F1-score: 0.8541625184637599\n",
      "Confidence interval 95%: (0.8114702925403485, 0.8968547443871713)\n",
      "Inteval: 0.042692225923411375 - Interval: 0.042692225923411375\n",
      "Inteval: 0.042692225923411375 - Interval: 0.042692225923411375\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p2plus\n",
      "Max F1-score: 0.7195185133624444\n",
      "Average F1-score: 0.6907312588286072\n",
      "Confidence interval 95%: (0.6662192572532091, 0.7152432604040053)\n",
      "Inteval: 0.024512001575398124 - Interval: 0.024512001575398124\n",
      "Inteval: 0.024512001575398124 - Interval: 0.024512001575398124\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p3\n",
      "Max F1-score: 0.4358343018951948\n",
      "Average F1-score: 0.38809366569371895\n",
      "Confidence interval 95%: (0.32610448893736577, 0.45008284245007213)\n",
      "Inteval: 0.06198917675635318 - Interval: 0.06198917675635318\n",
      "Inteval: 0.06198917675635318 - Interval: 0.06198917675635318\n",
      "\n",
      "\n",
      "Problem: opensource-percept_dataset_alpha5_p5\n",
      "Max F1-score: 0.4710362047440699\n",
      "Average F1-score: 0.3559163761102746\n",
      "Confidence interval 95%: (0.26970296812816164, 0.44212978409238757)\n",
      "Inteval: 0.08621340798211297 - Interval: 0.08621340798211297\n",
      "Inteval: 0.08621340798211302 - Interval: 0.08621340798211302\n"
     ]
    }
   ],
   "source": [
    "csv_files = [os.path.join(\"/home/neemias/PerceptSent-LLM-approach/experiments/zero-shot-bart\", f) \n",
    "             for f in os.listdir(\"/home/neemias/PerceptSent-LLM-approach/experiments/zero-shot-bart\") if f.endswith(\".csv\") and \"opensource\" in f]\n",
    "csv_files.sort()\n",
    "for csv_file in csv_files:\n",
    "    df_metrics = pd.read_csv(csv_file)\n",
    "    f1_scores = df_metrics[\"f1_score\"].to_list()\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "\n",
    "    # define the confidence level\n",
    "    confidence_level = 0.95\n",
    "    degrees_freedon = len(f1_scores)-1\n",
    "\n",
    "    confidence_interval = stats.t.interval(\n",
    "        confidence_level, \n",
    "        degrees_freedon, \n",
    "        loc=mean_f1, \n",
    "        scale=stats.sem(f1_scores)\n",
    "    )\n",
    "\n",
    "    print(f\"\\n\\nProblem: {csv_file.split('/')[-1].split('.')[0]}\")\n",
    "    print(f\"Max F1-score: {max(f1_scores)}\")\n",
    "    print(f\"Average F1-score: {mean_f1}\")\n",
    "    print(f\"Confidence interval 95%: {confidence_interval}\")\n",
    "    print(f\"Inteval: {abs(confidence_interval[0]-mean_f1)} - Interval: {abs(confidence_interval[1]-mean_f1)}\")\n",
    "    confidence_interval = stats.t.interval(\n",
    "        confidence_level, \n",
    "        degrees_freedon, \n",
    "        loc=max(f1_scores), \n",
    "        scale=stats.sem(f1_scores)\n",
    "    )\n",
    "\n",
    "    print(f\"Inteval: {abs(confidence_interval[0]-max(f1_scores))} - Interval: {abs(confidence_interval[1]-max(f1_scores))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
