{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# X-axis labels (models)\n",
    "models = [\"MiniGPT-4 (Open Source)\", \n",
    "          \"GPT-4o Mini (OpenAI)\",\n",
    "          \"PerceptSent Paper ResNet\", \n",
    "          \"DeepSeek VL2\"\n",
    "]\n",
    "x_values = np.arange(len(models))\n",
    "\n",
    "# Methods and random F1-scores\n",
    "methods = [\n",
    "    \"Percept Sent Paper ResNet - Benchmark\",\n",
    "    \"Vader\",\n",
    "    \"Zero-shot BART-LARGE-MNLI\",\n",
    "    \"Only the LLM\",\n",
    "    \"Fine-Tuning DISTIL-BERT\",\n",
    "    \"Fine-Tuning BART-LARGE-MNLI\",\n",
    "    \"Fine-Tuning LLAMA-3 using qLORA with Quantization\",\n",
    "    \"Fine-Tuning ModernBERT\"\n",
    "]\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "f1_scores = [\n",
    "    [None, None, 51.20, None],\t\n",
    "    [None, None, None, None],\n",
    "    [35.59, 78.49, None, None],\n",
    "    [None, 75.79, None, None], \n",
    "    [74.44, 83.17, None, 76.12], \n",
    "    [78.29, 82.87, None, 77.87],\n",
    "    [75.90, 83.68, None, None], \n",
    "    [76.37, 84.44, None, 74.87]]\n",
    "\n",
    "markers = ['o', 's', 'D', '^', 'v', 'p', 'h', '*']  # Different markers for each method\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(methods)))  # Unique colors\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, method in enumerate(methods):\n",
    "    plt.scatter(x_values, f1_scores[i], label=method, marker=markers[i % len(markers)], s=200, edgecolors='black', alpha=0.8)\n",
    "\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xticks(x_values, models, rotation=20)\n",
    "plt.xlabel(\"Approaches\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"F1-score - Threshold σ = 5, Classification Problem P5\")\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1, 0), fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# X-axis labels (models)\n",
    "models = [\"MiniGPT-4 (Open Source)\", \n",
    "          \"GPT-4o Mini (OpenAI)\",\n",
    "          \"PerceptSent Paper ResNet\", \n",
    "          \"DeepSeek VL2\"\n",
    "]\n",
    "x_values = np.arange(len(models))\n",
    "\n",
    "# Methods and random F1-scores\n",
    "methods = [\n",
    "    \"Percept Sent Paper ResNet - Benchmark\",\n",
    "    \"Vader\",\n",
    "    \"Zero-shot BART-LARGE-MNLI\",\n",
    "    \"Only the LLM\",\n",
    "    \"Fine-Tuning DISTIL-BERT\",\n",
    "    \"Fine-Tuning BART-LARGE-MNLI\",\n",
    "    \"Fine-Tuning LLAMA-3 using qLORA with Quantization\",\n",
    "    \"Fine-Tuning ModernBERT\"\n",
    "]\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "f1_scores = [\n",
    "    [38.81, None, 69.00, None],\t\n",
    "    [0.40, 0.40, None, 1.57],\n",
    "    [38.81, 84.67, None, None],\n",
    "    [None, 87.68, None, None], \n",
    "    [89.98, 95.53, None, 90.72], \n",
    "    [90.06, 95.63, None, 91.93],\n",
    "    [90.03, 92.70, None, None], \n",
    "    [90.16, 96.02, None, 80.50]]\n",
    "\n",
    "markers = ['o', 's', 'D', '^', 'v', 'p', 'h', '*']  # Different markers for each method\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(methods)))  # Unique colors\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, method in enumerate(methods):\n",
    "    plt.scatter(x_values, f1_scores[i], label=method, marker=markers[i % len(markers)], s=200, edgecolors='black', alpha=0.8)\n",
    "\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xticks(x_values, models, rotation=20)\n",
    "plt.xlabel(\"Approaches\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"F1-score - Threshold σ = 5, Classification Problem P3\")\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1, 0), fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# X-axis labels (models)\n",
    "models = [\"MiniGPT-4 (Open Source)\", \n",
    "          \"GPT-4o Mini (OpenAI)\",\n",
    "          \"PerceptSent Paper ResNet\", \n",
    "          \"DeepSeek VL2\"\n",
    "]\n",
    "x_values = np.arange(len(models))\n",
    "\n",
    "# Methods and random F1-scores\n",
    "methods = [\n",
    "    \"Percept Sent Paper ResNet - Benchmark\",\n",
    "    \"Vader\",\n",
    "    \"Zero-shot BART-LARGE-MNLI\",\n",
    "    \"Only the LLM\",\n",
    "    \"Fine-Tuning DISTIL-BERT\",\n",
    "    \"Fine-Tuning BART-LARGE-MNLI\",\n",
    "    \"Fine-Tuning LLAMA-3 using qLORA with Quantization\",\n",
    "    \"Fine-Tuning ModernBERT\"\n",
    "]\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "f1_scores = [\n",
    "    [None, None, 81.20, None],\t\n",
    "    [22.76, 62.28, None, 62.82],\n",
    "    [29.51, 89.61, None, None],\n",
    "    [None, 85.51, None, None], \n",
    "    [92.49, 95.42, None, 91.82], \n",
    "    [93.03, 95.47, None, 92.58],\n",
    "    [93.22, 94.60, None, None], \n",
    "    [92.19, 95.90, None, 92.08]]\n",
    "\n",
    "markers = ['o', 's', 'D', '^', 'v', 'p', 'h', '*']  # Different markers for each method\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(methods)))  # Unique colors\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, method in enumerate(methods):\n",
    "    plt.scatter(x_values, f1_scores[i], label=method, marker=markers[i % len(markers)], s=200, edgecolors='black', alpha=0.8)\n",
    "\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xticks(x_values, models, rotation=20)\n",
    "plt.xlabel(\"Approaches\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"F1-score - Threshold σ = 5, Classification Problem P2+\")\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1, 0), fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# X-axis labels (models)\n",
    "models = [\"MiniGPT-4 (Open Source)\", \n",
    "          \"GPT-4o Mini (OpenAI)\",\n",
    "          \"PerceptSent Paper ResNet\",\n",
    "          \"DeepSeek VL2\"\n",
    "]\n",
    "x_values = np.arange(len(models))\n",
    "\n",
    "# Methods and random F1-scores\n",
    "methods = [\n",
    "    \"Percept Sent Paper ResNet - Benchmark\",\n",
    "    \"Vader\",\n",
    "    \"Zero-shot BART-LARGE-MNLI\",\n",
    "    \"Only the LLM\",\n",
    "    \"Fine-Tuning DISTIL-BERT\",\n",
    "    \"Fine-Tuning BART-LARGE-MNLI\",\n",
    "    \"Fine-Tuning LLAMA-3 using qLORA with Quantization\",\n",
    "    \"Fine-Tuning ModernBERT\"\n",
    "]\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "f1_scores = [\n",
    "    [None, None,88.60, None],\t\n",
    "    [27.25, 48.81, None, 49.07],\n",
    "    [71.02, 84.56, None, None],\n",
    "    [None, 93.77, None, None], \n",
    "    [93.15, 96.44, None, 92.56], \n",
    "    [93.71, 96.33, None, 93.22],\n",
    "    [94.51, 96.10, None, None], \n",
    "    [94.46, 96.24, None, 92.93]\n",
    "]\n",
    "\n",
    "markers = ['o', 's', 'D', '^', 'v', 'p', 'h', '*']  # Different markers for each method\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(methods)))  # Unique colors\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, method in enumerate(methods):\n",
    "    plt.scatter(x_values, f1_scores[i], label=method, marker=markers[i % len(markers)], s=200, edgecolors='black', alpha=0.8)\n",
    "\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xticks(x_values, models, rotation=20)\n",
    "plt.xlabel(\"Approaches\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"F1-score - Threshold σ = 5, Classification Problem P2-\")\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1, 0), fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the data for each approach, classification problem, and error margins\n",
    "data = {\n",
    "    \"Threshold (σ)\": [3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
    "    \"Classification Problem\": [\"P5\", \"P3\", \"P2+\", \"P2-\", \n",
    "                               \"P5\", \"P3\", \"P2+\", \"P2-\", \n",
    "                               \"P5\", \"P3\", \"P2+\", \"P2-\"],\n",
    "    # ResNet Paper\n",
    "    \"ResNet - (Benchmark)\": [45.00, 61.00, 64.40, 74.80, 48.20, 68.00, 76.60, 84.00, 51.20, 69.00, 81.20, 88.60],\n",
    "    \"ResNet_err\": [3.4, 5.3, 6.2, 5.0, 8.9, 5.2, 6.2, 3.5, 6.3, 4.7, 5.4, 1.1],\n",
    "    # MiniGPT-4 (OpenSource)\n",
    "    \"MiniGPT-4 (OpenSource) + Vader\": [None, 5.27, 46.77, 26.75, None, 23.00, 23.00, 33.87, None, 0.40, 22.76, 27.25],\n",
    "    \"MiniGPT-4 (OpenSource) + Vader_err\": [None, 0.9, 1.8, 1.5, None, 1.6, 1.7, 2.5, None, 0.2, 3.7, 3.3],\n",
    "    \"MiniGPT-4 (OpenSource) + Zero-shot BART-LARGE-MNLI\": [21.44, 32.65, 54.06, 27.33, 27.92, 29.71, 34.35, 68.17, 35.59, 38.81, 29.51, 71.02],\n",
    "    \"Zero-shot_err\": [1.9, 1.0, 2.3, 1.4, 3.6, 2.7, 2.9, 1.8, 8.6, 6.1, 4.6, 4.0],\n",
    "    \"MiniGPT-4 (OpenSource) + Fine-Tuning DISTIL-BERT\": [48.06, 70.32, 77.83, 80.62, 62.45, 80.82, 85.51, 87.53, 74.44, 89.98, 92.49, 93.15],\n",
    "    \"FineTuning_DISTIL_err\": [1.8, 2.5, 1.5, 1.1, 1.5, 4.8, 1.5, 1.3, 6.9, 1.9, 0.4, 0.8],\n",
    "    \"MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI\": [56.96, 68.74, 78.09, 80.26, 64.48, 81.51, 85.71, 88.50, 78.29, 90.06, 93.03, 93.71],\n",
    "    \"FineTuning_BART_err\": [3.6, 2.1, 2.3, 2.3, 1.7, 2.4, 2.1, 2.0, 7.5, 2.2, 2.0, 2.3],\n",
    "    # MiniGPT-4 OpenAI\n",
    "    \"MiniGPT-4 (OpenAI) + Vader\": [None, 5.27, 51.54, 45.58, None, 1.95, 56.21, 47.86, None, 0.40, 62.28, 48.81],\n",
    "    \"OpenAI_Vader_err\": [None, 0.9, 1.9, 2.3, None, 0.3, 1.6, 2.5, None, 0.2, 3.5, 5.0],\n",
    "    \"MiniGPT-4 (OpenAI) + Zero-shot BART-LARGE-MNLI\": [48.25, 67.64, 78.15, 73.44, 62.28, 77.05, 84.83, 78.81, 78.49, 84.67, 89.61, 84.56],\n",
    "    \"OpenAI_Zero-shot_err\": [4.3, 1.8, 1.3, 1.9, 2.9, 1.6, 2.4, 1.9, 6.6, 2.9, 1.8, 2.2],\n",
    "    \"MiniGPT-4 (OpenAI)\": [44.58, 61.28, 72.63, 82.84, 50.06, 70.53, 82.51, 88.51, 75.79, 87.68, 85.51, 93.77],\n",
    "    \"OpenAI_err\": [3.1, 2.9, 1.1, 0.9, 2.6, 2.2, 2.3, 1.2, 4.7, 1.8, 1.6, 1.8],\n",
    "    \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT\": [56.74, 76.44, 82.11, 85.75, 71.32, 88.73, 90.48, 92.04, 83.17, 95.53, 95.42, 96.44],\n",
    "    \"OpenAI_BART_err\": [4.2, 1.5, 0.6, 1.4, 2.8, 1.3, 2.0, 1.7, 6.6, 1.1, 1.3, 1.2],\n",
    "    \"MiniGPT-4 (OpenAI) + Fine-Tuning BART-LARGE-MNLI\": [56.35, 75.47, 82.33, 82.53, 69.75, 87.79, 90.33, 91.43, 82.87, 95.63, 95.47, 96.33],\n",
    "    \"OpenAI_DISTIL_err\": [3.9, 1.2, 0.5, 2.7, 0.9, 1.5, 1.0, 1.8, 8.9, 1.7, 0.9, 0.9],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Unique classification problems for x-axis labels\n",
    "classification_problems = [\"P5\", \"P3\", \"P2+\", \"P2-\"]\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(20, 8.6))\n",
    "\n",
    "# Define styles for each approach\n",
    "approaches = {\n",
    "    \"ResNet - (Benchmark)\": {\"score\": \"ResNet - (Benchmark)\", \"err\": \"ResNet_err\", \"color\": \"mediumslateblue\", \"marker\": \"s\", \"linestyle\": \"--\"},\n",
    "    \"MiniGPT-4 (OpenSource) + Vader\": {\"score\": \"MiniGPT-4 (OpenSource) + Vader\", \"err\": \"MiniGPT-4 (OpenSource) + Vader_err\", \"color\": \"lightcoral\", \"marker\": \"D\", \"linestyle\": \"--\"},\n",
    "    \"MiniGPT-4 (OpenSource) + Zero-shot BART-LARGE-MNLI\": {\"score\": \"MiniGPT-4 (OpenSource) + Zero-shot BART-LARGE-MNLI\", \"err\": \"Zero-shot_err\", \"color\": \"lightgray\", \"marker\": \"^\", \"linestyle\": \"--\"},\n",
    "    \"MiniGPT-4 (OpenSource) + Fine-Tuning DISTIL-BERT\": {\"score\": \"MiniGPT-4 (OpenSource) + Fine-Tuning DISTIL-BERT\", \"err\": \"FineTuning_DISTIL_err\", \"color\": \"thistle\", \"marker\": \"o\", \"linestyle\": \"-\"},\n",
    "    \"MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI\": {\"score\": \"MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI\", \"err\": \"FineTuning_BART_err\", \"color\": \"lightgreen\", \"marker\": \"x\", \"linestyle\": \"-\"},\n",
    "    \"MiniGPT-4 (OpenAI) + Vader\": {\"score\": \"MiniGPT-4 (OpenAI) + Vader\", \"err\": \"OpenAI_Vader_err\", \"color\": \"red\", \"marker\": \"D\", \"linestyle\": \"--\"},\n",
    "    \"MiniGPT-4 (OpenAI) + Zero-shot BART-LARGE-MNLI\": {\"score\": \"MiniGPT-4 (OpenAI) + Zero-shot BART-LARGE-MNLI\", \"err\": \"OpenAI_Zero-shot_err\", \"color\": \"gray\", \"marker\": \"^\", \"linestyle\": \"--\"},\n",
    "    \"MiniGPT-4 (OpenAI)\": {\"score\": \"MiniGPT-4 (OpenAI)\", \"err\": \"OpenAI_err\", \"color\": \"orange\", \"marker\": \"s\", \"linestyle\": \"-\"},\n",
    "    \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT\": {\"score\": \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT\", \"err\": \"OpenAI_DISTIL_err\", \"color\": \"purple\", \"marker\": \"s\", \"linestyle\": \"-\"},\n",
    "    \"MiniGPT-4 (OpenAI) + Fine-Tuning BART-LARGE-MNLI\": {\"score\": \"MiniGPT-4 (OpenAI) + Fine-Tuning BART-LARGE-MNLI\", \"err\": \"OpenAI_BART_err\", \"color\": \"green\", \"marker\": \"x\", \"linestyle\": \"-\"}\n",
    "    \n",
    "}\n",
    "\n",
    "threshold_styles = {\n",
    "    3: {\"color\": \"blue\", \"marker\": \"s\", \"label\": r'$\\sigma=3$'},\n",
    "    4: {\"color\": \"red\", \"marker\": \"D\", \"label\": r'$\\sigma=4$'},\n",
    "    5: {\"color\": \"gray\", \"marker\": \"^\", \"label\": r'$\\sigma=5$'}\n",
    "}\n",
    "\n",
    "# Plot each approach with error bars\n",
    "for approach, style in approaches.items():\n",
    "    # Extract F1-scores and errors for each problem setup for current approach\n",
    "    scores = []\n",
    "    errors = []\n",
    "    for setup in classification_problems:\n",
    "        score = df[df[\"Classification Problem\"] == setup][style[\"score\"]].values\n",
    "        error = df[df[\"Classification Problem\"] == setup][style[\"err\"]].values\n",
    "        scores.append(score[0] if len(score) > 0 else np.nan)\n",
    "        errors.append(error[0] if len(error) > 0 else np.nan)\n",
    "    \n",
    "    # Plot data with error bars\n",
    "    ax.errorbar(classification_problems, scores, yerr=errors, label=approach,\n",
    "                marker=style[\"marker\"], color=style[\"color\"], linestyle=style[\"linestyle\"], linewidth=2, capsize=4)\n",
    "\n",
    "# Set axis labels and limits\n",
    "ax.set_xlabel(\"Problem setups\")\n",
    "ax.set_ylabel(\"F1-Score (%)\")\n",
    "ax.set_ylim(0, 100)\n",
    "ax.grid(True)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "# Display plot\n",
    "plt.title(\"F1-Score Comparison by Approach and Problem Setup\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the data for each approach, classification problem, and error margins\n",
    "data = {\n",
    "    \"Threshold (σ)\": [3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
    "    \"Classification Problem\": [\"P5\", \"P3\", \"P2+\", \"P2-\", \n",
    "                               \"P5\", \"P3\", \"P2+\", \"P2-\", \n",
    "                               \"P5\", \"P3\", \"P2+\", \"P2-\"],\n",
    "    # ResNet Paper\n",
    "    \"ResNet - (Benchmark)\": [45.00, 61.00, 64.40, 74.80, 48.20, 68.00, 76.60, 84.00, 51.20, 69.00, 81.20, 88.60],\n",
    "    \"ResNet - (Benchmark)_err\": [3.4, 5.3, 6.2, 5.0, 8.9, 5.2, 6.2, 3.5, 6.3, 4.7, 5.4, 1.1],\n",
    "    # MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI\n",
    "    \"MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI\": [56.96, 68.74, 78.09, 80.26, 64.48, 81.51, 85.71, 88.50, 78.29, 90.06, 93.03, 93.71],\n",
    "    \"MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI_err\": [3.6, 2.1, 2.3, 2.3, 1.7, 2.4, 2.1, 2.0, 7.5, 2.2, 2.0, 2.3],\n",
    "    # MiniGPT-4 (OpenSource) + Fine-Tuning DISTIL-BERT\n",
    "    \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT\": [56.74, 76.44, 82.11, 85.75, 71.32, 88.73, 90.48, 92.04, 83.17, 95.53, 95.42, 96.44],\n",
    "    \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT_err\": [4.2, 1.5, 0.6, 1.4, 2.8, 1.3, 2.0, 1.7, 6.6, 1.1, 1.3, 1.2],\n",
    "    \n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Unique classification problems for x-axis labels\n",
    "classification_problems = [\"P5\", \"P3\", \"P2+\", \"P2-\"]\n",
    "\n",
    "# Define threshold colors and markers\n",
    "threshold_styles = {\n",
    "    3: {\"color\": \"lightsteelblue\", \"marker\": \"s\", \"label\": r'$\\sigma=3$'},\n",
    "    4: {\"color\": \"lightcoral\", \"marker\": \"D\", \"label\": r'$\\sigma=4$'},\n",
    "    5: {\"color\": \"lightgreen\", \"marker\": \"^\", \"label\": r'$\\sigma=5$'}\n",
    "}\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(20, 8.6))\n",
    "\n",
    "# Loop over each threshold and plot with error bars for all approaches\n",
    "for threshold, style in threshold_styles.items():\n",
    "    subset = df[df[\"Threshold (σ)\"] == threshold]\n",
    "    if not subset.empty:\n",
    "        for approach in [\n",
    "            \"ResNet - (Benchmark)\", \n",
    "            # \"MiniGPT-4 (OpenSource) + Fine-Tuning BART-LARGE-MNLI\", \n",
    "            \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT\"\n",
    "        ]:\n",
    "            if approach in subset.columns:\n",
    "                if approach == \"MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT\":\n",
    "                    if threshold == 3:\n",
    "                        style[\"color\"] = \"blue\"\n",
    "                    elif threshold == 4:\n",
    "                        style[\"color\"] = \"red\"\n",
    "                    elif threshold == 5:\n",
    "                        style[\"color\"] = \"green\"\n",
    "                scores = subset[approach].values\n",
    "                errors = subset[f\"{approach}_err\"].values if f\"{approach}_err\" in subset.columns else np.zeros_like(scores)\n",
    "\n",
    "                ax.errorbar(classification_problems, scores, yerr=errors, \n",
    "                            fmt=style[\"marker\"], color=style[\"color\"], \n",
    "                            linestyle='--', linewidth=2, label=f\"{approach} ({style['label']})\", capsize=4)\n",
    "                \n",
    "                # Fill between for confidence interval\n",
    "                ax.fill_between(classification_problems, \n",
    "                                scores - errors, \n",
    "                                scores + errors, \n",
    "                                color=style[\"color\"], alpha=0.2)\n",
    "\n",
    "# Set axis labels and limits\n",
    "ax.set_xlabel(\"Problem setups\")\n",
    "ax.set_ylabel(\"F1-Score (%)\")\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xticks(range(len(classification_problems)))\n",
    "ax.set_xticklabels(classification_problems)\n",
    "ax.grid(True)\n",
    "\n",
    "# Add legend and title\n",
    "ax.legend(loc=\"best\")\n",
    "plt.title(\"F1-Score Comparison by Approach and Problem Setup with Confidence Intervals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (adjust these with your actual F1 scores and confidence intervals)\n",
    "setups = ['P5', 'P3', 'P2+', 'P2-']\n",
    "models = ['ResNet - (Benchmark) (σ=3)', 'MiniGPT-4  (OpenSource) + Fine-Tuning BART-LARGE-MNLI (σ=3)', 'MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT (σ=3)',\n",
    "          'ResNet - (Benchmark) (σ=4)', 'MiniGPT-4  (OpenSource) + Fine-Tuning BART-LARGE-MNLI (σ=4)', 'MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT (σ=4)',\n",
    "          'ResNet - (Benchmark) (σ=5)', 'MiniGPT-4  (OpenSource) + Fine-Tuning BART-LARGE-MNLI (σ=5)', 'MiniGPT-4 (OpenAI) + Fine-Tuning DISTIL-BERT (σ=5)'] \n",
    "\n",
    "scores = np.array([\n",
    "    [45.00, 56.96, 56.74, 48.20, 64.48, 71.32, 51.20, 78.29, 83.17],  # P5\n",
    "    [61.00, 68.74, 76.44, 68.00, 81.51, 88.73, 69.00, 90.06, 95.53],  # P3\n",
    "    [64.40, 78.09, 82.11, 76.60, 85.71, 90.48, 81.20, 93.03, 95.42],  # P2+\n",
    "    [74.80, 80.26, 85.75, 84.00, 88.50, 92.04, 88.60, 93.71, 96.44]   # P2-\n",
    "])\n",
    "errors = np.array([\n",
    "    [3.4, 3.6, 4.2, 8.9, 1.7, 2.8, 6.3, 7.5, 6.6],  # P5\n",
    "    [5.3, 2.1, 1.5, 5.2, 2.4, 1.3, 4.7, 2.2, 1.1],  # P3\n",
    "    [6.2, 2.3, 0.6, 6.2, 2.1, 2.0, 5.4, 2.0, 1.3],  # P2+\n",
    "    [5.0, 2.3, 1.4, 3.5, 2.0, 1.7, 1.1, 2.3, 1.2]   # P2-\n",
    "])\n",
    "\n",
    "# Plot each setup as a stacked bar\n",
    "num_setups = len(setups)\n",
    "num_models = len(models)\n",
    "bar_width = 0.15  # Width of each bar\n",
    "# index = np.arange(num_setups)  # X locations for each setup\n",
    "group_space = 0.3\n",
    "index = np.arange(num_setups) * (num_models * bar_width + group_space)\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# approaches_color = {\n",
    "#     \"ResNet - (Benchmark)\": \"blue\",\n",
    "#     \"MiniGPT-4  (OpenSource) + Fine-Tuning BART-LARGE-MNLI\": \"red\",\n",
    "# }\n",
    "\n",
    "# Plot each model's bars within each setup group\n",
    "for i in range(num_models):\n",
    "    ax.bar(index + i * bar_width, scores[:, i], bar_width, yerr=errors[:, i], \n",
    "           label=models[i], capsize=5)\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Problem Setups')\n",
    "ax.set_ylabel('F1-score (%)')\n",
    "ax.set_title('F1-Score Comparison by Approach and Problem Setup')\n",
    "ax.set_xticks(index + bar_width * (num_models - 1) / 2)  # Center the group labels\n",
    "ax.set_xticklabels(setups)  # Set the specific labels (P5, P3, P2+, P2-)\n",
    "ax.legend(title=\"Model Configurations\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
