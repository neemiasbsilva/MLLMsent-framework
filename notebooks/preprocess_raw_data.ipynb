{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Raw Data to be ready to Train\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook has the purpose to prepare the dataset to be ready use for the Deep Neural Networks Architecture that will be use for classify and compare with the paper PerceptSent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# import gensim\n",
    "from tqdm.notebook import tqdm\n",
    "# Deep learning packages\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "# from textaugment import Word2vec\n",
    "# from textaugment import Fasttext\n",
    "# from textaugment import Wordnet\n",
    "# from textaugment import Translate\n",
    "# from textaugment import Word2vec, Fasttext\n",
    "# from textaugment import Translate\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/neemias/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/neemias/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/neemias/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17rbdLJ5aNayZk9lK8wnVeICSgwJxLVA_</td>\n",
       "      <td>The image depicts a scene of a street with a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13rljxGdgMVqhS9Shw-QJdvAsrUtw6uG3</td>\n",
       "      <td>The image depicts a rustic scene with a large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150R6i7Id13s-D4dbuxcDnKDcA7sqjo7e</td>\n",
       "      <td>The image depicts a beautiful winter landscape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11DOuFmByYWPoQc2QyFxzxcb1da83nIqF</td>\n",
       "      <td>The image depicts an abandoned and dilapidated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135mA2oT4gSOf3qcrmsFj5OE7kL406F4T</td>\n",
       "      <td>The image depicts a nighttime scene with a per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0  17rbdLJ5aNayZk9lK8wnVeICSgwJxLVA_   \n",
       "1  13rljxGdgMVqhS9Shw-QJdvAsrUtw6uG3   \n",
       "2  150R6i7Id13s-D4dbuxcDnKDcA7sqjo7e   \n",
       "3  11DOuFmByYWPoQc2QyFxzxcb1da83nIqF   \n",
       "4  135mA2oT4gSOf3qcrmsFj5OE7kL406F4T   \n",
       "\n",
       "                                                text  \n",
       "0  The image depicts a scene of a street with a w...  \n",
       "1  The image depicts a rustic scene with a large ...  \n",
       "2  The image depicts a beautiful winter landscape...  \n",
       "3  The image depicts an abandoned and dilapidated...  \n",
       "4  The image depicts a nighttime scene with a per...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1w0roE1aw1yjQ8oY0__9t93nO1ARMYfV0</td>\n",
       "      <td>The image depicts a scene with a concrete stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1iXaZO6ytrrK2TyCCBwrjxiZ5ENHFr1b3</td>\n",
       "      <td>The image depicts a scene from what appears to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1ijXLFVUpmqbBhlACprg0b9NpEoznSMxM</td>\n",
       "      <td>The image depicts a dark, rocky surface with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1acey5joN49lEijBO-6VCVYDqbvJt67AI</td>\n",
       "      <td>The image depicts a vibrant graffiti mural pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1-f8C5VH-0TsCfr0DkrzUVp8Pub9xykXp</td>\n",
       "      <td>The image depicts a section of a building's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "4995  1w0roE1aw1yjQ8oY0__9t93nO1ARMYfV0   \n",
       "4996  1iXaZO6ytrrK2TyCCBwrjxiZ5ENHFr1b3   \n",
       "4997  1ijXLFVUpmqbBhlACprg0b9NpEoznSMxM   \n",
       "4998  1acey5joN49lEijBO-6VCVYDqbvJt67AI   \n",
       "4999  1-f8C5VH-0TsCfr0DkrzUVp8Pub9xykXp   \n",
       "\n",
       "                                                   text  \n",
       "4995  The image depicts a scene with a concrete stru...  \n",
       "4996  The image depicts a scene from what appears to...  \n",
       "4997  The image depicts a dark, rocky surface with a...  \n",
       "4998  The image depicts a vibrant graffiti mural pai...  \n",
       "4999        The image depicts a section of a building's  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../data/raw/image_caption_mini_GPT4.csv\") # captioning data for miniGPT-4\n",
    "# df = pd.read_csv(\"../data/raw/image_caption_blip.csv\") # captioning data for Blip Large model\n",
    "# df_mini = pd.read_csv(\"../data/raw/image_caption_minigpt4_completed.csv\") # captioning data for miniGPT-4\n",
    "# df = pd.read_csv(\"../data/raw/image_caption_gpt4_openai.csv\", delimiter=';') # captioning data for miniGPT-4\n",
    "df = pd.read_csv(\"../data/raw/image_caption_deepseek.csv\") # captioning data for miniGPT-4\n",
    "# df[\"url\"] = [\"https://drive.google.com/uc?export=view&id=\"+str(id) for id in df[\"id\"]]\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"id\"] = df[\"image_path\"].apply(lambda x: x.split('/')[-1].split('.')[0]) # for miniGPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"caption\"] = df[\"caption\"].apply(lambda x: x.replace(\"The image shows\", '').replace(\"This is\", '').replace(\"This image\", '').replace(\"The image\", '').replace(\"\\u200b\", '').replace(\"\\n\", ' ').replace(\"<Img>\", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.KeyedVectors.load_word2vec_format('../models/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"../data/raw/dataset.json\")\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {\n",
    "    \"SlightlyNegative\": \"Negative\",\n",
    "    # \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "    \"SlightlyPositive\": \"Positive\",\n",
    "    # \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "    \"Neutral\": \"Neutral\",\n",
    "    \"Positive\": \"Positive\",\n",
    "    \"Negative\": \"Negative\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia_calculation(sg):\n",
    "    \"\"\"\n",
    "    Calcula a métrica IA (Image Agreement) com base no vetor de sentimento agrupado (sg).\n",
    "\n",
    "    Parâmetros:\n",
    "    sg (list ou tuple): Vetor de sentimento agrupado, onde cada elemento representa o número de votos para uma categoria de sentimento.\n",
    "\n",
    "    Retorna:\n",
    "    float: A métrica IA.\n",
    "    \"\"\"\n",
    "    total_avaliadores = len(sg)\n",
    "    max_votos = max(sg)\n",
    "    IA = max_votos / total_avaliadores\n",
    "    return IA\n",
    "\n",
    "sentiment_data = {}\n",
    "\n",
    "for id, caption in tqdm(zip(df[\"id\"], df[\"caption\"]), total=len(df), desc=\"Create supervised dataset\"):\n",
    "    sentiment_data[id] = {\n",
    "        \"sparse sentiment\": [],\n",
    "        \"cluster sentiment\": [],\n",
    "        \"perceptions\": [],\n",
    "        \"caption\": caption,\n",
    "        \"image_agreement\": float,\n",
    "    }\n",
    "\n",
    "simple_sentiment = {\n",
    "    \"Positive\": \"Positive\",\n",
    "    \"SlightlyPositive\": \"Positive\",\n",
    "    # \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "    \"Neutral\": \"Neutral\",\n",
    "    \"SlightlyNegative\": \"Negative\",\n",
    "    # \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "    \"Negative\": \"Negative\"\n",
    "}\n",
    "# sentiment_idx = {\n",
    "#     \"Positive\": 4,\n",
    "#     \"SlightlyPositive\": 3,\n",
    "#     \"Neutral\": 2,\n",
    "#     \"SlightlyNegative\": 1,\n",
    "#     \"Negative\": 0\n",
    "# }\n",
    "sentiment_idx = {\n",
    "    \"Positive\": 2,\n",
    "    \"Neutral\": 0,\n",
    "    \"Negative\": 1\n",
    "}\n",
    "\n",
    "\n",
    "for samples in tqdm(data[\"tasks\"], desc=\"Image perceptions\"):\n",
    "    for sample in samples[\"images\"]:\n",
    "        id = sample[\"id\"]\n",
    "        sentiment = sample[\"sentiment\"]\n",
    "        # perceptions = ', '.join([str(per) for per in sample[\"perceptions\"]])\n",
    "        perceptions = [str(per) for per in sample[\"perceptions\"]]\n",
    "        \n",
    "        if id in sentiment_data:\n",
    "            # sentiment = [simple_sentiment[sent] for sent in sentiment]\n",
    "            sentiment_data[id][\"sparse sentiment\"].append(sentiment)\n",
    "            sentiment_data[id][\"cluster sentiment\"].append(simple_sentiment[sentiment])\n",
    "            for perception in perceptions:\n",
    "                sentiment_data[id][\"perceptions\"].append(perception)\n",
    "\n",
    "for id in tqdm(sentiment_data, desc=\"Image agreement calculation\"):\n",
    "    sentiment = sentiment_data[id][\"sparse sentiment\"]\n",
    "    sg = [0 for _ in range(len(sentiment))]\n",
    "    counter = Counter(sentiment)\n",
    "    for key in counter:\n",
    "        sg[sentiment_idx[key]] = counter[key]\n",
    "    sentiment_data[id][\"image_agreement\"] = ia_calculation(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = {\n",
    "    \"text\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "# sentiment_values = {\n",
    "#     \"Negative\": 0,\n",
    "#     \"SlightlyNegative\": 1,\n",
    "#     \"Neutral\": 2,\n",
    "#     \"SlightlyPositive\": 3,\n",
    "#     \"Positive\": 4,\n",
    "# }\n",
    "sentiment_values = {\n",
    "    \"Negative\": 0,\n",
    "    \"Neutral\": 0,\n",
    "    \"Positive\": 1,\n",
    "}\n",
    "\n",
    "for id in tqdm(sentiment_data, desc=\"Zero-shot-classification progress\"):\n",
    "    caption = sentiment_data[id][\"caption\"]\n",
    "    sentiment = list(sentiment_data[id][\"cluster sentiment\"])\n",
    "    unique_perceptions = list(set(sentiment_data[id][\"perceptions\"]))\n",
    "    # max_value = result[pred]\n",
    "    ia = sentiment_data[id][\"image_agreement\"]    \n",
    "\n",
    "    label = Counter(sentiment)\n",
    "    counter = Counter(sentiment)\n",
    "    # print(sentiment)\n",
    "    # print(label)\n",
    "    # print(counter)\n",
    "    most_common_sentiment, frequency = counter.most_common(1)[0]\n",
    "    if (frequency >= 5): # 3 -> alpha3; 4 -> alpha4; 5 -> alpha5\n",
    "        data[\"text\"].append(caption)\n",
    "        data[\"target\"].append(sentiment_values[most_common_sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"][0], data[\"target\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_distribution(df):\n",
    "    \"\"\"\"\n",
    "    Plots the distribution of sentiments\n",
    "    Parameters:\n",
    "        df(dataframe): DataFrame containing the \"sentiment\" column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    mapping = {0: \"Negative\", 1: \"Positive\"}\n",
    "    # mapping = {1: \"Negative\", 0: \"Neutral\", 2: \"Positive\"}\n",
    "    # mapping = {0: \"Negative\", 1: \"SlightlyNegative\", 2: \"Neutral\", 3: \"SlightlyPositive\", 4: \"Positive\"}\n",
    "    df[\"sentiment\"] = df[\"sentiment\"].map(mapping)\n",
    "    sentiment_counts = df[\"sentiment\"].value_counts()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sentiment_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "    plt.title(\"Sentiment Distribution\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiment_distribution(pd.DataFrame({\"sentiment\": data[\"target\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"][:5], data[\"target\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"../data/train/train.csv\", index=False)\n",
    "# # aug_train_df.to_csv(\"../data/train/aug_train.csv\", index=False)\n",
    "# val_df.to_csv(\"../data/validation/val.csv\", index=False)\n",
    "# test_df.to_csv(\"../data/test/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p5.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p3.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p2plus.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p2neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p5.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p3.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p2plus.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p2neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p5.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p3.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p2plus.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p2neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data to MiniGPT 4 classify sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17rbdLJ5aNayZk9lK8wnVeICSgwJxLVA_</td>\n",
       "      <td>The image depicts a scene of a street with a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13rljxGdgMVqhS9Shw-QJdvAsrUtw6uG3</td>\n",
       "      <td>The image depicts a rustic scene with a large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150R6i7Id13s-D4dbuxcDnKDcA7sqjo7e</td>\n",
       "      <td>The image depicts a beautiful winter landscape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11DOuFmByYWPoQc2QyFxzxcb1da83nIqF</td>\n",
       "      <td>The image depicts an abandoned and dilapidated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135mA2oT4gSOf3qcrmsFj5OE7kL406F4T</td>\n",
       "      <td>The image depicts a nighttime scene with a per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0  17rbdLJ5aNayZk9lK8wnVeICSgwJxLVA_   \n",
       "1  13rljxGdgMVqhS9Shw-QJdvAsrUtw6uG3   \n",
       "2  150R6i7Id13s-D4dbuxcDnKDcA7sqjo7e   \n",
       "3  11DOuFmByYWPoQc2QyFxzxcb1da83nIqF   \n",
       "4  135mA2oT4gSOf3qcrmsFj5OE7kL406F4T   \n",
       "\n",
       "                                                text  \n",
       "0  The image depicts a scene of a street with a w...  \n",
       "1  The image depicts a rustic scene with a large ...  \n",
       "2  The image depicts a beautiful winter landscape...  \n",
       "3  The image depicts an abandoned and dilapidated...  \n",
       "4  The image depicts a nighttime scene with a per...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1w0roE1aw1yjQ8oY0__9t93nO1ARMYfV0</td>\n",
       "      <td>The image depicts a scene with a concrete stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1iXaZO6ytrrK2TyCCBwrjxiZ5ENHFr1b3</td>\n",
       "      <td>The image depicts a scene from what appears to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1ijXLFVUpmqbBhlACprg0b9NpEoznSMxM</td>\n",
       "      <td>The image depicts a dark, rocky surface with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1acey5joN49lEijBO-6VCVYDqbvJt67AI</td>\n",
       "      <td>The image depicts a vibrant graffiti mural pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1-f8C5VH-0TsCfr0DkrzUVp8Pub9xykXp</td>\n",
       "      <td>The image depicts a section of a building's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "4995  1w0roE1aw1yjQ8oY0__9t93nO1ARMYfV0   \n",
       "4996  1iXaZO6ytrrK2TyCCBwrjxiZ5ENHFr1b3   \n",
       "4997  1ijXLFVUpmqbBhlACprg0b9NpEoznSMxM   \n",
       "4998  1acey5joN49lEijBO-6VCVYDqbvJt67AI   \n",
       "4999  1-f8C5VH-0TsCfr0DkrzUVp8Pub9xykXp   \n",
       "\n",
       "                                                   text  \n",
       "4995  The image depicts a scene with a concrete stru...  \n",
       "4996  The image depicts a scene from what appears to...  \n",
       "4997  The image depicts a dark, rocky surface with a...  \n",
       "4998  The image depicts a vibrant graffiti mural pai...  \n",
       "4999        The image depicts a section of a building's  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17rbdLJ5aNayZk9lK8wnVeICSgwJxLVA_</td>\n",
       "      <td>The image depicts a scene of a street with a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13rljxGdgMVqhS9Shw-QJdvAsrUtw6uG3</td>\n",
       "      <td>The image depicts a rustic scene with a large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150R6i7Id13s-D4dbuxcDnKDcA7sqjo7e</td>\n",
       "      <td>The image depicts a beautiful winter landscape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11DOuFmByYWPoQc2QyFxzxcb1da83nIqF</td>\n",
       "      <td>The image depicts an abandoned and dilapidated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135mA2oT4gSOf3qcrmsFj5OE7kL406F4T</td>\n",
       "      <td>The image depicts a nighttime scene with a per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0  17rbdLJ5aNayZk9lK8wnVeICSgwJxLVA_   \n",
       "1  13rljxGdgMVqhS9Shw-QJdvAsrUtw6uG3   \n",
       "2  150R6i7Id13s-D4dbuxcDnKDcA7sqjo7e   \n",
       "3  11DOuFmByYWPoQc2QyFxzxcb1da83nIqF   \n",
       "4  135mA2oT4gSOf3qcrmsFj5OE7kL406F4T   \n",
       "\n",
       "                                                text  \n",
       "0  The image depicts a scene of a street with a w...  \n",
       "1  The image depicts a rustic scene with a large ...  \n",
       "2  The image depicts a beautiful winter landscape...  \n",
       "3  The image depicts an abandoned and dilapidated...  \n",
       "4  The image depicts a nighttime scene with a per...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../data/raw/image_caption_minigpt4_completed.csv\") # captioning data for miniGPT-4\n",
    "# df = pd.read_csv(\"../data/raw/image_caption_gpt4_openai.csv\", delimiter=';') # captioning data for miniGPT-4\n",
    "# df[\"url\"] = [\"https://drive.google.com/uc?export=view&id=\"+str(id) for id in df[\"id\"]]\n",
    "df = pd.read_csv(\"../data/raw/image_caption_deepseek.csv\") # captioning data for miniGPT-4\n",
    "# df[\"url\"] = [\"https://drive.google.com/uc?export=view&id=\"+str(id) for id in df[\"id\"]]\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"../data/raw/dataset.json\")\n",
    "data_json = json.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia_calculation(sg):\n",
    "    \"\"\"\n",
    "    Calcula a métrica IA (Image Agreement) com base no vetor de sentimento agrupado (sg).\n",
    "\n",
    "    Parâmetros:\n",
    "    sg (list ou tuple): Vetor de sentimento agrupado, onde cada elemento representa o número de votos para uma categoria de sentimento.\n",
    "\n",
    "    Retorna:\n",
    "    float: A métrica IA.\n",
    "    \"\"\"\n",
    "    total_avaliadores = len(sg)\n",
    "    max_votos = max(sg)\n",
    "    IA = max_votos / total_avaliadores\n",
    "    return IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aa3d70a4c249dfb08bac7ee92a2da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create supervised dataset:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e633b6cc9dd41739dfeede88dd60b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image perceptions:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6862c2d04e4746a6b77c8b899a3b728e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image agreement calculation:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f664e7673045ef80bcadf3e70ee009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b251e043e54fc39dedc120eaea0496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3ec4568d114792963bc7055b5bbab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc3163bb0db416ca4525b77acaf15e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create supervised dataset:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ebe57ad04a4e3c8a2f9ea49ab66ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image perceptions:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32445c8b59f4cf6a748925f39855c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image agreement calculation:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b7870925fc4b03a14bb97f21cf4626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ca0d01072442bcaf21196303a9d6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd8a3371a794fd1b98f972790b97afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292b6479441243fcbbe67f769a4eec4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create supervised dataset:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c31dbe5523343d8a55b6e764f15f619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image perceptions:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbb4196da2d4864a66f4521675a31d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image agreement calculation:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8f1364bba54bedb1d2fb38753e6510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a72cc5bac1a4c6487a2413f4bad9c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7aca79410dc4d58ad4350f99b0f39bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7067d28e29c44008288f8e1f19f55d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create supervised dataset:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ca762a52bf4a9b86518d9b805eb232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image perceptions:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbf067dae6944c4a84de3484a464a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image agreement calculation:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258c221c1eea4bc79eff59208379e819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ffca055e064b2aa74794c1a5f5c862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa20551223346f288c19eebb3e1659d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate datasets:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for approach in range(0, 4):\n",
    "    if approach == 0: ## P5\n",
    "        p = 'p5'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "            \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"Positive\": 4,\n",
    "            \"SlightlyPositive\": 3,\n",
    "            \"Neutral\": 2,\n",
    "            \"SlightlyNegative\": 1,\n",
    "            \"Negative\": 0\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 0,\n",
    "            \"SlightlyNegative\": 1,\n",
    "            \"Neutral\": 2,\n",
    "            \"SlightlyPositive\": 3,\n",
    "            \"Positive\": 4,\n",
    "        }\n",
    "    elif approach == 1: ## P3\n",
    "        p = 'p3'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"SlightlyPositive\": 2,\n",
    "            \"Positive\": 2,\n",
    "            \"Neutral\": 0,\n",
    "            \"Negative\": 1,\n",
    "            \"SlightlyNegative\": 1,\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Positive\": 2,\n",
    "        }\n",
    "    elif approach == 2: ## P2+\n",
    "        p = 'p2plus'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Positive\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Positive\",\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"SlightlyPositive\": 0,\n",
    "            \"Positive\": 0,\n",
    "            \"Neutral\": 0,\n",
    "            \"Negative\": 1,\n",
    "            \"SlightlyNegative\": 1,\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Positive\": 0,\n",
    "        }\n",
    "    elif approach == 3: ## P2-\n",
    "        p = 'p2neg'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Negative\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Negative\",\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"SlightlyPositive\": 1,\n",
    "            \"Positive\": 1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Negative\": 0,\n",
    "            \"SlightlyNegative\": 0,\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 0,\n",
    "            \"Neutral\": 0,\n",
    "            \"Positive\": 1,\n",
    "        }\n",
    "\n",
    "    \n",
    "    sentiment_data = {}\n",
    "\n",
    "    for id, caption in tqdm(zip(df[\"id\"], df[\"text\"]), total=len(df), desc=\"Create supervised dataset\"):\n",
    "        sentiment_data[id] = {\n",
    "            \"sparse sentiment\": [],\n",
    "            \"cluster sentiment\": [],\n",
    "            \"perceptions\": [],\n",
    "            \"caption\": caption,\n",
    "            \"image_agreement\": float,\n",
    "        }\n",
    "\n",
    "        \n",
    "    for samples in tqdm(data_json[\"tasks\"], desc=\"Image perceptions\"):\n",
    "        for sample in samples[\"images\"]:\n",
    "            id = sample[\"id\"]\n",
    "            sentiment = sample[\"sentiment\"]\n",
    "            # perceptions = ', '.join([str(per) for per in sample[\"perceptions\"]])\n",
    "            perceptions = [str(per) for per in sample[\"perceptions\"]]\n",
    "            \n",
    "            if id in sentiment_data:\n",
    "                # sentiment = [simple_sentiment[sent] for sent in sentiment]\n",
    "                sentiment_data[id][\"sparse sentiment\"].append(sentiment)\n",
    "                sentiment_data[id][\"cluster sentiment\"].append(simple_sentiment[sentiment])\n",
    "                for perception in perceptions:\n",
    "                    sentiment_data[id][\"perceptions\"].append(perception)\n",
    "\n",
    "    for id in tqdm(sentiment_data, desc=\"Image agreement calculation\"):\n",
    "        sentiment = sentiment_data[id][\"sparse sentiment\"]\n",
    "        sg = [0 for _ in range(len(sentiment))]\n",
    "        counter = Counter(sentiment)\n",
    "        for key in counter:\n",
    "            # if p == 'p3':\n",
    "            #     print(sg)\n",
    "            #     print(key)\n",
    "            #     print(sentiment_idx)\n",
    "            sg[sentiment_idx[key]] = counter[key]\n",
    "        sentiment_data[id][\"image_agreement\"] = ia_calculation(sg)\n",
    "    \n",
    "    for f in range(3, 6):\n",
    "    \n",
    "        data = {\n",
    "            \"text\": [],\n",
    "            \"target\": [],\n",
    "            \"id\": []\n",
    "        }\n",
    "        for id in tqdm(sentiment_data, desc=\"Generate datasets\"):\n",
    "            caption = sentiment_data[id][\"caption\"]\n",
    "            sentiment = list(sentiment_data[id][\"cluster sentiment\"])\n",
    "            unique_perceptions = list(set(sentiment_data[id][\"perceptions\"]))\n",
    "            ia = sentiment_data[id][\"image_agreement\"]    \n",
    "\n",
    "            label = Counter(sentiment)\n",
    "            counter = Counter(sentiment)\n",
    "            most_common_sentiment, frequency = counter.most_common(1)[0]\n",
    "            if (frequency >= f): # 3 -> alpha3; 4 -> alpha4; 5 -> alpha5\n",
    "                data[\"text\"].append(caption)\n",
    "                data[\"target\"].append(sentiment_values[most_common_sentiment])\n",
    "                data[\"id\"].append(id)\n",
    "\n",
    "        pd.DataFrame({\"id\": data[\"id\"], \n",
    "                      \"text\": data[\"text\"], \n",
    "                      \"sentiment\": data[\"target\"]}).to_csv(\n",
    "                          f\"../data/deepseek/percept_dataset_alpha{f}_{p}.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
