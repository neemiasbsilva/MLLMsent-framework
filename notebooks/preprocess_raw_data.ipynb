{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Raw Data to be ready to Train\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook has the purpose to prepare the dataset to be ready use for the Deep Neural Networks Architecture that will be use for classify and compare with the paper PerceptSent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from tqdm.notebook import tqdm\n",
    "# Deep learning packages\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "# from textaugment import Word2vec\n",
    "# from textaugment import Fasttext\n",
    "# from textaugment import Wordnet\n",
    "# from textaugment import Translate\n",
    "# from textaugment import Word2vec, Fasttext\n",
    "# from textaugment import Translate\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/raw/image_caption_mini_GPT4.csv\") # captioning data for miniGPT-4\n",
    "# df = pd.read_csv(\"../data/raw/image_caption_blip.csv\") # captioning data for Blip Large model\n",
    "df_mini = pd.read_csv(\"../data/raw/image_caption_minigpt4_completed.csv\") # captioning data for miniGPT-4\n",
    "df = pd.read_csv(\"../data/raw/image_caption_gpt4_openai.csv\", delimiter=';') # captioning data for miniGPT-4\n",
    "df[\"url\"] = [\"https://drive.google.com/uc?export=view&id=\"+str(id) for id in df[\"id\"]]\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"id\"] = df[\"image_path\"].apply(lambda x: x.split('/')[-1].split('.')[0]) # for miniGPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"caption\"] = df[\"caption\"].apply(lambda x: x.replace(\"The image shows\", '').replace(\"This is\", '').replace(\"This image\", '').replace(\"The image\", '').replace(\"\\u200b\", '').replace(\"\\n\", ' ').replace(\"<Img>\", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.KeyedVectors.load_word2vec_format('../models/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"../data/raw/dataset.json\")\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {\n",
    "    \"SlightlyNegative\": \"Negative\",\n",
    "    # \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "    \"SlightlyPositive\": \"Positive\",\n",
    "    # \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "    \"Neutral\": \"Neutral\",\n",
    "    \"Positive\": \"Positive\",\n",
    "    \"Negative\": \"Negative\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia_calculation(sg):\n",
    "    \"\"\"\n",
    "    Calcula a métrica IA (Image Agreement) com base no vetor de sentimento agrupado (sg).\n",
    "\n",
    "    Parâmetros:\n",
    "    sg (list ou tuple): Vetor de sentimento agrupado, onde cada elemento representa o número de votos para uma categoria de sentimento.\n",
    "\n",
    "    Retorna:\n",
    "    float: A métrica IA.\n",
    "    \"\"\"\n",
    "    total_avaliadores = len(sg)\n",
    "    max_votos = max(sg)\n",
    "    IA = max_votos / total_avaliadores\n",
    "    return IA\n",
    "\n",
    "sentiment_data = {}\n",
    "\n",
    "for id, caption in tqdm(zip(df[\"id\"], df[\"caption\"]), total=len(df), desc=\"Create supervised dataset\"):\n",
    "    sentiment_data[id] = {\n",
    "        \"sparse sentiment\": [],\n",
    "        \"cluster sentiment\": [],\n",
    "        \"perceptions\": [],\n",
    "        \"caption\": caption,\n",
    "        \"image_agreement\": float,\n",
    "    }\n",
    "\n",
    "simple_sentiment = {\n",
    "    \"Positive\": \"Positive\",\n",
    "    \"SlightlyPositive\": \"Positive\",\n",
    "    # \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "    \"Neutral\": \"Neutral\",\n",
    "    \"SlightlyNegative\": \"Negative\",\n",
    "    # \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "    \"Negative\": \"Negative\"\n",
    "}\n",
    "# sentiment_idx = {\n",
    "#     \"Positive\": 4,\n",
    "#     \"SlightlyPositive\": 3,\n",
    "#     \"Neutral\": 2,\n",
    "#     \"SlightlyNegative\": 1,\n",
    "#     \"Negative\": 0\n",
    "# }\n",
    "sentiment_idx = {\n",
    "    \"Positive\": 2,\n",
    "    \"Neutral\": 0,\n",
    "    \"Negative\": 1\n",
    "}\n",
    "\n",
    "\n",
    "for samples in tqdm(data[\"tasks\"], desc=\"Image perceptions\"):\n",
    "    for sample in samples[\"images\"]:\n",
    "        id = sample[\"id\"]\n",
    "        sentiment = sample[\"sentiment\"]\n",
    "        # perceptions = ', '.join([str(per) for per in sample[\"perceptions\"]])\n",
    "        perceptions = [str(per) for per in sample[\"perceptions\"]]\n",
    "        \n",
    "        if id in sentiment_data:\n",
    "            # sentiment = [simple_sentiment[sent] for sent in sentiment]\n",
    "            sentiment_data[id][\"sparse sentiment\"].append(sentiment)\n",
    "            sentiment_data[id][\"cluster sentiment\"].append(simple_sentiment[sentiment])\n",
    "            for perception in perceptions:\n",
    "                sentiment_data[id][\"perceptions\"].append(perception)\n",
    "\n",
    "for id in tqdm(sentiment_data, desc=\"Image agreement calculation\"):\n",
    "    sentiment = sentiment_data[id][\"sparse sentiment\"]\n",
    "    sg = [0 for _ in range(len(sentiment))]\n",
    "    counter = Counter(sentiment)\n",
    "    for key in counter:\n",
    "        sg[sentiment_idx[key]] = counter[key]\n",
    "    sentiment_data[id][\"image_agreement\"] = ia_calculation(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = {\n",
    "    \"text\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "# sentiment_values = {\n",
    "#     \"Negative\": 0,\n",
    "#     \"SlightlyNegative\": 1,\n",
    "#     \"Neutral\": 2,\n",
    "#     \"SlightlyPositive\": 3,\n",
    "#     \"Positive\": 4,\n",
    "# }\n",
    "sentiment_values = {\n",
    "    \"Negative\": 0,\n",
    "    \"Neutral\": 0,\n",
    "    \"Positive\": 1,\n",
    "}\n",
    "\n",
    "for id in tqdm(sentiment_data, desc=\"Zero-shot-classification progress\"):\n",
    "    caption = sentiment_data[id][\"caption\"]\n",
    "    sentiment = list(sentiment_data[id][\"cluster sentiment\"])\n",
    "    unique_perceptions = list(set(sentiment_data[id][\"perceptions\"]))\n",
    "    # max_value = result[pred]\n",
    "    ia = sentiment_data[id][\"image_agreement\"]    \n",
    "\n",
    "    label = Counter(sentiment)\n",
    "    counter = Counter(sentiment)\n",
    "    # print(sentiment)\n",
    "    # print(label)\n",
    "    # print(counter)\n",
    "    most_common_sentiment, frequency = counter.most_common(1)[0]\n",
    "    if (frequency >= 5): # 3 -> alpha3; 4 -> alpha4; 5 -> alpha5\n",
    "        data[\"text\"].append(caption)\n",
    "        data[\"target\"].append(sentiment_values[most_common_sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"][0], data[\"target\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_distribution(df):\n",
    "    \"\"\"\"\n",
    "    Plots the distribution of sentiments\n",
    "    Parameters:\n",
    "        df(dataframe): DataFrame containing the \"sentiment\" column.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    mapping = {0: \"Negative\", 1: \"Positive\"}\n",
    "    # mapping = {1: \"Negative\", 0: \"Neutral\", 2: \"Positive\"}\n",
    "    # mapping = {0: \"Negative\", 1: \"SlightlyNegative\", 2: \"Neutral\", 3: \"SlightlyPositive\", 4: \"Positive\"}\n",
    "    df[\"sentiment\"] = df[\"sentiment\"].map(mapping)\n",
    "    sentiment_counts = df[\"sentiment\"].value_counts()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sentiment_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "    plt.title(\"Sentiment Distribution\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiment_distribution(pd.DataFrame({\"sentiment\": data[\"target\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"][:5], data[\"target\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"../data/train/train.csv\", index=False)\n",
    "# # aug_train_df.to_csv(\"../data/train/aug_train.csv\", index=False)\n",
    "# val_df.to_csv(\"../data/validation/val.csv\", index=False)\n",
    "# test_df.to_csv(\"../data/test/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p5.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p3.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p2plus.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha3_p2neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p5.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p3.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p2plus.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha4_p2neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p5.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p3.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p2plus.csv\", index=False)\n",
    "# pd.DataFrame({\"text\": data[\"text\"], \"sentiment\": data[\"target\"]}).to_csv(\"../data/percept_dataset_alpha5_p2neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data to MiniGPT 4 classify sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/raw/image_caption_minigpt4_completed.csv\") # captioning data for miniGPT-4\n",
    "df = pd.read_csv(\"../data/raw/image_caption_gpt4_openai.csv\", delimiter=';') # captioning data for miniGPT-4\n",
    "df[\"url\"] = [\"https://drive.google.com/uc?export=view&id=\"+str(id) for id in df[\"id\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"../data/raw/dataset.json\")\n",
    "data_json = json.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia_calculation(sg):\n",
    "    \"\"\"\n",
    "    Calcula a métrica IA (Image Agreement) com base no vetor de sentimento agrupado (sg).\n",
    "\n",
    "    Parâmetros:\n",
    "    sg (list ou tuple): Vetor de sentimento agrupado, onde cada elemento representa o número de votos para uma categoria de sentimento.\n",
    "\n",
    "    Retorna:\n",
    "    float: A métrica IA.\n",
    "    \"\"\"\n",
    "    total_avaliadores = len(sg)\n",
    "    max_votos = max(sg)\n",
    "    IA = max_votos / total_avaliadores\n",
    "    return IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for approach in range(0, 4):\n",
    "    if approach == 0: ## P5\n",
    "        p = 'p5'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "            \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"SlightlyPositive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"SlightlyNegative\": \"SlightlyNegative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"Positive\": 4,\n",
    "            \"SlightlyPositive\": 3,\n",
    "            \"Neutral\": 2,\n",
    "            \"SlightlyNegative\": 1,\n",
    "            \"Negative\": 0\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 0,\n",
    "            \"SlightlyNegative\": 1,\n",
    "            \"Neutral\": 2,\n",
    "            \"SlightlyPositive\": 3,\n",
    "            \"Positive\": 4,\n",
    "        }\n",
    "    elif approach == 1: ## P3\n",
    "        p = 'p3'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Neutral\",\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"SlightlyPositive\": 2,\n",
    "            \"Positive\": 2,\n",
    "            \"Neutral\": 0,\n",
    "            \"Negative\": 1,\n",
    "            \"SlightlyNegative\": 1,\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Positive\": 2,\n",
    "        }\n",
    "    elif approach == 2: ## P2+\n",
    "        p = 'p2plus'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Positive\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Positive\",\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"SlightlyPositive\": 0,\n",
    "            \"Positive\": 0,\n",
    "            \"Neutral\": 0,\n",
    "            \"Negative\": 1,\n",
    "            \"SlightlyNegative\": 1,\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Positive\": 0,\n",
    "        }\n",
    "    elif approach == 3: ## P2-\n",
    "        p = 'p2neg'\n",
    "        sentiment_dict = {\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Negative\",\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        simple_sentiment = {\n",
    "            \"Positive\": \"Positive\",\n",
    "            \"SlightlyPositive\": \"Positive\",\n",
    "            \"Neutral\": \"Negative\",\n",
    "            \"SlightlyNegative\": \"Negative\",\n",
    "            \"Negative\": \"Negative\"\n",
    "        }\n",
    "        sentiment_idx = {\n",
    "            \"SlightlyPositive\": 1,\n",
    "            \"Positive\": 1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Negative\": 0,\n",
    "            \"SlightlyNegative\": 0,\n",
    "        }\n",
    "        sentiment_values = {\n",
    "            \"Negative\": 0,\n",
    "            \"Neutral\": 0,\n",
    "            \"Positive\": 1,\n",
    "        }\n",
    "\n",
    "    \n",
    "    sentiment_data = {}\n",
    "\n",
    "    for id, caption in tqdm(zip(df[\"id\"], df[\"caption\"]), total=len(df), desc=\"Create supervised dataset\"):\n",
    "        sentiment_data[id] = {\n",
    "            \"sparse sentiment\": [],\n",
    "            \"cluster sentiment\": [],\n",
    "            \"perceptions\": [],\n",
    "            \"caption\": caption,\n",
    "            \"image_agreement\": float,\n",
    "        }\n",
    "\n",
    "        \n",
    "    for samples in tqdm(data_json[\"tasks\"], desc=\"Image perceptions\"):\n",
    "        for sample in samples[\"images\"]:\n",
    "            id = sample[\"id\"]\n",
    "            sentiment = sample[\"sentiment\"]\n",
    "            # perceptions = ', '.join([str(per) for per in sample[\"perceptions\"]])\n",
    "            perceptions = [str(per) for per in sample[\"perceptions\"]]\n",
    "            \n",
    "            if id in sentiment_data:\n",
    "                # sentiment = [simple_sentiment[sent] for sent in sentiment]\n",
    "                sentiment_data[id][\"sparse sentiment\"].append(sentiment)\n",
    "                sentiment_data[id][\"cluster sentiment\"].append(simple_sentiment[sentiment])\n",
    "                for perception in perceptions:\n",
    "                    sentiment_data[id][\"perceptions\"].append(perception)\n",
    "\n",
    "    for id in tqdm(sentiment_data, desc=\"Image agreement calculation\"):\n",
    "        sentiment = sentiment_data[id][\"sparse sentiment\"]\n",
    "        sg = [0 for _ in range(len(sentiment))]\n",
    "        counter = Counter(sentiment)\n",
    "        for key in counter:\n",
    "            # if p == 'p3':\n",
    "            #     print(sg)\n",
    "            #     print(key)\n",
    "            #     print(sentiment_idx)\n",
    "            sg[sentiment_idx[key]] = counter[key]\n",
    "        sentiment_data[id][\"image_agreement\"] = ia_calculation(sg)\n",
    "    \n",
    "    for f in range(3, 6):\n",
    "    \n",
    "        data = {\n",
    "            \"text\": [],\n",
    "            \"target\": [],\n",
    "            \"id\": []\n",
    "        }\n",
    "        for id in tqdm(sentiment_data, desc=\"Generate datasets\"):\n",
    "            caption = sentiment_data[id][\"caption\"]\n",
    "            sentiment = list(sentiment_data[id][\"cluster sentiment\"])\n",
    "            unique_perceptions = list(set(sentiment_data[id][\"perceptions\"]))\n",
    "            ia = sentiment_data[id][\"image_agreement\"]    \n",
    "\n",
    "            label = Counter(sentiment)\n",
    "            counter = Counter(sentiment)\n",
    "            most_common_sentiment, frequency = counter.most_common(1)[0]\n",
    "            if (frequency >= f): # 3 -> alpha3; 4 -> alpha4; 5 -> alpha5\n",
    "                data[\"text\"].append(caption)\n",
    "                data[\"target\"].append(sentiment_values[most_common_sentiment])\n",
    "                data[\"id\"].append(id)\n",
    "\n",
    "        pd.DataFrame({\"id\": data[\"id\"], \n",
    "                      \"text\": data[\"text\"], \n",
    "                      \"sentiment\": data[\"target\"]}).to_csv(\n",
    "                          f\"../data/gpt4-openai-classify/percept_dataset_alpha{f}_{p}.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
