{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha5_p3.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha3_p2neg.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha4_p5.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha4_p3.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha3_p2plus.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha5_p5.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha3_p5.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha5_p2plus.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha5_p2neg.csv',\n",
       " '/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha4_p2plus.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_open_source = \"/home/neemias/PerceptSent-LLM-approach/data/\"\n",
    "data_path_open_ai = \"/home/neemias/PerceptSent-LLM-approach/data/gpt4-openai-classify/\"\n",
    "data_paths = [os.path.join(data_path_open_source, f) \n",
    "              for f in os.listdir(data_path_open_source) if f.endswith('.csv')] + [os.path.join(data_path_open_ai, f)\n",
    "                                                              for f in os.listdir(data_path_open_ai) if f.endswith('.csv')]\n",
    "del data_paths[6]\n",
    "data_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The image shows a group of people standing on ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The image shows a long stretch of train tracks...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This image shows a busy city street with tall ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The image shows a street with a small pothole ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This image shows a view of clouds from an airp...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  The image shows a group of people standing on ...          1\n",
       "1  The image shows a long stretch of train tracks...          4\n",
       "2  This image shows a busy city street with tall ...          2\n",
       "3  The image shows a street with a small pothole ...          1\n",
       "4  This image shows a view of clouds from an airp...          4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/neemias/PerceptSent-LLM-approach/data/percept_dataset_alpha5_p5.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "4    221\n",
       "0     87\n",
       "2     75\n",
       "1     44\n",
       "3     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(row):\n",
    "    return f\"{row['text']} - {row['sentiment']}\"\n",
    "\n",
    "def prepare_data(dataframe: pd.DataFrame):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "\n",
    "    # X_train, X_test = train_test_split(\n",
    "    #     dataframe,\n",
    "    #     test_size=0.2,\n",
    "    #     random_state=42\n",
    "    # )\n",
    "    for sentiment in [0, 1, 2, 3, 4]:\n",
    "        \n",
    "        train, test = train_test_split(df[df.sentiment == sentiment],\n",
    "                                       test_size=0.2,\n",
    "                                       random_state=42)\n",
    "        X_train.append(train)\n",
    "        X_test.append(test)\n",
    "\n",
    "    X_train = pd.concat(X_train)\n",
    "    X_test = pd.concat(X_test)\n",
    "\n",
    "\n",
    "    prompt = \"\"\"What is the sentiment of this description? Please choose an answer from \n",
    "        {\n",
    "            \"Positive\": 4,\n",
    "            \"SlightlyPositive\": 3,\n",
    "            \"Neutral\": 2,\n",
    "            \"SlightlyNegative\": 1,\n",
    "            \"Negative\": 0\n",
    "        }\n",
    "    \"\"\"\n",
    "    #         {Positive/SlightlyPositive/Neutral/SlightlyNegative/Negative}.\n",
    "    # sentiment = {\n",
    "    #     4: \"Positive\",\n",
    "    #     3: \"SlightlyPositive\",\n",
    "    #     2: \"Neutral\",\n",
    "    #     1: \"SlightlyNegative\",\n",
    "    #     0: \"Negative\",\n",
    "    # }\n",
    "    # X_train[\"sentiment\"] = X_train[\"sentiment\"].apply(lambda x: sentiment[x])\n",
    "    # X_test[\"sentiment\"] = X_test[\"sentiment\"].apply(lambda x: sentiment[x])\n",
    "    # print(len(X_train), len(X_test))\n",
    "    X_train[\"input\"] = X_train[\"text\"]\n",
    "    X_test[\"input\"] = X_test[\"text\"]\n",
    "\n",
    "    X_train[\"text\"] = X_train[[\"text\", \"sentiment\"]].apply(lambda x: prompt+x[\"text\"]+'='+str(x[\"sentiment\"]), axis=1)\n",
    "    # X_test[\"text\"] = X_test[[\"text\", \"sentiment\"]].apply(lambda x: prompt+x[\"text\"]+'='+str(x[\"sentiment\"]), axis=1)\n",
    "    # X_train[\"text\"] = X_train[[\"text\"]].apply(lambda x: prompt+x+'=', axis=1)\n",
    "    X_test[\"text\"] = X_test[[\"text\"]].apply(lambda x: prompt+x+'=', axis=1)\n",
    "\n",
    "    train_data = Dataset.from_pandas(X_train)#.iloc[0:500])\n",
    "    test_data = Dataset.from_pandas(X_test)\n",
    "\n",
    "    return train_data, test_data, X_test.drop([\"sentiment\"], axis=1), X_test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, X_test, y_test = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'sentiment', 'input', '__index_level_0__'],\n",
       "    num_rows: 354\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>What is the sentiment of this description? Ple...</td>\n",
       "      <td>The image shows a car that has crashed into a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the sentiment of this description? Ple...</td>\n",
       "      <td>The image shows a group of trash cans lined up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>What is the sentiment of this description? Ple...</td>\n",
       "      <td>The image shows a view of a densely populated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>What is the sentiment of this description? Ple...</td>\n",
       "      <td>The image shows a car that has been involved i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>What is the sentiment of this description? Ple...</td>\n",
       "      <td>The image shows a group of people standing in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "367  What is the sentiment of this description? Ple...   \n",
       "8    What is the sentiment of this description? Ple...   \n",
       "144  What is the sentiment of this description? Ple...   \n",
       "113  What is the sentiment of this description? Ple...   \n",
       "61   What is the sentiment of this description? Ple...   \n",
       "\n",
       "                                                 input  \n",
       "367  The image shows a car that has crashed into a ...  \n",
       "8    The image shows a group of trash cans lined up...  \n",
       "144  The image shows a view of a densely populated ...  \n",
       "113  The image shows a car that has been involved i...  \n",
       "61   The image shows a group of people standing in ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the sentiment of this description? Please choose an answer from \\n        {\\n            \"Positive\": 4,\\n            \"SlightlyPositive\": 3,\\n            \"Neutral\": 2,\\n            \"SlightlyNegative\": 1,\\n            \"Negative\": 0\\n        }\\n    The image shows a car that has crashed into a ditch on the side of a road. The car is upside down, with its wheels in the air and its roof crumpled. There is mud and debris all around the car, and it appears to have sustained significant damage. The image is taken from a low angle, looking up at the car from the bottom of the ditch.='"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_model(model_name=\"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"):\n",
    "# def init_model(model_name=\"meta-llama/Llama-3.2-1B\"):\n",
    "# def init_model(model_name=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "def init_model(model_name=\"nvidia/Llama3-ChatQA-1.5-8B\"):\n",
    "# def init_model(model_name=\"nvidia/NV-Embed-v2\"):\n",
    "    compute_dtype = getattr(torch, \"float16\")\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    #     bnb_4bit_compute_dtype=torch.float16,\n",
    "        llm_int8_enable_fp32_cpu_offload=True,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f506e3c0ad3349b8b1745edc34e8c9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraModel, LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metric computation function\n",
    "def compute_metrics(eval_pred):\n",
    "    f1_metric = evaluate.load(\"f1\", use_auth_token=False)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\"f1\": f1[\"f1\"]}\n",
    "\n",
    "def train(model, tokenizer, train_data, eval_data):\n",
    "    peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        # lora_alpha=2,\n",
    "        # lora_dropout=0.1,\n",
    "        # r=8,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    training_arguments = TrainingArguments(\n",
    "        output_dir=\"../logs/log\",\n",
    "        num_train_epochs=100,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=8,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        save_steps=0,\n",
    "        logging_steps=25,\n",
    "        learning_rate=2e-4,\n",
    "        weight_decay=0.001,\n",
    "        fp16=True,\n",
    "        bf16=False,\n",
    "        max_grad_norm=0.3,\n",
    "        max_steps=-1,\n",
    "        warmup_ratio=0.03,\n",
    "        group_by_length=True,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        report_to=\"tensorboard\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        gradient_checkpointing=True,\n",
    "        eval_accumulation_steps=2,\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=eval_data,\n",
    "        peft_config=peft_config,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_arguments,\n",
    "        # compute_metrics=compute_metrics,\n",
    "        packing=False,\n",
    "        max_seq_length=1064,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    output_dir = \"../logs/results/trained_model\"\n",
    "\n",
    "    trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neemias/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf3cff8b6d742ba81e31497cf6718e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/354 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbd7b4fce074f4aaae5b805126864bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neemias/anaconda3/lib/python3.11/site-packages/accelerate/utils/imports.py:313: UserWarning: Intel Extension for PyTorch 2.4 needs to work with PyTorch 2.4.*, but PyTorch 2.5.1 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n",
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1018' max='2300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1018/2300 47:53 < 1:00:26, 0.35 it/s, Epoch 44.22/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.433744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.645800</td>\n",
       "      <td>0.738938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.961700</td>\n",
       "      <td>0.590182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.543468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.513700</td>\n",
       "      <td>0.533871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.535290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.556756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.588780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>0.608576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.642707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.705847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.715779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.778374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.885298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.905954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.943554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>1.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>1.055877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>1.003919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>1.095538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>1.135326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>1.082242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>1.151103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>1.112138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>1.297712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>1.162759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>1.323464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>1.208580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>1.232273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>1.275449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>1.309642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>1.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>1.328322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>1.328710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>1.290446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>1.342025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>1.318807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>1.284804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>1.393807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.385279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>1.431969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.344671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>1.416272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>1.459313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, tokenizer, train_data, test_data)\n",
      "Cell \u001b[0;32mIn[30], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer, train_data, eval_data)\u001b[0m\n\u001b[1;32m     21\u001b[0m training_arguments \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     22\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../logs/log\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     eval_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     45\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     46\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     47\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1064\u001b[39m,\n\u001b[1;32m     56\u001b[0m )\n\u001b[0;32m---> 58\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     60\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../logs/results/trained_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(output_dir)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2123\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2124\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2125\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2126\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2127\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2479\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2474\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2477\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2479\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2480\u001b[0m ):\n\u001b[1;32m   2481\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, tokenizer, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def inference(pipe, prompt):\n",
    "    result = pipe(prompt)\n",
    "    # print(result)\n",
    "    # print()\n",
    "    answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "    return answer\n",
    "\n",
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    pipe = pipeline(task=\"text-generation\",\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_new_tokens=1,\n",
    "                    temperature=0.01,\n",
    "                    do_sample=True\n",
    "                    # device='cuda'\n",
    "                    )\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        answer = inference(pipe, prompt)\n",
    "        # print(answer)\n",
    "        y_pred.append(int(answer))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f71b7544d3947b89a5e024231102990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/neemias/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = {\n",
    "    \"Positive\": 4,\n",
    "    \"SlightlyPositive\": 3,\n",
    "    \"Neutral\": 2,\n",
    "    \"SlightlyNegative\": 1,\n",
    "    \"Negative\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "print(f\"{f1_score(y_true=[sentiment[v] for v in y_test.to_list()], y_pred=[sentiment[v] for v in y_pred], average='weighted'):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f1_score(y_test, y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        18\n",
      "           1       0.33      0.44      0.38         9\n",
      "           2       0.75      0.60      0.67        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.89      0.93      0.91        45\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.56      0.56      0.56        91\n",
      "weighted avg       0.76      0.77      0.76        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
